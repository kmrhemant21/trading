{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ca39af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 08:00:11 | INFO | Universe (18): ^CNXAUTO, ^NSEBANK, ^CNXIT, ^CNXMEDIA, ^CNXMETAL, ^CNXPHARMA, ^CNXFMCG, ^CNXREALTY, ^CNXENERGY, ^CNXINFRA, ^CNXPSUBANK, NIFTY_PVT_BANK.NS, NIFTY_FIN_SERVICE.NS, NIFTYFINSRV25_50.NS, NIFTY_HEALTHCARE.NS, NIFTY_OIL_AND_GAS.NS, NIFTY_CONSR_DURBL.NS, ^NSEI | Benchmark=^NSEI\n",
      "2025-11-23 08:00:11 | WARNING | Dropping short-history/illiquid symbols (NaNs>15%): NIFTY_PVT_BANK.NS, NIFTYFINSRV25_50.NS, NIFTY_HEALTHCARE.NS, NIFTY_OIL_AND_GAS.NS, NIFTY_CONSR_DURBL.NS\n",
      "2025-11-23 08:00:13 | INFO | Saved: outputs/india_sector_rotation/2025-11-23/sector_scores.csv\n",
      "2025-11-23 08:00:13 | INFO | Saved: outputs/india_sector_rotation/2025-11-23/returns_table.csv\n",
      "2025-11-23 08:00:13 | INFO | Saved: outputs/india_sector_rotation/2025-11-23/latest_prices.csv\n",
      "2025-11-23 08:00:13 | INFO | Saved: outputs/india_sector_rotation/2025-11-23/ta_scores.csv\n",
      "2025-11-23 08:00:13 | INFO | Saved: outputs/india_sector_rotation/2025-11-23/signals.csv\n",
      "2025-11-23 08:00:13 | WARNING | Failed to fetch constituents CSV for NIFTY_FIN_SERVICE.NS (niftyfinservice): 404 Client Error: Not Found for url: https://nsearchives.nseindia.com/content/indices/ind_niftyfinservicelist.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ INDIA: TOP SECTOR OUTPERFORMERS (Momentum) ================\n",
      "                     score_composite score_percentile  ret_1m   ret_3m   ret_6m   ret_1y sharpe rs_vs_bench\n",
      "^CNXPSUBANK                     1.00            8.33%   6.69%   17.95%   25.66%   29.05%   0.08      16.81%\n",
      "^CNXAUTO                        2.75           16.67%   1.13%    8.12%   17.38%   20.18%   0.45       7.76%\n",
      "^NSEBANK                        4.25           25.00%   1.48%    5.69%    7.15%   17.31%   0.36       1.42%\n",
      "^CNXINFRA                       4.40           33.33%   2.07%    5.48%    8.17%   14.57%   0.26       1.83%\n",
      "^CNXMETAL                       4.80           41.67%  -0.88%    6.79%   10.49%   14.88%   0.16       3.64%\n",
      "NIFTY_FIN_SERVICE.NS            6.05           50.00%   0.11%    4.07%    5.11%   18.82%   0.44      -0.40%\n",
      "^CNXIT                          7.10           58.33%   4.49%    3.35%   -0.44%  -12.99%   0.07      -3.54%\n",
      "^CNXENERGY                      7.65           66.67%   0.58%    2.88%    1.40%   -3.23%   0.29      -2.85%\n",
      "^CNXPHARMA                      7.70           75.00%   0.29%    2.78%    4.92%    3.81%   0.31      -1.14%\n",
      "^CNXFMCG                        9.80           83.33%  -1.95%   -2.05%   -0.17%   -0.50%   0.40      -6.10%\n",
      "^CNXREALTY                     10.50           91.67%  -3.39%   -0.90%   -3.08%   -4.37%   0.18      -6.99%\n",
      "^CNXMEDIA                      12.00          100.00%  -6.31%  -11.86%  -13.73%  -24.95%  -0.15     -17.79%\n",
      "==========================================================================\n",
      "\n",
      "Leaders (TA-weighted strong-now, momentum-aware):\n",
      "            leaders_score score_composite mom_rank rs_vs_bench rs_rank rs_momentum    adx adx_rank regime_bull breakout_20 breakout_55 dist_52w dist_rank bbw_pct\n",
      "symbol                                                                                                                                                           \n",
      "^CNXPSUBANK          1.60            1.00     1.00       0.17%    1.00        0.00  41.26     2.00           1           0           0   -0.02%      8.00    0.60\n",
      "^CNXAUTO             4.70            2.75     2.00       0.08%    2.00        0.00  12.48    12.00           1           0           0   -0.00%     12.00    0.65\n",
      "^CNXINFRA            4.80            4.40     4.00       0.02%    4.00        0.00  28.22     6.00           1           0           0   -0.00%     11.00    0.25\n",
      "^CNXMETAL            4.90            4.80     5.00       0.04%    3.00        0.00  25.03     7.00           0           0           0   -0.06%      4.00    0.42\n",
      "^NSEBANK             5.00            4.25     3.00       0.01%    5.00        0.00  19.76     9.00           1           0           0   -0.01%     10.00    0.26\n",
      "\n",
      "Next-Up (building strength / likely to boom, momentum-aware):\n",
      "                     nextup_score score_composite mom_rank rs_momentum rs_mom_rank ppo_slope ppo_slope_rank adx_rising di_plus_gt breakout_20 breakout_55 dist_52w bbw_pct squeeze_rank rs_vs_bench\n",
      "symbol                                                                                                                                                                                             \n",
      "^CNXPSUBANK                  2.90            1.00     1.00        0.00        2.00      0.00           1.00          0          1           0           0   -0.02%    0.60        10.00       0.17%\n",
      "^NSEBANK                     3.00            4.25     3.00        0.00        1.00      0.00           3.00          0          1           0           0   -0.01%    0.26         7.00       0.01%\n",
      "^CNXINFRA                    4.50            4.40     4.00        0.00        5.00      0.00           5.00          0          1           0           0   -0.00%    0.25         5.00       0.02%\n",
      "NIFTY_FIN_SERVICE.NS         4.60            6.05     6.00        0.00        4.00      0.00           4.00          0          0           0           0   -0.01%    0.16         4.00      -0.00%\n",
      "^CNXMETAL                    5.70            4.80     5.00        0.00        3.00      0.00           9.00          1          0           0           0   -0.06%    0.42         9.00       0.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 08:01:48 | INFO | Saved: outputs/india_sector_rotation/2025-11-23/index_top_constituents.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-weight stock by index (approx weight, from market cap):\n",
      "index_yahoo           index_name  top_stock top_weight_pct_est\n",
      "   ^CNXAUTO           NIFTY AUTO     MARUTI             19.97%\n",
      " ^CNXENERGY         NIFTY ENERGY   RELIANCE             34.70%\n",
      "   ^CNXFMCG           NIFTY FMCG HINDUNILVR             24.03%\n",
      "  ^CNXINFRA NIFTY INFRASTRUCTURE   RELIANCE             25.17%\n",
      "     ^CNXIT             NIFTY IT        TCS             37.27%\n",
      "  ^CNXMEDIA          NIFTY MEDIA      SUNTV             23.13%\n",
      "  ^CNXMETAL          NIFTY METAL   ADANIENT             15.69%\n",
      " ^CNXPHARMA         NIFTY PHARMA  SUNPHARMA             24.33%\n",
      "^CNXPSUBANK       NIFTY PSU BANK       SBIN             49.11%\n",
      " ^CNXREALTY         NIFTY REALTY        DLF             28.52%\n",
      "   ^NSEBANK           NIFTY BANK   HDFCBANK             31.30%\n",
      "      ^NSEI             NIFTY 50   RELIANCE             10.00%\n",
      "\n",
      "Benchmark snapshot (NIFTY 50):\n",
      "ret_1m ret_3m ret_6m ret_1y ret_ytd sharpe\n",
      " 0.77%  4.06%  5.93% 10.77%  10.25%   0.40\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception:\n",
    "    raise SystemExit(\"Please: pip install yfinance pandas numpy\")\n",
    "\n",
    "import requests  # for NSE index CSVs\n",
    "\n",
    "# =========================\n",
    "# LOGGING\n",
    "# =========================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"india_sector_scanner_ta\")\n",
    "\n",
    "# Columns we store as percentages (numeric*100)\n",
    "PCT_COLS = [\n",
    "    \"ret_1w\", \"ret_1m\", \"ret_3m\", \"ret_6m\", \"ret_1y\",\n",
    "    \"ret_ytd\", \"cagr\", \"vol_ann\", \"rs_vs_bench\"\n",
    "]\n",
    "\n",
    "# Common headers for NSE archive CSV\n",
    "NSE_HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"text/csv,application/json,application/xhtml+xml,text/html;q=0.9,*/*;q=0.8\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    start_date: str = \"2012-01-01\"\n",
    "    end_date: Optional[str] = None\n",
    "\n",
    "    symbols: List[str] = field(default_factory=lambda: [\n",
    "        # NSE sector indices (Yahoo caret tickers)\n",
    "        \"^CNXAUTO\",      # Nifty Auto\n",
    "        \"^NSEBANK\",      # Nifty Bank\n",
    "        \"^CNXIT\",        # Nifty IT\n",
    "        \"^CNXMEDIA\",     # Nifty Media\n",
    "        \"^CNXMETAL\",     # Nifty Metal\n",
    "        \"^CNXPHARMA\",    # Nifty Pharma\n",
    "        \"^CNXFMCG\",      # Nifty FMCG\n",
    "        \"^CNXREALTY\",    # Nifty Realty\n",
    "        \"^CNXENERGY\",    # Nifty Energy\n",
    "        \"^CNXINFRA\",     # Nifty Infrastructure\n",
    "        \"^CNXPSUBANK\",   # Nifty PSU Bank\n",
    "\n",
    "        # Additional NSE index symbols exposed with .NS on Yahoo\n",
    "        \"NIFTY_PVT_BANK.NS\",       # Nifty Private Bank\n",
    "        \"NIFTY_FIN_SERVICE.NS\",    # Nifty Financial Services\n",
    "        \"NIFTYFINSRV25_50.NS\",     # Nifty Financial Services 25/50\n",
    "        \"NIFTY_HEALTHCARE.NS\",     # Nifty Healthcare\n",
    "        \"NIFTY_OIL_AND_GAS.NS\",    # Nifty Oil & Gas\n",
    "        \"NIFTY_CONSR_DURBL.NS\",    # Nifty Consumer Durables\n",
    "    ])\n",
    "\n",
    "    symbols_path: Optional[str] = None\n",
    "    benchmark: str = \"^NSEI\"\n",
    "\n",
    "    lookbacks_days: Optional[Dict[str, int]] = None\n",
    "    composite_weights: Optional[Dict[str, float]] = None\n",
    "\n",
    "    risk_free_rate_annual: float = 0.06\n",
    "    trading_days_per_year: int = 252\n",
    "\n",
    "    out_root: str = \"outputs/india_sector_rotation\"\n",
    "    top_n: int = 5\n",
    "    save_latest_prices: bool = True\n",
    "\n",
    "    max_retries: int = 3\n",
    "    retry_sleep_sec: float = 2.5\n",
    "    threads: bool = True\n",
    "\n",
    "    tz_display: str = \"Asia/Kolkata\"\n",
    "\n",
    "    # TA Params\n",
    "    sma_fast: int = 50\n",
    "    sma_slow: int = 200\n",
    "    ema_fast: int = 12\n",
    "    ema_slow: int = 26\n",
    "    bb_len: int = 20\n",
    "    bb_k: float = 2.0\n",
    "    adx_len: int = 14\n",
    "    rrg_window: int = 63      # days for RS momentum slope\n",
    "    breakout_short: int = 20\n",
    "    breakout_long: int = 55\n",
    "    dist_52w_len: int = 252\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.lookbacks_days is None:\n",
    "            self.lookbacks_days = {\n",
    "                \"ret_1w\": 5,\n",
    "                \"ret_1m\": 21,\n",
    "                \"ret_3m\": 63,\n",
    "                \"ret_6m\": 126,\n",
    "                \"ret_1y\": 252,\n",
    "            }\n",
    "        if self.composite_weights is None:\n",
    "            self.composite_weights = {\n",
    "                \"ret_1m\": 0.25,\n",
    "                \"ret_3m\": 0.35,\n",
    "                \"ret_6m\": 0.25,\n",
    "                \"ret_1y\": 0.15,\n",
    "            }\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# =========================\n",
    "# INDEX NAME MAP (Yahoo -> Pretty name)\n",
    "# =========================\n",
    "INDEX_NAME_MAP: Dict[str, str] = {\n",
    "    \"^CNXAUTO\": \"NIFTY AUTO\",\n",
    "    \"^NSEBANK\": \"NIFTY BANK\",\n",
    "    \"^CNXIT\": \"NIFTY IT\",\n",
    "    \"^CNXMEDIA\": \"NIFTY MEDIA\",\n",
    "    \"^CNXMETAL\": \"NIFTY METAL\",\n",
    "    \"^CNXPHARMA\": \"NIFTY PHARMA\",\n",
    "    \"^CNXFMCG\": \"NIFTY FMCG\",\n",
    "    \"^CNXREALTY\": \"NIFTY REALTY\",\n",
    "    \"^CNXENERGY\": \"NIFTY ENERGY\",\n",
    "    \"^CNXINFRA\": \"NIFTY INFRASTRUCTURE\",\n",
    "    \"^CNXPSUBANK\": \"NIFTY PSU BANK\",\n",
    "\n",
    "    \"NIFTY_PVT_BANK.NS\": \"NIFTY PRIVATE BANK\",\n",
    "    \"NIFTY_FIN_SERVICE.NS\": \"NIFTY FINANCIAL SERVICES\",\n",
    "    \"NIFTYFINSRV25_50.NS\": \"NIFTY FINANCIAL SERVICES 25/50\",\n",
    "    \"NIFTY_HEALTHCARE.NS\": \"NIFTY HEALTHCARE INDEX\",\n",
    "    \"NIFTY_OIL_AND_GAS.NS\": \"NIFTY OIL & GAS\",\n",
    "    \"NIFTY_CONSR_DURBL.NS\": \"NIFTY CONSUMER DURABLES\",\n",
    "\n",
    "    \"^NSEI\": \"NIFTY 50\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# INDEX SLUG MAP (Yahoo -> archives slug for CSV)\n",
    "# =========================\n",
    "INDEX_SLUG_MAP: Dict[str, str] = {\n",
    "    \"^NSEI\": \"nifty50\",\n",
    "    \"^NSEBANK\": \"niftybank\",\n",
    "    \"^CNXAUTO\": \"niftyauto\",\n",
    "    \"^CNXFMCG\": \"niftyfmcg\",\n",
    "    \"^CNXIT\": \"niftyit\",\n",
    "    \"^CNXMEDIA\": \"niftymedia\",\n",
    "    \"^CNXMETAL\": \"niftymetal\",\n",
    "    \"^CNXPHARMA\": \"niftypharma\",\n",
    "    \"^CNXREALTY\": \"niftyrealty\",\n",
    "    \"^CNXENERGY\": \"niftyenergy\",\n",
    "    \"^CNXINFRA\": \"niftyinfra\",\n",
    "    \"^CNXPSUBANK\": \"niftypsubank\",\n",
    "    \"NIFTY_PVT_BANK.NS\": \"niftypvtbank\",\n",
    "    \"NIFTY_FIN_SERVICE.NS\": \"niftyfinservice\",\n",
    "    \"NIFTY_HEALTHCARE.NS\": \"niftyhealthcare\",\n",
    "    \"NIFTY_OIL_AND_GAS.NS\": \"niftyoilgas\",\n",
    "    \"NIFTY_CONSR_DURBL.NS\": \"niftyconsrdurbl\",\n",
    "    # NIFTYFINSRV25_50 is tricky; may not have CSV\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# UTILITIES\n",
    "# =========================\n",
    "def ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def today_folder(root: str, tz: str) -> str:\n",
    "    now = pd.Timestamp.now(tz)\n",
    "    d = os.path.join(root, now.strftime(\"%Y-%m-%d\"))\n",
    "    ensure_dir(d)\n",
    "    return d\n",
    "\n",
    "def read_symbols_from_file(path: str) -> List[str]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "def yahoo_download(tickers: List[str], start: str, end: Optional[str],\n",
    "                   max_retries: int, sleep_s: float, threads: bool) -> pd.DataFrame:\n",
    "    last_err = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            return yf.download(\n",
    "                tickers=tickers,\n",
    "                start=start if start else None,\n",
    "                end=end,\n",
    "                auto_adjust=False,\n",
    "                actions=False,\n",
    "                group_by=\"ticker\",\n",
    "                threads=threads,\n",
    "                progress=False,\n",
    "                multi_level_index=False,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            log.warning(f\"Download attempt {attempt}/{max_retries} failed: {e}\")\n",
    "            time.sleep(sleep_s)\n",
    "    raise RuntimeError(f\"Yahoo download failed after {max_retries} retries: {last_err}\")\n",
    "\n",
    "def extract_wide(download_df: pd.DataFrame, tickers: List[str]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Return dict with wide DataFrames: Adj Close, Close, High, Low (Date x Ticker).\"\"\"\n",
    "    out = {}\n",
    "    if isinstance(download_df.columns, pd.MultiIndex):\n",
    "        for field in [\"Adj Close\", \"Close\", \"High\", \"Low\"]:\n",
    "            frames = []\n",
    "            for t in tickers:\n",
    "                if (t, field) in download_df.columns:\n",
    "                    frames.append(download_df[(t, field)].rename(t))\n",
    "            out[field] = pd.concat(frames, axis=1).sort_index() if frames else pd.DataFrame()\n",
    "    else:\n",
    "        # Single ticker fallback\n",
    "        for field in [\"Adj Close\", \"Close\", \"High\", \"Low\"]:\n",
    "            if field in download_df.columns and len(tickers) == 1:\n",
    "                out[field] = download_df[field].to_frame(tickers[0])\n",
    "            else:\n",
    "                out[field] = pd.DataFrame()\n",
    "    # Clean & ffill\n",
    "    for k in out:\n",
    "        out[k] = out[k].dropna(how=\"all\", axis=1).ffill()\n",
    "    return out\n",
    "\n",
    "def ytd_anchor_idx(prices: pd.Series) -> Optional[pd.Timestamp]:\n",
    "    if prices.empty:\n",
    "        return None\n",
    "    idx = prices.index\n",
    "    this_year = idx[idx.year == idx[-1].year]\n",
    "    if len(this_year) == 0:\n",
    "        return None\n",
    "    first_this_year = this_year[0]\n",
    "    pos = idx.get_loc(first_this_year)\n",
    "    return idx[pos - 1] if pos > 0 else None\n",
    "\n",
    "# =========================\n",
    "# TOP CONSTITUENT (approx) VIA MARKET CAP\n",
    "# =========================\n",
    "def fetch_top_constituent_by_mcap(index_yahoo: str, timeout: float = 10.0) -> Optional[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Approximate biggest-weight stock for a given index:\n",
    "      1) Download index constituents CSV from NSE archives\n",
    "      2) For each 'Symbol', fetch market cap from Yahoo (SYMBOL.NS)\n",
    "      3) Compute weights from market cap and return (symbol, weight%)\n",
    "\n",
    "    Returns None if anything fails or no caps found.\n",
    "    \"\"\"\n",
    "    slug = INDEX_SLUG_MAP.get(index_yahoo)\n",
    "    if not slug:\n",
    "        log.debug(f\"No slug mapping for index {index_yahoo}, skipping.\")\n",
    "        return None\n",
    "\n",
    "    url = f\"https://nsearchives.nseindia.com/content/indices/ind_{slug}list.csv\"\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, headers=NSE_HEADERS, timeout=timeout)\n",
    "        resp.raise_for_status()\n",
    "        csv_text = resp.text\n",
    "        df = pd.read_csv(io.StringIO(csv_text))\n",
    "    except Exception as e:\n",
    "        log.warning(f\"Failed to fetch constituents CSV for {index_yahoo} ({slug}): {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"Symbol\" not in df.columns:\n",
    "        log.warning(f\"Constituents CSV for {index_yahoo} has no 'Symbol' column; columns={list(df.columns)}\")\n",
    "        return None\n",
    "\n",
    "    symbols = (\n",
    "        df[\"Symbol\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .tolist()\n",
    "    )\n",
    "    if not symbols:\n",
    "        return None\n",
    "\n",
    "    caps: Dict[str, float] = {}\n",
    "    for sym in symbols:\n",
    "        tkr = yf.Ticker(sym + \".NS\")\n",
    "        mc = None\n",
    "        try:\n",
    "            fast_info = getattr(tkr, \"fast_info\", None)\n",
    "            if fast_info is not None:\n",
    "                mc = fast_info.get(\"market_cap\") or fast_info.get(\"marketCap\")\n",
    "        except Exception:\n",
    "            mc = None\n",
    "\n",
    "        if mc is None:\n",
    "            try:\n",
    "                info = tkr.info\n",
    "                mc = info.get(\"marketCap\")\n",
    "            except Exception:\n",
    "                mc = None\n",
    "\n",
    "        if mc is not None and mc > 0:\n",
    "            caps[sym] = float(mc)\n",
    "\n",
    "    if not caps:\n",
    "        log.warning(f\"No market caps obtained for index {index_yahoo} ({slug})\")\n",
    "        return None\n",
    "\n",
    "    total_cap = sum(caps.values())\n",
    "    top_sym, top_cap = max(caps.items(), key=lambda kv: kv[1])\n",
    "    weight_pct = (top_cap / total_cap) * 100.0 if total_cap > 0 else float(\"nan\")\n",
    "    return top_sym, weight_pct\n",
    "\n",
    "# =========================\n",
    "# CORE METRICS\n",
    "# =========================\n",
    "def compute_returns_table(adj: pd.DataFrame, benchmark: str,\n",
    "                          lookbacks: Dict[str, int], rfr: float, tdpy: int) -> pd.DataFrame:\n",
    "    if adj.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    adj = adj.sort_index().dropna(how=\"all\")\n",
    "    latest_prices = adj.iloc[-1]\n",
    "\n",
    "    lr = np.log(adj / adj.shift(1))\n",
    "    vol_ann = lr.std(skipna=True) * math.sqrt(tdpy)\n",
    "\n",
    "    def col_cagr(col: pd.Series) -> float:\n",
    "        col = col.dropna()\n",
    "        if len(col) < 2:\n",
    "            return np.nan\n",
    "        start_val, end_val = col.iloc[0], col.iloc[-1]\n",
    "        years = (col.index[-1] - col.index[0]).days / 365.25\n",
    "        return (end_val / start_val) ** (1 / years) - 1 if years > 0 else np.nan\n",
    "\n",
    "    cagr = adj.apply(col_cagr, axis=0)\n",
    "\n",
    "    daily_excess = lr.sub(rfr / tdpy, axis=0)\n",
    "    sharpe = (daily_excess.mean(skipna=True) / daily_excess.std(skipna=True)) * math.sqrt(tdpy)\n",
    "\n",
    "    rets = {name: adj.iloc[-1] / adj.shift(n).iloc[-1] - 1 for name, n in lookbacks.items()}\n",
    "\n",
    "    ytd_vals: Dict[str, float] = {}\n",
    "    for t in adj.columns:\n",
    "        anchor = ytd_anchor_idx(adj[t])\n",
    "        ytd_vals[t] = adj[t].iloc[-1] / adj[t].loc[anchor] - 1 if anchor is not None else np.nan\n",
    "    ret_ytd = pd.Series(ytd_vals, name=\"ret_ytd\")\n",
    "\n",
    "    # RS vs benchmark (3M/6M blend)\n",
    "    if benchmark in adj.columns:\n",
    "        try:\n",
    "            b3 = adj[benchmark].iloc[-1] / adj[benchmark].shift(63).iloc[-1] - 1\n",
    "            b6 = adj[benchmark].iloc[-1] / adj[benchmark].shift(126).iloc[-1] - 1\n",
    "            base = 0.5 * b3 + 0.5 * b6\n",
    "        except Exception:\n",
    "            base = np.nan\n",
    "    else:\n",
    "        base = np.nan\n",
    "\n",
    "    rs_vals: Dict[str, float] = {}\n",
    "    for t in adj.columns:\n",
    "        try:\n",
    "            r3 = adj[t].iloc[-1] / adj[t].shift(63).iloc[-1] - 1\n",
    "            r6 = adj[t].iloc[-1] / adj[t].shift(126).iloc[-1] - 1\n",
    "            rs_vals[t] = 0.5 * r3 + 0.5 * r6 - base\n",
    "        except Exception:\n",
    "            rs_vals[t] = np.nan\n",
    "    rs_vs_bench = pd.Series(rs_vals, name=\"rs_vs_bench\")\n",
    "\n",
    "    out = pd.DataFrame(index=adj.columns)\n",
    "    out[\"price_latest\"] = latest_prices\n",
    "    for k, v in rets.items():\n",
    "        out[k] = v\n",
    "    out[\"ret_ytd\"] = ret_ytd\n",
    "    out[\"vol_ann\"] = vol_ann\n",
    "    out[\"cagr\"] = cagr\n",
    "    out[\"sharpe\"] = sharpe\n",
    "    out[\"rs_vs_bench\"] = rs_vs_bench\n",
    "    return out\n",
    "\n",
    "def rank_and_score(df: pd.DataFrame, weights: Dict[str, float]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    cols = [c for c in weights.keys() if c in df.columns]\n",
    "    if not cols:\n",
    "        raise ValueError(\"No ranking columns found; check composite_weights vs computed columns.\")\n",
    "    for c in cols:\n",
    "        df[f\"rank_{c}\"] = df[c].rank(ascending=False, method=\"min\")\n",
    "    sw = sum(weights[c] for c in cols)\n",
    "    norm_w = {c: weights[c] / sw for c in cols}\n",
    "    df[\"score_composite\"] = sum(norm_w[c] * df[f\"rank_{c}\"] for c in cols)\n",
    "    df[\"score_percentile\"] = (df[\"score_composite\"].rank(ascending=True) / len(df)) * 100.0\n",
    "    return df.sort_values([\"score_composite\", \"sharpe\"], ascending=[True, False])\n",
    "\n",
    "def to_percent_inplace(df: pd.DataFrame, cols: List[str]) -> None:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c] * 100.0\n",
    "\n",
    "# =========================\n",
    "# TA HELPERS\n",
    "# =========================\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "\n",
    "def sma(series: pd.Series, length: int) -> pd.Series:\n",
    "    return series.rolling(length, min_periods=length).mean()\n",
    "\n",
    "def bb_width(close: pd.Series, length: int, k: float) -> pd.Series:\n",
    "    ma = sma(close, length)\n",
    "    sd = close.rolling(length, min_periods=length).std()\n",
    "    upper = ma + k * sd\n",
    "    lower = ma - k * sd\n",
    "    return (upper - lower) / ma\n",
    "\n",
    "def pct_rank(series: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"Percentile rank of last value within a rolling window (0-1).\"\"\"\n",
    "    def pr(x):\n",
    "        if len(x) < 2:\n",
    "            return np.nan\n",
    "        return (x.rank(pct=True).iloc[-1])\n",
    "    return series.rolling(window).apply(pr, raw=False)\n",
    "\n",
    "def linear_slope(y: pd.Series) -> float:\n",
    "    \"\"\"Slope via linear regression over index 0..n-1 (nan-safe).\"\"\"\n",
    "    y = y.dropna()\n",
    "    n = len(y)\n",
    "    if n < 3:\n",
    "        return np.nan\n",
    "    x = np.arange(n, dtype=float)\n",
    "    num = (x - x.mean()) @ (y.values - y.mean())\n",
    "    den = ((x - x.mean()) ** 2).sum()\n",
    "    return float(num / den) if den != 0 else np.nan\n",
    "\n",
    "def true_range(h: pd.Series, l: pd.Series, c: pd.Series) -> pd.Series:\n",
    "    prev_c = c.shift(1)\n",
    "    return pd.concat([(h - l), (h - prev_c).abs(), (l - prev_c).abs()], axis=1).max(axis=1)\n",
    "\n",
    "def adx_series(h: pd.Series, l: pd.Series, c: pd.Series, n: int = 14) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
    "    \"\"\"Classic Welles Wilder ADX with DI+, DI- (nan-safe).\"\"\"\n",
    "    up = h.diff()\n",
    "    dn = -l.diff()\n",
    "    plus_dm = np.where((up > dn) & (up > 0), up, 0.0)\n",
    "    minus_dm = np.where((dn > up) & (dn > 0), dn, 0.0)\n",
    "\n",
    "    tr = true_range(h, l, c)\n",
    "    atr = tr.rolling(n, min_periods=n).mean()\n",
    "\n",
    "    plus_di = (pd.Series(plus_dm, index=h.index).rolling(n, min_periods=n).mean() / atr) * 100.0\n",
    "    minus_di = (pd.Series(minus_dm, index=h.index).rolling(n, min_periods=n).mean() / atr) * 100.0\n",
    "\n",
    "    dx = ((plus_di - minus_di).abs() / (plus_di + minus_di)) * 100.0\n",
    "    adx = dx.rolling(n, min_periods=n).mean()\n",
    "    return adx, plus_di, minus_di\n",
    "\n",
    "# =========================\n",
    "# TA PANEL\n",
    "# =========================\n",
    "def compute_ta_panel(close: pd.DataFrame, high: pd.DataFrame, low: pd.DataFrame,\n",
    "                     bench_close: pd.Series, cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a per-symbol table of TA metrics at the last date.\n",
    "    \"\"\"\n",
    "    # Align all\n",
    "    idx = close.index\n",
    "    bench_close = bench_close.reindex(idx).ffill()\n",
    "\n",
    "    rows = []\n",
    "    for t in close.columns:\n",
    "        cl = close[t].dropna()\n",
    "        if len(cl) < max(cfg.sma_slow, cfg.dist_52w_len) + 5:\n",
    "            continue\n",
    "\n",
    "        h = high[t].reindex(cl.index).ffill()\n",
    "        l = low[t].reindex(cl.index).ffill()\n",
    "\n",
    "        # MAs & regime\n",
    "        sma_f = sma(cl, cfg.sma_fast)\n",
    "        sma_s = sma(cl, cfg.sma_slow)\n",
    "        regime_bull = int((cl.iloc[-1] > sma_f.iloc[-1] > sma_s.iloc[-1]) if not np.isnan(sma_f.iloc[-1]) and not np.isnan(sma_s.iloc[-1]) else 0)\n",
    "        above_50 = int(cl.iloc[-1] > sma_f.iloc[-1]) if not np.isnan(sma_f.iloc[-1]) else 0\n",
    "        above_200 = int(cl.iloc[-1] > sma_s.iloc[-1]) if not np.isnan(sma_s.iloc[-1]) else 0\n",
    "\n",
    "        # PPO & slope\n",
    "        ema_f = ema(cl, cfg.ema_fast)\n",
    "        ema_s = ema(cl, cfg.ema_slow)\n",
    "        ppo = ((ema_f - ema_s) / ema_s).iloc[-1] if not np.isnan(ema_s.iloc[-1]) and ema_s.iloc[-1] != 0 else np.nan\n",
    "        ppo_slope = linear_slope(((ema_f - ema_s) / ema_s).dropna().tail(cfg.rrg_window))\n",
    "\n",
    "        # RS vs benchmark + RS momentum (slope)\n",
    "        rs_series = (cl / bench_close.reindex(cl.index)).dropna()\n",
    "        rs_level = (rs_series.iloc[-1] / rs_series.shift(63).iloc[-1] - 1) if len(rs_series) > 63 else np.nan\n",
    "        rs_momentum = linear_slope(rs_series.tail(cfg.rrg_window))  # slope of RS line\n",
    "\n",
    "        # Breakouts\n",
    "        hh20 = cl.rolling(cfg.breakout_short, min_periods=cfg.breakout_short).max()\n",
    "        hh55 = cl.rolling(cfg.breakout_long,  min_periods=cfg.breakout_long).max()\n",
    "        brk20 = int(cl.iloc[-1] > hh20.iloc[-1]) if not np.isnan(hh20.iloc[-1]) else 0\n",
    "        brk55 = int(cl.iloc[-1] > hh55.iloc[-1]) if not np.isnan(hh55.iloc[-1]) else 0\n",
    "\n",
    "        # Distance to 52W high\n",
    "        hh52 = cl.rolling(cfg.dist_52w_len, min_periods=cfg.dist_52w_len).max()\n",
    "        dist_52w = (cl.iloc[-1] / hh52.iloc[-1] - 1) if not np.isnan(hh52.iloc[-1]) and hh52.iloc[-1] != 0 else np.nan\n",
    "\n",
    "        # BB width (contraction percentile over ~6 months)\n",
    "        bbw = bb_width(cl, cfg.bb_len, cfg.bb_k)\n",
    "        bbw_pct = pct_rank(bbw, 126).iloc[-1]  # 0..1; low => contraction\n",
    "\n",
    "        # ADX & ADX rising\n",
    "        adx, di_p, di_m = adx_series(h, l, cl, n=cfg.adx_len)\n",
    "        adx_val = adx.iloc[-1] if len(adx.dropna()) else np.nan\n",
    "        adx_rising = int(adx.diff().iloc[-1] > 0) if not np.isnan(adx_val) else 0\n",
    "        di_plus_gt = int(di_p.iloc[-1] > di_m.iloc[-1]) if di_p.notna().iloc[-1] and di_m.notna().iloc[-1] else 0\n",
    "\n",
    "        # % bars above 50DMA in last month (stability)\n",
    "        last21 = cl.tail(21)\n",
    "        sma_f_last = sma_f.reindex(last21.index)\n",
    "        pct_above50_last21 = float((last21 > sma_f_last).mean()) if sma_f_last.notna().all() else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"symbol\": t,\n",
    "            \"ppo\": ppo,\n",
    "            \"ppo_slope\": ppo_slope,\n",
    "            \"rs_level_3m\": rs_level,       # ~3M RS change\n",
    "            \"rs_momentum\": rs_momentum,    # slope of RS line\n",
    "            \"regime_bull\": regime_bull,\n",
    "            \"above_50\": above_50,\n",
    "            \"above_200\": above_200,\n",
    "            \"breakout_20\": brk20,\n",
    "            \"breakout_55\": brk55,\n",
    "            \"dist_52w\": dist_52w,          # <= 0 close to high; negative means below high\n",
    "            \"bbw_pct\": bbw_pct,            # 0..1; lower => tighter\n",
    "            \"adx\": adx_val,\n",
    "            \"adx_rising\": adx_rising,\n",
    "            \"di_plus_gt\": di_plus_gt,\n",
    "            \"pct_above50_last21\": pct_above50_last21,\n",
    "        })\n",
    "\n",
    "    ta = pd.DataFrame(rows).set_index(\"symbol\").sort_index()\n",
    "    return ta\n",
    "\n",
    "# =========================\n",
    "# SIGNALS / SCORING\n",
    "# =========================\n",
    "def rank_series(s: pd.Series, ascending: bool) -> pd.Series:\n",
    "    return s.rank(ascending=ascending, method=\"min\")\n",
    "\n",
    "def build_signals(ta: pd.DataFrame, table: pd.DataFrame, benchmark: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build 'leaders' and 'next-up' composite scores.\n",
    "\n",
    "    Uses momentum rank (score_composite) so Leaders / Next-Up\n",
    "    are consistent with the main momentum table.\n",
    "    \"\"\"\n",
    "    # Join TA with RS/Sharpe and momentum score\n",
    "    df = ta.join(table[[\"rs_vs_bench\", \"sharpe\", \"score_composite\"]], how=\"left\")\n",
    "\n",
    "    # Guard: ensure all used columns exist\n",
    "    for col in [\n",
    "        \"ppo\", \"ppo_slope\", \"rs_level_3m\", \"rs_momentum\",\n",
    "        \"adx\", \"rs_vs_bench\", \"dist_52w\", \"bbw_pct\", \"score_composite\",\n",
    "        \"adx_rising\", \"di_plus_gt\", \"regime_bull\", \"breakout_20\", \"breakout_55\",\n",
    "    ]:\n",
    "        if col not in df:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # ---------- Common ranks ----------\n",
    "    # Momentum rank (1 = best momentum)\n",
    "    mom_rank = rank_series(df[\"score_composite\"], ascending=True)\n",
    "\n",
    "    # RS & ADX ranks (higher better => lower rank)\n",
    "    rs_rank   = rank_series(df[\"rs_vs_bench\"], ascending=False)\n",
    "    adx_rank  = rank_series(df[\"adx\"],         ascending=False)\n",
    "\n",
    "    # Distance to 52W high: closer to high better\n",
    "    dist_rank = rank_series(\n",
    "        -df[\"dist_52w\"].clip(lower=-20.0, upper=0.0),  # dist_52w is already in %\n",
    "        ascending=False,\n",
    "    )\n",
    "\n",
    "    # RS momentum & PPO slope for Next-Up\n",
    "    rs_mom_rank     = rank_series(df[\"rs_momentum\"], ascending=False)\n",
    "    ppo_slope_rank  = rank_series(df[\"ppo_slope\"],   ascending=False)\n",
    "\n",
    "    # Volatility contraction: lower bbw_pct better\n",
    "    squeeze_rank = rank_series(-df[\"bbw_pct\"], ascending=False)\n",
    "\n",
    "    # ---------- Leaders: momentum-heavy, TA-filtered ----------\n",
    "    leaders_score = (\n",
    "        mom_rank * 0.50 +      # main driver: same momentum rank as TOP table\n",
    "        rs_rank  * 0.20 +      # strong RS vs NIFTY\n",
    "        adx_rank * 0.20 +      # strong trend\n",
    "        dist_rank * 0.10       # closer to 52W high\n",
    "    )\n",
    "\n",
    "    # Small bonus: bullish regime & breakouts reduce score (better)\n",
    "    leaders_score = leaders_score - (\n",
    "        df[\"regime_bull\"].fillna(0) * 0.30 +\n",
    "        df[\"breakout_20\"].fillna(0) * 0.20 +\n",
    "        df[\"breakout_55\"].fillna(0) * 0.20\n",
    "    )\n",
    "\n",
    "    # ---------- Next-Up: improvement + some momentum ----------\n",
    "    nextup_score = (\n",
    "        mom_rank       * 0.30 +   # still respect overall momentum\n",
    "        rs_mom_rank    * 0.30 +   # RS improving\n",
    "        ppo_slope_rank * 0.20 +   # PPO (MACD) slope improving\n",
    "        squeeze_rank   * 0.20     # volatility contraction (squeeze)\n",
    "    )\n",
    "\n",
    "    # Bonus: ADX rising, DI+ > DI-, near breakouts\n",
    "    nextup_score = nextup_score - (\n",
    "        df[\"adx_rising\"].fillna(0) * 0.30 +\n",
    "        df[\"di_plus_gt\"].fillna(0) * 0.20 +\n",
    "        df[\"breakout_20\"].fillna(0) * 0.25 +\n",
    "        df[\"breakout_55\"].fillna(0) * 0.25\n",
    "    )\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"leaders_score\"] = leaders_score\n",
    "    out[\"nextup_score\"] = nextup_score\n",
    "\n",
    "    # Optional: keep ranks for debugging\n",
    "    out[\"mom_rank\"]       = mom_rank\n",
    "    out[\"rs_rank\"]        = rs_rank\n",
    "    out[\"adx_rank\"]       = adx_rank\n",
    "    out[\"dist_rank\"]      = dist_rank\n",
    "    out[\"rs_mom_rank\"]    = rs_mom_rank\n",
    "    out[\"ppo_slope_rank\"] = ppo_slope_rank\n",
    "    out[\"squeeze_rank\"]   = squeeze_rank\n",
    "\n",
    "    # Lower score = better â‡’ sort ascending\n",
    "    out = out.sort_values([\"leaders_score\", \"nextup_score\"], ascending=[True, True])\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    # ===== Universe =====\n",
    "    symbols = CFG.symbols\n",
    "    if CFG.symbols_path:\n",
    "        symbols = read_symbols_from_file(CFG.symbols_path)\n",
    "    symbols = list(dict.fromkeys([s.strip().upper() for s in symbols if s.strip()]))\n",
    "    if CFG.benchmark.upper() not in symbols:\n",
    "        symbols.append(CFG.benchmark.upper())\n",
    "\n",
    "    log.info(f\"Universe ({len(symbols)}): {', '.join(symbols)} | Benchmark={CFG.benchmark}\")\n",
    "\n",
    "    # ===== Download =====\n",
    "    dl = yahoo_download(\n",
    "        tickers=symbols,\n",
    "        start=CFG.start_date,\n",
    "        end=CFG.end_date,\n",
    "        max_retries=CFG.max_retries,\n",
    "        sleep_s=CFG.retry_sleep_sec,\n",
    "        threads=CFG.threads,\n",
    "    )\n",
    "    wide = extract_wide(dl, tickers=symbols)\n",
    "    adj, close, high, low = wide[\"Adj Close\"], wide[\"Close\"], wide[\"High\"], wide[\"Low\"]\n",
    "    if adj.empty or close.empty:\n",
    "        raise SystemExit(\"No data downloaded. Check tickers/date range.\")\n",
    "\n",
    "    # Drop short-history columns (>15% NaNs)\n",
    "    valid_frac = adj.notna().mean()\n",
    "    keep_cols = valid_frac[valid_frac > 0.85].index.tolist()\n",
    "    dropped = [c for c in adj.columns if c not in keep_cols]\n",
    "    if dropped:\n",
    "        log.warning(f\"Dropping short-history/illiquid symbols (NaNs>15%): {', '.join(dropped)}\")\n",
    "    adj = adj[keep_cols]\n",
    "    close = close[keep_cols]\n",
    "    high = high[keep_cols]\n",
    "    low = low[keep_cols]\n",
    "\n",
    "    # ===== CORE METRICS =====\n",
    "    table = compute_returns_table(\n",
    "        adj=adj,\n",
    "        benchmark=CFG.benchmark.upper(),\n",
    "        lookbacks=CFG.lookbacks_days,\n",
    "        rfr=CFG.risk_free_rate_annual,\n",
    "        tdpy=CFG.trading_days_per_year,\n",
    "    )\n",
    "    if table.empty or len(table) < 2:\n",
    "        raise SystemExit(\"Insufficient data after filtering; adjust universe or dates.\")\n",
    "\n",
    "    # ===== MOMENTUM RANKING (exclude benchmark) =====\n",
    "    rank_df = table.copy()\n",
    "    if CFG.benchmark.upper() in rank_df.index:\n",
    "        rank_df_no_bm = rank_df.drop(index=[CFG.benchmark.upper()])\n",
    "    else:\n",
    "        rank_df_no_bm = rank_df\n",
    "\n",
    "    ranked = rank_and_score(rank_df_no_bm, CFG.composite_weights)\n",
    "\n",
    "    # Propagate momentum score back into table so signals can use it\n",
    "    table[\"score_composite\"] = ranked[\"score_composite\"]\n",
    "\n",
    "    # ===== TA PANEL =====\n",
    "    bench_close = close[CFG.benchmark.upper()] if CFG.benchmark.upper() in close.columns else pd.Series(index=close.index, dtype=float)\n",
    "    ta = compute_ta_panel(\n",
    "        close.drop(columns=[CFG.benchmark.upper()], errors=\"ignore\"),\n",
    "        high.drop(columns=[CFG.benchmark.upper()], errors=\"ignore\"),\n",
    "        low.drop(columns=[CFG.benchmark.upper()], errors=\"ignore\"),\n",
    "        bench_close,\n",
    "        CFG,\n",
    "    )\n",
    "\n",
    "    # ===== SIGNALS =====\n",
    "    # IMPORTANT: pass full `table` (has score_composite), not rank_df_no_bm\n",
    "    signals = build_signals(ta, table, CFG.benchmark.upper())\n",
    "    leaders = signals.sort_values(\"leaders_score\", ascending=True).head(CFG.top_n)\n",
    "    nextup  = signals.sort_values(\"nextup_score\",  ascending=True).head(CFG.top_n)\n",
    "\n",
    "    # ===== Convert to % where applicable =====\n",
    "    to_percent_inplace(table, PCT_COLS)\n",
    "    to_percent_inplace(ranked, [c for c in PCT_COLS if c in ranked.columns])\n",
    "    if \"dist_52w\" in ta.columns:\n",
    "        ta[\"dist_52w\"] = ta[\"dist_52w\"] * 100.0\n",
    "\n",
    "    # ===== Outputs =====\n",
    "    out_dir = today_folder(CFG.out_root, CFG.tz_display)\n",
    "    returns_csv = os.path.join(out_dir, \"returns_table.csv\")\n",
    "    ranked_csv = os.path.join(out_dir, \"sector_scores.csv\")\n",
    "    latest_csv = os.path.join(out_dir, \"latest_prices.csv\")\n",
    "    ta_csv = os.path.join(out_dir, \"ta_scores.csv\")\n",
    "    sig_csv = os.path.join(out_dir, \"signals.csv\")\n",
    "\n",
    "    table.sort_index().to_csv(returns_csv, float_format=\"%.2f\")\n",
    "    ranked.to_csv(ranked_csv, float_format=\"%.2f\")\n",
    "    if CFG.save_latest_prices:\n",
    "        pd.DataFrame({\"price_latest\": adj.iloc[-1]}).sort_index().to_csv(latest_csv, float_format=\"%.2f\")\n",
    "    ta.to_csv(ta_csv, float_format=\"%.6f\")\n",
    "    signals.to_csv(sig_csv, float_format=\"%.6f\")\n",
    "\n",
    "    log.info(f\"Saved: {ranked_csv}\")\n",
    "    log.info(f\"Saved: {returns_csv}\")\n",
    "    if CFG.save_latest_prices:\n",
    "        log.info(f\"Saved: {latest_csv}\")\n",
    "    log.info(f\"Saved: {ta_csv}\")\n",
    "    log.info(f\"Saved: {sig_csv}\")\n",
    "\n",
    "    # ===== Console summary =====\n",
    "    print(\"\\n================ INDIA: TOP SECTOR OUTPERFORMERS (Momentum) ================\")\n",
    "    disp_cols = [\"score_composite\", \"score_percentile\", \"ret_1m\", \"ret_3m\", \"ret_6m\", \"ret_1y\", \"sharpe\", \"rs_vs_bench\"]\n",
    "    disp = ranked[disp_cols].copy().astype(object)\n",
    "    for c in [\"score_percentile\", \"ret_1m\", \"ret_3m\", \"ret_6m\", \"ret_1y\", \"rs_vs_bench\"]:\n",
    "        if c in disp.columns:\n",
    "            disp[c] = disp[c].map(lambda x: f\"{float(x):.2f}%\")\n",
    "    if \"sharpe\" in disp.columns:\n",
    "        disp[\"sharpe\"] = disp[\"sharpe\"].map(lambda x: f\"{float(x):.2f}\")\n",
    "    if \"score_composite\" in disp.columns:\n",
    "        disp[\"score_composite\"] = disp[\"score_composite\"].map(lambda x: f\"{float(x):.2f}\")\n",
    "    print(disp.to_string())\n",
    "    print(\"==========================================================================\\n\")\n",
    "\n",
    "    print(\"Leaders (TA-weighted strong-now, momentum-aware):\")\n",
    "    ld = leaders[[\n",
    "        \"leaders_score\",\"score_composite\",\"mom_rank\",\n",
    "        \"rs_vs_bench\",\"rs_rank\",\"rs_momentum\",\n",
    "        \"adx\",\"adx_rank\",\"regime_bull\",\"breakout_20\",\"breakout_55\",\n",
    "        \"dist_52w\",\"dist_rank\",\"bbw_pct\"\n",
    "    ]].copy().astype(object)\n",
    "    for c in [\"rs_vs_bench\", \"dist_52w\"]:\n",
    "        if c in ld.columns:\n",
    "            ld[c] = ld[c].map(lambda x: f\"{float(x):.2f}%\" if pd.notna(x) else \"nan\")\n",
    "    for c in [\"leaders_score\",\"score_composite\",\"mom_rank\",\"rs_rank\",\"adx_rank\",\"dist_rank\",\"bbw_pct\",\"adx\",\"rs_momentum\"]:\n",
    "        if c in ld.columns:\n",
    "            ld[c] = ld[c].map(lambda x: f\"{float(x):.2f}\" if pd.notna(x) else \"nan\")\n",
    "    print(ld.to_string())\n",
    "    print()\n",
    "\n",
    "    print(\"Next-Up (building strength / likely to boom, momentum-aware):\")\n",
    "    nu = nextup[[\n",
    "        \"nextup_score\",\"score_composite\",\"mom_rank\",\n",
    "        \"rs_momentum\",\"rs_mom_rank\",\"ppo_slope\",\"ppo_slope_rank\",\n",
    "        \"adx_rising\",\"di_plus_gt\",\"breakout_20\",\"breakout_55\",\n",
    "        \"dist_52w\",\"bbw_pct\",\"squeeze_rank\",\"rs_vs_bench\"\n",
    "    ]].copy().astype(object)\n",
    "    for c in [\"dist_52w\",\"rs_vs_bench\"]:\n",
    "        if c in nu.columns:\n",
    "            nu[c] = nu[c].map(lambda x: f\"{float(x):.2f}%\" if pd.notna(x) else \"nan\")\n",
    "    for c in [\"nextup_score\",\"score_composite\",\"mom_rank\",\"rs_mom_rank\",\"ppo_slope_rank\",\"squeeze_rank\",\"bbw_pct\",\"rs_momentum\",\"ppo_slope\"]:\n",
    "        if c in nu.columns:\n",
    "            nu[c] = nu[c].map(lambda x: f\"{float(x):.2f}\" if pd.notna(x) else \"nan\")\n",
    "    print(nu.to_string())\n",
    "\n",
    "    # ===== Top-weight stock for each index (approx via market cap) =====\n",
    "    index_rows = []\n",
    "    for sym in sorted(adj.columns):\n",
    "        pretty_name = INDEX_NAME_MAP.get(sym, sym)\n",
    "        top_const = fetch_top_constituent_by_mcap(sym)\n",
    "        if not top_const:\n",
    "            continue\n",
    "        top_symbol, top_weight = top_const\n",
    "        index_rows.append(\n",
    "            {\n",
    "                \"index_yahoo\": sym,\n",
    "                \"index_name\": pretty_name,\n",
    "                \"top_stock\": top_symbol,\n",
    "                \"top_weight_pct_est\": top_weight,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if index_rows:\n",
    "        idx_df = pd.DataFrame(index_rows)\n",
    "        top_constituents_csv = os.path.join(out_dir, \"index_top_constituents.csv\")\n",
    "        idx_df.to_csv(top_constituents_csv, index=False, float_format=\"%.2f\")\n",
    "        log.info(f\"Saved: {top_constituents_csv}\")\n",
    "\n",
    "        print(\"\\nTop-weight stock by index (approx weight, from market cap):\")\n",
    "        disp_idx = idx_df.copy()\n",
    "        disp_idx[\"top_weight_pct_est\"] = disp_idx[\"top_weight_pct_est\"].map(\n",
    "            lambda x: f\"{float(x):.2f}%\" if pd.notna(x) else \"nan\"\n",
    "        )\n",
    "        print(disp_idx.to_string(index=False))\n",
    "\n",
    "    # Benchmark snapshot\n",
    "    if CFG.benchmark.upper() in table.index:\n",
    "        bm = table.loc[CFG.benchmark.upper(), [\"ret_1m\",\"ret_3m\",\"ret_6m\",\"ret_1y\",\"ret_ytd\",\"sharpe\"]].copy()\n",
    "        bm_disp = bm.astype(object)\n",
    "        for c in [\"ret_1m\",\"ret_3m\",\"ret_6m\",\"ret_1y\",\"ret_ytd\"]:\n",
    "            if c in bm_disp.index:\n",
    "                bm_disp[c] = f\"{float(bm[c]):.2f}%\"\n",
    "        if \"sharpe\" in bm_disp.index:\n",
    "            bm_disp[\"sharpe\"] = f\"{float(bm['sharpe']):.2f}\"\n",
    "        print(\"\\nBenchmark snapshot (NIFTY 50):\")\n",
    "        print(pd.DataFrame(bm_disp).T.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
