{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7888514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 11:50:46,728 | INFO | RF AUC train=1.000, test=0.523\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_15071/801459373.py:358: UserWarning: direction has no effect if short_entries and short_exits are set\n",
      "  pf = vbt.Portfolio.from_signals(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved patterns: outputs/patterns.csv\n",
      "Saved trades: outputs/trades.csv\n",
      "\n",
      "=== BACKTEST STATS ===\n",
      "Start                         2022-11-04 00:00:00\n",
      "End                           2025-11-04 00:00:00\n",
      "Period                          741 days 00:00:00\n",
      "Start Value                               50000.0\n",
      "End Value                            54889.329486\n",
      "Total Return [%]                         9.778659\n",
      "Benchmark Return [%]                    24.400731\n",
      "Max Gross Exposure [%]                  83.064563\n",
      "Total Fees Paid                        100.084113\n",
      "Max Drawdown [%]                         2.945328\n",
      "Max Drawdown Duration           139 days 06:00:00\n",
      "Total Trades                                  2.0\n",
      "Total Closed Trades                           2.0\n",
      "Total Open Trades                             0.0\n",
      "Open Trade PnL                                0.0\n",
      "Win Rate [%]                                100.0\n",
      "Best Trade [%]                           6.975184\n",
      "Worst Trade [%]                          4.004598\n",
      "Avg Winning Trade [%]                    5.498083\n",
      "Avg Losing Trade [%]                          NaN\n",
      "Avg Winning Trade Duration       14 days 11:00:00\n",
      "Avg Losing Trade Duration                     NaT\n",
      "Profit Factor                                 inf\n",
      "Expectancy                            2748.352429\n",
      "Sharpe Ratio                                  inf\n",
      "Calmar Ratio                             2.290586\n",
      "Omega Ratio                                   inf\n",
      "Sortino Ratio                                 inf\n",
      "\n",
      "Top 10 trades by PnL:\n",
      " Exit Trade Id      ticker      size Entry Timestamp  Avg Entry Price  Entry Fees Exit Timestamp  Avg Exit Price  Exit Fees         pnl      ret Direction Status  Position Id\n",
      "             9 HDFCBANK.NS 61.760618      2024-01-08       809.172604   24.987500     2024-01-17      748.279297  23.107096 3712.713671 0.074291     Short Closed            9\n",
      "             0 RELIANCE.NS 42.305052      2023-11-21      1181.301293   24.987506     2023-12-19     1269.652710  26.856362 3685.867412 0.073754      Long Closed            0\n",
      "             8     INFY.NS 36.022244      2023-12-06      1388.725266   25.012500     2023-12-15     1486.039795  26.765244 3453.709949 0.069040      Long Closed            8\n",
      "             6     INFY.NS 35.236591      2022-12-12      1418.270002   24.987500     2023-01-06     1328.459106  23.405185 3116.237124 0.062356     Short Closed            6\n",
      "             2      TCS.NS 15.702817      2023-02-24      3182.550019   24.987500     2023-03-16     2982.397461  23.416021 3094.555434 0.061922     Short Closed            2\n",
      "             5      TCS.NS 12.075070      2024-08-14      4142.833077   25.012500     2024-08-30     4389.965332  26.504570 2932.622249 0.058623      Long Closed            5\n",
      "             7     INFY.NS 39.404484      2023-08-01      1269.525559   25.012500     2023-08-30     1333.239541  26.267808 2459.336300 0.049162      Long Closed            7\n",
      "             1 RELIANCE.NS 36.519493      2024-10-09      1368.447270   24.987500     2024-11-06     1320.737798  24.116337 1693.221887 0.033881     Short Closed            1\n",
      "             4      TCS.NS 12.425076      2024-07-12      4026.132177   25.012500     2024-08-12     4042.722257  25.115567  156.004937 0.003119      Long Closed            4\n",
      "             3      TCS.NS 13.608163      2024-05-21      3672.428004   24.987500     2024-06-19     3658.299916  24.891371  142.378466 0.002849     Short Closed            3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_15071/801459373.py:425: UserWarning: Object has multiple columns. Aggregating using <function mean at 0x10d2e8a40>. Pass column to select a single column/group.\n",
      "  stats = pf.stats()\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Chart + ML-Driven Pattern Trading (NSE) â€” Patched\n",
    "=================================================\n",
    "\n",
    "Fixes:\n",
    "- vectorbt `init_cash` dict TypeError -> use cash_sharing=False & scalar per-column pocket\n",
    "- Separate long_entries and short_entries (direction='both')\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, math, warnings, logging\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    import vectorbt as vbt\n",
    "except Exception:\n",
    "    print(\"Install deps: pip install yfinance vectorbt scikit-learn scipy\")\n",
    "    pass\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "@dataclass\n",
    "class CFG:\n",
    "    # Universe (append .NS automatically if not present)\n",
    "    tickers: List[str] = None\n",
    "    period: str = \"3y\"\n",
    "    interval: str = \"1d\"\n",
    "\n",
    "    # Pattern geometry params\n",
    "    peak_distance: int = 5\n",
    "    peak_prominence: float = 0.0\n",
    "    twin_tolerance: float = 0.025\n",
    "    hs_min_sep: int = 5\n",
    "\n",
    "    # Labeling (forward return)\n",
    "    fwd_horizon: int = 10\n",
    "    label_threshold: float = 0.02\n",
    "\n",
    "    # ML\n",
    "    train_ratio: float = 0.7\n",
    "    clf_n_estimators: int = 400\n",
    "    clf_max_depth: Optional[int] = None\n",
    "    proba_threshold: float = 0.55\n",
    "\n",
    "    # Backtest\n",
    "    capital_per_stock: float = 50_000.0  # per-column pocket (cash_sharing=False)\n",
    "    sl_pct: float = 0.03\n",
    "    tp_pct: float = 0.06\n",
    "    hold_max_bars: int = 20\n",
    "\n",
    "    # IO\n",
    "    out_dir: str = \"outputs\"\n",
    "\n",
    "CFG = CFG(\n",
    "    tickers=[\"RELIANCE\", \"TCS\", \"INFY\", \"HDFCBANK\", \"ICICIBANK\"],\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# UTILS\n",
    "# =========================\n",
    "def add_ns_suffix(t: str) -> str:\n",
    "    return t if t.endswith(\".NS\") else t + \".NS\"\n",
    "\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def rsi(series: pd.Series, length: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    roll_up = up.ewm(alpha=1/length, adjust=False).mean()\n",
    "    roll_down = down.ewm(alpha=1/length, adjust=False).mean()\n",
    "    rs = roll_up / (roll_down.replace(0, np.nan))\n",
    "    out = 100 - (100 / (1 + rs))\n",
    "    return out.fillna(50)\n",
    "\n",
    "def annualized_vol(returns: pd.Series, periods_per_year: int = 252) -> float:\n",
    "    return returns.std() * math.sqrt(periods_per_year)\n",
    "\n",
    "# =========================\n",
    "# DATA\n",
    "# =========================\n",
    "def fetch_data(cfg: CFG) -> Dict[str, pd.DataFrame]:\n",
    "    tickers = [add_ns_suffix(t) for t in cfg.tickers]\n",
    "    data = {}\n",
    "    for t in tickers:\n",
    "        df = yf.download(t, period=cfg.period, interval=cfg.interval, progress=False, multi_level_index=False)\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "        df = df.rename(columns=str.title)\n",
    "        df = df[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]].dropna().copy()\n",
    "        df[\"ret\"] = df[\"Close\"].pct_change()\n",
    "        df[\"ema20\"] = ema(df[\"Close\"], 20)\n",
    "        df[\"ema50\"] = ema(df[\"Close\"], 50)\n",
    "        df[\"rsi14\"] = rsi(df[\"Close\"], 14)\n",
    "        data[t] = df\n",
    "    return data\n",
    "\n",
    "# =========================\n",
    "# PATTERN DETECTORS\n",
    "# =========================\n",
    "def swing_points(series: pd.Series, distance: int, prominence: float=0.0):\n",
    "    peaks, _ = find_peaks(series.values, distance=distance, prominence=prominence)\n",
    "    troughs, _ = find_peaks((-series).values, distance=distance, prominence=prominence)\n",
    "    return peaks, troughs\n",
    "\n",
    "def detect_double_top(df: pd.DataFrame, cfg: CFG) -> List[Dict]:\n",
    "    out = []\n",
    "    peaks, _ = find_peaks(df[\"High\"].values, distance=cfg.peak_distance, prominence=cfg.peak_prominence)\n",
    "    for i in range(len(peaks)-1):\n",
    "        p1, p2 = peaks[i], peaks[i+1]\n",
    "        h1, h2 = df[\"High\"].iloc[p1], df[\"High\"].iloc[p2]\n",
    "        if abs(h1 - h2) / ((h1+h2)/2) <= cfg.twin_tolerance:\n",
    "            mid_low_idx = df[\"Low\"].iloc[p1:p2+1].idxmin()\n",
    "            neckline = df.loc[mid_low_idx, \"Low\"]\n",
    "            out.append(dict(\n",
    "                pattern=\"DoubleTop\",\n",
    "                p1=int(p1), p2=int(p2),\n",
    "                p1_ts=df.index[p1], p2_ts=df.index[p2],\n",
    "                neckline=float(neckline),\n",
    "                dir=\"short\"\n",
    "            ))\n",
    "    return out\n",
    "\n",
    "def detect_double_bottom(df: pd.DataFrame, cfg: CFG) -> List[Dict]:\n",
    "    out = []\n",
    "    troughs, _ = find_peaks((-df[\"Low\"]).values, distance=cfg.peak_distance, prominence=cfg.peak_prominence)\n",
    "    for i in range(len(troughs)-1):\n",
    "        t1, t2 = troughs[i], troughs[i+1]\n",
    "        l1, l2 = df[\"Low\"].iloc[t1], df[\"Low\"].iloc[t2]\n",
    "        if abs(l1 - l2) / ((l1+l2)/2) <= cfg.twin_tolerance:\n",
    "            mid_high_idx = df[\"High\"].iloc[t1:t2+1].idxmax()\n",
    "            neckline = df.loc[mid_high_idx, \"High\"]\n",
    "            out.append(dict(\n",
    "                pattern=\"DoubleBottom\",\n",
    "                t1=int(t1), t2=int(t2),\n",
    "                t1_ts=df.index[t1], t2_ts=df.index[t2],\n",
    "                neckline=float(neckline),\n",
    "                dir=\"long\"\n",
    "            ))\n",
    "    return out\n",
    "\n",
    "def detect_head_shoulders(df: pd.DataFrame, cfg: CFG) -> List[Dict]:\n",
    "    out = []\n",
    "    peaks, _ = find_peaks(df[\"High\"].values, distance=cfg.peak_distance, prominence=cfg.peak_prominence)\n",
    "    for i in range(0, len(peaks)-2):\n",
    "        L, H, R = peaks[i], peaks[i+1], peaks[i+2]\n",
    "        if H - L < cfg.hs_min_sep or R - H < cfg.hs_min_sep:\n",
    "            continue\n",
    "        hL, hH, hR = df[\"High\"].iloc[L], df[\"High\"].iloc[H], df[\"High\"].iloc[R]\n",
    "        if not (hH > hL and hH > hR):\n",
    "            continue\n",
    "        low_LH = df[\"Low\"].iloc[L:H+1].min()\n",
    "        low_HR = df[\"Low\"].iloc[H:R+1].min()\n",
    "        neckline = (low_LH + low_HR) / 2\n",
    "        out.append(dict(\n",
    "            pattern=\"HeadShoulders\",\n",
    "            L=int(L), H=int(H), R=int(R),\n",
    "            L_ts=df.index[L], H_ts=df.index[H], R_ts=df.index[R],\n",
    "            neckline=float(neckline),\n",
    "            dir=\"short\"\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# FEATURES + LABELS\n",
    "# =========================\n",
    "def window_features(df: pd.DataFrame, idxs: List[int]) -> Dict[str, float]:\n",
    "    lo, hi = min(idxs), max(idxs)\n",
    "    w = df.iloc[lo:hi+1]\n",
    "\n",
    "    hi_px = w[\"High\"].max()\n",
    "    lo_px = w[\"Low\"].min()\n",
    "    rng = (hi_px - lo_px) / lo_px if lo_px > 0 else 0\n",
    "\n",
    "    ret_w = w[\"Close\"].pct_change().dropna()\n",
    "    vol_ann = annualized_vol(ret_w) if len(ret_w) > 3 else 0\n",
    "    slope_close = (w[\"Close\"].iloc[-1] - w[\"Close\"].iloc[0]) / max(1, len(w)-1)\n",
    "    slope_ema20 = (w[\"ema20\"].iloc[-1] - w[\"ema20\"].iloc[0]) / max(1, len(w)-1)\n",
    "\n",
    "    rsi_end = w[\"rsi14\"].iloc[-1]\n",
    "\n",
    "    vol_mean = w[\"Volume\"].replace(0, np.nan).mean()\n",
    "    vol_last = w[\"Volume\"].iloc[-1] if not w.empty else np.nan\n",
    "    vol_rel = (vol_last / vol_mean) if vol_mean and not np.isnan(vol_mean) else 1.0\n",
    "\n",
    "    return dict(\n",
    "        win_len=len(w), win_range=rng, ann_vol=vol_ann,\n",
    "        slope_close=slope_close, slope_ema20=slope_ema20, rsi_end=rsi_end,\n",
    "        vol_rel=vol_rel\n",
    "    )\n",
    "\n",
    "def make_examples(ticker: str, df: pd.DataFrame, cfg: CFG) -> pd.DataFrame:\n",
    "    examples = []\n",
    "\n",
    "    dts = detect_double_top(df, cfg)\n",
    "    dbs = detect_double_bottom(df, cfg)\n",
    "    hss = detect_head_shoulders(df, cfg)\n",
    "\n",
    "    for p in dts:\n",
    "        lo, hi = p[\"p1\"], p[\"p2\"]\n",
    "        feats = window_features(df, [lo, hi])\n",
    "        entry_idx = p[\"p2\"] + 1\n",
    "        if entry_idx >= len(df):\n",
    "            continue\n",
    "        entry_ts = df.index[entry_idx]\n",
    "        entry_px = df[\"Close\"].iloc[entry_idx]\n",
    "        fwd_end = min(len(df)-1, entry_idx + cfg.fwd_horizon)\n",
    "        fwd_ret = (df[\"Close\"].iloc[fwd_end] - entry_px) / entry_px\n",
    "        y = 1 if fwd_ret <= -cfg.label_threshold else 0\n",
    "        examples.append(dict(\n",
    "            ticker=ticker, pattern=\"DoubleTop\", dir=\"short\",\n",
    "            entry_idx=entry_idx, entry_ts=entry_ts, entry_px=float(entry_px),\n",
    "            neckline=p[\"neckline\"], fwd_ret=float(fwd_ret), y=y, **feats\n",
    "        ))\n",
    "\n",
    "    for p in dbs:\n",
    "        lo, hi = p[\"t1\"], p[\"t2\"]\n",
    "        feats = window_features(df, [lo, hi])\n",
    "        entry_idx = p[\"t2\"] + 1\n",
    "        if entry_idx >= len(df):\n",
    "            continue\n",
    "        entry_ts = df.index[entry_idx]\n",
    "        entry_px = df[\"Close\"].iloc[entry_idx]\n",
    "        fwd_end = min(len(df)-1, entry_idx + cfg.fwd_horizon)\n",
    "        fwd_ret = (df[\"Close\"].iloc[fwd_end] - entry_px) / entry_px\n",
    "        y = 1 if fwd_ret >= cfg.label_threshold else 0\n",
    "        examples.append(dict(\n",
    "            ticker=ticker, pattern=\"DoubleBottom\", dir=\"long\",\n",
    "            entry_idx=entry_idx, entry_ts=entry_ts, entry_px=float(entry_px),\n",
    "            neckline=p[\"neckline\"], fwd_ret=float(fwd_ret), y=y, **feats\n",
    "        ))\n",
    "\n",
    "    for p in hss:\n",
    "        lo, hi = p[\"L\"], p[\"R\"]\n",
    "        feats = window_features(df, [lo, hi])\n",
    "        entry_idx = p[\"R\"] + 1\n",
    "        if entry_idx >= len(df):\n",
    "            continue\n",
    "        entry_ts = df.index[entry_idx]\n",
    "        entry_px = df[\"Close\"].iloc[entry_idx]\n",
    "        fwd_end = min(len(df)-1, entry_idx + cfg.fwd_horizon)\n",
    "        fwd_ret = (df[\"Close\"].iloc[fwd_end] - entry_px) / entry_px\n",
    "        y = 1 if fwd_ret <= -cfg.label_threshold else 0\n",
    "        examples.append(dict(\n",
    "            ticker=ticker, pattern=\"HeadShoulders\", dir=\"short\",\n",
    "            entry_idx=entry_idx, entry_ts=entry_ts, entry_px=float(entry_px),\n",
    "            neckline=p[\"neckline\"], fwd_ret=float(fwd_ret), y=y, **feats\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(examples)\n",
    "\n",
    "# =========================\n",
    "# ML TRAIN / SCORE\n",
    "# =========================\n",
    "FEATURES = [\n",
    "    \"win_len\",\"win_range\",\"ann_vol\",\"slope_close\",\"slope_ema20\",\"rsi_end\",\"vol_rel\"\n",
    "]\n",
    "\n",
    "def time_split(df: pd.DataFrame, ratio: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = df.sort_values(\"entry_ts\")\n",
    "    n = len(df)\n",
    "    k = int(n * ratio)\n",
    "    return df.iloc[:k].copy(), df.iloc[k:].copy()\n",
    "\n",
    "def train_and_score(df_all: pd.DataFrame, cfg: CFG) -> pd.DataFrame:\n",
    "    if df_all.empty:\n",
    "        return df_all\n",
    "    df_all = df_all.sort_values(\"entry_ts\")\n",
    "    train, test = time_split(df_all, cfg.train_ratio)\n",
    "\n",
    "    Xtr = train[FEATURES].values\n",
    "    ytr = train[\"y\"].values\n",
    "    Xte = test[FEATURES].values\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=cfg.clf_n_estimators,\n",
    "        max_depth=cfg.clf_max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(Xtr, ytr)\n",
    "    proba_tr = clf.predict_proba(Xtr)[:,1]\n",
    "    proba_te = clf.predict_proba(Xte)[:,1]\n",
    "\n",
    "    try:\n",
    "        auc_tr = roc_auc_score(ytr, proba_tr) if len(np.unique(ytr))>1 else np.nan\n",
    "        auc_te = roc_auc_score(test[\"y\"], proba_te) if len(np.unique(test[\"y\"]))>1 else np.nan\n",
    "        logging.info(f\"RF AUC train={auc_tr:.3f}, test={auc_te:.3f}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    train = train.copy(); test = test.copy()\n",
    "    train[\"ml_proba\"] = proba_tr\n",
    "    test[\"ml_proba\"] = proba_te\n",
    "    return pd.concat([train, test], axis=0).sort_values(\"entry_ts\")\n",
    "\n",
    "# =========================\n",
    "# SIGNALS + BACKTEST (vectorbt)\n",
    "# =========================\n",
    "def build_signals_and_backtest(raw_data: Dict[str,pd.DataFrame], scored: pd.DataFrame, cfg: CFG):\n",
    "    if not raw_data or scored.empty:\n",
    "        print(\"No data/signals to backtest.\")\n",
    "        return pd.DataFrame(), None\n",
    "\n",
    "    prices = pd.DataFrame({t: df[\"Close\"] for t, df in raw_data.items()}).dropna(how=\"all\")\n",
    "\n",
    "    # Build entry signals per ticker\n",
    "    long_entries_map, short_entries_map = {}, {}\n",
    "    for t, df in raw_data.items():\n",
    "        e_long = pd.Series(False, index=df.index)\n",
    "        e_short = pd.Series(False, index=df.index)\n",
    "\n",
    "        sub = scored[scored[\"ticker\"] == t]\n",
    "        for _, row in sub.iterrows():\n",
    "            ts = row[\"entry_ts\"]\n",
    "            if ts not in df.index or row[\"ml_proba\"] < cfg.proba_threshold:\n",
    "                continue\n",
    "            i = df.index.get_loc(ts)\n",
    "            if row[\"dir\"] == \"long\":\n",
    "                if df[\"Close\"].iloc[i] > row[\"neckline\"]:\n",
    "                    e_long.iloc[i] = True\n",
    "            else:\n",
    "                if df[\"Close\"].iloc[i] < row[\"neckline\"]:\n",
    "                    e_short.iloc[i] = True\n",
    "\n",
    "        long_entries_map[t] = e_long\n",
    "        short_entries_map[t] = e_short\n",
    "\n",
    "    long_entries  = pd.DataFrame({t: s.reindex(prices.index).fillna(False) for t,s in long_entries_map.items()})\n",
    "    short_entries = pd.DataFrame({t: s.reindex(prices.index).fillna(False) for t,s in short_entries_map.items()})\n",
    "\n",
    "    # --------- TIME-BASED EXITS (replace unsupported max_hold) ----------\n",
    "    hold_n = int(cfg.hold_max_bars)\n",
    "    # Each entry exits exactly N bars later if SL/TP hasn't closed it earlier\n",
    "    long_time_exits  = long_entries.shift(hold_n, fill_value=False)\n",
    "    short_time_exits = short_entries.shift(hold_n, fill_value=False)\n",
    "    # --------------------------------------------------------------------\n",
    "\n",
    "    # Stops\n",
    "    sl_stop = cfg.sl_pct\n",
    "    tp_stop = cfg.tp_pct\n",
    "\n",
    "    # Use independent cash pockets per column; invest full pocket value per trade\n",
    "    pf = vbt.Portfolio.from_signals(\n",
    "        close=prices,\n",
    "        entries=long_entries,\n",
    "        exits=long_time_exits,\n",
    "        short_entries=short_entries,\n",
    "        short_exits=short_time_exits,\n",
    "        direction='both',\n",
    "        sl_stop=sl_stop,\n",
    "        tp_stop=tp_stop,\n",
    "        freq=\"D\",\n",
    "        cash_sharing=False,\n",
    "        init_cash=cfg.capital_per_stock,\n",
    "        size_type='value',           # <-- invest by cash value\n",
    "        size=cfg.capital_per_stock,  # <-- deploy full pocket per entry\n",
    "        fees=0.0005,\n",
    "        slippage=0.0005,\n",
    "    )\n",
    "\n",
    "    trades = pf.trades.records_readable\n",
    "    if trades is None or trades.empty:\n",
    "        print(\"No trades triggered.\")\n",
    "        return pd.DataFrame(), pf\n",
    "\n",
    "    trades = trades.rename(columns={\n",
    "        \"Column\":\"ticker\",\"Entry Time\":\"entry_ts\",\"Exit Time\":\"exit_ts\",\n",
    "        \"Entry Price\":\"entry_px\",\"Exit Price\":\"exit_px\",\n",
    "        \"PnL\":\"pnl\",\"Return\":\"ret\",\"Size\":\"size\"\n",
    "    })\n",
    "    return trades, pf\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "    os.makedirs(CFG.out_dir, exist_ok=True)\n",
    "    data = fetch_data(CFG)\n",
    "    if not data:\n",
    "        print(\"No data fetched. Check tickers/period/interval.\")\n",
    "        return\n",
    "\n",
    "    # build dataset\n",
    "    ex_all = []\n",
    "    for t, df in data.items():\n",
    "        ex = make_examples(t, df, CFG)\n",
    "        if not ex.empty:\n",
    "            ex_all.append(ex)\n",
    "    if not ex_all:\n",
    "        print(\"No patterns detected.\")\n",
    "        return\n",
    "    df_all = pd.concat(ex_all, ignore_index=True).sort_values(\"entry_ts\")\n",
    "\n",
    "    scored = train_and_score(df_all, CFG)\n",
    "\n",
    "    patterns_path = os.path.join(CFG.out_dir, \"patterns.csv\")\n",
    "    scored.to_csv(patterns_path, index=False)\n",
    "    print(f\"Saved patterns: {patterns_path}\")\n",
    "\n",
    "    trades, pf = build_signals_and_backtest(data, scored, CFG)\n",
    "\n",
    "    trades_path = os.path.join(CFG.out_dir, \"trades.csv\")\n",
    "    (trades if trades is not None else pd.DataFrame()).to_csv(trades_path, index=False)\n",
    "    print(f\"Saved trades: {trades_path}\")\n",
    "\n",
    "    if pf is not None:\n",
    "        stats = pf.stats()\n",
    "        print(\"\\n=== BACKTEST STATS ===\")\n",
    "        print(stats.to_string())\n",
    "        if trades is not None and not trades.empty:\n",
    "            print(\"\\nTop 10 trades by PnL:\")\n",
    "            print(trades.sort_values(\"pnl\", ascending=False).head(10).to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
