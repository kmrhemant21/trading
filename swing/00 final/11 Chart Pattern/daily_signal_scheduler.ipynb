{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c33fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-13  BSE.NS        LONG   Falling Wedge             Break above wedge upper ~2384.18\n",
      "2025-10-13  CEATLTD.NS    LONG   Symmetrical Triangle (Up)  Upper trendline break ~3533.64\n",
      "Saved: signals/signals_2025-10-13.csv\n",
      "Plots: 2 files → signals/plots\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Daily Chart-Pattern Scanner (schedule-friendly) + Plot Export\n",
    "\n",
    "Scans the latest daily bar for breakout confirmations of BULLISH patterns\n",
    "(Tier-1 + selected Tier-2) and prints a concise line per hit:\n",
    "\n",
    "  YYYY-MM-DD  TICKER  LONG  <PatternName>  <reason>\n",
    "\n",
    "Also saves a PNG chart per hit with key levels annotated.\n",
    "\n",
    "Excluded: candlestick set (as requested).\n",
    "\n",
    "Patterns implemented:\n",
    "  Tier-1: Double Bottom, Ascending Triangle, Bullish Rectangle, Symmetrical Triangle (up-break)\n",
    "  Tier-2: Inverse H&S, Bullish Flag/Pennant, Falling Wedge, Cup & Handle, Ascending Channel\n",
    "\n",
    "Rules/filters:\n",
    "  • Trend filter: Close > MA200 AND MA200 slope > 0\n",
    "  • Volume confirmation: Volume > vol_confirm_mult × VOL_MA20\n",
    "  • Breakout must occur on the most recent bar\n",
    "\n",
    "Inputs (universe):\n",
    "  • Env var SCAN_TICKERS=\"RELIANCE.NS,TCS.NS,HDFCBANK.NS\" (comma/space sep), or\n",
    "  • File ./tickers.txt (one symbol per line), or\n",
    "  • Default list in DEFAULT_TICKERS below\n",
    "\n",
    "Outputs:\n",
    "  • Prints matches to stdout\n",
    "  • Writes CSV to ./signals/signals_YYYY-MM-DD.csv\n",
    "  • Saves pattern plots to ./signals/plots/<ticker>_<date>_<pattern>.png when SCAN_SAVE_PLOTS=1\n",
    "\n",
    "Scheduling (example, run Mon–Fri 18:30 IST after market close):\n",
    "  $ crontab -e\n",
    "  TZ=Asia/Kolkata\n",
    "  30 18 * * 1-5 /usr/bin/python3 /path/to/daily_pattern_scanner.py >> /path/to/scan.log 2>&1\n",
    "\n",
    "Dependencies:\n",
    "  pip install yfinance pandas numpy matplotlib\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, math, warnings, logging\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception:\n",
    "    yf = None\n",
    "\n",
    "# matplotlib + mplfinance for plot export\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # for headless servers\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import mplfinance as mpf\n",
    "except Exception:\n",
    "    mpf = None\n",
    "import matplotlib.dates as mdates\n",
    "try:\n",
    "    from mplfinance.original_flavor import candlestick_ohlc\n",
    "except Exception:\n",
    "    candlestick_ohlc = None\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# =========================\n",
    "# CONFIG (tune here)\n",
    "# =========================\n",
    "DEFAULT_TICKERS = ['360ONE.NS', '3MINDIA.NS', 'AADHARHFC.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ABB.NS', 'ABBOTINDIA.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'ABLBL.NS', 'ABREL.NS', 'ABSLAMC.NS', 'ACC.NS', 'ACE.NS', 'ACMESOLAR.NS', 'ADANIENSOL.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'AEGISLOG.NS', 'AEGISVOPAK.NS', 'AFCONS.NS', 'AFFLE.NS', 'AGARWALEYE.NS', 'AIAENG.NS', 'AIIL.NS', 'AJANTPHARM.NS', 'AKUMS.NS', 'AKZOINDIA.NS', 'ALKEM.NS', 'ALKYLAMINE.NS', 'ALOKINDS.NS', 'AMBER.NS', 'AMBUJACEM.NS', 'ANANDRATHI.NS', 'ANANTRAJ.NS', 'ANGELONE.NS', 'APARINDS.NS', 'APLAPOLLO.NS', 'APLLTD.NS', 'APOLLOHOSP.NS', 'APOLLOTYRE.NS', 'APTUS.NS', 'ARE&M.NS', 'ASAHIINDIA.NS', 'ASHOKLEY.NS', 'ASIANPAINT.NS', 'ASTERDM.NS', 'ASTRAL.NS', 'ASTRAZEN.NS', 'ATGL.NS', 'ATHERENERG.NS', 'ATUL.NS', 'AUBANK.NS', 'AUROPHARMA.NS', 'AWL.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJAJFINSV.NS', 'BAJAJHFL.NS', 'BAJAJHLDNG.NS', 'BAJFINANCE.NS', 'BALKRISIND.NS', 'BALRAMCHIN.NS', 'BANDHANBNK.NS', 'BANKBARODA.NS', 'BANKINDIA.NS', 'BASF.NS', 'BATAINDIA.NS', 'BAYERCROP.NS', 'BBTC.NS', 'BDL.NS', 'BEL.NS', 'BEML.NS', 'BERGEPAINT.NS', 'BHARATFORG.NS', 'BHARTIARTL.NS', 'BHARTIHEXA.NS', 'BHEL.NS', 'BIKAJI.NS', 'BIOCON.NS', 'BLS.NS', 'BLUEDART.NS', 'BLUEJET.NS', 'BLUESTARCO.NS', 'BOSCHLTD.NS', 'BPCL.NS', 'BRIGADE.NS', 'BRITANNIA.NS', 'BSE.NS', 'BSOFT.NS', 'CAMPUS.NS', 'CAMS.NS', 'CANBK.NS', 'CANFINHOME.NS', 'CAPLIPOINT.NS', 'CARBORUNIV.NS', 'CASTROLIND.NS', 'CCL.NS', 'CDSL.NS', 'CEATLTD.NS', 'CENTRALBK.NS', 'CENTURYPLY.NS', 'CERA.NS', 'CESC.NS', 'CGCL.NS', 'CGPOWER.NS', 'CHALET.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CHOICEIN.NS', 'CHOLAFIN.NS', 'CHOLAHLDNG.NS', 'CIPLA.NS', 'CLEAN.NS', 'COALINDIA.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COHANCE.NS', 'COLPAL.NS', 'CONCOR.NS', 'CONCORDBIO.NS', 'COROMANDEL.NS', 'CRAFTSMAN.NS', 'CREDITACC.NS', 'CRISIL.NS', 'CROMPTON.NS', 'CUB.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DALBHARAT.NS', 'DATAPATTNS.NS', 'DBREALTY.NS', 'DCMSHRIRAM.NS', 'DEEPAKFERT.NS', 'DEEPAKNTR.NS', 'DELHIVERY.NS', 'DEVYANI.NS', 'DIVISLAB.NS', 'DIXON.NS', 'DLF.NS', 'DMART.NS', 'DOMS.NS', 'DRREDDY.NS', 'ECLERX.NS', 'EICHERMOT.NS', 'EIDPARRY.NS', 'EIHOTEL.NS', 'ELECON.NS', 'ELGIEQUIP.NS', 'EMAMILTD.NS', 'EMCURE.NS', 'ENDURANCE.NS', 'ENGINERSIN.NS', 'ENRIN.NS', 'ERIS.NS', 'ESCORTS.NS', 'ETERNAL.NS', 'EXIDEIND.NS', 'FACT.NS', 'FEDERALBNK.NS', 'FINCABLES.NS', 'FINPIPE.NS', 'FIRSTCRY.NS', 'FIVESTAR.NS', 'FLUOROCHEM.NS', 'FORCEMOT.NS', 'FORTIS.NS', 'FSL.NS', 'GAIL.NS', 'GESHIP.NS', 'GICRE.NS', 'GILLETTE.NS', 'GLAND.NS', 'GLAXO.NS', 'GLENMARK.NS', 'GMDCLTD.NS', 'GMRAIRPORT.NS', 'GODFRYPHLP.NS', 'GODIGIT.NS', 'GODREJAGRO.NS', 'GODREJCP.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GPIL.NS', 'GRANULES.NS', 'GRAPHITE.NS', 'GRASIM.NS', 'GRAVITA.NS', 'GRSE.NS', 'GSPL.NS', 'GUJGASLTD.NS', 'GVT&D.NS', 'HAL.NS', 'HAPPSTMNDS.NS', 'HAVELLS.NS', 'HBLENGINE.NS', 'HCLTECH.NS', 'HDFCAMC.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEG.NS', 'HEROMOTOCO.NS', 'HEXT.NS', 'HFCL.NS', 'HINDALCO.NS', 'HINDCOPPER.NS', 'HINDPETRO.NS', 'HINDUNILVR.NS', 'HINDZINC.NS', 'HOMEFIRST.NS', 'HONASA.NS', 'HONAUT.NS', 'HSCL.NS', 'HUDCO.NS', 'HYUNDAI.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'IDBI.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFCI.NS', 'IGIL.NS', 'IGL.NS', 'IIFL.NS', 'IKS.NS', 'INDGN.NS', 'INDHOTEL.NS', 'INDIACEM.NS', 'INDIAMART.NS', 'INDIANB.NS', 'INDIGO.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INFY.NS', 'INOXINDIA.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'IOB.NS', 'IOC.NS', 'IPCALAB.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'IREDA.NS', 'IRFC.NS', 'ITC.NS', 'ITCHOTELS.NS', 'ITI.NS', 'J&KBANK.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JINDALSAW.NS', 'JINDALSTEL.NS', 'JIOFIN.NS', 'JKCEMENT.NS', 'JKTYRE.NS', 'JMFINANCIL.NS', 'JPPOWER.NS', 'JSL.NS', 'JSWENERGY.NS', 'JSWINFRA.NS', 'JSWSTEEL.NS', 'JUBLFOOD.NS', 'JUBLINGREA.NS', 'JUBLPHARMA.NS', 'JWL.NS', 'JYOTHYLAB.NS', 'JYOTICNC.NS', 'KAJARIACER.NS', 'KALYANKJIL.NS', 'KARURVYSYA.NS', 'KAYNES.NS', 'KEC.NS', 'KEI.NS', 'KFINTECH.NS', 'KIMS.NS', 'KIRLOSBROS.NS', 'KIRLOSENG.NS', 'KOTAKBANK.NS', 'KPIL.NS', 'KPITTECH.NS', 'KPRMILL.NS', 'KSB.NS', 'LALPATHLAB.NS', 'LATENTVIEW.NS', 'LAURUSLABS.NS', 'LEMONTREE.NS', 'LICHSGFIN.NS', 'LICI.NS', 'LINDEINDIA.NS', 'LLOYDSME.NS', 'LODHA.NS', 'LT.NS', 'LTF.NS', 'LTFOODS.NS', 'LTIM.NS', 'LTTS.NS', 'LUPIN.NS', 'M&M.NS', 'M&MFIN.NS', 'MAHABANK.NS', 'MAHSCOOTER.NS', 'MAHSEAMLES.NS', 'MANAPPURAM.NS', 'MANKIND.NS', 'MANYAVAR.NS', 'MAPMYINDIA.NS', 'MARICO.NS', 'MARUTI.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MCX.NS', 'MEDANTA.NS', 'METROPOLIS.NS', 'MFSL.NS', 'MGL.NS', 'MINDACORP.NS', 'MMTC.NS', 'MOTHERSON.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MRF.NS', 'MRPL.NS', 'MSUMI.NS', 'MUTHOOTFIN.NS', 'NAM-INDIA.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAUKRI.NS', 'NAVA.NS', 'NAVINFLUOR.NS', 'NBCC.NS', 'NCC.NS', 'NESTLEIND.NS', 'NETWEB.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NH.NS', 'NHPC.NS', 'NIACL.NS', 'NIVABUPA.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NSLNISP.NS', 'NTPC.NS', 'NTPCGREEN.NS', 'NUVAMA.NS', 'NUVOCO.NS', 'NYKAA.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLAELEC.NS', 'OLECTRA.NS', 'ONESOURCE.NS', 'ONGC.NS', 'PAGEIND.NS', 'PATANJALI.NS', 'PAYTM.NS', 'PCBL.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PFC.NS', 'PFIZER.NS', 'PGEL.NS', 'PGHH.NS', 'PHOENIXLTD.NS', 'PIDILITIND.NS', 'PIIND.NS', 'PNB.NS', 'PNBHOUSING.NS', 'POLICYBZR.NS', 'POLYCAB.NS', 'POLYMED.NS', 'POONAWALLA.NS', 'POWERGRID.NS', 'POWERINDIA.NS', 'PPLPHARMA.NS', 'PRAJIND.NS', 'PREMIERENE.NS', 'PRESTIGE.NS', 'PTCIL.NS', 'PVRINOX.NS', 'RADICO.NS', 'RAILTEL.NS', 'RAINBOW.NS', 'RAMCOCEM.NS', 'RBLBANK.NS', 'RCF.NS', 'RECLTD.NS', 'REDINGTON.NS', 'RELIANCE.NS', 'RELINFRA.NS', 'RHIM.NS', 'RITES.NS', 'RKFORGE.NS', 'RPOWER.NS', 'RRKABEL.NS', 'RVNL.NS', 'SAGILITY.NS', 'SAIL.NS', 'SAILIFE.NS', 'SAMMAANCAP.NS', 'SAPPHIRE.NS', 'SARDAEN.NS', 'SAREGAMA.NS', 'SBFC.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SBIN.NS', 'SCHAEFFLER.NS', 'SCHNEIDER.NS', 'SCI.NS', 'SHREECEM.NS', 'SHRIRAMFIN.NS', 'SHYAMMETL.NS', 'SIEMENS.NS', 'SIGNATURE.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SOBHA.NS', 'SOLARINDS.NS', 'SONACOMS.NS', 'SONATSOFTW.NS', 'SRF.NS', 'STARHEALTH.NS', 'SUMICHEM.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUNPHARMA.NS', 'SUNTV.NS', 'SUPREMEIND.NS', 'SUZLON.NS', 'SWANCORP.NS', 'SWIGGY.NS', 'SYNGENE.NS', 'SYRMA.NS', 'TARIL.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATACONSUM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TATATECH.NS', 'TBOTEK.NS', 'TCS.NS', 'TECHM.NS', 'TECHNOE.NS', 'TEJASNET.NS', 'THELEELA.NS', 'THERMAX.NS', 'TIINDIA.NS', 'TIMKEN.NS', 'TITAGARH.NS', 'TITAN.NS', 'TORNTPHARM.NS', 'TORNTPOWER.NS', 'TRENT.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'TRIVENI.NS', 'TTML.NS', 'TVSMOTOR.NS', 'UBL.NS', 'UCOBANK.NS', 'ULTRACEMCO.NS', 'UNIONBANK.NS', 'UNITDSPR.NS', 'UNOMINDA.NS', 'UPL.NS', 'USHAMART.NS', 'UTIAMC.NS', 'VBL.NS', 'VEDL.NS', 'VENTIVE.NS', 'VGUARD.NS', 'VIJAYA.NS', 'VMM.NS', 'VOLTAS.NS', 'VTL.NS', 'WAAREEENER.NS', 'WELCORP.NS', 'WELSPUNLIV.NS', 'WHIRLPOOL.NS', 'WIPRO.NS', 'WOCKPHARMA.NS', 'YESBANK.NS', 'ZEEL.NS', 'ZENSARTECH.NS', 'ZENTEC.NS', 'ZFCVINDIA.NS', 'ZYDUSLIFE.NS']\n",
    "START_DATE = os.environ.get(\"SCAN_START\", \"2015-01-01\")\n",
    "END_DATE = None  # None = up to latest\n",
    "\n",
    "# Detection knobs\n",
    "ZIGZAG_PCT = float(os.environ.get(\"ZIGZAG_PCT\", 4.0))        # 3–6 typical\n",
    "VOL_CONFIRM_MULT = float(os.environ.get(\"VOL_CONFIRM_MULT\", 1.2))  # 1.1–1.3 typical\n",
    "FLAT_STDEV_THRESH = float(os.environ.get(\"FLAT_STDEV_THRESH\", 0.015))  # ~1–2%\n",
    "SHOULDER_TOL = float(os.environ.get(\"SHOULDER_TOL\", 0.08))   # 5–8%\n",
    "MAX_FLAG_LEN = int(os.environ.get(\"MAX_FLAG_LEN\", 20))\n",
    "MIN_CUP_BARS = int(os.environ.get(\"MIN_CUP_BARS\", 30))\n",
    "MAX_HANDLE_DEPTH = float(os.environ.get(\"MAX_HANDLE_DEPTH\", 0.35))\n",
    "\n",
    "# Trend filter params\n",
    "MA_SHORT = 50\n",
    "MA_LONG = 200\n",
    "MA_LONG_SLOPE_LOOKBACK = 5  # MA200[t] > MA200[t-5]\n",
    "\n",
    "# Output dirs & plotting\n",
    "OUT_DIR = os.environ.get(\"SCAN_OUT_DIR\", \"signals\")\n",
    "SAVE_PLOTS = os.environ.get(\"SCAN_SAVE_PLOTS\", \"1\").strip() not in (\"0\", \"false\", \"False\", \"no\")\n",
    "PLOT_DIR = os.path.join(OUT_DIR, \"plots\")\n",
    "PLOT_BARS = int(os.environ.get(\"SCAN_PLOT_BARS\", 240))\n",
    "PLOT_PAD_DAYS = int(os.environ.get(\"SCAN_PLOT_PAD_DAYS\", 7))  # right-side padding (axis extension) to avoid clipping\n",
    "\n",
    "# =========================\n",
    "# LOGGING\n",
    "# =========================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"daily_pattern_scanner\")\n",
    "\n",
    "# =========================\n",
    "# UTILITIES\n",
    "# =========================\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def parse_tickers() -> List[str]:\n",
    "    env = os.environ.get(\"SCAN_TICKERS\", \"\").strip()\n",
    "    if env:\n",
    "        if \",\" in env:\n",
    "            toks = [t.strip() for t in env.replace(\";\", \",\").split(\",\") if t.strip()]\n",
    "        else:\n",
    "            toks = [t.strip() for t in env.split() if t.strip()]\n",
    "        if toks:\n",
    "            return toks\n",
    "    if os.path.exists(\"tickers.txt\"):\n",
    "        with open(\"tickers.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [ln.strip() for ln in f if ln.strip() and not ln.startswith(\"#\")]\n",
    "        if lines:\n",
    "            return lines\n",
    "    return DEFAULT_TICKERS\n",
    "\n",
    "\n",
    "def rolling_slope(x: pd.Series, lookback: int = MA_LONG_SLOPE_LOOKBACK) -> pd.Series:\n",
    "    return x / x.shift(lookback) - 1.0\n",
    "\n",
    "\n",
    "def flat_enough(series: pd.Series, thresh: float) -> bool:\n",
    "    s = series.dropna()\n",
    "    if len(s) < 5:\n",
    "        return False\n",
    "    mu = s.mean()\n",
    "    if mu == 0:\n",
    "        return False\n",
    "    return (s.std() / abs(mu)) < thresh\n",
    "\n",
    "\n",
    "def vol_confirm_row(row: pd.Series) -> bool:\n",
    "    return row[\"Volume\"] > VOL_CONFIRM_MULT * max(1e-9, row[\"VOL_MA20\"])\n",
    "\n",
    "\n",
    "def trend_filter_row(row: pd.Series) -> bool:\n",
    "    return (row[\"Close\"] > row[\"MA200\"]) and (row[\"MA200_slope\"] > 0)\n",
    "\n",
    "# =========================\n",
    "# DATA\n",
    "# =========================\n",
    "\n",
    "def load_ohlcv(ticker: str, start: str, end: Optional[str] = None) -> pd.DataFrame:\n",
    "    if yf is None:\n",
    "        raise RuntimeError(\"yfinance is not available. pip install yfinance\")\n",
    "    df = yf.download(ticker, start=start, end=end, auto_adjust=False, progress=False, multi_level_index=False)\n",
    "    df = df.dropna()\n",
    "    if df.empty:\n",
    "        return df\n",
    "    # Indicators\n",
    "    df[\"MA50\"] = df[\"Close\"].rolling(MA_SHORT).mean()\n",
    "    df[\"MA200\"] = df[\"Close\"].rolling(MA_LONG).mean()\n",
    "    df[\"MA200_slope\"] = rolling_slope(df[\"MA200\"], MA_LONG_SLOPE_LOOKBACK)\n",
    "    df[\"VOL_MA20\"] = df[\"Volume\"].rolling(20).mean()\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# ZIGZAG (percent swings)\n",
    "# =========================\n",
    "\n",
    "def zigzag_indices(close: pd.Series, pct_threshold: float) -> List[pd.Timestamp]:\n",
    "    p = pct_threshold / 100.0\n",
    "    idx = close.index\n",
    "    piv = [idx[0]]\n",
    "    last_px = close.iloc[0]\n",
    "    last_dir = 0  # +1 up, -1 down\n",
    "    for i in range(1, len(close)):\n",
    "        chg = (close.iloc[i] - last_px) / last_px\n",
    "        if last_dir >= 0 and chg >= p:\n",
    "            last_dir = +1; last_px = close.iloc[i]; piv.append(idx[i])\n",
    "        elif last_dir <= 0 and chg <= -p:\n",
    "            last_dir = -1; last_px = close.iloc[i]; piv.append(idx[i])\n",
    "        else:\n",
    "            if last_dir == +1 and close.iloc[i] > last_px:\n",
    "                last_px = close.iloc[i]; piv[-1] = idx[i]\n",
    "            elif last_dir == -1 and close.iloc[i] < last_px:\n",
    "                last_px = close.iloc[i]; piv[-1] = idx[i]\n",
    "    return sorted(set(piv))\n",
    "\n",
    "\n",
    "def recent_swings(df: pd.DataFrame, n_last: int = 12) -> pd.DataFrame:\n",
    "    zz = zigzag_indices(df[\"Close\"], ZIGZAG_PCT)\n",
    "    return df.loc[zz].tail(n_last)\n",
    "\n",
    "# =========================\n",
    "# PLOT UTIL\n",
    "# =========================\n",
    "\n",
    "def save_pattern_plot(ticker: str, df: pd.DataFrame, as_of: pd.Timestamp,\n",
    "                      pattern: str, reason: str, plot_info: Dict[str, Any],\n",
    "                      out_dir: str = PLOT_DIR, bars: int = PLOT_BARS) -> str:\n",
    "    \"\"\"\n",
    "    Robust candlestick plot with pattern overlays.\n",
    "    - Tries mplfinance; if it fails to render candles, falls back to Matplotlib candlesticks.\n",
    "    - No MAs/EMAs. Prevents right-edge clipping by extending x-limits.\n",
    "    \"\"\"\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    w = df.loc[:as_of].tail(bars).copy()\n",
    "    if w.empty:\n",
    "        return \"\"\n",
    "    cols = [c for c in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"] if c in w.columns]\n",
    "    w = w[cols].dropna(subset=[\"Open\", \"High\", \"Low\", \"Close\"])\n",
    "    if w.empty:\n",
    "        return \"\"\n",
    "\n",
    "    # ---- Build overlays data (we’ll draw them in both engines)\n",
    "    hlines = [(float(p), str(lbl)) for p, lbl in plot_info.get(\"hlines\", [])]\n",
    "    segments = [ (pd.to_datetime(x1), float(y1), pd.to_datetime(x2), float(y2))\n",
    "                 for (x1, y1), (x2, y2) in plot_info.get(\"segments\", []) ]\n",
    "    points   = [ (str(lbl), pd.to_datetime(x), float(y)) for lbl, x, y in plot_info.get(\"points\", []) ]\n",
    "\n",
    "    fig, ax = None, None\n",
    "    used_fallback = False\n",
    "\n",
    "    # ---- Try mplfinance first\n",
    "    try:\n",
    "        h_cfg = dict(hlines=[p for p,_ in hlines], colors='tab:blue', linewidths=1.8, linestyle='--', alpha=0.95) if hlines else None\n",
    "        a_cfg = dict(alines=[[(x1,y1),(x2,y2)] for x1,y1,x2,y2 in segments], colors='crimson', linewidths=2.0, linestyle='--', alpha=0.95) if segments else None\n",
    "\n",
    "        fig, axlist = mpf.plot(\n",
    "            w, type=\"candle\", style=\"yahoo\",\n",
    "            datetime_format=\"%Y-%m\", xrotation=0, volume=False,\n",
    "            figsize=(11, 5.5), tight_layout=False, returnfig=True,\n",
    "            hlines=h_cfg, alines=a_cfg\n",
    "        )\n",
    "        ax = axlist[0]\n",
    "\n",
    "        # Quick sanity check: if no candles landed (rare backend quirk), fall back\n",
    "        if not ax.collections and not ax.patches:\n",
    "            used_fallback = True\n",
    "            plt.close(fig)\n",
    "    except Exception:\n",
    "        used_fallback = True\n",
    "\n",
    "    # ---- Fallback: plain Matplotlib candlesticks\n",
    "    if used_fallback:\n",
    "        if candlestick_ohlc is None:\n",
    "            raise RuntimeError(\"mplfinance fallback not available. Install: pip install mplfinance\")\n",
    "        fig, ax = plt.subplots(figsize=(11, 5.5))\n",
    "        d = w.reset_index().rename(columns={w.index.name or \"index\": \"Date\"})\n",
    "        d[\"DateNum\"] = mdates.date2num(pd.to_datetime(d[\"Date\"]))\n",
    "        ohlc = d[[\"DateNum\", \"Open\", \"High\", \"Low\", \"Close\"]].values\n",
    "        candlestick_ohlc(ax, ohlc, width=0.6, colorup=\"tab:green\", colordown=\"tab:red\", alpha=0.9)\n",
    "        ax.xaxis_date()\n",
    "        ax.grid(True, linewidth=0.4)\n",
    "\n",
    "        # overlays\n",
    "        for price, _lbl in hlines:\n",
    "            ax.hlines(price, xmin=w.index[0], xmax=w.index[-1], colors='tab:blue', linestyles='--', linewidth=1.8, alpha=0.95)\n",
    "        for x1,y1,x2,y2 in segments:\n",
    "            ax.plot([x1, x2], [y1, y2], linestyle='--', linewidth=2.0, color='crimson', alpha=0.95)\n",
    "\n",
    "    # ---- Labels & layout (both engines)\n",
    "    # Right padding to avoid clipping\n",
    "    if PLOT_PAD_DAYS > 0:\n",
    "        ax.set_xlim(w.index[0], w.index[-1] + pd.Timedelta(days=PLOT_PAD_DAYS))\n",
    "\n",
    "    # Make sure hlines are visible within y-lims\n",
    "    if hlines:\n",
    "        ymin = min(w[\"Low\"].min(), min(p for p,_ in hlines)) * 0.98\n",
    "        ymax = max(w[\"High\"].max(), max(p for p,_ in hlines)) * 1.02\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    # annotate labels for hlines ~85% into the window\n",
    "    if hlines:\n",
    "        x_label = w.index[int(max(1, round(len(w) * 0.85))) - 1]\n",
    "        for price, label in hlines:\n",
    "            ax.text(pd.to_datetime(x_label), price, f\"{label}:{price:.2f}\",\n",
    "                    va=\"bottom\", ha=\"left\", fontsize=9, color=\"tab:blue\",\n",
    "                    backgroundcolor=\"white\", alpha=0.7, clip_on=False)\n",
    "\n",
    "    # points\n",
    "    for lbl, x, y in points:\n",
    "        ax.scatter([x], [y], s=28, color=\"black\", zorder=6)\n",
    "        ax.annotate(lbl, xy=(x, y), xytext=(4, 6), textcoords=\"offset points\", fontsize=9, color=\"black\")\n",
    "\n",
    "    title = f\"{ticker} | {pattern} @ {as_of.date()}  {reason}\"\n",
    "    fig.suptitle(title, fontsize=14, fontweight=\"bold\", y=0.97)\n",
    "    ax.margins(x=0.02, y=0.10)\n",
    "    plt.subplots_adjust(top=0.88, right=0.97, left=0.08, bottom=0.12)\n",
    "\n",
    "    fname = f\"{ticker.replace('.', '_')}_{as_of.date()}_{pattern.replace(' ', '_').replace('&','and').replace('/', '')}.png\"\n",
    "    path = os.path.join(out_dir, fname)\n",
    "    fig.savefig(path, dpi=190)\n",
    "    plt.close(fig)\n",
    "    return path\n",
    "\n",
    "# =========================\n",
    "# PATTERN DETECTORS (BULLISH)\n",
    "# Each returns (pattern_name, side, reason_str, plot_info) OR None\n",
    "# Breakout must be confirmed on the last bar of the window\n",
    "# =========================\n",
    "\n",
    "def detect_double_bottom(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    pts = recent_swings(win, 10)\n",
    "    if len(pts) < 4:\n",
    "        return None\n",
    "    lows = pts[\"Low\"]\n",
    "    two = lows.nsmallest(2)\n",
    "    if len(two) < 2:\n",
    "        return None\n",
    "    l1i, l2i = two.index[0], two.index[1]\n",
    "    if abs(win.loc[l1i, \"Low\"] / win.loc[l2i, \"Low\"] - 1) > 0.015:\n",
    "        return None\n",
    "    neckline = win.loc[min(l1i, l2i):max(l1i, l2i)][\"High\"].max()\n",
    "    t = win.index[-1]\n",
    "    row = win.loc[t]\n",
    "    if row[\"Close\"] > neckline and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        plot = {\n",
    "            \"hlines\": [(neckline, \"Neckline\")],\n",
    "            \"points\": [(\"B1\", l1i, win.loc[l1i, \"Low\"]), (\"B2\", l2i, win.loc[l2i, \"Low\"])]\n",
    "        }\n",
    "        return (\"Double Bottom\", \"long\", f\"Neckline break {neckline:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_ascending_triangle(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    w = win.tail(60)\n",
    "    H, L = w[\"High\"], w[\"Low\"]\n",
    "    top = H.rolling(5).max().dropna()\n",
    "    bot = L.rolling(5).min().dropna()\n",
    "    if len(top) < 10 or len(bot) < 10:\n",
    "        return None\n",
    "    t = w.index[-1]\n",
    "    row = w.loc[t]\n",
    "    if not (flat_enough(top, FLAT_STDEV_THRESH) and bot.iloc[-1] > bot.iloc[0] * 1.02):\n",
    "        return None\n",
    "    brk = top.mean()\n",
    "    if row[\"Close\"] > brk and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        # rising lows line (approx): straight line from first to last bot\n",
    "        x1, x2 = bot.index[0], bot.index[-1]\n",
    "        y1, y2 = bot.iloc[0], bot.iloc[-1]\n",
    "        plot = {\n",
    "            \"hlines\": [(brk, \"Flat Top\")],\n",
    "            \"segments\": [((x1, y1), (x2, y2))],\n",
    "        }\n",
    "        return (\"Ascending Triangle\", \"long\", f\"Breakout above flat top ~{brk:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_bullish_rectangle(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    w = win.tail(40)\n",
    "    H, L = w[\"High\"], w[\"Low\"]\n",
    "    top_series = H.rolling(10).max().dropna()\n",
    "    bot_series = L.rolling(10).min().dropna()\n",
    "    if top_series.empty or bot_series.empty:\n",
    "        return None\n",
    "    top = top_series.iloc[-1]\n",
    "    bot = bot_series.iloc[-1]\n",
    "    if not (flat_enough(top_series, FLAT_STDEV_THRESH) and flat_enough(bot_series, FLAT_STDEV_THRESH)):\n",
    "        return None\n",
    "    t = w.index[-1]\n",
    "    row = w.loc[t]\n",
    "    if row[\"Close\"] > top and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        plot = {\"hlines\": [(top, \"Range High\"), (bot, \"Range Low\")]} \n",
    "        return (\"Bullish Rectangle\", \"long\", f\"Range breakout above {top:.2f} (range low {bot:.2f})\", plot)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_sym_triangle_up(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    w = win.tail(60)\n",
    "    H, L = w[\"High\"], w[\"Low\"]\n",
    "    top = H.rolling(5).max().dropna()\n",
    "    bot = L.rolling(5).min().dropna()\n",
    "    if len(top) < 10 or len(bot) < 10:\n",
    "        return None\n",
    "    if not (top.iloc[-1] < top.iloc[0] * 0.995 and bot.iloc[-1] > bot.iloc[0] * 1.005):\n",
    "        return None\n",
    "    brk = top.iloc[-10:].mean()\n",
    "    t = w.index[-1]\n",
    "    row = w.loc[t]\n",
    "    if row[\"Close\"] > brk and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        # draw approximate converging lines\n",
    "        plot = {\n",
    "            \"hlines\": [(brk, \"Upper TL (~avg)\")],\n",
    "            \"segments\": [((top.index[0], top.iloc[0]), (top.index[-1], top.iloc[-1])),\n",
    "                          ((bot.index[0], bot.iloc[0]), (bot.index[-1], bot.iloc[-1]))],\n",
    "        }\n",
    "        return (\"Symmetrical Triangle (Up)\", \"long\", f\"Upper trendline break ~{brk:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "# ---- Tier-2 simplified ----\n",
    "\n",
    "def detect_inverse_hs(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    pts = recent_swings(win, 12)\n",
    "    if len(pts) < 5:\n",
    "        return None\n",
    "    lows = pts[\"Low\"]\n",
    "    mid_i = lows.idxmin()  # head\n",
    "    left = pts.loc[:mid_i]\n",
    "    right = pts.loc[mid_i:]\n",
    "    if len(left) < 2 or len(right) < 2:\n",
    "        return None\n",
    "    L1i = left[\"Low\"].iloc[:-1].idxmin()\n",
    "    L3i = right[\"Low\"].iloc[1:].idxmin()\n",
    "    if abs(win.loc[L1i, \"Low\"] / win.loc[L3i, \"Low\"] - 1) > SHOULDER_TOL:\n",
    "        return None\n",
    "    nl = np.mean([\n",
    "        win.loc[min(L1i, mid_i):max(L1i, mid_i)][\"High\"].max(),\n",
    "        win.loc[min(mid_i, L3i):max(mid_i, L3i)][\"High\"].max(),\n",
    "    ])\n",
    "    t = win.index[-1]\n",
    "    row = win.loc[t]\n",
    "    if row[\"Close\"] > nl and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        plot = {\"hlines\": [(nl, \"Neckline\")],\n",
    "                \"points\": [(\"LS\", L1i, win.loc[L1i, \"Low\"]), (\"H\", mid_i, win.loc[mid_i, \"Low\"]), (\"RS\", L3i, win.loc[L3i, \"Low\"])]}\n",
    "        return (\"Inverse Head & Shoulders\", \"long\", f\"Neckline break {nl:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_flag_pennant(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    w = win.tail(40)\n",
    "    if len(w) < 25:\n",
    "        return None\n",
    "    ret20 = w[\"Close\"].iloc[-1] / w[\"Close\"].iloc[-21] - 1.0\n",
    "    atrp = (w[\"High\"] - w[\"Low\"]) / w[\"Close\"]\n",
    "    impulse = (ret20 > 0.1) and (atrp.rolling(10).mean().iloc[-1] > atrp.rolling(10).mean().iloc[-11])\n",
    "    if not impulse:\n",
    "        return None\n",
    "    cons = w.tail(MAX_FLAG_LEN)\n",
    "    H, L = cons[\"High\"], cons[\"Low\"]\n",
    "    top = H.rolling(5).max().dropna()\n",
    "    bot = L.rolling(5).min().dropna()\n",
    "    t = cons.index[-1]\n",
    "    row = cons.loc[t]\n",
    "    is_flag = (top.iloc[-1] <= top.iloc[0] * 1.01) and (bot.iloc[-1] <= bot.iloc[0] * 1.01)\n",
    "    is_penn = (top.iloc[-1] < top.iloc[0]) and (bot.iloc[-1] > bot.iloc[0])\n",
    "    brk = top.mean()\n",
    "    if (is_flag or is_penn) and row[\"Close\"] > brk and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        label = \"Bullish Flag\" if is_flag else \"Bullish Pennant\"\n",
    "        plot = {\"hlines\": [(brk, \"Break\")],\n",
    "                \"segments\": [((top.index[0], top.iloc[0]), (top.index[-1], top.iloc[-1])),\n",
    "                              ((bot.index[0], bot.iloc[0]), (bot.index[-1], bot.iloc[-1]))]}\n",
    "        return (label, \"long\", f\"Break above consolidation ~{brk:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_falling_wedge(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    w = win.tail(60)\n",
    "    H, L = w[\"High\"], w[\"Low\"]\n",
    "    down_top = H.iloc[-1] < H.iloc[0] * 0.98\n",
    "    down_bot = L.iloc[-1] < L.iloc[0] * 0.98\n",
    "    narrowing = (H.max() - L.min()) > 1.2 * (H.tail(10).max() - L.tail(10).min())\n",
    "    if not (down_top and down_bot and narrowing):\n",
    "        return None\n",
    "    upper_avg = H.rolling(5).max().dropna().mean()\n",
    "    t = w.index[-1]\n",
    "    row = w.loc[t]\n",
    "    if row[\"Close\"] > upper_avg and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        plot = {\"hlines\": [(upper_avg, \"Upper (avg)\")],\n",
    "                \"segments\": [((w.index[0], H.iloc[0]), (w.index[-1], H.iloc[-1])),\n",
    "                              ((w.index[0], L.iloc[0]), (w.index[-1], L.iloc[-1]))]}\n",
    "        return (\"Falling Wedge\", \"long\", f\"Break above wedge upper ~{upper_avg:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_cup_handle(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    w = win.tail(max(MIN_CUP_BARS + 10, 50))\n",
    "    if len(w) < MIN_CUP_BARS:\n",
    "        return None\n",
    "    hi_idx = w[\"High\"].idxmax()\n",
    "    lo_idx = w[\"Low\"].idxmin()\n",
    "    if not (hi_idx < lo_idx):\n",
    "        return None\n",
    "    rim_right = w.loc[lo_idx:][\"High\"].max()\n",
    "    cup_depth = (w.loc[hi_idx, \"High\"] - w.loc[lo_idx, \"Low\"]) / max(1e-9, w.loc[hi_idx, \"High\"])\n",
    "    if cup_depth < 0.1:\n",
    "        return None\n",
    "    handle = w.tail(12)\n",
    "    handle_depth = (rim_right - handle[\"Low\"].min()) / max(1e-9, rim_right)\n",
    "    if handle_depth > MAX_HANDLE_DEPTH:\n",
    "        return None\n",
    "    t = w.index[-1]\n",
    "    row = w.loc[t]\n",
    "    if row[\"Close\"] > rim_right and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        plot = {\"hlines\": [(rim_right, \"Rim\")], \"points\": [(\"Cup Low\", lo_idx, w.loc[lo_idx, \"Low\"]) ]}\n",
    "        return (\"Cup & Handle\", \"long\", f\"Rim breakout {rim_right:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_ascending_channel(win: pd.DataFrame) -> Optional[Tuple[str, str, str, Dict[str, Any]]]:\n",
    "    w = win.tail(60)\n",
    "    H, L = w[\"High\"], w[\"Low\"]\n",
    "    x = np.arange(len(w))\n",
    "    slope_H = np.polyfit(x, H.values, 1)[0]\n",
    "    slope_L = np.polyfit(x, L.values, 1)[0]\n",
    "    if not (slope_H > 0 and slope_L > 0):\n",
    "        return None\n",
    "    spread = (H - L)\n",
    "    if spread.std() / max(1e-9, spread.mean()) > 0.25:\n",
    "        return None\n",
    "    t = w.index[-1]\n",
    "    row = w.loc[t]\n",
    "    upper = H.rolling(5).max().iloc[-1]\n",
    "    lower = L.rolling(5).min().iloc[-1]\n",
    "    if row[\"Close\"] > upper and vol_confirm_row(row) and trend_filter_row(row):\n",
    "        plot = {\"segments\": [((w.index[0], upper), (w.index[-1], upper)), ((w.index[0], lower), (w.index[-1], lower))],\n",
    "                \"hlines\": [(upper, \"Upper\"), (lower, \"Lower\")]}\n",
    "        return (\"Ascending Channel\", \"long\", f\"Break above channel ~{upper:.2f}\", plot)\n",
    "    return None\n",
    "\n",
    "# Priority order\n",
    "DETECTORS = [\n",
    "    detect_double_bottom,\n",
    "    detect_ascending_triangle,\n",
    "    detect_bullish_rectangle,\n",
    "    detect_sym_triangle_up,\n",
    "    detect_inverse_hs,\n",
    "    detect_flag_pennant,\n",
    "    detect_falling_wedge,\n",
    "    detect_cup_handle,\n",
    "    detect_ascending_channel,\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# SCAN LOGIC\n",
    "# =========================\n",
    "\n",
    "def scan_ticker_lastbar(ticker: str) -> Optional[Tuple[pd.Timestamp, str, str, str, Dict[str, Any], pd.DataFrame]]:\n",
    "    df = load_ohlcv(ticker, START_DATE, END_DATE)\n",
    "    if df.empty or len(df) < 220:\n",
    "        return None\n",
    "    w = df.tail(250)\n",
    "    if math.isnan(w[\"MA200\"].iloc[-1]) or math.isnan(w[\"MA200_slope\"].iloc[-1]) or math.isnan(w[\"VOL_MA20\"].iloc[-1]):\n",
    "        return None\n",
    "    for det in DETECTORS:\n",
    "        out = det(w)\n",
    "        if out:\n",
    "            pattern, side, reason, plot_info = out\n",
    "            return (w.index[-1], pattern, side, reason, plot_info, df)\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "\n",
    "def main():\n",
    "    tickers = parse_tickers()\n",
    "    ensure_dir(OUT_DIR)\n",
    "    if SAVE_PLOTS:\n",
    "        ensure_dir(PLOT_DIR)\n",
    "\n",
    "    rows = []\n",
    "    hits = 0\n",
    "    saved_imgs = []\n",
    "\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            res = scan_ticker_lastbar(t)\n",
    "        except Exception as e:\n",
    "            log.warning(\"%s: scan error: %s\", t, e)\n",
    "            continue\n",
    "        if res is None:\n",
    "            continue\n",
    "        d, pattern, side, reason, plot_info, df = res\n",
    "        hits += 1\n",
    "        line = f\"{d.date()}  {t:<12}  {side.upper():<5}  {pattern:<24}  {reason}\"\n",
    "        print(line)\n",
    "        rows.append({\n",
    "            \"date\": d.date(),\n",
    "            \"ticker\": t,\n",
    "            \"side\": side,\n",
    "            \"pattern\": pattern,\n",
    "            \"reason\": reason,\n",
    "        })\n",
    "        if SAVE_PLOTS:\n",
    "            path = save_pattern_plot(t, df, d, pattern, reason, plot_info)\n",
    "            if path:\n",
    "                saved_imgs.append(path)\n",
    "\n",
    "    run_date = rows[0][\"date\"] if rows else pd.Timestamp.today().date()\n",
    "    out_path = os.path.join(OUT_DIR, f\"signals_{run_date}.csv\")\n",
    "    pd.DataFrame(rows).to_csv(out_path, index=False)\n",
    "\n",
    "    if hits == 0:\n",
    "        print(\"No breakouts today that passed trend & volume filters.\")\n",
    "    else:\n",
    "        print(f\"Saved: {out_path}\")\n",
    "        if SAVE_PLOTS:\n",
    "            print(f\"Plots: {len(saved_imgs)} files → {PLOT_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
