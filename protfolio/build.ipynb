{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04bbacc7",
   "metadata": {},
   "source": [
    "# Build optimized portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14de1e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: matplotlib in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: statsmodels in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: pandas_datareader in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (0.10.0)\n",
      "Requirement already satisfied: datetime in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (5.5)\n",
      "Requirement already satisfied: yfinance in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (0.2.65)\n",
      "Requirement already satisfied: scikit-learn in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: PyPortfolioOpt in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (1.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from statsmodels) (1.16.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: lxml in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas_datareader) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas_datareader) (2.32.4)\n",
      "Requirement already satisfied: zope.interface in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from datetime) (7.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (4.13.4)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (6.31.1)\n",
      "Requirement already satisfied: websockets>=13.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: cvxpy>=1.1.19 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from PyPortfolioOpt) (1.7.2)\n",
      "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from PyPortfolioOpt) (2.0.14)\n",
      "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from PyPortfolioOpt) (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (9.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
      "Requirement already satisfied: pycparser in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: osqp>=0.6.2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (1.0.4)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.11.1)\n",
      "Requirement already satisfied: scs>=3.2.4.post1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (3.2.8)\n",
      "Requirement already satisfied: jinja2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (80.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from requests>=2.19.0->pandas_datareader) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from requests>=2.19.0->pandas_datareader) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from requests>=2.19.0->pandas_datareader) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from jinja2->osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib statsmodels pandas_datareader datetime yfinance scikit-learn PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Load nifty500 stocks prices data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aeeb971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  500 of 500 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017-08-30</th>\n",
       "      <th>3MINDIA.NS</th>\n",
       "      <td>14062.560547</td>\n",
       "      <td>14099.103755</td>\n",
       "      <td>13745.531702</td>\n",
       "      <td>13939.017146</td>\n",
       "      <td>1945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AARTIIND.NS</th>\n",
       "      <td>199.474930</td>\n",
       "      <td>200.136137</td>\n",
       "      <td>194.539416</td>\n",
       "      <td>197.644772</td>\n",
       "      <td>102710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABB.NS</th>\n",
       "      <td>1184.403198</td>\n",
       "      <td>1197.884318</td>\n",
       "      <td>1176.850247</td>\n",
       "      <td>1190.023982</td>\n",
       "      <td>24289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBOTINDIA.NS</th>\n",
       "      <td>3978.401611</td>\n",
       "      <td>3991.379643</td>\n",
       "      <td>3941.100996</td>\n",
       "      <td>3968.131154</td>\n",
       "      <td>1083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABFRL.NS</th>\n",
       "      <td>167.077377</td>\n",
       "      <td>169.048798</td>\n",
       "      <td>166.091675</td>\n",
       "      <td>166.190247</td>\n",
       "      <td>155835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2025-08-26</th>\n",
       "      <th>ZEEL.NS</th>\n",
       "      <td>118.230003</td>\n",
       "      <td>120.790001</td>\n",
       "      <td>117.400002</td>\n",
       "      <td>120.099998</td>\n",
       "      <td>7159088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZENSARTECH.NS</th>\n",
       "      <td>804.549988</td>\n",
       "      <td>814.849976</td>\n",
       "      <td>796.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>312950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZENTEC.NS</th>\n",
       "      <td>1504.099976</td>\n",
       "      <td>1538.099976</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1538.099976</td>\n",
       "      <td>579088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZFCVINDIA.NS</th>\n",
       "      <td>14270.000000</td>\n",
       "      <td>14895.000000</td>\n",
       "      <td>14200.000000</td>\n",
       "      <td>14855.000000</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYDUSLIFE.NS</th>\n",
       "      <td>987.849976</td>\n",
       "      <td>1016.950012</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>2997316.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842020 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                            close          high           low  \\\n",
       "date       ticker                                                    \n",
       "2017-08-30 3MINDIA.NS     14062.560547  14099.103755  13745.531702   \n",
       "           AARTIIND.NS      199.474930    200.136137    194.539416   \n",
       "           ABB.NS          1184.403198   1197.884318   1176.850247   \n",
       "           ABBOTINDIA.NS   3978.401611   3991.379643   3941.100996   \n",
       "           ABFRL.NS         167.077377    169.048798    166.091675   \n",
       "...                                ...           ...           ...   \n",
       "2025-08-26 ZEEL.NS          118.230003    120.790001    117.400002   \n",
       "           ZENSARTECH.NS    804.549988    814.849976    796.000000   \n",
       "           ZENTEC.NS       1504.099976   1538.099976   1470.000000   \n",
       "           ZFCVINDIA.NS   14270.000000  14895.000000  14200.000000   \n",
       "           ZYDUSLIFE.NS     987.849976   1016.950012    982.000000   \n",
       "\n",
       "Price                             open     volume  \n",
       "date       ticker                                  \n",
       "2017-08-30 3MINDIA.NS     13939.017146     1945.0  \n",
       "           AARTIIND.NS      197.644772   102710.0  \n",
       "           ABB.NS          1190.023982    24289.0  \n",
       "           ABBOTINDIA.NS   3968.131154     1083.0  \n",
       "           ABFRL.NS         166.190247   155835.0  \n",
       "...                                ...        ...  \n",
       "2025-08-26 ZEEL.NS          120.099998  7159088.0  \n",
       "           ZENSARTECH.NS    804.000000   312950.0  \n",
       "           ZENTEC.NS       1538.099976   579088.0  \n",
       "           ZFCVINDIA.NS   14855.000000     9999.0  \n",
       "           ZYDUSLIFE.NS    1015.000000  2997316.0  \n",
       "\n",
       "[842020 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import talib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "base_nifty500 = ['360ONE', '3MINDIA', 'ABB', 'ACC', 'ACMESOLAR', 'AIAENG', 'APLAPOLLO', 'AUBANK', 'AWL', 'AADHARHFC', 'AARTIIND', 'AAVAS', 'ABBOTINDIA', 'ACE', 'ADANIENSOL', 'ADANIENT', 'ADANIGREEN', 'ADANIPORTS', 'ADANIPOWER', 'ATGL', 'ABCAPITAL', 'ABFRL', 'ABREL', 'ABSLAMC', 'AEGISLOG', 'AFCONS', 'AFFLE', 'AJANTPHARM', 'AKUMS', 'APLLTD', 'ALIVUS', 'ALKEM', 'ALKYLAMINE', 'ALOKINDS', 'ARE&M', 'AMBER', 'AMBUJACEM', 'ANANDRATHI', 'ANANTRAJ', 'ANGELONE', 'APARINDS', 'APOLLOHOSP', 'APOLLOTYRE', 'APTUS', 'ASAHIINDIA', 'ASHOKLEY', 'ASIANPAINT', 'ASTERDM', 'ASTRAZEN', 'ASTRAL', 'ATUL', 'AUROPHARMA', 'AIIL', 'DMART', 'AXISBANK', 'BASF', 'BEML', 'BLS', 'BSE', 'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV', 'BAJAJHLDNG', 'BAJAJHFL', 'BALKRISIND', 'BALRAMCHIN', 'BANDHANBNK', 'BANKBARODA', 'BANKINDIA', 'MAHABANK', 'BATAINDIA', 'BAYERCROP', 'BERGEPAINT', 'BDL', 'BEL', 'BHARATFORG', 'BHEL', 'BPCL', 'BHARTIARTL', 'BHARTIHEXA', 'BIKAJI', 'BIOCON', 'BSOFT', 'BLUEDART', 'BLUESTARCO', 'BBTC', 'BOSCHLTD', 'FIRSTCRY', 'BRIGADE', 'BRITANNIA', 'MAPMYINDIA', 'CCL', 'CESC', 'CGPOWER', 'CRISIL', 'CAMPUS', 'CANFINHOME', 'CANBK', 'CAPLIPOINT', 'CGCL', 'CARBORUNIV', 'CASTROLIND', 'CEATLTD', 'CENTRALBK', 'CDSL', 'CENTURYPLY', 'CERA', 'CHALET', 'CHAMBLFERT', 'CHENNPETRO', 'CHOLAHLDNG', 'CHOLAFIN', 'CIPLA', 'CUB', 'CLEAN', 'COALINDIA', 'COCHINSHIP', 'COFORGE', 'COHANCE', 'COLPAL', 'CAMS', 'CONCORDBIO', 'CONCOR', 'COROMANDEL', 'CRAFTSMAN', 'CREDITACC', 'CROMPTON', 'CUMMINSIND', 'CYIENT', 'DCMSHRIRAM', 'DLF', 'DOMS', 'DABUR', 'DALBHARAT', 'DATAPATTNS', 'DEEPAKFERT', 'DEEPAKNTR', 'DELHIVERY', 'DEVYANI', 'DIVISLAB', 'DIXON', 'LALPATHLAB', 'DRREDDY', 'EIDPARRY', 'EIHOTEL', 'EICHERMOT', 'ELECON', 'ELGIEQUIP', 'EMAMILTD', 'EMCURE', 'ENDURANCE', 'ENGINERSIN', 'ERIS', 'ESCORTS', 'ETERNAL', 'EXIDEIND', 'NYKAA', 'FEDERALBNK', 'FACT', 'FINCABLES', 'FINPIPE', 'FSL', 'FIVESTAR', 'FORTIS', 'GAIL', 'GVT&D', 'GMRAIRPORT', 'GRSE', 'GICRE', 'GILLETTE', 'GLAND', 'GLAXO', 'GLENMARK', 'MEDANTA', 'GODIGIT', 'GPIL', 'GODFRYPHLP', 'GODREJAGRO', 'GODREJCP', 'GODREJIND', 'GODREJPROP', 'GRANULES', 'GRAPHITE', 'GRASIM', 'GRAVITA', 'GESHIP', 'FLUOROCHEM', 'GUJGASLTD', 'GMDCLTD', 'GNFC', 'GPPL', 'GSPL', 'HEG', 'HBLENGINE', 'HCLTECH', 'HDFCAMC', 'HDFCBANK', 'HDFCLIFE', 'HFCL', 'HAPPSTMNDS', 'HAVELLS', 'HEROMOTOCO', 'HSCL', 'HINDALCO', 'HAL', 'HINDCOPPER', 'HINDPETRO', 'HINDUNILVR', 'HINDZINC', 'POWERINDIA', 'HOMEFIRST', 'HONASA', 'HONAUT', 'HUDCO', 'HYUNDAI', 'ICICIBANK', 'ICICIGI', 'ICICIPRULI', 'IDBI', 'IDFCFIRSTB', 'IFCI', 'IIFL', 'INOXINDIA', 'IRB', 'IRCON', 'ITC', 'ITI', 'INDGN', 'INDIACEM', 'INDIAMART', 'INDIANB', 'IEX', 'INDHOTEL', 'IOC', 'IOB', 'IRCTC', 'IRFC', 'IREDA', 'IGL', 'INDUSTOWER', 'INDUSINDBK', 'NAUKRI', 'INFY', 'INOXWIND', 'INTELLECT', 'INDIGO', 'IGIL', 'IKS', 'IPCALAB', 'JBCHEPHARM', 'JKCEMENT', 'JBMA', 'JKTYRE', 'JMFINANCIL', 'JSWENERGY', 'JSWHL', 'JSWINFRA', 'JSWSTEEL', 'JPPOWER', 'J&KBANK', 'JINDALSAW', 'JSL', 'JINDALSTEL', 'JIOFIN', 'JUBLFOOD', 'JUBLINGREA', 'JUBLPHARMA', 'JWL', 'JUSTDIAL', 'JYOTHYLAB', 'JYOTICNC', 'KPRMILL', 'KEI', 'KNRCON', 'KPITTECH', 'KAJARIACER', 'KPIL', 'KALYANKJIL', 'KANSAINER', 'KARURVYSYA', 'KAYNES', 'KEC', 'KFINTECH', 'KIRLOSBROS', 'KIRLOSENG', 'KOTAKBANK', 'KIMS', 'LTF', 'LTTS', 'LICHSGFIN', 'LTFOODS', 'LTIM', 'LT', 'LATENTVIEW', 'LAURUSLABS', 'LEMONTREE', 'LICI', 'LINDEINDIA', 'LLOYDSME', 'LODHA', 'LUPIN', 'MMTC', 'MRF', 'MGL', 'MAHSEAMLES', 'M&MFIN', 'M&M', 'MANAPPURAM', 'MRPL', 'MANKIND', 'MARICO', 'MARUTI', 'MASTEK', 'MFSL', 'MAXHEALTH', 'MAZDOCK', 'METROPOLIS', 'MINDACORP', 'MSUMI', 'MOTILALOFS', 'MPHASIS', 'MCX', 'MUTHOOTFIN', 'NATCOPHARM', 'NBCC', 'NCC', 'NHPC', 'NLCINDIA', 'NMDC', 'NSLNISP', 'NTPCGREEN', 'NTPC', 'NH', 'NATIONALUM', 'NAVA', 'NAVINFLUOR', 'NESTLEIND', 'NETWEB', 'NETWORK18', 'NEULANDLAB', 'NEWGEN', 'NAM-INDIA', 'NIVABUPA', 'NUVAMA', 'OBEROIRLTY', 'ONGC', 'OIL', 'OLAELEC', 'OLECTRA', 'PAYTM', 'OFSS', 'POLICYBZR', 'PCBL', 'PGEL', 'PIIND', 'PNBHOUSING', 'PNCINFRA', 'PTCIL', 'PVRINOX', 'PAGEIND', 'PATANJALI', 'PERSISTENT', 'PETRONET', 'PFIZER', 'PHOENIXLTD', 'PIDILITIND', 'PEL', 'PPLPHARMA', 'POLYMED', 'POLYCAB', 'POONAWALLA', 'PFC', 'POWERGRID', 'PRAJIND', 'PREMIERENE', 'PRESTIGE', 'PNB', 'RRKABEL', 'RBLBANK', 'RECLTD', 'RHIM', 'RITES', 'RADICO', 'RVNL', 'RAILTEL', 'RAINBOW', 'RKFORGE', 'RCF', 'RTNINDIA', 'RAYMONDLSL', 'RAYMOND', 'REDINGTON', 'RELIANCE', 'RPOWER', 'ROUTE', 'SBFC', 'SBICARD', 'SBILIFE', 'SJVN', 'SKFINDIA', 'SRF', 'SAGILITY', 'SAILIFE', 'SAMMAANCAP', 'MOTHERSON', 'SAPPHIRE', 'SARDAEN', 'SAREGAMA', 'SCHAEFFLER', 'SCHNEIDER', 'SCI', 'SHREECEM', 'RENUKA', 'SHRIRAMFIN', 'SHYAMMETL', 'SIEMENS', 'SIGNATURE', 'SOBHA', 'SOLARINDS', 'SONACOMS', 'SONATSOFTW', 'STARHEALTH', 'SBIN', 'SAIL', 'SWSOLAR', 'SUMICHEM', 'SUNPHARMA', 'SUNTV', 'SUNDARMFIN', 'SUNDRMFAST', 'SUPREMEIND', 'SUZLON', 'SWANENERGY', 'SWIGGY', 'SYNGENE', 'SYRMA', 'TBOTEK', 'TVSMOTOR', 'TANLA', 'TATACHEM', 'TATACOMM', 'TCS', 'TATACONSUM', 'TATAELXSI', 'TATAINVEST', 'TATAMOTORS', 'TATAPOWER', 'TATASTEEL', 'TATATECH', 'TTML', 'TECHM', 'TECHNOE', 'TEJASNET', 'NIACL', 'RAMCOCEM', 'THERMAX', 'TIMKEN', 'TITAGARH', 'TITAN', 'TORNTPHARM', 'TORNTPOWER', 'TARIL', 'TRENT', 'TRIDENT', 'TRIVENI', 'TRITURBINE', 'TIINDIA', 'UCOBANK', 'UNOMINDA', 'UPL', 'UTIAMC', 'ULTRACEMCO', 'UNIONBANK', 'UBL', 'UNITDSPR', 'USHAMART', 'VGUARD', 'DBREALTY', 'VTL', 'VBL', 'MANYAVAR', 'VEDL', 'VIJAYA', 'VMM', 'IDEA', 'VOLTAS', 'WAAREEENER', 'WELCORP', 'WELSPUNLIV', 'WESTLIFE', 'WHIRLPOOL', 'WIPRO', 'WOCKPHARMA', 'YESBANK', 'ZFCVINDIA', 'ZEEL', 'ZENTEC', 'ZENSARTECH', 'ZYDUSLIFE', 'ECLERX']\n",
    "\n",
    "# base_nifty500 = ['360ONE', '3MINDIA']\n",
    "nifty500 = [ticker + \".NS\" for ticker in base_nifty500]\n",
    "end_date = '2025-08-28'\n",
    "start_date = pd.to_datetime(end_date)-pd.DateOffset(365*8)\n",
    "df = yf.download(tickers=nifty500,\n",
    "                 start=start_date,\n",
    "                 end=end_date).stack()\n",
    "\n",
    "df.index.names = ['date', 'ticker']\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f0d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers provided: 5 (showing first 10): ['INFY.NS', 'TCS.NS', 'RELIANCE.NS', 'HDFCBANK.NS', 'ICICIBANK.NS']\n",
      "Downloading data for 5 tickers from 2018-01-01 to today...\n",
      "Downloaded 5 usable tickers.\n",
      "Fold 1: train=(1302, 15) valid=(1322, 15)\n",
      "Fold 2: train=(2624, 15) valid=(1322, 15)\n",
      "Fold 3: train=(3946, 15) valid=(1322, 15)\n",
      "Fold 4: train=(5268, 15) valid=(1322, 15)\n",
      "Fold 5: train=(6590, 15) valid=(1322, 15)\n",
      "Fold 6: train=(7912, 15) valid=(1322, 15)\n",
      "enet OOF RMSE: 0.078297\n",
      "rf   OOF RMSE: 0.080306\n",
      "gbr  OOF RMSE: 0.082343\n",
      "stack OOF RMSE: 0.076797\n",
      "Selected top 25: ['TCS.NS', 'RELIANCE.NS', 'ICICIBANK.NS', 'INFY.NS', 'HDFCBANK.NS']\n"
     ]
    },
    {
     "ename": "OptimizationError",
     "evalue": "('Please check your objectives/constraints or use a different solver.', 'Solver status: infeasible')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOptimizationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 492\u001b[39m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutputs saved under:     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.OUTDIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 450\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m    447\u001b[39m pd.Series(selected, name=\u001b[33m\"\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m\"\u001b[39m).to_csv(os.path.join(cfg.OUTDIR, \u001b[33m\"\u001b[39m\u001b[33mselected_stocks.csv\u001b[39m\u001b[33m\"\u001b[39m), index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# 8) Optimize weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m weights = \u001b[43moptimize_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu_ann\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_ann\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m w_series = pd.Series(weights).sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    452\u001b[39m w_series.to_csv(os.path.join(cfg.OUTDIR, \u001b[33m\"\u001b[39m\u001b[33moptimal_weights.csv\u001b[39m\u001b[33m\"\u001b[39m), header=[\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 392\u001b[39m, in \u001b[36moptimize_weights\u001b[39m\u001b[34m(mu, cov, cfg)\u001b[39m\n\u001b[32m    389\u001b[39m     ef.max_quadratic_utility(risk_aversion=\u001b[32m1e-8\u001b[39m)  \u001b[38;5;66;03m# near-zero RA ≈ max return with some regularization\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    391\u001b[39m     \u001b[38;5;66;03m# Default: maximize Sharpe with rf=0\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m     \u001b[43mef\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_sharpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m w = ef.clean_weights()\n\u001b[32m    395\u001b[39m perf = ef.portfolio_performance(verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.talib/lib/python3.12/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:290\u001b[39m, in \u001b[36mEfficientFrontier.max_sharpe\u001b[39m\u001b[34m(self, risk_free_rate)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# Transformed max_sharpe convex problem:\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;28mself\u001b[39m._constraints = [\n\u001b[32m    285\u001b[39m     (\u001b[38;5;28mself\u001b[39m.expected_returns - risk_free_rate).T @ \u001b[38;5;28mself\u001b[39m._w == \u001b[32m1\u001b[39m,\n\u001b[32m    286\u001b[39m     cp.sum(\u001b[38;5;28mself\u001b[39m._w) == k,\n\u001b[32m    287\u001b[39m     k >= \u001b[32m0\u001b[39m,\n\u001b[32m    288\u001b[39m ] + new_constraints\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_solve_cvxpy_opt_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# Inverse-transform\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28mself\u001b[39m.weights = (\u001b[38;5;28mself\u001b[39m._w.value / k.value).round(\u001b[32m16\u001b[39m) + \u001b[32m0.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.talib/lib/python3.12/site-packages/pypfopt/base_optimizer.py:315\u001b[39m, in \u001b[36mBaseConvexOptimizer._solve_cvxpy_opt_problem\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.OptimizationError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._opt.status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33moptimal\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moptimal_inaccurate\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.OptimizationError(\n\u001b[32m    316\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSolver status: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m._opt.status)\n\u001b[32m    317\u001b[39m     )\n\u001b[32m    318\u001b[39m \u001b[38;5;28mself\u001b[39m.weights = \u001b[38;5;28mself\u001b[39m._w.value.round(\u001b[32m16\u001b[39m) + \u001b[32m0.0\u001b[39m  \u001b[38;5;66;03m# +0.0 removes signed zero\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_output_weights()\n",
      "\u001b[31mOptimizationError\u001b[39m: ('Please check your objectives/constraints or use a different solver.', 'Solver status: infeasible')"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ML + Portfolio Optimization for a 1‑Month Horizon (NSE)\n",
    "------------------------------------------------------\n",
    "- Input: array/list of NSE tickers (e.g., [\"INFY.NS\", \"TCS.NS\", ...])\n",
    "- Label: next 21 trading‑day (≈1 month) log return\n",
    "- Model: simple blend of ElasticNet + RandomForest + GradientBoosting (sklearn)\n",
    "- Risk model: Ledoit‑Wolf shrinkage covariance on daily log returns\n",
    "- Optimizer: PyPortfolioOpt EfficientFrontier (max Sharpe by default)\n",
    "\n",
    "Outputs:\n",
    "- data/selected_stocks.csv             (top-N by predicted 1‑month return)\n",
    "- data/optimal_weights.csv             (continuous weights)\n",
    "- data/discrete_allocation.csv         (integer share allocation given CAPITAL)\n",
    "- data/predictions_latest.csv          (per‑stock predicted 1‑month returns)\n",
    "- console summary of performance metrics\n",
    "\n",
    "Install once:\n",
    "    pip install --upgrade pandas numpy yfinance scikit-learn pypfopt matplotlib\n",
    "\n",
    "Run:\n",
    "    python portfolio_one_month_ml.py\n",
    "\n",
    "Notes:\n",
    "- Ensure your NSE tickers have the \".NS\" suffix.\n",
    "- You can load tickers from a JSON or CSV instead of hardcoding (see CONFIG).\n",
    "- This is a research/starter script: no guarantees of performance!\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data and model\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import ElasticNetCV, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "# Optimization\n",
    "from pypfopt import risk_models, expected_returns, EfficientFrontier, objective_functions, DiscreteAllocation, CLA\n",
    "\n",
    "# Plot (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "@dataclass\n",
    "class Config:\n",
    "    # --- Provide your tickers here ---\n",
    "    TICKERS: List[str] = None  # e.g., [\"INFY.NS\", \"TCS.NS\", ...]  # Keep \".NS\" for NSE\n",
    "\n",
    "    # You can alternatively load from files (set to a path or None)\n",
    "    TICKERS_JSON: Optional[str] = None   # expects {\"tickers\": [\"INFY.NS\", \"...\"]}\n",
    "    TICKERS_CSV: Optional[str]  = None   # expects a column named \"ticker\"\n",
    "\n",
    "    START: str = \"2018-01-01\"\n",
    "    END: Optional[str] = None  # until today\n",
    "    PRICE_COL: str = \"Adj Close\"  # \"Adj Close\" if auto_adjust=False; \"Close\" if auto_adjust=True\n",
    "\n",
    "    # Label horizon (≈1 month ~ 21 trading days)\n",
    "    HORIZON_DAYS: int = 21\n",
    "\n",
    "    # Feature params\n",
    "    RSI_LEN: int = 14\n",
    "    MACD_FAST: int = 12\n",
    "    MACD_SLOW: int = 26\n",
    "    MACD_SIGNAL: int = 9\n",
    "\n",
    "    # Model / CV\n",
    "    N_SPLITS: int = 6\n",
    "    GAP_DAYS: int = 21  # purge gap to avoid leakage (≈ horizon)\n",
    "    RANDOM_STATE: int = 42\n",
    "\n",
    "    # Portfolio selection\n",
    "    TOP_N: int = 25         # choose top-N by predicted 1‑month return for optimization\n",
    "    WEIGHT_BOUNDS: Tuple[float, float] = (0.0, 0.08)  # cap per‑stock to avoid concentration\n",
    "\n",
    "    # Optimization objective: \"max_sharpe\" or \"max_return\"\n",
    "    OPT_OBJECTIVE: str = \"max_sharpe\"\n",
    "    L2_GAMMA: float = 0.1  # L2 penalty to reduce concentration (works with most objectives)\n",
    "\n",
    "    # Allocation\n",
    "    CAPITAL: float = 1_000_000.0\n",
    "    FEES_BPS: float = 5.0  # 0.05% assumed for sizing (not used in optimizer, only discrete alloc metadata)\n",
    "\n",
    "    # Output\n",
    "    OUTDIR: str = \"data\"\n",
    "    PLOT_WEIGHTS: bool = True\n",
    "\n",
    "BASE_TICKERS = ['360ONE', '3MINDIA', 'ABB', 'ACC', 'ACMESOLAR', 'AIAENG', 'APLAPOLLO', 'AUBANK', 'AWL', 'AADHARHFC', 'AARTIIND', 'AAVAS', 'ABBOTINDIA', 'ACE', 'ADANIENSOL', 'ADANIENT', 'ADANIGREEN', 'ADANIPORTS', 'ADANIPOWER', 'ATGL', 'ABCAPITAL', 'ABFRL', 'ABREL', 'ABSLAMC', 'AEGISLOG', 'AFCONS', 'AFFLE', 'AJANTPHARM', 'AKUMS', 'APLLTD', 'ALIVUS', 'ALKEM', 'ALKYLAMINE', 'ALOKINDS', 'ARE&M', 'AMBER', 'AMBUJACEM', 'ANANDRATHI', 'ANANTRAJ', 'ANGELONE', 'APARINDS', 'APOLLOHOSP', 'APOLLOTYRE', 'APTUS', 'ASAHIINDIA', 'ASHOKLEY', 'ASIANPAINT', 'ASTERDM', 'ASTRAZEN', 'ASTRAL', 'ATUL', 'AUROPHARMA', 'AIIL', 'DMART', 'AXISBANK', 'BASF', 'BEML', 'BLS', 'BSE', 'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV', 'BAJAJHLDNG', 'BAJAJHFL', 'BALKRISIND', 'BALRAMCHIN', 'BANDHANBNK', 'BANKBARODA', 'BANKINDIA', 'MAHABANK', 'BATAINDIA', 'BAYERCROP', 'BERGEPAINT', 'BDL', 'BEL', 'BHARATFORG', 'BHEL', 'BPCL', 'BHARTIARTL', 'BHARTIHEXA', 'BIKAJI', 'BIOCON', 'BSOFT', 'BLUEDART', 'BLUESTARCO', 'BBTC', 'BOSCHLTD', 'FIRSTCRY', 'BRIGADE', 'BRITANNIA', 'MAPMYINDIA', 'CCL', 'CESC', 'CGPOWER', 'CRISIL', 'CAMPUS', 'CANFINHOME', 'CANBK', 'CAPLIPOINT', 'CGCL', 'CARBORUNIV', 'CASTROLIND', 'CEATLTD', 'CENTRALBK', 'CDSL', 'CENTURYPLY', 'CERA', 'CHALET', 'CHAMBLFERT', 'CHENNPETRO', 'CHOLAHLDNG', 'CHOLAFIN', 'CIPLA', 'CUB', 'CLEAN', 'COALINDIA', 'COCHINSHIP', 'COFORGE', 'COHANCE', 'COLPAL', 'CAMS', 'CONCORDBIO', 'CONCOR', 'COROMANDEL', 'CRAFTSMAN', 'CREDITACC', 'CROMPTON', 'CUMMINSIND', 'CYIENT', 'DCMSHRIRAM', 'DLF', 'DOMS', 'DABUR', 'DALBHARAT', 'DATAPATTNS', 'DEEPAKFERT', 'DEEPAKNTR', 'DELHIVERY', 'DEVYANI', 'DIVISLAB', 'DIXON', 'LALPATHLAB', 'DRREDDY', 'DUMMYDBRLT', 'EIDPARRY', 'EIHOTEL', 'EICHERMOT', 'ELECON', 'ELGIEQUIP', 'EMAMILTD', 'EMCURE', 'ENDURANCE', 'ENGINERSIN', 'ERIS', 'ESCORTS', 'ETERNAL', 'EXIDEIND', 'NYKAA', 'FEDERALBNK', 'FACT', 'FINCABLES', 'FINPIPE', 'FSL', 'FIVESTAR', 'FORTIS', 'GAIL', 'GVT&D', 'GMRAIRPORT', 'GRSE', 'GICRE', 'GILLETTE', 'GLAND', 'GLAXO', 'GLENMARK', 'MEDANTA', 'GODIGIT', 'GPIL', 'GODFRYPHLP', 'GODREJAGRO', 'GODREJCP', 'GODREJIND', 'GODREJPROP', 'GRANULES', 'GRAPHITE', 'GRASIM', 'GRAVITA', 'GESHIP', 'FLUOROCHEM', 'GUJGASLTD', 'GMDCLTD', 'GNFC', 'GPPL', 'GSPL', 'HEG', 'HBLENGINE', 'HCLTECH', 'HDFCAMC', 'HDFCBANK', 'HDFCLIFE', 'HFCL', 'HAPPSTMNDS', 'HAVELLS', 'HEROMOTOCO', 'HSCL', 'HINDALCO', 'HAL', 'HINDCOPPER', 'HINDPETRO', 'HINDUNILVR', 'HINDZINC', 'POWERINDIA', 'HOMEFIRST', 'HONASA', 'HONAUT', 'HUDCO', 'HYUNDAI', 'ICICIBANK', 'ICICIGI', 'ICICIPRULI', 'IDBI', 'IDFCFIRSTB', 'IFCI', 'IIFL', 'INOXINDIA', 'IRB', 'IRCON', 'ITC', 'ITI', 'INDGN', 'INDIACEM', 'INDIAMART', 'INDIANB', 'IEX', 'INDHOTEL', 'IOC', 'IOB', 'IRCTC', 'IRFC', 'IREDA', 'IGL', 'INDUSTOWER', 'INDUSINDBK', 'NAUKRI', 'INFY', 'INOXWIND', 'INTELLECT', 'INDIGO', 'IGIL', 'IKS', 'IPCALAB', 'JBCHEPHARM', 'JKCEMENT', 'JBMA', 'JKTYRE', 'JMFINANCIL', 'JSWENERGY', 'JSWHL', 'JSWINFRA', 'JSWSTEEL', 'JPPOWER', 'J&KBANK', 'JINDALSAW', 'JSL', 'JINDALSTEL', 'JIOFIN', 'JUBLFOOD', 'JUBLINGREA', 'JUBLPHARMA', 'JWL', 'JUSTDIAL', 'JYOTHYLAB', 'JYOTICNC', 'KPRMILL', 'KEI', 'KNRCON', 'KPITTECH', 'KAJARIACER', 'KPIL', 'KALYANKJIL', 'KANSAINER', 'KARURVYSYA', 'KAYNES', 'KEC', 'KFINTECH', 'KIRLOSBROS', 'KIRLOSENG', 'KOTAKBANK', 'KIMS', 'LTF', 'LTTS', 'LICHSGFIN', 'LTFOODS', 'LTIM', 'LT', 'LATENTVIEW', 'LAURUSLABS', 'LEMONTREE', 'LICI', 'LINDEINDIA', 'LLOYDSME', 'LODHA', 'LUPIN', 'MMTC', 'MRF', 'MGL', 'MAHSEAMLES', 'M&MFIN', 'M&M', 'MANAPPURAM', 'MRPL', 'MANKIND', 'MARICO', 'MARUTI', 'MASTEK', 'MFSL', 'MAXHEALTH', 'MAZDOCK', 'METROPOLIS', 'MINDACORP', 'MSUMI', 'MOTILALOFS', 'MPHASIS', 'MCX', 'MUTHOOTFIN', 'NATCOPHARM', 'NBCC', 'NCC', 'NHPC', 'NLCINDIA', 'NMDC', 'NSLNISP', 'NTPCGREEN', 'NTPC', 'NH', 'NATIONALUM', 'NAVA', 'NAVINFLUOR', 'NESTLEIND', 'NETWEB', 'NETWORK18', 'NEULANDLAB', 'NEWGEN', 'NAM-INDIA', 'NIVABUPA', 'NUVAMA', 'OBEROIRLTY', 'ONGC', 'OIL', 'OLAELEC', 'OLECTRA', 'PAYTM', 'OFSS', 'POLICYBZR', 'PCBL', 'PGEL', 'PIIND', 'PNBHOUSING', 'PNCINFRA', 'PTCIL', 'PVRINOX', 'PAGEIND', 'PATANJALI', 'PERSISTENT', 'PETRONET', 'PFIZER', 'PHOENIXLTD', 'PIDILITIND', 'PEL', 'PPLPHARMA', 'POLYMED', 'POLYCAB', 'POONAWALLA', 'PFC', 'POWERGRID', 'PRAJIND', 'PREMIERENE', 'PRESTIGE', 'PNB', 'RRKABEL', 'RBLBANK', 'RECLTD', 'RHIM', 'RITES', 'RADICO', 'RVNL', 'RAILTEL', 'RAINBOW', 'RKFORGE', 'RCF', 'RTNINDIA', 'RAYMONDLSL', 'RAYMOND', 'REDINGTON', 'RELIANCE', 'RPOWER', 'ROUTE', 'SBFC', 'SBICARD', 'SBILIFE', 'SJVN', 'SKFINDIA', 'SRF', 'SAGILITY', 'SAILIFE', 'SAMMAANCAP', 'MOTHERSON', 'SAPPHIRE', 'SARDAEN', 'SAREGAMA', 'SCHAEFFLER', 'SCHNEIDER', 'SCI', 'SHREECEM', 'RENUKA', 'SHRIRAMFIN', 'SHYAMMETL', 'SIEMENS', 'SIGNATURE', 'SOBHA', 'SOLARINDS', 'SONACOMS', 'SONATSOFTW', 'STARHEALTH', 'SBIN', 'SAIL', 'SWSOLAR', 'SUMICHEM', 'SUNPHARMA', 'SUNTV', 'SUNDARMFIN', 'SUNDRMFAST', 'SUPREMEIND', 'SUZLON', 'SWANENERGY', 'SWIGGY', 'SYNGENE', 'SYRMA', 'TBOTEK', 'TVSMOTOR', 'TANLA', 'TATACHEM', 'TATACOMM', 'TCS', 'TATACONSUM', 'TATAELXSI', 'TATAINVEST', 'TATAMOTORS', 'TATAPOWER', 'TATASTEEL', 'TATATECH', 'TTML', 'TECHM', 'TECHNOE', 'TEJASNET', 'NIACL', 'RAMCOCEM', 'THERMAX', 'TIMKEN', 'TITAGARH', 'TITAN', 'TORNTPHARM', 'TORNTPOWER', 'TARIL', 'TRENT', 'TRIDENT', 'TRIVENI', 'TRITURBINE', 'TIINDIA', 'UCOBANK', 'UNOMINDA', 'UPL', 'UTIAMC', 'ULTRACEMCO', 'UNIONBANK', 'UBL', 'UNITDSPR', 'USHAMART', 'VGUARD', 'DBREALTY', 'VTL', 'VBL', 'MANYAVAR', 'VEDL', 'VIJAYA', 'VMM', 'IDEA', 'VOLTAS', 'WAAREEENER', 'WELCORP', 'WELSPUNLIV', 'WESTLIFE', 'WHIRLPOOL', 'WIPRO', 'WOCKPHARMA', 'YESBANK', 'ZFCVINDIA', 'ZEEL', 'ZENTEC', 'ZENSARTECH', 'ZYDUSLIFE', 'ECLERX']\n",
    "\n",
    "\n",
    "\n",
    "CFG = Config(\n",
    "    # Example placeholder; REPLACE with your ~500 NSE tickers list:\n",
    "    TICKERS=[ t + \".NS\" for t in BASE_TICKERS ]\n",
    ")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Helpers\n",
    "# ==============================\n",
    "def load_tickers(cfg: Config) -> List[str]:\n",
    "    if cfg.TICKERS and len(cfg.TICKERS) > 0:\n",
    "        return cfg.TICKERS\n",
    "\n",
    "    if cfg.TICKERS_JSON and os.path.exists(cfg.TICKERS_JSON):\n",
    "        with open(cfg.TICKERS_JSON, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return list(map(str, data.get(\"tickers\", [])))\n",
    "\n",
    "    if cfg.TICKERS_CSV and os.path.exists(cfg.TICKERS_CSV):\n",
    "        df = pd.read_csv(cfg.TICKERS_CSV)\n",
    "        # expect a \"ticker\" column\n",
    "        if \"ticker\" not in df.columns:\n",
    "            raise ValueError(\"CSV must contain a 'ticker' column.\")\n",
    "        return list(map(str, df[\"ticker\"].dropna().unique().tolist()))\n",
    "\n",
    "    raise ValueError(\"Please provide tickers via CFG.TICKERS or TICKERS_JSON/CSV.\")\n",
    "\n",
    "\n",
    "def download_prices(tickers: List[str], start: str, end: Optional[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a wide dataframe with columns as tickers and rows as dates (Adj Close).\n",
    "    Skips tickers that fail download or have insufficient data.\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data for {len(tickers)} tickers from {start} to {end or 'today'}...\")\n",
    "    out = {}\n",
    "    good = []\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            df = yf.download(t, start=start, end=end, progress=False, auto_adjust=True, threads=True, multi_level_index=False)\n",
    "            if df is None or df.empty or \"Close\" not in df.columns:\n",
    "                print(f\"  - Skipping {t}: no data\")\n",
    "                continue\n",
    "            s = df[\"Close\"].dropna().copy()\n",
    "            if s.index.nunique() < 300:\n",
    "                print(f\"  - Skipping {t}: too few rows ({len(s)})\")\n",
    "                continue\n",
    "            out[t] = s\n",
    "            good.append(t)\n",
    "        except Exception as e:\n",
    "            print(f\"  - Skipping {t}: error {e}\")\n",
    "            continue\n",
    "\n",
    "    if not out:\n",
    "        raise RuntimeError(\"No usable tickers after download.\")\n",
    "    px = pd.DataFrame(out)\n",
    "    px.index.name = \"Date\"\n",
    "    print(f\"Downloaded {len(good)} usable tickers.\")\n",
    "    return px\n",
    "\n",
    "\n",
    "def rsi(series: pd.Series, window: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    up = np.where(delta > 0, delta, 0.0)\n",
    "    down = np.where(delta < 0, -delta, 0.0)\n",
    "    roll_up = pd.Series(up, index=series.index).ewm(alpha=1/window, adjust=False).mean()\n",
    "    roll_down = pd.Series(down, index=series.index).ewm(alpha=1/window, adjust=False).mean()\n",
    "    rs = roll_up / (roll_down + 1e-12)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "\n",
    "def macd(series: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series]:\n",
    "    ema_fast = series.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = series.ewm(span=slow, adjust=False).mean()\n",
    "    line = ema_fast - ema_slow\n",
    "    signal_line = line.ewm(span=signal, adjust=False).mean()\n",
    "    hist = line - signal_line\n",
    "    return line, signal_line\n",
    "\n",
    "\n",
    "def make_features(px: pd.DataFrame, cfg: Config) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build cross‑sectional features for each (date, ticker).\n",
    "    Returns:\n",
    "        X: features DataFrame indexed by (Date, Ticker)\n",
    "        y: future 21‑day log return as label\n",
    "    \"\"\"\n",
    "    daily_ret = np.log(px / px.shift(1))\n",
    "    ftrs = {}\n",
    "    labels = {}\n",
    "\n",
    "    for t in px.columns:\n",
    "        s = px[t]\n",
    "        r = daily_ret[t]\n",
    "\n",
    "        # Momentum\n",
    "        mom3  = s.pct_change(3)\n",
    "        mom5  = s.pct_change(5)\n",
    "        mom10 = s.pct_change(10)\n",
    "        mom21 = s.pct_change(21)\n",
    "\n",
    "        # Volatility (realized)\n",
    "        vol5  = r.rolling(5).std()\n",
    "        vol10 = r.rolling(10).std()\n",
    "        vol21 = r.rolling(21).std()\n",
    "\n",
    "        # RSI\n",
    "        rsi14 = rsi(s, cfg.RSI_LEN)\n",
    "\n",
    "        # Moving average distances\n",
    "        sma5  = s.rolling(5).mean()\n",
    "        sma10 = s.rolling(10).mean()\n",
    "        sma21 = s.rolling(21).mean()\n",
    "        dist_sma5  = s / sma5  - 1\n",
    "        dist_sma10 = s / sma10 - 1\n",
    "        dist_sma21 = s / sma21 - 1\n",
    "\n",
    "        # MACD\n",
    "        macd_line, macd_signal = macd(s, cfg.MACD_FAST, cfg.MACD_SLOW, cfg.MACD_SIGNAL)\n",
    "        macd_hist = macd_line - macd_signal\n",
    "\n",
    "        # Volume features\n",
    "        if \"Volume\" in px.columns:  # unlikely, because px is Close only\n",
    "            vol = px[\"Volume\"][t]\n",
    "        # For simplicity, use returns' rolling z-score as a \"volatility pressure\"\n",
    "        zret5 = (r - r.rolling(20).mean()) / (r.rolling(20).std() + 1e-9)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"mom3\": mom3, \"mom5\": mom5, \"mom10\": mom10, \"mom21\": mom21,\n",
    "            \"vol5\": vol5, \"vol10\": vol10, \"vol21\": vol21,\n",
    "            \"rsi14\": rsi14,\n",
    "            \"dist_sma5\": dist_sma5, \"dist_sma10\": dist_sma10, \"dist_sma21\": dist_sma21,\n",
    "            \"macd_line\": macd_line, \"macd_signal\": macd_signal, \"macd_hist\": macd_hist,\n",
    "            \"zret5\": zret5,\n",
    "        })\n",
    "\n",
    "        # Label: future HORIZON_DAYS log return\n",
    "        fut_ret = np.log(s.shift(-cfg.HORIZON_DAYS) / s)\n",
    "        ftrs[t] = df\n",
    "        labels[t] = fut_ret\n",
    "\n",
    "    # Stack\n",
    "    X = pd.concat(ftrs, axis=1)  # columns = MultiIndex (feature per ticker)\n",
    "    y = pd.concat(labels, axis=1)  # columns = tickers\n",
    "\n",
    "    # Convert to long format (Date, Ticker)\n",
    "    X_long = (\n",
    "        X.stack(level=0, future_stack=True)\n",
    "        .rename_axis(index=[\"Date\", \"Ticker\"])\n",
    "        .sort_index()\n",
    "    )\n",
    "    y_long = (\n",
    "        y.stack(future_stack=True)\n",
    "        .rename(\"y\")\n",
    "        .rename_axis(index=[\"Date\", \"Ticker\"])\n",
    "        .sort_index()\n",
    "        .to_frame()\n",
    "    )\n",
    "\n",
    "    # Align and drop NaNs\n",
    "    df = X_long.join(y_long, how=\"inner\")\n",
    "    df = df.dropna()\n",
    "    return df.drop(columns=[\"y\"]), df[[\"y\"]]\n",
    "\n",
    "\n",
    "def build_models(random_state: int = 42):\n",
    "    models = {\n",
    "        \"enet\": ElasticNetCV(\n",
    "            l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            alphas=np.logspace(-4, 1, 20),\n",
    "            max_iter=10000,\n",
    "            cv=3,\n",
    "            n_jobs=None,\n",
    "            random_state=random_state,\n",
    "        ),\n",
    "        \"rf\": RandomForestRegressor(\n",
    "            n_estimators=400, max_depth=6, min_samples_leaf=5, random_state=random_state, n_jobs=-1\n",
    "        ),\n",
    "        \"gbr\": GradientBoostingRegressor(\n",
    "            n_estimators=300, learning_rate=0.05, max_depth=3, random_state=random_state\n",
    "        ),\n",
    "    }\n",
    "    return models\n",
    "\n",
    "\n",
    "def walk_forward_oof(X: pd.DataFrame, y: pd.Series, cfg: Config):\n",
    "    \"\"\"\n",
    "    Produce out‑of‑fold predictions and a simple stacked model on top.\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=cfg.N_SPLITS, gap=cfg.GAP_DAYS)\n",
    "    models = build_models(cfg.RANDOM_STATE)\n",
    "    oof_preds = {name: np.full(len(y), np.nan) for name in models}\n",
    "    idx = y.index  # MultiIndex (Date, Ticker)\n",
    "\n",
    "    for fold, (tr, va) in enumerate(tscv.split(X), start=1):\n",
    "        X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "        y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "        print(f\"Fold {fold}: train={X_tr.shape} valid={X_va.shape}\")\n",
    "\n",
    "        for name, mdl in models.items():\n",
    "            mdl.fit(X_tr, y_tr)\n",
    "            p = mdl.predict(X_va)\n",
    "            oof_preds[name][va] = p\n",
    "\n",
    "    # Compute RMSE per base model\n",
    "    for name in models.keys():\n",
    "        mask = ~np.isnan(oof_preds[name])\n",
    "        rmse = math.sqrt(mean_squared_error(y.values[mask], oof_preds[name][mask]))\n",
    "        print(f\"{name:4s} OOF RMSE: {rmse:.6f}\")\n",
    "\n",
    "    # Simple stacked meta-model (Ridge)\n",
    "    oof_df = pd.DataFrame({k: v for k, v in oof_preds.items()}, index=idx).dropna()\n",
    "    meta = RidgeCV(alphas=np.logspace(-4, 2, 20))\n",
    "    meta.fit(oof_df.values, y.loc[oof_df.index].values)\n",
    "    meta_rmse = math.sqrt(mean_squared_error(y.loc[oof_df.index].values, meta.predict(oof_df.values)))\n",
    "    print(f\"stack OOF RMSE: {meta_rmse:.6f}\")\n",
    "\n",
    "    # Fit all models on FULL data\n",
    "    for name, mdl in models.items():\n",
    "        mdl.fit(X, y)\n",
    "    meta.fit(pd.DataFrame({k: mdl.predict(X) for k, mdl in models.items()}), y)\n",
    "\n",
    "    return models, meta\n",
    "\n",
    "\n",
    "def latest_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter to the last date per ticker for latest prediction snapshot.\n",
    "    \"\"\"\n",
    "    # X is indexed by (Date, Ticker)\n",
    "    last_dates = X.reset_index().groupby(\"Ticker\")[\"Date\"].max()\n",
    "    mask = X.reset_index().merge(last_dates, on=[\"Ticker\", \"Date\"], how=\"inner\").set_index([\"Date\", \"Ticker\"]).index\n",
    "    X_last = X.loc[mask].sort_index()\n",
    "    return X_last\n",
    "\n",
    "\n",
    "def predict_latest(models: Dict[str, any], meta, X: pd.DataFrame) -> pd.DataFrame:\n",
    "    base_preds = {name: mdl.predict(X) for name, mdl in models.items()}\n",
    "    base_df = pd.DataFrame(base_preds, index=X.index)\n",
    "    stack_pred = meta.predict(base_df)\n",
    "    out = base_df.copy()\n",
    "    out[\"stack\"] = stack_pred\n",
    "    return out\n",
    "\n",
    "\n",
    "def annualize_from_horizon(r_horizon: pd.Series, horizon_days: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert horizon log‑return expectation to annualized mean simple return for optimizer.\n",
    "    - r_horizon is in log‑returns (as the model was trained on).\n",
    "    \"\"\"\n",
    "    # Expected simple return over horizon\n",
    "    exp_simple = np.expm1(r_horizon)  # e^r - 1\n",
    "    ann = (1.0 + exp_simple) ** (252.0 / horizon_days) - 1.0\n",
    "    return ann\n",
    "\n",
    "\n",
    "def select_top_by_prediction(pred_df: pd.DataFrame, top_n: int) -> pd.Index:\n",
    "    # pred_df indexed by (Date, Ticker), column 'stack'\n",
    "    last_day = pred_df.index.get_level_values(\"Date\").max()\n",
    "    sdf = pred_df.xs(last_day, level=\"Date\")\n",
    "    sdf = sdf.sort_values(\"stack\", ascending=False)\n",
    "    return sdf.head(top_n).index\n",
    "\n",
    "\n",
    "def build_covariance(px: pd.DataFrame, selected: List[str]) -> pd.DataFrame:\n",
    "    # Daily log returns\n",
    "    r = np.log(px[selected] / px[selected].shift(1)).dropna(how=\"all\")\n",
    "    # Ledoit‑Wolf shrinkage for robust covariance\n",
    "    lw = LedoitWolf().fit(r.fillna(0).values)\n",
    "    cov = pd.DataFrame(lw.covariance_, index=selected, columns=selected)\n",
    "    # Annualize\n",
    "    cov = cov * 252.0\n",
    "    return cov\n",
    "\n",
    "\n",
    "def optimize_weights(mu: pd.Series, cov: pd.DataFrame, cfg: Config) -> Dict[str, float]:\n",
    "    ef = EfficientFrontier(mu, cov, weight_bounds=cfg.WEIGHT_BOUNDS)\n",
    "    ef.add_objective(objective_functions.L2_reg, gamma=cfg.L2_GAMMA)\n",
    "\n",
    "    if cfg.OPT_OBJECTIVE == \"max_return\":\n",
    "        ef.max_quadratic_utility(risk_aversion=1e-8)  # near-zero RA ≈ max return with some regularization\n",
    "    else:\n",
    "        # Default: maximize Sharpe with rf=0\n",
    "        ef.max_sharpe()\n",
    "\n",
    "    w = ef.clean_weights()\n",
    "    perf = ef.portfolio_performance(verbose=True)\n",
    "    print(f\"Optimized performance: (exp_ret, exp_vol, Sharpe) = {perf}\")\n",
    "    return w\n",
    "\n",
    "\n",
    "def discrete_allocation(weights: Dict[str, float], last_prices: pd.Series, capital: float) -> Tuple[Dict[str, int], float]:\n",
    "    da = DiscreteAllocation(weights, last_prices.to_dict(), total_portfolio_value=capital)\n",
    "    alloc, leftover = da.lp_portfolio()\n",
    "    return alloc, leftover\n",
    "\n",
    "\n",
    "def main(cfg: Config):\n",
    "    os.makedirs(cfg.OUTDIR, exist_ok=True)\n",
    "\n",
    "    # 1) Tickers\n",
    "    tickers = load_tickers(cfg)\n",
    "    print(f\"Tickers provided: {len(tickers)} (showing first 10): {tickers[:10]}\")\n",
    "\n",
    "    # 2) Data\n",
    "    px = download_prices(tickers, cfg.START, cfg.END)\n",
    "    # Keep only tickers present in px\n",
    "    tickers = [t for t in tickers if t in px.columns]\n",
    "\n",
    "    # 3) Features & Label\n",
    "    X, ydf = make_features(px, cfg)\n",
    "    y = ydf[\"y\"]\n",
    "\n",
    "    # 4) Walk‑forward OOF + fit final models\n",
    "    models, meta = walk_forward_oof(X, y, cfg)\n",
    "\n",
    "    # 5) Latest snapshot predictions\n",
    "    X_last = latest_features(X)\n",
    "    preds_last = predict_latest(models, meta, X_last)\n",
    "    preds_last = preds_last.reset_index().rename(columns={\"stack\": \"pred_logret_horizon\"})\n",
    "    # Keep only latest date\n",
    "    latest_date = preds_last[\"Date\"].max()\n",
    "    preds_today = preds_last[preds_last[\"Date\"] == latest_date].copy()\n",
    "\n",
    "    # 6) Select top‑N by predicted 1‑month log return\n",
    "    preds_today.set_index([\"Date\", \"Ticker\"], inplace=True)\n",
    "    top_idx = select_top_by_prediction(preds_today[[\"pred_logret_horizon\"]].rename(columns={\"pred_logret_horizon\":\"stack\"}), cfg.TOP_N)\n",
    "    selected = list(top_idx)\n",
    "    print(f\"Selected top {cfg.TOP_N}: {selected[:10]}{'...' if len(selected)>10 else ''}\")\n",
    "\n",
    "    # 7) Build expected returns (annualized) & covariance\n",
    "    # Convert predicted log return over horizon to annualized simple return\n",
    "    pred_map = preds_today[\"pred_logret_horizon\"].xs(latest_date, level=\"Date\")\n",
    "    mu_ann = annualize_from_horizon(pred_map[selected], cfg.HORIZON_DAYS)\n",
    "    cov_ann = build_covariance(px, selected)\n",
    "\n",
    "    # Save diagnostics\n",
    "    preds_today.reset_index().to_csv(os.path.join(cfg.OUTDIR, \"predictions_latest.csv\"), index=False)\n",
    "    pd.Series(selected, name=\"ticker\").to_csv(os.path.join(cfg.OUTDIR, \"selected_stocks.csv\"), index=False)\n",
    "\n",
    "    # 8) Optimize weights\n",
    "    weights = optimize_weights(mu_ann, cov_ann, cfg)\n",
    "    w_series = pd.Series(weights).sort_values(ascending=False)\n",
    "    w_series.to_csv(os.path.join(cfg.OUTDIR, \"optimal_weights.csv\"), header=[\"weight\"])\n",
    "\n",
    "    # 9) Discrete allocation given CAPITAL\n",
    "    last_px = px[selected].ffill().iloc[-1]\n",
    "    alloc, leftover = discrete_allocation(weights, last_px, cfg.CAPITAL)\n",
    "    alloc_df = pd.DataFrame({\"shares\": pd.Series(alloc)}).sort_values(\"shares\", ascending=False)\n",
    "    alloc_df[\"price\"] = last_px.reindex(alloc_df.index)\n",
    "    alloc_df[\"alloc_value\"] = alloc_df[\"shares\"] * alloc_df[\"price\"]\n",
    "    alloc_df.to_csv(os.path.join(cfg.OUTDIR, \"discrete_allocation.csv\"))\n",
    "    print(f\"Discrete allocation leftover cash: ₹{leftover:,.2f}\")\n",
    "\n",
    "    # 10) Optional: bar plot of weights\n",
    "    if cfg.PLOT_WEIGHTS:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        w_series.head(30).plot(kind=\"bar\")\n",
    "        plt.title(\"Top Weights (first 30)\")\n",
    "        plt.ylabel(\"Weight\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(cfg.OUTDIR, \"weights_bar.png\"), dpi=150)\n",
    "        # plt.show()\n",
    "\n",
    "    # 11) Summary\n",
    "    exp_ret = (weights and sum(mu_ann.reindex(weights.keys()) * pd.Series(weights))) or np.nan\n",
    "    exp_vol = np.sqrt(\n",
    "        np.dot(pd.Series(weights).values, np.dot(cov_ann.values, pd.Series(weights).values))\n",
    "    )\n",
    "    sharpe = (exp_ret / exp_vol) if exp_vol > 0 else np.nan\n",
    "    print(\"\\n=== Portfolio Summary (based on model expectations) ===\")\n",
    "    print(f\"Latest date:             {latest_date.date()}\")\n",
    "    print(f\"Selected tickers:        {len(selected)}\")\n",
    "    print(f\"Expected annual return:  {exp_ret:.2%}\")\n",
    "    print(f\"Expected annual vol:     {exp_vol:.2%}\")\n",
    "    print(f\"Expected Sharpe (rf=0):  {sharpe:.2f}\")\n",
    "    print(f\"Weight bounds:           {cfg.WEIGHT_BOUNDS}\")\n",
    "    print(f\"Objective:               {cfg.OPT_OBJECTIVE} (with L2 gamma={cfg.L2_GAMMA})\")\n",
    "    print(f\"Capital for discrete:    ₹{cfg.CAPITAL:,.0f}\")\n",
    "    print(f\"Outputs saved under:     {cfg.OUTDIR}/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(CFG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
