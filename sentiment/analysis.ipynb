{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd7195e",
   "metadata": {},
   "source": [
    "# News-Sentiment DMA Screener ‚Äî README\n",
    "\n",
    "A single-file Python tool that:\n",
    "\n",
    "* Fetches India equity news via **Google News RSS** using **dynamic company names** loaded from **NSE index CSVs** (Nifty 50 / Next 50 / Bank / 500 / Midcap 100 / Smallcap 100).\n",
    "* Filters to an **allowlist of publishers** (Moneycontrol, Economic Times, Mint/LiveMint, Business Standard, CNBC TV18) with a safe **fallback** if none match.\n",
    "* Extracts **full article text** (trafilatura ‚Üí readability-lxml ‚Üí newspaper3k) + AMP/canonical cleanup.\n",
    "* Runs **FinBERT** sentiment on **headlines** and **articles**.\n",
    "* Applies **recency weighting** (‚â§24h = 1.5√ó, 24‚Äì48h = 1.2√ó).\n",
    "* Outputs a per-ticker **bias**: `LONG` / `SHORT` / `NEUTRAL`.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) What you get\n",
    "\n",
    "For each ticker, the script prints a table:\n",
    "\n",
    "| column           | meaning                                                     |\n",
    "| ---------------- | ----------------------------------------------------------- |\n",
    "| `symbol`         | NSE ticker with `.NS` suffix (e.g., `LUPIN.NS`)             |\n",
    "| `headline_avg`   | Recency-weighted sentiment from headlines only (‚àí1..+1)     |\n",
    "| `article_avg`    | Average sentiment from extracted article bodies / summaries |\n",
    "| `combined_score` | Final score (prefers article if available; else headline)   |\n",
    "| `bias`           | `LONG` if > +0.05, `SHORT` if < ‚àí0.05, else `NEUTRAL`       |\n",
    "| `n_headlines`    | Number of headlines considered                              |\n",
    "| `n_articles`     | Number of articles whose text was extracted / used          |\n",
    "\n",
    "> Tip: If `n_articles` is 0, the script still uses headline sentiment (and, if enabled, RSS summary fallback).\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Requirements\n",
    "\n",
    "* Python **3.10+**\n",
    "* Packages:\n",
    "\n",
    "  * Always: `requests`, `feedparser`, `pandas`, `transformers`\n",
    "  * Optional (recommended for better extraction):\n",
    "    `trafilatura`, `readability-lxml`, `lxml`, `newspaper3k`\n",
    "* Model: `ProsusAI/finbert` (downloaded automatically by ü§ó Transformers)\n",
    "* macOS/Apple Silicon: MPS is fine (transformers prints `Device set to use mps:0`)\n",
    "\n",
    "Install:\n",
    "\n",
    "```bash\n",
    "pip install requests feedparser pandas transformers\n",
    "# optional but recommended:\n",
    "pip install trafilatura readability-lxml lxml newspaper3k\n",
    "```\n",
    "\n",
    "> If you use a GPU/Metal, Transformers will auto-choose the device. No config needed.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) How it works\n",
    "\n",
    "1. **Dynamic company names**\n",
    "   The script warms up an NSE session, downloads multiple index CSVs, and builds `NAME_MAP = {SYMBOL: \"Company Name\"}`.\n",
    "   Example: `\"LUPIN\" ‚Üí \"Lupin\"`, `\"CENTRALBK\" ‚Üí \"Central Bank of India\"`.\n",
    "\n",
    "2. **News fetching (Google News RSS)**\n",
    "   For each ticker, it queries with:\n",
    "\n",
    "   * `\"Company Name\" stock india`\n",
    "   * `Company Name shares`\n",
    "   * `SYMBOL stock india`\n",
    "     It keeps **allowlisted publishers** if present; otherwise it **returns all** to avoid empty results.\n",
    "\n",
    "3. **Text extraction**\n",
    "   For each link, it:\n",
    "\n",
    "   * Canonicalizes/cleans the URL (removes AMP and tracking where safe).\n",
    "   * Tries `trafilatura` ‚Üí `readability` ‚Üí `newspaper3k` in order.\n",
    "   * Uses article text if ‚â•120 chars; else falls back to RSS summary (if available).\n",
    "\n",
    "4. **Sentiment & weighting**\n",
    "\n",
    "   * Headline sentiment: recency-weighted (‚â§24h: 1.5√ó, 24‚Äì48h: 1.2√ó, else 1.0√ó).\n",
    "   * Article sentiment: average of chunked body text (512-token budget heuristic).\n",
    "   * Combined: `0.7 * article_avg + 0.3 * headline_avg` *if* any articles were read; otherwise `headline_avg`.\n",
    "\n",
    "5. **Bias rule**\n",
    "\n",
    "   * `combined_score > +0.05` ‚Üí **LONG**\n",
    "   * `combined_score < ‚àí0.05` ‚Üí **SHORT**\n",
    "   * otherwise **NEUTRAL**\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Running it\n",
    "\n",
    "Edit the `tickers` list at the bottom and run:\n",
    "\n",
    "```bash\n",
    "python news_sentiment_dma.py\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = [\n",
    "        \"CENTRALBK.NS\",\n",
    "        \"LUPIN.NS\",\n",
    "        \"UCOBANK.NS\",\n",
    "    ]\n",
    "    sentiment_df = build_sentiment_table(tickers)\n",
    "    print(sentiment_df)\n",
    "```\n",
    "\n",
    "> Note: In Python, each item in the list needs a comma. A missing comma will concatenate adjacent strings.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Configuration knobs\n",
    "\n",
    "* **Allowlist domains**: update `ALLOWLIST` to tighten/loosen publisher filtering.\n",
    "* **Recency weighting**: tweak `recency_weight()` thresholds/weights.\n",
    "* **Neutral band**: adjust `SENTIMENT_NEUTRAL_BAND` (default 0.05).\n",
    "* **Extraction threshold**: change `MIN_ARTICLE_CHARS` (default 200; logic uses 120 in the final gate).\n",
    "* **Max items**: `MAX_HEADLINES`, `MAX_ARTICLES_PER_TICKER`.\n",
    "* **Token budget**: `MAX_TOKENS_PER_ARTICLE` (rough 4 chars/token heuristic).\n",
    "* **Dynamic names**: extend/override `DEFAULT_NSE_INDEX_URLS` or add entries to `EXTRA_NAME_MAP`.\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Troubleshooting\n",
    "\n",
    "* **All zeros / no headlines**\n",
    "\n",
    "  * Your query might be too strict or network is blocked. Try printing raw rows:\n",
    "\n",
    "    ```python\n",
    "    raw_df = pd.concat([fetch_news_for_ticker(\"LUPIN.NS\")], ignore_index=True)\n",
    "    print(raw_df[[\"title\",\"link\",\"allowlisted\"]])\n",
    "    ```\n",
    "  * If allowlist filters out everything, the script **falls back** to returning all publishers.\n",
    "\n",
    "* **`n_articles = 0`**\n",
    "\n",
    "  * Many finance sites are AMP/JS/paywalled; extraction can fail.\n",
    "  * Lower thresholds (`MIN_ARTICLE_CHARS`), ensure optional libs are installed, and rely on RSS **summary fallback** (already enabled).\n",
    "\n",
    "* **NSE CSV errors**\n",
    "\n",
    "  * NSE can be finicky without cookies. The script warms up a session; re-run if a CSV fails transiently.\n",
    "  * You can limit to fewer CSV URLs if needed.\n",
    "\n",
    "* **Model errors**\n",
    "\n",
    "  * If Transformers downloads stall, try `pip install -U transformers` and ensure internet access.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Extending it\n",
    "\n",
    "* **Combine with DMA/RSI screener**\n",
    "  Use `combined_score`/`bias` as a **news gate**: only consider longs where both **technicals** (DMA/RSI) and **news** are bullish.\n",
    "\n",
    "* **Add Bing News RSS fallback**\n",
    "  You can implement a second fetcher to merge Bing RSS results if Google News is sparse.\n",
    "\n",
    "* **Recency within articles**\n",
    "  Weight article paragraphs by detected timestamps or TF-IDF to emphasize fresh info.\n",
    "\n",
    "* **Caching**\n",
    "  Cache `NAME_MAP` (JSON) and news results to speed up repeated runs.\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Notes & disclaimers\n",
    "\n",
    "* This is **for research/education**. It‚Äôs not investment advice. Backtest before live trading.\n",
    "* Respect publishers‚Äô **robots/terms**; avoid aggressive scraping.\n",
    "* Sentiment models can misread sarcasm, corporate wording, or headlines that invert sentiment (e.g., ‚Äúloss narrows‚Äù). Use as one input among many.\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Quick reference (key functions)\n",
    "\n",
    "* `load_name_map_from_nse()` ‚Üí builds `{SYMBOL: Company}` dynamically\n",
    "* `get_company_name(ticker)` ‚Üí returns company name from `NAME_MAP` for `\"LUPIN.NS\"`\n",
    "* `fetch_news_for_ticker(ticker)` ‚Üí DataFrame of news rows for that ticker\n",
    "* `analyze_ticker_news(df_news, ticker)` ‚Üí dict with sentiment & bias for 1 ticker\n",
    "* `build_sentiment_table(tickers)` ‚Üí final table across tickers\n",
    "\n",
    "---\n",
    "\n",
    "Happy screening! If you want, I can add a **CSV export** (e.g., `sentiment_df.to_csv`) or a small **CLI** wrapper (`--tickers`, `--since`) for notebook-free runs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
