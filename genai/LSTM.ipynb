{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e147c0",
   "metadata": {},
   "source": [
    "Here’s a self-contained template that pulls 5-minute OHLCV data, trains an LSTM to predict next-period returns, turns those predictions into long/flat signals, and backtests the signals with **vectorbt**. You can drop this into a Jupyter notebook or a `.py` file—just adjust the `SYMBOL`, date range, look-back window, etc., as needed.\n",
    "\n",
    "---\n",
    "\n",
    "### What’s happening\n",
    "\n",
    "1. **Data download**:\n",
    "   We grab 5-min OHLCV for `SYMBOL` from Yahoo Finance (note: Yahoo only serves up to \\~60 days of intraday data).\n",
    "\n",
    "2. **Preprocessing**:\n",
    "\n",
    "   * **StandardScaler** normalizes the close price for more stable LSTM training.\n",
    "   * We slide a window of `LOOKBACK` bars to build each input sequence.\n",
    "   * The target is the *next* 5-min return.\n",
    "\n",
    "3. **Model**:\n",
    "   A two-layer LSTM with dropout, optimized on mean squared error.\n",
    "\n",
    "4. **Signals**:\n",
    "   We go **long** when the model predicts a positive return, flat otherwise.\n",
    "\n",
    "5. **Backtest**:\n",
    "   Using **vectorbt** at a 5-minute frequency, with 0.1% round-trip fees.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "* **Expand features**: add volume, RSI, momentum, or other technicals into your sequences.\n",
    "* **Hyperparameter tuning**: experiment with look-back length, LSTM units, batch size.\n",
    "* **Walk-forward validation**: roll your train/test windows to avoid overfitting.\n",
    "* **Stop-loss / take-profit** rules: integrate via custom exit signals.\n",
    "\n",
    "Let me know if you run into any issues or want to extend this (e.g., classification thresholding, multi-symbol portfolios, live execution hooks)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356dc76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_84865/3928424749.py:20: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 4642 bars from 2025-04-11 to 2025-07-09\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemank/Documents/github/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 8.6706e-06\n",
      "Epoch 2/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 8.6706e-06\n",
      "Epoch 2/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4651e-04 - val_loss: 2.7440e-06\n",
      "Epoch 3/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4651e-04 - val_loss: 2.7440e-06\n",
      "Epoch 3/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.9805e-05 - val_loss: 5.7172e-06\n",
      "Epoch 4/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.9805e-05 - val_loss: 5.7172e-06\n",
      "Epoch 4/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.6943e-05 - val_loss: 5.8353e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.6943e-05 - val_loss: 5.8353e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.9951e-05 - val_loss: 2.7354e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.9951e-05 - val_loss: 2.7354e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.1495e-05 - val_loss: 3.7196e-06\n",
      "Epoch 7/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.1495e-05 - val_loss: 3.7196e-06\n",
      "Epoch 7/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.4680e-05 - val_loss: 2.7855e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.4680e-05 - val_loss: 2.7855e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.4537e-05 - val_loss: 4.1151e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.4537e-05 - val_loss: 4.1151e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1136e-05 - val_loss: 2.6235e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.1136e-05 - val_loss: 2.6235e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8673e-05 - val_loss: 3.9525e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.8673e-05 - val_loss: 3.9525e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.7619e-05 - val_loss: 5.1824e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.7619e-05 - val_loss: 5.1824e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6441e-05 - val_loss: 3.2929e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6441e-05 - val_loss: 3.2929e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6423e-05 - val_loss: 2.4741e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6423e-05 - val_loss: 2.4741e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.4985e-05 - val_loss: 4.0384e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.4985e-05 - val_loss: 4.0384e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5874e-05 - val_loss: 3.3236e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5874e-05 - val_loss: 3.3236e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.5934e-05 - val_loss: 4.2573e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.5934e-05 - val_loss: 4.2573e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2987e-05 - val_loss: 7.9362e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2987e-05 - val_loss: 7.9362e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.5760e-05 - val_loss: 5.1215e-06\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.5760e-05 - val_loss: 5.1215e-06\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Raw predictions shape: (925, 1)\n",
      "Flattened predictions shape: (925,)\n",
      "Test len: 925 predictions: (925,) closes: (925, 1)\n",
      "Aligned lengths - idx: 925, pred: 925, close: 925\n",
      "Raw predictions shape: (925, 1)\n",
      "Flattened predictions shape: (925,)\n",
      "Test len: 925 predictions: (925,) closes: (925, 1)\n",
      "Aligned lengths - idx: 925, pred: 925, close: 925\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (925, 1) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    100\u001b[39m close_test_aligned = close_test[:min_len]\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAligned lengths - idx: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(idx_test_aligned)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, pred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_pred_aligned)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, close: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(close_test_aligned)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m signals = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mClose\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m    \u001b[49m\u001b[43mclose_test_aligned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpred_ret\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_aligned\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43midx_test_aligned\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m entries = signals[\u001b[33m\"\u001b[39m\u001b[33mpred_ret\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0\u001b[39m\n\u001b[32m    110\u001b[39m exits   = ~entries  \u001b[38;5;66;03m# exit whenever pred_ret ≤ 0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/pandas/core/frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:119\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     arrays, refs = \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \n\u001b[32m    126\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    127\u001b[39m     index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:629\u001b[39m, in \u001b[36m_homogenize\u001b[39m\u001b[34m(data, index, dtype)\u001b[39m\n\u001b[32m    626\u001b[39m         val = \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[32m    627\u001b[39m     val = lib.fast_multiget(val, oindex._values, default=np.nan)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m val = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m com.require_length_match(val, index)\n\u001b[32m    631\u001b[39m refs.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/pandas/core/construction.py:656\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, allow_2d)\u001b[39m\n\u001b[32m    653\u001b[39m             subarr = cast(np.ndarray, subarr)\n\u001b[32m    654\u001b[39m             subarr = maybe_infer_to_datetimelike(subarr)\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m subarr = \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np.ndarray):\n\u001b[32m    659\u001b[39m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[32m    660\u001b[39m     dtype = cast(np.dtype, dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/pandas/core/construction.py:715\u001b[39m, in \u001b[36m_sanitize_ndim\u001b[39m\u001b[34m(result, data, dtype, index, allow_2d)\u001b[39m\n\u001b[32m    713\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[32m    714\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    716\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    717\u001b[39m     )\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[32m    719\u001b[39m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[32m    721\u001b[39m     result = com.asarray_tuplesafe(data, dtype=np.dtype(\u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mValueError\u001b[39m: Data must be 1-dimensional, got ndarray of shape (925, 1) instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import vectorbt as vbt\n",
    "\n",
    "# ────────── 1. PARAMETERS ──────────\n",
    "SYMBOL     = \"AAPL\"     # ticker to backtest\n",
    "PERIOD     = \"60d\"      # last 60 days of 5m data\n",
    "INTERVAL   = \"5m\"\n",
    "LOOKBACK   = 20         # bars per LSTM input sequence\n",
    "TEST_RATIO = 0.2\n",
    "EPOCHS     = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# ────────── 2. FETCH INTRADAY DATA ──────────\n",
    "data = yf.download(\n",
    "    SYMBOL,\n",
    "    period=PERIOD,\n",
    "    interval=INTERVAL,\n",
    "    progress=False\n",
    ")\n",
    "if data.empty:\n",
    "    raise ValueError(\"No intraday data – check your symbol/interval!\")\n",
    "close_series = data[\"Close\"].dropna()  # pandas Series (1-D)\n",
    "print(f\"Fetched {len(close_series)} bars from {close_series.index.min().date()} to {close_series.index.max().date()}\")\n",
    "\n",
    "# ────────── 3. SCALE CLOSE PRICE ──────────\n",
    "scaler    = StandardScaler()\n",
    "# Use .values.reshape(-1,1) to give scaler a 2-D array\n",
    "close_s   = scaler.fit_transform(close_series.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "close_arr  = close_series.values        # shape (N,)\n",
    "scaled_arr = close_s                    # shape (N,)\n",
    "\n",
    "# ────────── 4. BUILD SEQUENCES & TARGETS ──────────\n",
    "seqs, targets, idxs = [], [], []\n",
    "for i in range(LOOKBACK, len(close_arr) - 1):\n",
    "    seqs.append(scaled_arr[i - LOOKBACK : i])               # last LOOKBACK scalars\n",
    "    targets.append((close_arr[i + 1] - close_arr[i]) / close_arr[i])  # next-bar return\n",
    "    idxs.append(close_series.index[i])                      # timestamp\n",
    "\n",
    "X = np.array(seqs).reshape(-1, LOOKBACK, 1)  # (samples, timesteps, features)\n",
    "y = np.array(targets)                        # (samples,)\n",
    "idxs = pd.DatetimeIndex(idxs)\n",
    "\n",
    "# ────────── 5. TRAIN/TEST SPLIT ──────────\n",
    "n_samples = len(X)\n",
    "split     = int(n_samples * (1 - TEST_RATIO))\n",
    "\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "idx_train, idx_test = idxs[:split], idxs[split:]\n",
    "\n",
    "# ────────── 6. DEFINE LSTM MODEL ──────────\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(LOOKBACK, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# ────────── 7. TRAIN WITH EARLY STOPPING ──────────\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ────────── 8. PREDICT & FLATTEN ──────────\n",
    "y_pred_raw = model.predict(X_test)\n",
    "print(f\"Raw predictions shape: {y_pred_raw.shape}\")\n",
    "y_pred = y_pred_raw.flatten()  # Ensure 1D array\n",
    "print(f\"Flattened predictions shape: {y_pred.shape}\")\n",
    "\n",
    "# ────────── 9. BUILD SIGNALS ──────────\n",
    "# Align raw closes with our sequences:\n",
    "close_seq  = close_arr[LOOKBACK : -1]   # drop first LOOKBACK and last bar\n",
    "close_test = close_seq[split:]          # test portion\n",
    "\n",
    "# Verify both are 1-D and same length\n",
    "print(\"Test len:\", len(idx_test), \n",
    "      \"predictions:\", y_pred.shape, \n",
    "      \"closes:\", close_test.shape)\n",
    "\n",
    "# Ensure all arrays have matching lengths\n",
    "min_len = min(len(idx_test), len(y_pred), len(close_test))\n",
    "idx_test_aligned = idx_test[:min_len]\n",
    "y_pred_aligned = y_pred[:min_len]\n",
    "close_test_aligned = close_test[:min_len]\n",
    "\n",
    "print(f\"Aligned lengths - idx: {len(idx_test_aligned)}, pred: {len(y_pred_aligned)}, close: {len(close_test_aligned)}\")\n",
    "\n",
    "signals = pd.DataFrame({\n",
    "    \"Close\":    close_test_aligned,\n",
    "    \"pred_ret\": y_pred_aligned\n",
    "}, index=idx_test_aligned)\n",
    "\n",
    "entries = signals[\"pred_ret\"] > 0\n",
    "exits   = ~entries  # exit whenever pred_ret ≤ 0\n",
    "\n",
    "# ────────── 10. BACKTEST WITH VECTORBT ──────────\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    close=signals[\"Close\"],\n",
    "    entries=entries,\n",
    "    exits=exits,\n",
    "    init_cash=100_000,\n",
    "    fees=0.001,\n",
    "    freq=\"5T\"\n",
    ")\n",
    "\n",
    "# ────────── 11. PERFORMANCE & PLOT ──────────\n",
    "print(\"\\n=== Performance Summary ===\")\n",
    "print(f\"Total Return      : {pf.total_return() * 100:.2f}%\")\n",
    "print(f\"Annualized Return : {pf.annualized_return() * 100:.2f}%\")\n",
    "print(f\"Sharpe Ratio      : {pf.sharpe_ratio():.2f}\")\n",
    "print(f\"Max Drawdown      : {pf.max_drawdown() * 100:.2f}%\")\n",
    "\n",
    "pf.plot().show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
