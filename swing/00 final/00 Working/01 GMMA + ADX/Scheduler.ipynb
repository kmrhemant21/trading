{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4bd2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_89682/819214419.py:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"\n",
      "2025-10-28 22:50:13 | ERROR | HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ^CNX500\"}}}\n",
      "2025-10-28 22:50:13 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-28 22:50:13 | ERROR | ['^CNX500']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "2025-10-28 22:50:13 | INFO | Using benchmark: ^CRSLDX\n",
      "2025-10-28 22:50:13 | INFO | Trading calendar: today=2025-10-28 | next=2025-10-29\n",
      "2025-10-28 22:50:14 | INFO | === SUMMARY (2025-10-28) ===\n",
      "2025-10-28 22:50:14 | INFO | Open positions: 0 | Pending BUY: 0 | Pending SELL: 0\n",
      "2025-10-28 22:50:14 | INFO | No new BUY/SELL scheduled for next session.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "# GMMA+ADX Daily Scheduler — Documentation\n",
    "\n",
    "This doc explains how to use, configure, and operate the **daily scheduler** built on your GMMA+ADX framework. It runs once **after market close (post 15:30 IST)**, generates BUY/SELL recommendations with reasons, and maintains state in CSVs.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) What the scheduler does\n",
    "\n",
    "* **Executes** any previously scheduled orders whose `entry_date == today`:\n",
    "\n",
    "  * `PENDING_BUY` → fills at **today’s Open** → becomes `OPEN`\n",
    "  * `PENDING_SELL` → fills at **today’s Open** → position removed; PnL logged\n",
    "* **Scans exits** for all `OPEN` positions on **today’s daily bar**:\n",
    "\n",
    "  * Priority: **stop**, **target**, then **GMMA break**\n",
    "  * Schedules exit as `PENDING_SELL` for **next business day** (fills at next Open)\n",
    "* **Scans new BUYs** for **today**:\n",
    "\n",
    "  * Signal: **ADX cross above level** AND **all GMMA(short) > all GMMA(long)**\n",
    "  * Filters: within **52-week high threshold**, **VOLAr** ranking\n",
    "  * Respects `max_concurrent_positions`\n",
    "  * Schedules `PENDING_BUY` for **next business day** (fills at next Open)\n",
    "* **Writes**:\n",
    "\n",
    "  * `outputs/positions.csv` (persistent portfolio state)\n",
    "  * `outputs/trades_log.csv` (executed BUY/SELL fills with fees, PnL)\n",
    "  * `outputs/recommendations_YYYYMMDD.csv` (human-readable actions for next session)\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Quick start\n",
    "\n",
    "1. Save the script as `gmma_adx_scheduler.py`.\n",
    "2. Create a universe:\n",
    "\n",
    "   * Either set `CFG.static_symbols = ['RELIANCE.NS', 'TCS.NS', ...]`\n",
    "   * Or keep `CFG.static_symbols_path = \"nifty500.txt\"` (one symbol per line, **use .NS**)\n",
    "3. (Optional) Place NSE holiday dates in `config/nse_holidays_2025.csv` (one `YYYY-MM-DD` per line) and set:\n",
    "\n",
    "   ```python\n",
    "   CFG.holiday_csv = \"config/nse_holidays_2025.csv\"\n",
    "   ```\n",
    "4. Run once after **15:30 IST**:\n",
    "\n",
    "   ```bash\n",
    "   python gmma_adx_scheduler.py\n",
    "   ```\n",
    "5. Check outputs in the `outputs/` folder.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Files & folders\n",
    "\n",
    "```\n",
    "project/\n",
    "├── gmma_adx_scheduler.py\n",
    "├── nifty500.txt                 # your universe (optional)\n",
    "├── config/\n",
    "│   └── nse_holidays_2025.csv    # optional holiday list\n",
    "├── cache/                       # auto-created price cache (per symbol .parquet)\n",
    "└── outputs/\n",
    "    ├── positions.csv\n",
    "    ├── trades_log.csv\n",
    "    └── recommendations_YYYYMMDD.csv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4) CSV schemas\n",
    "\n",
    "### 4.1 `outputs/positions.csv`\n",
    "\n",
    "Tracks current & pending positions.\n",
    "\n",
    "| column      | type      | note                                                          |\n",
    "| ----------- | --------- | ------------------------------------------------------------- |\n",
    "| ticker      | str       | e.g., `RELIANCE.NS`                                           |\n",
    "| status      | str       | `OPEN`, `PENDING_BUY`, `PENDING_SELL`                         |\n",
    "| entry_date  | date      | **Trading date** the order will/was filled (daily index date) |\n",
    "| entry_price | float     | Filled price (Open of `entry_date`) for buys; NaN for pending |\n",
    "| shares      | int       | Rounded down based on allocation                              |\n",
    "| stop_px     | float     | `entry_price * (1 - stop_loss_pct)`                           |\n",
    "| tgt_px      | float     | `entry_price * (1 + target_pct)`                              |\n",
    "| buy_fee     | float     | Fees charged on BUY fill                                      |\n",
    "| notes       | str       | Reason strings & audit info                                   |\n",
    "| created_at  | timestamp | IST timestamp row created                                     |\n",
    "| updated_at  | timestamp | IST timestamp last updated                                    |\n",
    "\n",
    "**Lifecycle**\n",
    "`PENDING_BUY` → (fill next open) → `OPEN` → (exit signal) → `PENDING_SELL` → (fill next open) → removed.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 `outputs/trades_log.csv`\n",
    "\n",
    "Executed BUY/SELL fills (after they actually happen).\n",
    "\n",
    "| column   | type  | note                                                          |\n",
    "| -------- | ----- | ------------------------------------------------------------- |\n",
    "| ticker   | str   | Symbol                                                        |\n",
    "| side     | str   | `BUY` or `SELL`                                               |\n",
    "| date     | date  | Trading date filled (Open)                                    |\n",
    "| price    | float | Fill price                                                    |\n",
    "| shares   | int   | Shares                                                        |\n",
    "| reason   | str   | Why this fill happened                                        |\n",
    "| fees_inr | float | Fees for this leg                                             |\n",
    "| pnl_inr  | float | Net PnL (for SELL) = (sell - buy)*shares - buy_fee - sell_fee |\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 `outputs/recommendations_YYYYMMDD.csv`\n",
    "\n",
    "Human-readable daily plan generated after you run the scheduler.\n",
    "\n",
    "| column          | type | example                                                              |\n",
    "| --------------- | ---- | -------------------------------------------------------------------- |\n",
    "| date            | date | 2025-10-20                                                           |\n",
    "| for_action_date | date | 2025-10-21                                                           |\n",
    "| type            | str  | `BUY (next open)` / `SELL (next open)`                               |\n",
    "| ticker          | str  | `INFY.NS`                                                            |\n",
    "| reason          | str  | `ADX↑>30 & GMMA(short)>GMMA(long); 52w%=91.3%; VOLAr=0.88; ADX=34.6` |\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Configuration guide (key fields)\n",
    "\n",
    "Inside `Config`:\n",
    "\n",
    "* **Data**\n",
    "\n",
    "  * `start_date`, `end_date=None` (uses today)\n",
    "  * `static_symbols` or `static_symbols_path`\n",
    "* **Signals**\n",
    "\n",
    "  * `gmma_short=(3,5,8,10,12,15)`\n",
    "  * `gmma_long=(30,35,40,45,50,60)`\n",
    "  * `adx_len=14`, `adx_cross_level=30.0`\n",
    "  * `within_pct_of_52w_high=0.50` (keep stocks ≥ 50% of 52W high)\n",
    "* **Risk**\n",
    "\n",
    "  * `stop_loss_pct=0.05`, `target_pct=0.10`\n",
    "* **Portfolio**\n",
    "\n",
    "  * `max_concurrent_positions=5`\n",
    "  * `top_k_daily=300` (ranked candidates cap)\n",
    "  * `per_trade_inr=100_000.0` (allocation per new entry)\n",
    "  * `apply_fees=True` (approx Groww-like)\n",
    "* **Calendar**\n",
    "\n",
    "  * `force_today_after_close=True` (use **today** if run after 15:30 IST)\n",
    "  * `market_close_hhmm=\"15:30\"`\n",
    "  * `holiday_csv=None` (optional NSE holidays CSV)\n",
    "* **Liquidity (optional)**\n",
    "\n",
    "  * `enable_basic_liquidity=False`\n",
    "  * `min_price_inr=50.0`, `min_avg_vol_20d=50_000.0`\n",
    "\n",
    "---\n",
    "\n",
    "## 6) How the trading calendar works\n",
    "\n",
    "* When you run after **15:30 IST** and `force_today_after_close=True`, the scheduler sets:\n",
    "\n",
    "  * `signal_day = today (IST)` if it’s a weekday and not a holiday.\n",
    "* It computes `next_td` as the **next business day** (skips weekends + holidays).\n",
    "* This avoids `next=None` even if the benchmark index doesn’t yet include “tomorrow”.\n",
    "\n",
    "**Tip:** If you must run before close, set `force_today_after_close=False` so it uses the last completed benchmark day instead.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Daily run workflow (example)\n",
    "\n",
    "1. **You run** on Mon **2025-10-20** at 17:00 IST.\n",
    "2. The script:\n",
    "\n",
    "   * Fills any orders scheduled for 2025-10-20 at **Open[2025-10-20]**\n",
    "   * Scans **exits** for `OPEN` positions using the 2025-10-20 bar → schedules `PENDING_SELL` for **2025-10-21**\n",
    "   * Scans **new BUYs** for 2025-10-20 → schedules `PENDING_BUY` for **2025-10-21**\n",
    "   * Writes `recommendations_20251020.csv`\n",
    "\n",
    "On Tue **2025-10-21** after close, run again: it will **fill** all `PENDING_*` dated 2025-10-21 at **Open[2025-10-21]**.\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Starting from scratch or migrating\n",
    "\n",
    "* **Fresh start:** Ensure `outputs/positions.csv` does **not** exist; the script will create it.\n",
    "* **Migrating existing positions:** Create `outputs/positions.csv` with your open holdings:\n",
    "\n",
    "  ```\n",
    "  ticker,status,entry_date,entry_price,shares,stop_px,tgt_px,buy_fee,notes,created_at,updated_at\n",
    "  INFY.NS,OPEN,2025-10-10,1650.00,60,1567.50,1815.00,18.50,seed import,2025-10-20T16:05:00,2025-10-20T16:05:00\n",
    "  ```\n",
    "\n",
    "  Missing columns will be auto-added as NaN; fill what you know.\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Scheduling (automation)\n",
    "\n",
    "* **Linux/macOS (cron):**\n",
    "\n",
    "  ```\n",
    "  # Run at 16:05 IST on weekdays\n",
    "  35 10 * * 1-5 /usr/bin/python3 /path/gmma_adx_scheduler.py >> /path/cron.log 2>&1\n",
    "  ```\n",
    "\n",
    "  (10:35 UTC ≈ 16:05 IST; adjust for DST/host TZ.)\n",
    "* **Windows (Task Scheduler):**\n",
    "\n",
    "  * Trigger: Daily at 16:05\n",
    "  * Action: `python.exe` with arguments `C:\\path\\gmma_adx_scheduler.py`\n",
    "\n",
    "---\n",
    "\n",
    "## 10) Common issues & fixes\n",
    "\n",
    "* **`next=None` in logs**\n",
    "  Use the provided script version. It computes next business day independent of benchmark rows.\n",
    "* **No recommendations generated**\n",
    "\n",
    "  * The bar may be incomplete (ran before close). Either run after **15:30 IST** or set `force_today_after_close=False`.\n",
    "  * Your thresholds may be tight (`adx_cross_level`, `within_pct_of_52w_high`). Relax to test.\n",
    "* **Symbols missing data**\n",
    "  Ensure `.NS` suffix. Check `cache/` was written—if a symbol fails from YF it’s skipped.\n",
    "* **Timezone confusion**\n",
    "  Daily bars have **naive** dates; we use **IST clock** for deciding “today” and “next” but keep trading dates naive for indexing consistency.\n",
    "* **Fees look off**\n",
    "  The fee model is an approximation. Tune `calc_fees` as per your broker contract.\n",
    "\n",
    "---\n",
    "\n",
    "## 11) Customization ideas\n",
    "\n",
    "* **Sizing**: Replace `per_trade_inr` with your **MVO sizing + cash cap** (you already have that in your backtester). The place to plug in is where `PENDING_BUY` fills and where BUYs are **scheduled**.\n",
    "* **Additional filters**: Add 200-EMA trend filter, minimum ADV, sector whitelist, etc., inside `day_buy_signals`.\n",
    "* **Different exits**: Add time-based exit, trailing stop, ADX weaken, etc., in `eval_exit_signals`.\n",
    "* **Notifications**: Tail a simple Telegram webhook after writing `recommendations_*.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "## 12) FAQ\n",
    "\n",
    "**Q: Can I run multiple times a day?**\n",
    "A: Yes; only the latest run after close matters. Running pre-close with `force_today_after_close=True` will still try to use “today”, which might lead to acting on an incomplete bar—avoid that; or set it to `False` if you must run earlier.\n",
    "\n",
    "**Q: How do I limit the universe to NIFTY50?**\n",
    "A: Put the 50 symbols in a text file and set `CFG.static_symbols_path` to that file.\n",
    "\n",
    "**Q: What about yfinance limits?**\n",
    "A: The script caches each symbol to `cache/*.parquet`. The scheduler only re-downloads if the last cached date < `end_date`.\n",
    "\n",
    "---\n",
    "\n",
    "## 13) Sanity checklist before going live\n",
    "\n",
    "* [ ] Universe file has **.NS** suffixes\n",
    "* [ ] Holiday CSV configured (optional but recommended)\n",
    "* [ ] `max_concurrent_positions` and `per_trade_inr` align with your risk\n",
    "* [ ] Run once manually after close; inspect `recommendations_*.csv`\n",
    "* [ ] Review `positions.csv` lifecycle after first 2–3 days\n",
    "\n",
    "---\n",
    "\n",
    "Need this tailored to your **MVO sizing** and **deploy-cash cap** like in your backtester? Say the word—I’ll slot that logic into the scheduler while preserving the same CSV state machine.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os, json, math, warnings, logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# =========================\n",
    "# LOGGING\n",
    "# =========================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"gmma_adx_daily_scheduler\")\n",
    "\n",
    "IST = \"Asia/Kolkata\"\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Data\n",
    "    start_date: str = \"2015-01-01\"\n",
    "    end_date: Optional[str] = None  # None => up to today (IST)\n",
    "    static_symbols: Optional[List[str]] = None\n",
    "    static_symbols_path: Optional[str] = None\n",
    "    cache_dir: str = \"cache\"\n",
    "    out_dir: str   = \"outputs\"\n",
    "    plot: bool     = False  # Scheduler doesn't plot\n",
    "\n",
    "    # GMMA\n",
    "    gmma_short: Tuple[int,...] = (3,5,8,10,12,15)\n",
    "    gmma_long:  Tuple[int,...] = (30,35,40,45,50,60)\n",
    "\n",
    "    # ADX\n",
    "    adx_len: int = 14\n",
    "    adx_cross_level: float = 30.0\n",
    "\n",
    "    # Risk management\n",
    "    stop_loss_pct: float = 0.05\n",
    "    target_pct: float    = 0.10\n",
    "\n",
    "    # Portfolio policy (scheduler)\n",
    "    max_concurrent_positions: int = 5\n",
    "    top_k_daily: int = 300\n",
    "    per_trade_inr: float = 100_000.0   # fixed allocation per new entry\n",
    "    apply_fees: bool = True\n",
    "\n",
    "    # Entry/Exit execution model\n",
    "    entry_on_next_open: bool = True\n",
    "    exit_on_next_open: bool = True\n",
    "\n",
    "    # Ranking & filters\n",
    "    benchmark_try: Tuple[str,...] = (\"^CNX500\",\"^CRSLDX\",\"^NSE500\",\"^NIFTY500\",\"^BSE500\",\"^NSEI\")\n",
    "    volar_lookback: int = 252\n",
    "    filter_52w_window: int = 252\n",
    "    within_pct_of_52w_high: float = 0.50\n",
    "\n",
    "    # Liquidity (optional)\n",
    "    enable_basic_liquidity: bool = False\n",
    "    min_price_inr: float = 50.0\n",
    "    min_avg_vol_20d: float = 50_000.0\n",
    "\n",
    "    # Exchange calendar controls (NEW)\n",
    "    force_today_after_close: bool = True\n",
    "    market_close_hhmm: str = \"15:30\"        # IST close\n",
    "    holiday_csv: Optional[str] = None       # CSV of YYYY-MM-DD (NSE holidays)\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# =========================\n",
    "# FEES (Groww-style ballpark)\n",
    "# =========================\n",
    "APPLY_FEES = True\n",
    "def calc_fees(turnover_buy: float, turnover_sell: float) -> float:\n",
    "    if not APPLY_FEES:\n",
    "        return 0.0\n",
    "    BROKER_PCT = 0.001; BROKER_MIN = 5.0; BROKER_CAP = 20.0\n",
    "    STT_PCT = 0.001\n",
    "    STAMP_BUY_PCT = 0.00015\n",
    "    EXCH_PCT = 0.0000297\n",
    "    SEBI_PCT = 0.000001\n",
    "    IPFT_PCT = 0.000001\n",
    "    GST_PCT = 0.18\n",
    "    DP_SELL = 20.0 if turnover_sell >= 100 else 0.0\n",
    "    def _broker(turnover):\n",
    "        if turnover <= 0: return 0.0\n",
    "        fee = turnover * BROKER_PCT\n",
    "        return max(BROKER_MIN, min(fee, BROKER_CAP))\n",
    "    br_buy = _broker(turnover_buy); br_sell = _broker(turnover_sell)\n",
    "    stt = STT_PCT * (turnover_buy + turnover_sell)\n",
    "    stamp = STAMP_BUY_PCT * turnover_buy\n",
    "    misc = (EXCH_PCT + SEBI_PCT + IPFT_PCT) * (turnover_buy + turnover_sell)\n",
    "    gst = GST_PCT * (br_buy + br_sell + misc + DP_SELL)\n",
    "    return float(br_buy + br_sell + stt + stamp + misc + DP_SELL + gst)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def ensure_dirs(*paths):\n",
    "    for p in paths:\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def today_ist_date_str() -> str:\n",
    "    return pd.Timestamp.now(tz=IST).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def load_static_symbols(static_symbols: Optional[List[str]], static_symbols_path: Optional[str]) -> List[str]:\n",
    "    syms: List[str] = []\n",
    "    if static_symbols and len(static_symbols) > 0:\n",
    "        syms = list(static_symbols)\n",
    "    elif static_symbols_path and os.path.exists(static_symbols_path):\n",
    "        with open(static_symbols_path, \"r\") as f:\n",
    "            syms = [line.strip() for line in f if line.strip()]\n",
    "    else:\n",
    "        raise ValueError(\"Provide CFG.static_symbols=[...] (.NS) or CFG.static_symbols_path file.\")\n",
    "    out = []\n",
    "    for s in syms:\n",
    "        s = s.strip().upper()\n",
    "        if not s.endswith(\".NS\"):\n",
    "            s = f\"{s}.NS\"\n",
    "        out.append(s)\n",
    "    uniq = []\n",
    "    seen = set()\n",
    "    for s in out:\n",
    "        if s not in seen:\n",
    "            uniq.append(s); seen.add(s)\n",
    "    return uniq\n",
    "\n",
    "def fetch_prices(tickers: List[str], start: str, end: Optional[str], cache_dir: str) -> Dict[str, pd.DataFrame]:\n",
    "    ensure_dirs(cache_dir)\n",
    "    data = {}\n",
    "    end = end or today_ist_date_str()\n",
    "    for ticker in tickers:\n",
    "        cache_path = os.path.join(cache_dir, f\"{ticker.replace('^', '_')}.parquet\")\n",
    "        use_cache = False\n",
    "        if os.path.exists(cache_path):\n",
    "            try:\n",
    "                df = pd.read_parquet(cache_path)\n",
    "                if len(df) and pd.to_datetime(df.index[-1]).strftime(\"%Y-%m-%d\") >= end:\n",
    "                    data[ticker] = df; use_cache = True\n",
    "            except Exception:\n",
    "                pass\n",
    "        if use_cache:\n",
    "            continue\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end, auto_adjust=True, progress=False, multi_level_index=False)\n",
    "            if df is None or df.empty:\n",
    "                continue\n",
    "            df = df.rename(columns=str.title)[['Open','High','Low','Close','Volume']].dropna()\n",
    "            df.index.name = \"date\"\n",
    "            df.to_parquet(cache_path)\n",
    "            data[ticker] = df\n",
    "        except Exception:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "\n",
    "def _true_range(high: pd.Series, low: pd.Series, prev_close: pd.Series) -> pd.Series:\n",
    "    return pd.concat([(high-low).abs(), (high-prev_close).abs(), (low-prev_close).abs()], axis=1).max(axis=1)\n",
    "\n",
    "def adx(high: pd.Series, low: pd.Series, close: pd.Series, length: int = 14) -> pd.Series:\n",
    "    prev_high, prev_low, prev_close = high.shift(1), low.shift(1), close.shift(1)\n",
    "    up_move, down_move = high - prev_high, prev_low - low\n",
    "    plus_dm  = up_move.where((up_move > down_move) & (up_move > 0), 0.0)\n",
    "    minus_dm = down_move.where((down_move > up_move) & (down_move > 0), 0.0)\n",
    "    tr = _true_range(high, low, prev_close)\n",
    "    alpha = 1.0/length\n",
    "    atr = tr.ewm(alpha=alpha, adjust=False, min_periods=length).mean()\n",
    "    plus_di  = 100 * (plus_dm.ewm(alpha=alpha, adjust=False, min_periods=length).mean() / atr)\n",
    "    minus_di = 100 * (minus_dm.ewm(alpha=alpha, adjust=False, min_periods=length).mean() / atr)\n",
    "    dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di).replace(0, np.nan)\n",
    "    return dx.ewm(alpha=alpha, adjust=False, min_periods=length).mean()\n",
    "\n",
    "def gmma_frames(df: pd.DataFrame, short_p: Tuple[int,...], long_p: Tuple[int,...]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    s = pd.DataFrame({f\"S{p}\": ema(df[\"Close\"], p) for p in short_p}, index=df.index)\n",
    "    l = pd.DataFrame({f\"L{p}\": ema(df[\"Close\"], p) for p in long_p}, index=df.index)\n",
    "    return s, l\n",
    "\n",
    "def compute_indicators(df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    s, l = gmma_frames(out, cfg.gmma_short, cfg.gmma_long)\n",
    "    out = out.join(s).join(l)\n",
    "    out[\"min_short\"] = s.min(axis=1); out[\"max_short\"] = s.max(axis=1)\n",
    "    out[\"min_long\"]  = l.min(axis=1); out[\"max_long\"]  = l.max(axis=1)\n",
    "    out[\"adx\"] = adx(out[\"High\"], out[\"Low\"], out[\"Close\"], cfg.adx_len)\n",
    "    out[\"adx_prev\"] = out[\"adx\"].shift(1)\n",
    "    out[\"avg_vol_20\"] = out[\"Volume\"].rolling(20).mean()\n",
    "    out[\"high_52w\"]   = out[\"Close\"].rolling(cfg.filter_52w_window).max()\n",
    "    return out.dropna()\n",
    "\n",
    "def basic_liquidity_ok(row: pd.Series, cfg: Config) -> bool:\n",
    "    if not cfg.enable_basic_liquidity: return True\n",
    "    if row[\"Close\"] < cfg.min_price_inr: return False\n",
    "    if row[\"avg_vol_20\"] < cfg.min_avg_vol_20d: return False\n",
    "    return True\n",
    "\n",
    "# =========================\n",
    "# Benchmark & VOLAr\n",
    "# =========================\n",
    "def pick_benchmark(benchmarks: Tuple[str,...], start: str, end: Optional[str], cache_dir: str) -> Tuple[str, pd.DataFrame]:\n",
    "    for t in benchmarks:\n",
    "        data = fetch_prices([t], start, end, cache_dir)\n",
    "        df = data.get(t)\n",
    "        if df is not None and not df.empty:\n",
    "            log.info(\"Using benchmark: %s\", t)\n",
    "            return t, df\n",
    "    idx = pd.date_range(start=start, end=end or today_ist_date_str(), freq=\"B\")\n",
    "    df = pd.DataFrame({\"Close\": np.ones(len(idx))}, index=idx)\n",
    "    log.warning(\"No benchmark found; using synthetic flat series.\")\n",
    "    return \"SYNTH_BENCH\", df\n",
    "\n",
    "def compute_volar_scores(end_dt: pd.Timestamp, tickers: List[str], data_map: Dict[str,pd.DataFrame], bench_df: pd.DataFrame, lookback: int) -> Dict[str, float]:\n",
    "    scores = {}\n",
    "    bser = bench_df[\"Close\"].loc[:end_dt].pct_change().dropna().iloc[-lookback:]\n",
    "    for t in tickers:\n",
    "        df = data_map.get(t)\n",
    "        if df is None or df.empty:\n",
    "            scores[t] = 0.0; continue\n",
    "        r = df[\"Close\"].loc[:end_dt].pct_change().dropna().iloc[-lookback:]\n",
    "        common = pd.concat([r, bser], axis=1, keys=[\"s\",\"b\"]).dropna()\n",
    "        if common.shape[0] < max(20, int(0.4*lookback)):\n",
    "            scores[t] = 0.0; continue\n",
    "        excess = common[\"s\"] - common[\"b\"]\n",
    "        vol = common[\"s\"].std(ddof=0)\n",
    "        scores[t] = 0.0 if vol <= 1e-8 else float((excess.mean() / vol) * math.sqrt(252.0))\n",
    "    return scores\n",
    "\n",
    "# =========================\n",
    "# Positions & Trades storage\n",
    "# =========================\n",
    "POS_COLS = [\n",
    "    \"ticker\",\"status\",\"entry_date\",\"entry_price\",\"shares\",\"stop_px\",\"tgt_px\",\n",
    "    \"buy_fee\",\"notes\",\"created_at\",\"updated_at\"\n",
    "]\n",
    "TRD_COLS = [\n",
    "    \"ticker\",\"side\",\"date\",\"price\",\"shares\",\"reason\",\"fees_inr\",\"pnl_inr\"\n",
    "]\n",
    "def positions_path(cfg: Config) -> str:\n",
    "    return os.path.join(cfg.out_dir, \"positions.csv\")\n",
    "def trades_log_path(cfg: Config) -> str:\n",
    "    return os.path.join(cfg.out_dir, \"trades_log.csv\")\n",
    "def recos_path(cfg: Config, dt: pd.Timestamp) -> str:\n",
    "    return os.path.join(cfg.out_dir, f\"recommendations_{pd.Timestamp(dt).strftime('%Y%m%d')}.csv\")\n",
    "\n",
    "def load_positions(cfg: Config) -> pd.DataFrame:\n",
    "    p = positions_path(cfg)\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p)\n",
    "        for c in POS_COLS:\n",
    "            if c not in df.columns:\n",
    "                df[c] = np.nan\n",
    "        # keep trading dates naive (align with yfinance daily index)\n",
    "        df[\"entry_date\"] = pd.to_datetime(df[\"entry_date\"])\n",
    "        df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "        df[\"updated_at\"] = pd.to_datetime(df[\"updated_at\"])\n",
    "        return df[POS_COLS].copy()\n",
    "    return pd.DataFrame(columns=POS_COLS)\n",
    "\n",
    "def save_positions(df: pd.DataFrame, cfg: Config):\n",
    "    df = df.copy()\n",
    "    df.to_csv(positions_path(cfg), index=False)\n",
    "\n",
    "def append_trade_log(rows: List[dict], cfg: Config):\n",
    "    path = trades_log_path(cfg)\n",
    "    if os.path.exists(path):\n",
    "        old = pd.read_csv(path)\n",
    "        new = pd.DataFrame(rows, columns=TRD_COLS)\n",
    "        out = pd.concat([old, new], ignore_index=True)\n",
    "    else:\n",
    "        out = pd.DataFrame(rows, columns=TRD_COLS)\n",
    "    out.to_csv(path, index=False)\n",
    "\n",
    "# =========================\n",
    "# Trading day helpers (robust)\n",
    "# =========================\n",
    "from datetime import time as _time\n",
    "\n",
    "def _load_holidays(path: Optional[str]) -> set:\n",
    "    if not path or not os.path.exists(path):\n",
    "        return set()\n",
    "    s = pd.read_csv(path, header=None)[0].astype(str).str.strip()\n",
    "    return set(pd.to_datetime(s).dt.strftime(\"%Y-%m-%d\").tolist())\n",
    "\n",
    "def _is_business_day(d: pd.Timestamp, holidays: set) -> bool:\n",
    "    # 'd' is naive date (midnight). Weekend check + holiday check.\n",
    "    if d.weekday() >= 5:\n",
    "        return False\n",
    "    return d.strftime(\"%Y-%m-%d\") not in holidays\n",
    "\n",
    "def _next_business_day(d: pd.Timestamp, holidays: set) -> pd.Timestamp:\n",
    "    x = d + pd.Timedelta(days=1)\n",
    "    while not _is_business_day(x, holidays):\n",
    "        x += pd.Timedelta(days=1)\n",
    "    return x\n",
    "\n",
    "def resolve_signal_and_next_days(cfg: Config, bench_df: pd.DataFrame) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Decide 'signal_day' (the day whose signals we evaluate) and 'next_td' (the day on which\n",
    "    pending orders will fill at the open), without requiring the benchmark to contain 'next_td'.\n",
    "    \"\"\"\n",
    "    now_ist = pd.Timestamp.now(tz=IST)\n",
    "    hh, mm = map(int, getattr(cfg, \"market_close_hhmm\", \"15:30\").split(\":\"))\n",
    "    market_closed = now_ist.time() >= _time(hh, mm)\n",
    "\n",
    "    today_naive = pd.to_datetime(now_ist.strftime(\"%Y-%m-%d\"))  # naive date\n",
    "    holidays = _load_holidays(getattr(cfg, \"holiday_csv\", None))\n",
    "\n",
    "    if cfg.force_today_after_close and market_closed and _is_business_day(today_naive, holidays):\n",
    "        signal_day = today_naive\n",
    "    else:\n",
    "        # fallback to last available benchmark day (e.g., before close or non-business day)\n",
    "        signal_day = pd.to_datetime(bench_df.index[-1])\n",
    "\n",
    "    next_td = _next_business_day(signal_day, holidays)\n",
    "    return signal_day, next_td\n",
    "\n",
    "# =========================\n",
    "# Signal logic (one-day scan)\n",
    "# =========================\n",
    "def day_buy_signals(dt: pd.Timestamp, data_map: Dict[str,pd.DataFrame], cfg: Config, bench_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    recs = []\n",
    "    for tkr, df in data_map.items():\n",
    "        if df is None or df.empty or dt not in df.index:\n",
    "            continue\n",
    "        d = compute_indicators(df, cfg)\n",
    "        if dt not in d.index:\n",
    "            continue\n",
    "        row = d.loc[dt]\n",
    "        adx_cross = (row[\"adx_prev\"] <= cfg.adx_cross_level) and (row[\"adx\"] > cfg.adx_cross_level)\n",
    "        long_ok = (row[\"min_short\"] > row[\"max_long\"])\n",
    "        if adx_cross and long_ok and basic_liquidity_ok(row, cfg):\n",
    "            close = float(row[\"Close\"])\n",
    "            high_52w = float(row[\"high_52w\"])\n",
    "            pct_52w = (close / high_52w) if (high_52w and high_52w>0) else np.nan\n",
    "            recs.append({\n",
    "                \"ticker\": tkr,\n",
    "                \"date\": dt,\n",
    "                \"close\": close,\n",
    "                \"high_52w\": high_52w,\n",
    "                \"pct_of_52w\": pct_52w,\n",
    "                \"adx\": float(row[\"adx\"]),\n",
    "                \"min_short\": float(row[\"min_short\"]),\n",
    "                \"max_long\": float(row[\"max_long\"]),\n",
    "                \"signal_reason\": f\"ADX↑>{cfg.adx_cross_level:.0f} & GMMA(short)>GMMA(long)\"\n",
    "            })\n",
    "    out = pd.DataFrame(recs)\n",
    "    if out.empty:\n",
    "        return out\n",
    "\n",
    "    # 52w filter\n",
    "    out = out[out[\"pct_of_52w\"] >= cfg.within_pct_of_52w_high].copy()\n",
    "    if out.empty:\n",
    "        return out\n",
    "\n",
    "    # VOLAr ranking\n",
    "    tickers = out[\"ticker\"].tolist()\n",
    "    volar = compute_volar_scores(dt, tickers, data_map, bench_df, cfg.volar_lookback)\n",
    "    out[\"volar\"] = out[\"ticker\"].map(volar)\n",
    "    out = out.sort_values([\"volar\",\"adx\",\"pct_of_52w\"], ascending=[False, False, False]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def eval_exit_signals(dt: pd.Timestamp, pos_df: pd.DataFrame, data_map: Dict[str,pd.DataFrame], cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each OPEN position, check if today's bar generates an exit signal.\n",
    "    Exit is scheduled for next trading day (next open fill).\n",
    "    Priorities: stop/target hit (today's H/L), else GMMA break.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for _, pos in pos_df[pos_df[\"status\"]==\"OPEN\"].iterrows():\n",
    "        tkr = pos[\"ticker\"]\n",
    "        df = data_map.get(tkr)\n",
    "        if df is None or df.empty or dt not in df.index:\n",
    "            continue\n",
    "        ind = compute_indicators(df, cfg)\n",
    "        if dt not in ind.index:\n",
    "            continue\n",
    "        row = ind.loc[dt]\n",
    "        today = df.loc[dt]\n",
    "\n",
    "        entry_px = float(pos[\"entry_price\"])\n",
    "        stop_px  = float(pos[\"stop_px\"])\n",
    "        tgt_px   = float(pos[\"tgt_px\"])\n",
    "\n",
    "        hit = None\n",
    "        if (today[\"Low\"] <= stop_px) and (today[\"High\"] >= tgt_px):\n",
    "            hit = (\"SELL\", \"target\")\n",
    "        elif today[\"Low\"] <= stop_px:\n",
    "            hit = (\"SELL\", \"stop\")\n",
    "        elif today[\"High\"] >= tgt_px:\n",
    "            hit = (\"SELL\", \"target\")\n",
    "        elif not (row[\"min_short\"] > row[\"max_long\"]):\n",
    "            hit = (\"SELL\", \"gmma_break\")\n",
    "\n",
    "        if hit is not None:\n",
    "            rows.append({\n",
    "                \"ticker\": tkr,\n",
    "                \"side\": hit[0],\n",
    "                \"signal_date\": dt,\n",
    "                \"reason\": hit[1],\n",
    "                \"note\": f\"Exit scheduled next open: {hit[1]} | entry={entry_px:.2f}, stop={stop_px:.2f}, tgt={tgt_px:.2f}\"\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# =========================\n",
    "# Fees helpers\n",
    "# =========================\n",
    "def fee_for_buy(turnover: float) -> float: return calc_fees(turnover, 0.0)\n",
    "def fee_for_sell(turnover: float) -> float: return calc_fees(0.0, turnover)\n",
    "\n",
    "# =========================\n",
    "# Scheduler main\n",
    "# =========================\n",
    "def scheduler_run(cfg: Config):\n",
    "    ensure_dirs(cfg.cache_dir, cfg.out_dir)\n",
    "    global APPLY_FEES\n",
    "    APPLY_FEES = bool(cfg.apply_fees)\n",
    "\n",
    "    # Universe & data\n",
    "    symbols = load_static_symbols(cfg.static_symbols, cfg.static_symbols_path)\n",
    "    sym_set = set(symbols)\n",
    "\n",
    "    # Pull prices\n",
    "    data_map = fetch_prices(symbols, cfg.start_date, cfg.end_date, cfg.cache_dir)\n",
    "\n",
    "    # Benchmark for calendar reference\n",
    "    bench_tkr, bench_df = pick_benchmark(cfg.benchmark_try, cfg.start_date, cfg.end_date, cfg.cache_dir)\n",
    "    if bench_df is None or bench_df.empty:\n",
    "        raise RuntimeError(\"No benchmark data to determine trading days.\")\n",
    "\n",
    "    # Resolve robust dates (FIXED)\n",
    "    today_td, next_td = resolve_signal_and_next_days(cfg, bench_df)\n",
    "    log.info(\"Trading calendar: today=%s | next=%s\", today_td.date(), next_td.date())\n",
    "\n",
    "    # Load or init positions\n",
    "    pos = load_positions(cfg)\n",
    "    now_ts = pd.Timestamp.now(tz=IST)\n",
    "\n",
    "    # Drop symbols no longer in universe (optional)\n",
    "    if not pos.empty:\n",
    "        pos = pos[pos[\"ticker\"].isin(sym_set)].copy()\n",
    "\n",
    "    # 1) EXECUTE pending orders whose date == today_td\n",
    "    executed_trades = []\n",
    "\n",
    "    # PENDING_BUY -> fill at today's Open\n",
    "    pend_buy = pos[(pos[\"status\"]==\"PENDING_BUY\") & (pos[\"entry_date\"]==today_td)].copy()\n",
    "    for i, r in pend_buy.iterrows():\n",
    "        tkr = r[\"ticker\"]; df = data_map.get(tkr)\n",
    "        if df is None or df.empty or today_td not in df.index:\n",
    "            continue\n",
    "        px = float(df.loc[today_td, \"Open\"])\n",
    "        shares = int(max(1, math.floor(float(cfg.per_trade_inr) / px)))\n",
    "        buy_turn = shares * px\n",
    "        fee = fee_for_buy(buy_turn)\n",
    "        stop_px = px * (1 - cfg.stop_loss_pct)\n",
    "        tgt_px  = px * (1 + cfg.target_pct)\n",
    "        pos.loc[i, [\"status\",\"entry_price\",\"shares\",\"stop_px\",\"tgt_px\",\"buy_fee\",\"updated_at\"]] = \\\n",
    "            [\"OPEN\", px, shares, stop_px, tgt_px, fee, now_ts]\n",
    "        executed_trades.append({\n",
    "            \"ticker\": tkr, \"side\":\"BUY\", \"date\": today_td, \"price\": px, \"shares\": shares,\n",
    "            \"reason\": \"filled pending BUY at next open\", \"fees_inr\": fee, \"pnl_inr\": 0.0\n",
    "        })\n",
    "        log.info(\"FILLED BUY  %-12s @ %.2f sh=%d (fee %.2f) -> OPEN\", tkr, px, shares, fee)\n",
    "\n",
    "    # PENDING_SELL -> fill at today's Open; remove from positions\n",
    "    pend_sell = pos[(pos[\"status\"]==\"PENDING_SELL\") & (pos[\"entry_date\"]==today_td)].copy()\n",
    "    rows_to_drop = []\n",
    "    for i, r in pend_sell.iterrows():\n",
    "        tkr = r[\"ticker\"]; df = data_map.get(tkr)\n",
    "        if df is None or df.empty or today_td not in df.index:\n",
    "            continue\n",
    "        px = float(df.loc[today_td, \"Open\"])\n",
    "        shares = int(r[\"shares\"])\n",
    "        sell_turn = shares * px\n",
    "        fee = fee_for_sell(sell_turn)\n",
    "        buy_fee = float(r.get(\"buy_fee\", 0.0))\n",
    "        pnl = (px - float(r[\"entry_price\"])) * shares - buy_fee - fee\n",
    "        executed_trades.append({\n",
    "            \"ticker\": tkr, \"side\":\"SELL\", \"date\": today_td, \"price\": px, \"shares\": shares,\n",
    "            \"reason\": r.get(\"notes\",\"filled pending SELL at next open\"), \"fees_inr\": fee, \"pnl_inr\": pnl\n",
    "        })\n",
    "        rows_to_drop.append(i)\n",
    "        log.info(\"FILLED SELL %-12s @ %.2f sh=%d (fee %.2f) -> CLOSED | net PnL=%.2f\", tkr, px, shares, fee, pnl)\n",
    "    if rows_to_drop:\n",
    "        pos = pos.drop(index=rows_to_drop).reset_index(drop=True)\n",
    "\n",
    "    if executed_trades:\n",
    "        append_trade_log(executed_trades, cfg)\n",
    "\n",
    "    # 2) EVALUATE exits for all OPEN positions on today_td -> schedule PENDING_SELL for next_td\n",
    "    exit_signals = eval_exit_signals(today_td, pos, data_map, cfg)\n",
    "    planned_exits = []\n",
    "    if (exit_signals is not None) and (not exit_signals.empty):\n",
    "        for _, sig in exit_signals.iterrows():\n",
    "            tkr = sig[\"ticker\"]\n",
    "            idx = pos[(pos[\"ticker\"]==tkr) & (pos[\"status\"]==\"OPEN\")].index\n",
    "            if len(idx)==0:\n",
    "                continue\n",
    "            i = idx[0]\n",
    "            pos.loc[i, [\"status\",\"entry_date\",\"updated_at\",\"notes\"]] = \\\n",
    "                [\"PENDING_SELL\", next_td, now_ts, sig[\"note\"]]\n",
    "            planned_exits.append({\n",
    "                \"type\": \"SELL\",\n",
    "                \"ticker\": tkr,\n",
    "                \"for_date\": next_td,\n",
    "                \"reason\": sig[\"reason\"],\n",
    "                \"note\": sig[\"note\"]\n",
    "            })\n",
    "            log.info(\"SCHEDULE SELL %-12s on %s | %s\", tkr, str(next_td.date()), sig[\"note\"])\n",
    "\n",
    "    # 3) SCAN new BUY signals today -> schedule PENDING_BUY for next_td (respect slots)\n",
    "    open_count = (pos[\"status\"]==\"OPEN\").sum()\n",
    "    pending_buy_count = (pos[\"status\"]==\"PENDING_BUY\").sum()\n",
    "    slots_left = max(0, int(cfg.max_concurrent_positions) - int(open_count) - int(pending_buy_count))\n",
    "    planned_buys = []\n",
    "    if slots_left > 0:\n",
    "        buys = day_buy_signals(today_td, data_map, cfg, bench_df)\n",
    "        if (buys is not None) and (not buys.empty):\n",
    "            # exclude already held/pending\n",
    "            held = set(pos[pos[\"status\"].isin([\"OPEN\",\"PENDING_BUY\"])][\"ticker\"].tolist())\n",
    "            buys = buys[~buys[\"ticker\"].isin(held)].reset_index(drop=True)\n",
    "            if not buys.empty:\n",
    "                select = buys.head(min(cfg.top_k_daily, slots_left)).copy()\n",
    "                for _, r in select.iterrows():\n",
    "                    tkr = r[\"ticker\"]\n",
    "                    reason = f\"{r['signal_reason']}; 52w%={r['pct_of_52w']:.1%}; VOLAr={r['volar']:.2f}; ADX={r['adx']:.1f}\"\n",
    "                    pos = pd.concat([pos, pd.DataFrame([{\n",
    "                        \"ticker\": tkr,\n",
    "                        \"status\": \"PENDING_BUY\",\n",
    "                        \"entry_date\": next_td,  # will fill next open\n",
    "                        \"entry_price\": np.nan,\n",
    "                        \"shares\": np.nan,\n",
    "                        \"stop_px\": np.nan,\n",
    "                        \"tgt_px\": np.nan,\n",
    "                        \"buy_fee\": np.nan,\n",
    "                        \"notes\": reason,\n",
    "                        \"created_at\": now_ts,\n",
    "                        \"updated_at\": now_ts\n",
    "                    }])], ignore_index=True)\n",
    "                    planned_buys.append({\n",
    "                        \"type\":\"BUY\",\n",
    "                        \"ticker\": tkr,\n",
    "                        \"for_date\": next_td,\n",
    "                        \"reason\": reason\n",
    "                    })\n",
    "                    log.info(\"SCHEDULE BUY  %-12s on %s | %s\", tkr, str(next_td.date()), reason)\n",
    "\n",
    "    # 4) Persist artifacts\n",
    "    ensure_dirs(cfg.out_dir)\n",
    "    save_positions(pos, cfg)\n",
    "\n",
    "    # Human-friendly daily recommendations CSV\n",
    "    reco_rows = []\n",
    "    for b in planned_buys:\n",
    "        reco_rows.append({\n",
    "            \"date\": today_td.date(),\n",
    "            \"for_action_date\": b[\"for_date\"].date(),\n",
    "            \"type\": \"BUY (next open)\",\n",
    "            \"ticker\": b[\"ticker\"],\n",
    "            \"reason\": b[\"reason\"]\n",
    "        })\n",
    "    for e in planned_exits:\n",
    "        reco_rows.append({\n",
    "            \"date\": today_td.date(),\n",
    "            \"for_action_date\": e[\"for_date\"].date(),\n",
    "            \"type\": \"SELL (next open)\",\n",
    "            \"ticker\": e[\"ticker\"],\n",
    "            \"reason\": f\"{e['reason']}: {e['note']}\"\n",
    "        })\n",
    "    recos = pd.DataFrame(reco_rows, columns=[\"date\",\"for_action_date\",\"type\",\"ticker\",\"reason\"])\n",
    "    recos.to_csv(recos_path(cfg, today_td), index=False)\n",
    "\n",
    "    # 5) Console summary\n",
    "    log.info(\"=== SUMMARY (%s) ===\", str(today_td.date()))\n",
    "    log.info(\"Open positions: %d | Pending BUY: %d | Pending SELL: %d\",\n",
    "             int((pos['status']=='OPEN').sum()), int((pos['status']=='PENDING_BUY').sum()), int((pos['status']=='PENDING_SELL').sum()))\n",
    "    if not recos.empty:\n",
    "        log.info(\"Recommendations saved -> %s\", recos_path(cfg, today_td))\n",
    "    else:\n",
    "        log.info(\"No new BUY/SELL scheduled for next session.\")\n",
    "\n",
    "def main():\n",
    "    # === Configure your universe here ===\n",
    "    # Example:\n",
    "    # CFG.static_symbols = ['RELIANCE.NS','TCS.NS','HDFCBANK.NS','INFY.NS','ICICIBANK.NS']\n",
    "    CFG.static_symbols_path = \"nifty500.txt\"  # or comment the line above and use static_symbols\n",
    "\n",
    "    # Optional: NSE holidays CSV (YYYY-MM-DD one per line)\n",
    "    # CFG.holiday_csv = \"config/nse_holidays_2025.csv\"\n",
    "\n",
    "    scheduler_run(CFG)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
