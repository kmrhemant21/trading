{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce83567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 19:20:17 | ERROR | HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ^CNX500\"}}}\n",
      "2025-10-14 19:20:18 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-14 19:20:18 | ERROR | ['^CNX500']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "2025-10-14 19:20:19 | ERROR | HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ^NIFTY500\"}}}\n",
      "2025-10-14 19:20:19 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-14 19:20:19 | ERROR | ['^NIFTY500']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "2025-10-14 19:20:19 | INFO | Using benchmark: ^CRSLDX\n",
      "2025-10-14 19:20:29 | INFO | Wrote plan → outputs/plan_20251014.csv\n",
      "2025-10-14 19:20:29 | INFO | Open positions snapshot → outputs/open_positions.csv\n",
      "2025-10-14 19:20:29 | INFO | Cash: 200000.00 | Open positions: 0 | Pending orders: 0 | New plan rows: 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Daily EOD Scheduler — Supertrend(10,3) + RSI(14) + RS(55) + optional EMA200\n",
    "\n",
    "How it works (EOD cadence):\n",
    "1) Loads persistent state (open positions, pending orders) from ./state/positions.json\n",
    "2) Fetches OHLCV for your universe + benchmark (yfinance, auto_adjust=True).\n",
    "3) Promotes any PENDING orders whose planned date has arrived:\n",
    "     - BUY: fill at that session's Open -> becomes an open position; SL/TP set.\n",
    "     - SELL: fill at that session's Open -> position closed; execution recorded.\n",
    "4) On the most recent completed bar (D0), generates:\n",
    "     - New BUY signals (for next session open), unless already held or pending.\n",
    "     - Exit signals (for next session open) for currently held positions:\n",
    "         • If D0 High ≥ TP or Low ≤ SL  ⇒ schedule SELL next open (priority configurable)\n",
    "         • Else if indicator exit (ST red or RS<0 or RSI<60) ⇒ schedule SELL next open.\n",
    "5) Saves:\n",
    "     - ./outputs/plan_YYYYMMDD.csv   (orders to place next session)\n",
    "     - ./outputs/executions.csv       (append-only fills history)\n",
    "     - ./outputs/open_positions.csv   (snapshot of current holdings)\n",
    "     - ./state/positions.json         (persistent state)\n",
    "\"\"\"\n",
    "\n",
    "import os, json, math, warnings, logging\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# =========================\n",
    "# LOGGING\n",
    "# =========================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%-Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"daily_scheduler_supertrend_rsi_rs55\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG (no CLI; edit here)\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Data window\n",
    "    start_date: str = \"2015-01-01\"\n",
    "    end_date: Optional[str] = None  # None = today India\n",
    "    max_lookback_days: int = 600    # fetch recent to speed up\n",
    "\n",
    "    # Universe ('.NS' suffix expected; add more tickers or set from file)\n",
    "    static_symbols: List[str] = None\n",
    "    static_symbols_path: Optional[str] = None\n",
    "\n",
    "    # Benchmark for RS(55) Mansfield (tries these in order)\n",
    "    benchmark_try: Tuple[str,...] = (\"^CNX500\",\"^NIFTY500\",\"^CRSLDX\",\"^BSE500\",\"^NSE500\",\"^NSEI\")\n",
    "\n",
    "    # Indicators / Strategy\n",
    "    rsi_len: int = 14\n",
    "    rs_lookback: int = 55\n",
    "    st_atr_len: int = 10\n",
    "    st_mult: float = 3.0\n",
    "    use_ema200_filter: bool = True\n",
    "    ema200_len: int = 200\n",
    "\n",
    "    # Entry/Exit thresholds\n",
    "    rsi_entry_min: float = 60.0\n",
    "    rsi_exit_min: float  = 60.0\n",
    "    rs_zero: float = 0.0  # >0 to enter, <0 to exit\n",
    "\n",
    "    # Risk management\n",
    "    stop_loss_pct: float = 0.05   # 5% hard stop\n",
    "    target_pct: float    = 0.10   # 10% hard target\n",
    "    stop_target_priority: str = \"stop_first\"  # or \"target_first\"\n",
    "\n",
    "    # Portfolio sizing (simple)\n",
    "    capital_inr: float = 200_000.0\n",
    "    per_trade_inr: float = 50_000.0  # fixed allocation per new entry\n",
    "    max_concurrent_positions: int = 4\n",
    "    top_k_daily: int = 5             # cap number of new entries per day\n",
    "\n",
    "    # Optional universe filters for new entries\n",
    "    within_pct_of_52w_high: float = 0.70\n",
    "    filter_52w_window: int = 252\n",
    "    min_price_inr: float = 50.0\n",
    "    min_avg_vol_20d: float = 50_000.0\n",
    "    enable_basic_liquidity: bool = False\n",
    "\n",
    "    # Paths\n",
    "    cache_dir: str = \"cache\"\n",
    "    out_dir: str   = \"outputs\"\n",
    "    state_dir: str = \"state\"\n",
    "\n",
    "CFG = Config(\n",
    "    static_symbols= ['360ONE.NS', '3MINDIA.NS', 'AADHARHFC.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ABB.NS', 'ABBOTINDIA.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'ABLBL.NS', 'ABREL.NS', 'ABSLAMC.NS', 'ACC.NS', 'ACE.NS', 'ACMESOLAR.NS', 'ADANIENSOL.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'AEGISLOG.NS', 'AEGISVOPAK.NS', 'AFCONS.NS', 'AFFLE.NS', 'AGARWALEYE.NS', 'AIAENG.NS', 'AIIL.NS', 'AJANTPHARM.NS', 'AKUMS.NS', 'AKZOINDIA.NS', 'ALKEM.NS', 'ALKYLAMINE.NS', 'ALOKINDS.NS', 'AMBER.NS', 'AMBUJACEM.NS', 'ANANDRATHI.NS', 'ANANTRAJ.NS', 'ANGELONE.NS', 'APARINDS.NS', 'APLAPOLLO.NS', 'APLLTD.NS', 'APOLLOHOSP.NS', 'APOLLOTYRE.NS', 'APTUS.NS', 'ARE&M.NS', 'ASAHIINDIA.NS', 'ASHOKLEY.NS', 'ASIANPAINT.NS', 'ASTERDM.NS', 'ASTRAL.NS', 'ASTRAZEN.NS', 'ATGL.NS', 'ATHERENERG.NS', 'ATUL.NS', 'AUBANK.NS', 'AUROPHARMA.NS', 'AWL.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJAJFINSV.NS', 'BAJAJHFL.NS', 'BAJAJHLDNG.NS', 'BAJFINANCE.NS', 'BALKRISIND.NS', 'BALRAMCHIN.NS', 'BANDHANBNK.NS', 'BANKBARODA.NS', 'BANKINDIA.NS', 'BASF.NS', 'BATAINDIA.NS', 'BAYERCROP.NS', 'BBTC.NS', 'BDL.NS', 'BEL.NS', 'BEML.NS', 'BERGEPAINT.NS', 'BHARATFORG.NS', 'BHARTIARTL.NS', 'BHARTIHEXA.NS', 'BHEL.NS', 'BIKAJI.NS', 'BIOCON.NS', 'BLS.NS', 'BLUEDART.NS', 'BLUEJET.NS', 'BLUESTARCO.NS', 'BOSCHLTD.NS', 'BPCL.NS', 'BRIGADE.NS', 'BRITANNIA.NS', 'BSE.NS', 'BSOFT.NS', 'CAMPUS.NS', 'CAMS.NS', 'CANBK.NS', 'CANFINHOME.NS', 'CAPLIPOINT.NS', 'CARBORUNIV.NS', 'CASTROLIND.NS', 'CCL.NS', 'CDSL.NS', 'CEATLTD.NS', 'CENTRALBK.NS', 'CENTURYPLY.NS', 'CERA.NS', 'CESC.NS', 'CGCL.NS', 'CGPOWER.NS', 'CHALET.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CHOICEIN.NS', 'CHOLAFIN.NS', 'CHOLAHLDNG.NS', 'CIPLA.NS', 'CLEAN.NS', 'COALINDIA.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COHANCE.NS', 'COLPAL.NS', 'CONCOR.NS', 'CONCORDBIO.NS', 'COROMANDEL.NS', 'CRAFTSMAN.NS', 'CREDITACC.NS', 'CRISIL.NS', 'CROMPTON.NS', 'CUB.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DALBHARAT.NS', 'DATAPATTNS.NS', 'DBREALTY.NS', 'DCMSHRIRAM.NS', 'DEEPAKFERT.NS', 'DEEPAKNTR.NS', 'DELHIVERY.NS', 'DEVYANI.NS', 'DIVISLAB.NS', 'DIXON.NS', 'DLF.NS', 'DMART.NS', 'DOMS.NS', 'DRREDDY.NS', 'ECLERX.NS', 'EICHERMOT.NS', 'EIDPARRY.NS', 'EIHOTEL.NS', 'ELECON.NS', 'ELGIEQUIP.NS', 'EMAMILTD.NS', 'EMCURE.NS', 'ENDURANCE.NS', 'ENGINERSIN.NS', 'ENRIN.NS', 'ERIS.NS', 'ESCORTS.NS', 'ETERNAL.NS', 'EXIDEIND.NS', 'FACT.NS', 'FEDERALBNK.NS', 'FINCABLES.NS', 'FINPIPE.NS', 'FIRSTCRY.NS', 'FIVESTAR.NS', 'FLUOROCHEM.NS', 'FORCEMOT.NS', 'FORTIS.NS', 'FSL.NS', 'GAIL.NS', 'GESHIP.NS', 'GICRE.NS', 'GILLETTE.NS', 'GLAND.NS', 'GLAXO.NS', 'GLENMARK.NS', 'GMDCLTD.NS', 'GMRAIRPORT.NS', 'GODFRYPHLP.NS', 'GODIGIT.NS', 'GODREJAGRO.NS', 'GODREJCP.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GPIL.NS', 'GRANULES.NS', 'GRAPHITE.NS', 'GRASIM.NS', 'GRAVITA.NS', 'GRSE.NS', 'GSPL.NS', 'GUJGASLTD.NS', 'GVT&D.NS', 'HAL.NS', 'HAPPSTMNDS.NS', 'HAVELLS.NS', 'HBLENGINE.NS', 'HCLTECH.NS', 'HDFCAMC.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEG.NS', 'HEROMOTOCO.NS', 'HEXT.NS', 'HFCL.NS', 'HINDALCO.NS', 'HINDCOPPER.NS', 'HINDPETRO.NS', 'HINDUNILVR.NS', 'HINDZINC.NS', 'HOMEFIRST.NS', 'HONASA.NS', 'HONAUT.NS', 'HSCL.NS', 'HUDCO.NS', 'HYUNDAI.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'IDBI.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFCI.NS', 'IGIL.NS', 'IGL.NS', 'IIFL.NS', 'IKS.NS', 'INDGN.NS', 'INDHOTEL.NS', 'INDIACEM.NS', 'INDIAMART.NS', 'INDIANB.NS', 'INDIGO.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INFY.NS', 'INOXINDIA.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'IOB.NS', 'IOC.NS', 'IPCALAB.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'IREDA.NS', 'IRFC.NS', 'ITC.NS', 'ITCHOTELS.NS', 'ITI.NS', 'J&KBANK.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JINDALSAW.NS', 'JINDALSTEL.NS', 'JIOFIN.NS', 'JKCEMENT.NS', 'JKTYRE.NS', 'JMFINANCIL.NS', 'JPPOWER.NS', 'JSL.NS', 'JSWENERGY.NS', 'JSWINFRA.NS', 'JSWSTEEL.NS', 'JUBLFOOD.NS', 'JUBLINGREA.NS', 'JUBLPHARMA.NS', 'JWL.NS', 'JYOTHYLAB.NS', 'JYOTICNC.NS', 'KAJARIACER.NS', 'KALYANKJIL.NS', 'KARURVYSYA.NS', 'KAYNES.NS', 'KEC.NS', 'KEI.NS', 'KFINTECH.NS', 'KIMS.NS', 'KIRLOSBROS.NS', 'KIRLOSENG.NS', 'KOTAKBANK.NS', 'KPIL.NS', 'KPITTECH.NS', 'KPRMILL.NS', 'KSB.NS', 'LALPATHLAB.NS', 'LATENTVIEW.NS', 'LAURUSLABS.NS', 'LEMONTREE.NS', 'LICHSGFIN.NS', 'LICI.NS', 'LINDEINDIA.NS', 'LLOYDSME.NS', 'LODHA.NS', 'LT.NS', 'LTF.NS', 'LTFOODS.NS', 'LTIM.NS', 'LTTS.NS', 'LUPIN.NS', 'M&M.NS', 'M&MFIN.NS', 'MAHABANK.NS', 'MAHSCOOTER.NS', 'MAHSEAMLES.NS', 'MANAPPURAM.NS', 'MANKIND.NS', 'MANYAVAR.NS', 'MAPMYINDIA.NS', 'MARICO.NS', 'MARUTI.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MCX.NS', 'MEDANTA.NS', 'METROPOLIS.NS', 'MFSL.NS', 'MGL.NS', 'MINDACORP.NS', 'MMTC.NS', 'MOTHERSON.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MRF.NS', 'MRPL.NS', 'MSUMI.NS', 'MUTHOOTFIN.NS', 'NAM-INDIA.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAUKRI.NS', 'NAVA.NS', 'NAVINFLUOR.NS', 'NBCC.NS', 'NCC.NS', 'NESTLEIND.NS', 'NETWEB.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NH.NS', 'NHPC.NS', 'NIACL.NS', 'NIVABUPA.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NSLNISP.NS', 'NTPC.NS', 'NTPCGREEN.NS', 'NUVAMA.NS', 'NUVOCO.NS', 'NYKAA.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLAELEC.NS', 'OLECTRA.NS', 'ONESOURCE.NS', 'ONGC.NS', 'PAGEIND.NS', 'PATANJALI.NS', 'PAYTM.NS', 'PCBL.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PFC.NS', 'PFIZER.NS', 'PGEL.NS', 'PGHH.NS', 'PHOENIXLTD.NS', 'PIDILITIND.NS', 'PIIND.NS', 'PNB.NS', 'PNBHOUSING.NS', 'POLICYBZR.NS', 'POLYCAB.NS', 'POLYMED.NS', 'POONAWALLA.NS', 'POWERGRID.NS', 'POWERINDIA.NS', 'PPLPHARMA.NS', 'PRAJIND.NS', 'PREMIERENE.NS', 'PRESTIGE.NS', 'PTCIL.NS', 'PVRINOX.NS', 'RADICO.NS', 'RAILTEL.NS', 'RAINBOW.NS', 'RAMCOCEM.NS', 'RBLBANK.NS', 'RCF.NS', 'RECLTD.NS', 'REDINGTON.NS', 'RELIANCE.NS', 'RELINFRA.NS', 'RHIM.NS', 'RITES.NS', 'RKFORGE.NS', 'RPOWER.NS', 'RRKABEL.NS', 'RVNL.NS', 'SAGILITY.NS', 'SAIL.NS', 'SAILIFE.NS', 'SAMMAANCAP.NS', 'SAPPHIRE.NS', 'SARDAEN.NS', 'SAREGAMA.NS', 'SBFC.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SBIN.NS', 'SCHAEFFLER.NS', 'SCHNEIDER.NS', 'SCI.NS', 'SHREECEM.NS', 'SHRIRAMFIN.NS', 'SHYAMMETL.NS', 'SIEMENS.NS', 'SIGNATURE.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SOBHA.NS', 'SOLARINDS.NS', 'SONACOMS.NS', 'SONATSOFTW.NS', 'SRF.NS', 'STARHEALTH.NS', 'SUMICHEM.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUNPHARMA.NS', 'SUNTV.NS', 'SUPREMEIND.NS', 'SUZLON.NS', 'SWANCORP.NS', 'SWIGGY.NS', 'SYNGENE.NS', 'SYRMA.NS', 'TARIL.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATACONSUM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TATATECH.NS', 'TBOTEK.NS', 'TCS.NS', 'TECHM.NS', 'TECHNOE.NS', 'TEJASNET.NS', 'THELEELA.NS', 'THERMAX.NS', 'TIINDIA.NS', 'TIMKEN.NS', 'TITAGARH.NS', 'TITAN.NS', 'TORNTPHARM.NS', 'TORNTPOWER.NS', 'TRENT.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'TRIVENI.NS', 'TTML.NS', 'TVSMOTOR.NS', 'UBL.NS', 'UCOBANK.NS', 'ULTRACEMCO.NS', 'UNIONBANK.NS', 'UNITDSPR.NS', 'UNOMINDA.NS', 'UPL.NS', 'USHAMART.NS', 'UTIAMC.NS', 'VBL.NS', 'VEDL.NS', 'VENTIVE.NS', 'VGUARD.NS', 'VIJAYA.NS', 'VMM.NS', 'VOLTAS.NS', 'VTL.NS', 'WAAREEENER.NS', 'WELCORP.NS', 'WELSPUNLIV.NS', 'WHIRLPOOL.NS', 'WIPRO.NS', 'WOCKPHARMA.NS', 'YESBANK.NS', 'ZEEL.NS', 'ZENSARTECH.NS', 'ZENTEC.NS', 'ZFCVINDIA.NS', 'ZYDUSLIFE.NS']\n",
    "\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# FEES (simple, optional)\n",
    "# =========================\n",
    "def calc_fees(turnover_buy: float, turnover_sell: float) -> float:\n",
    "    # Keep light for scheduler; edit to your broker if needed\n",
    "    BROKER_PCT = 0.001; BROKER_MIN = 5.0; BROKER_CAP = 20.0\n",
    "    STT_PCT = 0.001; STAMP_BUY_PCT = 0.00015\n",
    "    EXCH_PCT = 0.0000297; SEBI_PCT = 0.000001; IPFT_PCT = 0.000001\n",
    "    GST_PCT = 0.18; DP_SELL = 20.0 if turnover_sell >= 100 else 0.0\n",
    "\n",
    "    def _broker(turnover):\n",
    "        if turnover <= 0: return 0.0\n",
    "        fee = max(BROKER_MIN, min(turnover * BROKER_PCT, BROKER_CAP))\n",
    "        return fee\n",
    "\n",
    "    br_buy, br_sell = _broker(turnover_buy), _broker(turnover_sell)\n",
    "    stt   = STT_PCT * (turnover_buy + turnover_sell)\n",
    "    stamp = STAMP_BUY_PCT * turnover_buy\n",
    "    exch  = EXCH_PCT * (turnover_buy + turnover_sell)\n",
    "    sebi  = SEBI_PCT * (turnover_buy + turnover_sell)\n",
    "    ipft  = IPFT_PCT * (turnover_buy + turnover_sell)\n",
    "    gst   = GST_PCT * (br_buy + br_sell + exch + sebi + ipft + DP_SELL)\n",
    "    return float((br_buy + br_sell) + stt + stamp + exch + sebi + ipft + DP_SELL + gst)\n",
    "\n",
    "# =========================\n",
    "# IO helpers\n",
    "# =========================\n",
    "def ensure_dirs(*paths):\n",
    "    for p in paths:\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def today_india_str():\n",
    "    return pd.Timestamp.today(tz=\"Asia/Kolkata\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "STATE_PATH = os.path.join(CFG.state_dir, \"positions.json\")\n",
    "EXEC_PATH  = os.path.join(CFG.out_dir, \"executions.csv\")\n",
    "\n",
    "def load_state():\n",
    "    ensure_dirs(CFG.state_dir, CFG.out_dir, CFG.cache_dir)\n",
    "    if os.path.exists(STATE_PATH):\n",
    "        with open(STATE_PATH, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {\"cash_inr\": CFG.capital_inr, \"open_positions\": {}, \"pending_orders\": []}\n",
    "\n",
    "def save_state(state):\n",
    "    with open(STATE_PATH, \"w\") as f:\n",
    "        json.dump(state, f, indent=2, default=str)\n",
    "\n",
    "def append_execution_row(row: dict):\n",
    "    ensure_dirs(CFG.out_dir)\n",
    "    row = {k: (v if not isinstance(v, pd.Timestamp) else v.strftime(\"%Y-%m-%d\")) for k, v in row.items()}\n",
    "    if not os.path.exists(EXEC_PATH):\n",
    "        pd.DataFrame([row]).to_csv(EXEC_PATH, index=False)\n",
    "    else:\n",
    "        pd.DataFrame([row]).to_csv(EXEC_PATH, mode=\"a\", header=False, index=False)\n",
    "\n",
    "# =========================\n",
    "# Data + Indicators\n",
    "# =========================\n",
    "def _normalize_syms(symbols: List[str]) -> List[str]:\n",
    "    out = []\n",
    "    for s in symbols:\n",
    "        s = s.strip().upper()\n",
    "        if not s.endswith(\".NS\") and not s.startswith(\"^\"):\n",
    "            s = f\"{s}.NS\"\n",
    "        out.append(s)\n",
    "    return out\n",
    "\n",
    "def fetch_prices(tickers: List[str], start: str, end: Optional[str]) -> Dict[str, pd.DataFrame]:\n",
    "    ensure_dirs(CFG.cache_dir)\n",
    "    data = {}\n",
    "    end = end or today_india_str()\n",
    "    for ticker in tickers:\n",
    "        cache_path = os.path.join(CFG.cache_dir, f\"{ticker.replace('^','_')}.parquet\")\n",
    "        use_cached = False\n",
    "        if os.path.exists(cache_path):\n",
    "            try:\n",
    "                df = pd.read_parquet(cache_path)\n",
    "                if len(df) and pd.to_datetime(df.index[-1]).strftime(\"%Y-%m-%d\") >= end:\n",
    "                    data[ticker] = df\n",
    "                    use_cached = True\n",
    "            except Exception:\n",
    "                pass\n",
    "        if not use_cached:\n",
    "            try:\n",
    "                df = yf.download(ticker, start=start, end=end, auto_adjust=True, progress=False, multi_level_index=False)\n",
    "                if df is None or df.empty:\n",
    "                    continue\n",
    "                df = df.rename(columns=str.title)[['Open','High','Low','Close','Volume']].dropna()\n",
    "                df.index.name = \"date\"\n",
    "                df = df.tail(CFG.max_lookback_days)\n",
    "                df.to_parquet(cache_path)\n",
    "                data[ticker] = df\n",
    "            except Exception:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "def rsi(series: pd.Series, length: int = 14) -> pd.Series:\n",
    "    d = series.diff()\n",
    "    gain = d.clip(lower=0).rolling(length).mean()\n",
    "    loss = (-d.clip(upper=0)).rolling(length).mean()\n",
    "    rs = gain / loss.replace(0.0, np.nan)\n",
    "    out = 100 - (100 / (1 + rs))\n",
    "    return out.fillna(50.0)\n",
    "\n",
    "def _true_range(h, l, pc):\n",
    "    return pd.concat([(h-l).abs(), (h-pc).abs(), (l-pc).abs()], axis=1).max(axis=1)\n",
    "\n",
    "def atr(h, l, c, length=14):\n",
    "    return _true_range(h, l, c.shift(1)).ewm(alpha=1/length, adjust=False, min_periods=length).mean()\n",
    "\n",
    "def supertrend(df: pd.DataFrame, atr_len: int, mult: float) -> pd.DataFrame:\n",
    "    h, l, c = df[\"High\"], df[\"Low\"], df[\"Close\"]\n",
    "    _atr = atr(h, l, c, atr_len)\n",
    "    hl2 = (h + l) / 2.0\n",
    "    ub = hl2 + mult * _atr\n",
    "    lb = hl2 - mult * _atr\n",
    "    st = pd.Series(index=df.index, dtype=float)\n",
    "    dr = pd.Series(index=df.index, dtype=int)\n",
    "    st.iloc[0] = ub.iloc[0]; dr.iloc[0] = -1\n",
    "    for i in range(1, len(df)):\n",
    "        up = min(ub.iloc[i], ub.iloc[i-1])\n",
    "        lo = max(lb.iloc[i], lb.iloc[i-1])\n",
    "        if dr.iloc[i-1] == -1:\n",
    "            st_val = up\n",
    "            if c.iloc[i] > st_val:\n",
    "                dr.iloc[i] = 1; st_val = lo\n",
    "            else:\n",
    "                dr.iloc[i] = -1\n",
    "        else:\n",
    "            st_val = lo\n",
    "            if c.iloc[i] < st_val:\n",
    "                dr.iloc[i] = -1; st_val = up\n",
    "            else:\n",
    "                dr.iloc[i] = 1\n",
    "        st.iloc[i] = st_val\n",
    "    out = df.copy()\n",
    "    out[\"st\"] = st; out[\"st_dir\"] = dr.fillna(-1)\n",
    "    return out[[\"st\",\"st_dir\"]]\n",
    "\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "\n",
    "def pick_benchmark(benchmarks: Tuple[str,...], start: str, end: Optional[str]) -> Tuple[str, pd.DataFrame]:\n",
    "    for t in benchmarks:\n",
    "        data = fetch_prices([t], start, end)\n",
    "        df = data.get(t)\n",
    "        if df is not None and not df.empty:\n",
    "            log.info(\"Using benchmark: %s\", t)\n",
    "            return t, df\n",
    "    idx = pd.date_range(start=start, end=end or today_india_str(), freq=\"B\")\n",
    "    df = pd.DataFrame({\"Close\": np.ones(len(idx))}, index=idx)\n",
    "    log.warning(\"No benchmark found; using synthetic flat series.\")\n",
    "    return \"SYNTH_BENCH\", df\n",
    "\n",
    "def mansfield_rs(stock_close: pd.Series, bench_close: pd.Series, lookback: int) -> pd.Series:\n",
    "    r = (stock_close / bench_close).dropna()\n",
    "    sma = r.rolling(lookback).mean()\n",
    "    rs = 100.0 * (r / sma - 1.0)\n",
    "    return rs.reindex(stock_close.index).fillna(method=\"ffill\")\n",
    "\n",
    "def compute_indicators(df: pd.DataFrame, bench_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"rsi\"] = rsi(out[\"Close\"], CFG.rsi_len)\n",
    "    st = supertrend(out[[\"High\",\"Low\",\"Close\"]], CFG.st_atr_len, CFG.st_mult)\n",
    "    out = pd.concat([out, st], axis=1)\n",
    "    out[\"ema200\"] = ema(out[\"Close\"], CFG.ema200_len)\n",
    "    # RS vs benchmark\n",
    "    bclose = bench_df[\"Close\"].reindex(out.index).fillna(method=\"ffill\")\n",
    "    out[\"rs55\"] = mansfield_rs(out[\"Close\"], bclose, CFG.rs_lookback)\n",
    "    # helpers\n",
    "    out[\"avg_vol_20\"] = out[\"Volume\"].rolling(20).mean()\n",
    "    out[\"high_52w\"] = out[\"Close\"].rolling(CFG.filter_52w_window).max()\n",
    "    return out.dropna()\n",
    "\n",
    "# =========================\n",
    "# Signal Logic (EOD bar D0 → plan for next session)\n",
    "# =========================\n",
    "def basic_liquidity_ok(row: pd.Series) -> bool:\n",
    "    if not CFG.enable_basic_liquidity: return True\n",
    "    if row[\"Close\"] < CFG.min_price_inr: return False\n",
    "    if row[\"avg_vol_20\"] < CFG.min_avg_vol_20d: return False\n",
    "    return True\n",
    "\n",
    "def entry_conditions(row: pd.Series) -> Tuple[bool, str]:\n",
    "    conds = []\n",
    "    ok = True\n",
    "\n",
    "    rsi_ok = row[\"rsi\"] > CFG.rsi_entry_min\n",
    "    conds.append(f\"RSI>{CFG.rsi_entry_min:.0f}\" if rsi_ok else f\"RSI≤{CFG.rsi_entry_min:.0f}\")\n",
    "    ok &= rsi_ok\n",
    "\n",
    "    rs_ok = row[\"rs55\"] > CFG.rs_zero\n",
    "    conds.append(\"RS55>0\" if rs_ok else \"RS55≤0\")\n",
    "    ok &= rs_ok\n",
    "\n",
    "    st_flip = (row[\"st_dir\"] == 1)  # we will check flip vs prior bar outside\n",
    "    conds.append(\"ST=BUY\" if st_flip else \"ST≠BUY\")\n",
    "    ok &= st_flip\n",
    "\n",
    "    if CFG.use_ema200_filter:\n",
    "        ema_ok = row[\"Close\"] > row[\"ema200\"]\n",
    "        conds.append(\"Close>EMA200\" if ema_ok else \"Close≤EMA200\")\n",
    "        ok &= ema_ok\n",
    "\n",
    "    return bool(ok), \"; \".join(conds)\n",
    "\n",
    "def exit_conditions(row_today: pd.Series, st_red: bool, rs_below: bool, rsi_below: bool) -> Tuple[bool, str]:\n",
    "    reasons = []\n",
    "    if st_red:    reasons.append(\"Supertrend RED\")\n",
    "    if rs_below:  reasons.append(\"RS55<0\")\n",
    "    if rsi_below: reasons.append(f\"RSI<{CFG.rsi_exit_min:.0f}\")\n",
    "    return (len(reasons) > 0), \" & \".join(reasons)\n",
    "\n",
    "# =========================\n",
    "# State promotion (pending → executed)\n",
    "# =========================\n",
    "def promote_pending_orders(state, data_map):\n",
    "    \"\"\"\n",
    "    For each pending order, if a bar exists on or after planned_date for that ticker,\n",
    "    execute at that day's Open and update state.\n",
    "    \"\"\"\n",
    "    still_pending = []\n",
    "    for od in state[\"pending_orders\"]:\n",
    "        tkr = od[\"ticker\"]\n",
    "        df = data_map.get(tkr)\n",
    "        if df is None or df.empty:\n",
    "            still_pending.append(od)\n",
    "            continue\n",
    "\n",
    "        planned = pd.to_datetime(od[\"planned_date\"]).date()\n",
    "        # Find first available bar >= planned_date\n",
    "        exec_date = None\n",
    "        for dt in df.index.date:\n",
    "            if dt >= planned:\n",
    "                exec_date = pd.Timestamp(dt)\n",
    "                break\n",
    "        if exec_date is None:\n",
    "            still_pending.append(od)\n",
    "            continue\n",
    "\n",
    "        px = float(df.loc[exec_date, \"Open\"])\n",
    "        side = od[\"side\"].upper()\n",
    "\n",
    "        if side == \"BUY\":\n",
    "            if tkr in state[\"open_positions\"]:\n",
    "                # Already held—skip\n",
    "                continue\n",
    "            # shares via fixed per-trade budget\n",
    "            cap = float(state.get(\"cash_inr\", 0.0))\n",
    "            budget = min(CFG.per_trade_inr, cap)\n",
    "            shares = int(math.floor(budget / px)) if px > 0 else 0\n",
    "            if shares <= 0:\n",
    "                log.info(\"Skip BUY fill %s — insufficient cash @ %.2f\", tkr, px)\n",
    "                continue\n",
    "            turn = shares * px\n",
    "            fee = calc_fees(turn, 0.0)\n",
    "            total = turn + fee\n",
    "            if total > cap:\n",
    "                shares = int(math.floor((cap - fee) / px))\n",
    "                if shares <= 0:\n",
    "                    log.info(\"Skip BUY fill %s — cash after fees not enough\", tkr)\n",
    "                    continue\n",
    "                turn = shares * px; total = turn + fee\n",
    "\n",
    "            state[\"cash_inr\"] = cap - total\n",
    "            sl = px * (1 - CFG.stop_loss_pct)\n",
    "            tp = px * (1 + CFG.target_pct)\n",
    "            state[\"open_positions\"][tkr] = {\n",
    "                \"entry_date\": exec_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"entry_px\": px,\n",
    "                \"shares\": shares,\n",
    "                \"stop_px\": sl,\n",
    "                \"target_px\": tp\n",
    "            }\n",
    "            append_execution_row({\n",
    "                \"date\": exec_date, \"ticker\": tkr, \"side\": \"BUY\",\n",
    "                \"price\": px, \"shares\": shares, \"fees_inr\": fee,\n",
    "                \"note\": od.get(\"reason\",\"planned_buy\")\n",
    "            })\n",
    "            log.info(\"FILLED BUY %-12s @ %.2f x %d | cash=%.2f | SL=%.2f TP=%.2f\",\n",
    "                     tkr, px, shares, state[\"cash_inr\"], sl, tp)\n",
    "\n",
    "        elif side == \"SELL\":\n",
    "            pos = state[\"open_positions\"].get(tkr)\n",
    "            if pos is None:\n",
    "                continue\n",
    "            shares = int(pos[\"shares\"])\n",
    "            turn = shares * px\n",
    "            fee = calc_fees(0.0, turn)\n",
    "            pnl = (px - pos[\"entry_px\"]) * shares - fee\n",
    "            state[\"cash_inr\"] = float(state.get(\"cash_inr\", 0.0)) + (turn - fee)\n",
    "            append_execution_row({\n",
    "                \"date\": exec_date, \"ticker\": tkr, \"side\": \"SELL\",\n",
    "                \"price\": px, \"shares\": shares, \"fees_inr\": fee,\n",
    "                \"note\": od.get(\"reason\",\"planned_sell\"), \"pnl_inr\": pnl\n",
    "            })\n",
    "            del state[\"open_positions\"][tkr]\n",
    "            log.info(\"FILLED SELL %-12s @ %.2f x %d | pnl=%.2f | cash=%.2f\",\n",
    "                     tkr, px, shares, pnl, state[\"cash_inr\"])\n",
    "        else:\n",
    "            still_pending.append(od)\n",
    "\n",
    "    state[\"pending_orders\"] = still_pending\n",
    "\n",
    "# =========================\n",
    "# Daily planning\n",
    "# =========================\n",
    "def next_bday(date_like: pd.Timestamp) -> str:\n",
    "    # naive next business day (calendar) — actual fill is chosen from real bars on promotion\n",
    "    d1 = pd.Timestamp(date_like).tz_localize(None) + pd.tseries.offsets.BDay(1)\n",
    "    return d1.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def generate_daily_plan(state, data_map, bench_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Inspects the LAST available bar D0 for each ticker to decide entries/exits\n",
    "    to plan for next session open.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # Build quick views\n",
    "    open_tickers = set(state[\"open_positions\"].keys())\n",
    "    pending_pairs = {(od[\"ticker\"], od[\"side\"]) for od in state[\"pending_orders\"]}\n",
    "\n",
    "    # For capacity management\n",
    "    slots_avail = max(0, CFG.max_concurrent_positions - len(open_tickers))\n",
    "\n",
    "    # ENTRY candidates (collect first, then select top-K by simple momentum score)\n",
    "    entries = []\n",
    "    indicators_map = {}\n",
    "    for tkr, df in data_map.items():\n",
    "        if df is None or df.empty: continue\n",
    "        ind = compute_indicators(df, bench_df)\n",
    "        if ind.empty: continue\n",
    "        D0 = ind.index[-1]\n",
    "        prev = ind.index[-2] if len(ind) >= 2 else None\n",
    "        row = ind.iloc[-1]\n",
    "        indicators_map[tkr] = (D0, row)\n",
    "\n",
    "        # Skip if already held or pending buy\n",
    "        if tkr in open_tickers or (tkr, \"BUY\") in pending_pairs:\n",
    "            continue\n",
    "\n",
    "        # Optional proximity to 52w high + basic liquidity\n",
    "        if CFG.within_pct_of_52w_high > 0:\n",
    "            hi = row[\"high_52w\"]; cl = row[\"Close\"]\n",
    "            if not (hi > 0 and cl >= CFG.within_pct_of_52w_high * hi):\n",
    "                continue\n",
    "        if not basic_liquidity_ok(row):\n",
    "            continue\n",
    "\n",
    "        # Entry rules require a flip to BUY today: st_dir==1 and yesterday == -1\n",
    "        st_flip_today = bool(row[\"st_dir\"] == 1 and (ind.loc[prev, \"st_dir\"] == -1) if prev is not None else False)\n",
    "        if not st_flip_today:\n",
    "            continue\n",
    "\n",
    "        ok, reason = entry_conditions(row)\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        # score: combine RS and RSI (simple)\n",
    "        score = float(row[\"rs55\"]) + float(row[\"rsi\"])\n",
    "        entries.append((tkr, D0, score, reason))\n",
    "\n",
    "    # Pick top-K entries given available slots\n",
    "    entries = sorted(entries, key=lambda x: x[2], reverse=True)\n",
    "    entries = entries[:min(CFG.top_k_daily, slots_avail)]\n",
    "\n",
    "    for (tkr, D0, _score, reason) in entries:\n",
    "        # plan for next business day (actual fill chosen on promotion)\n",
    "        rows.append({\n",
    "            \"planned_date\": next_bday(D0),\n",
    "            \"side\": \"BUY\",\n",
    "            \"ticker\": tkr,\n",
    "            \"reason\": f\"{reason}; plan entry next open\",\n",
    "        })\n",
    "        state[\"pending_orders\"].append({\n",
    "            \"planned_date\": next_bday(D0),\n",
    "            \"side\": \"BUY\",\n",
    "            \"ticker\": tkr,\n",
    "            \"reason\": reason\n",
    "        })\n",
    "\n",
    "    # EXIT checks for open positions\n",
    "    for tkr, pos in list(state[\"open_positions\"].items()):\n",
    "        df = data_map.get(tkr)\n",
    "        if df is None or df.empty: continue\n",
    "        ind = compute_indicators(df, bench_df)\n",
    "        if ind.empty: continue\n",
    "        row = ind.iloc[-1]\n",
    "        D0 = ind.index[-1]\n",
    "        # hard SL/TP check with D0 range\n",
    "        sl = float(pos[\"stop_px\"]); tp = float(pos[\"target_px\"])\n",
    "        lowD0 = float(ind.loc[D0, \"Low\"]); highD0 = float(ind.loc[D0, \"High\"])\n",
    "\n",
    "        hit = None\n",
    "        if CFG.stop_target_priority == \"stop_first\":\n",
    "            if lowD0 <= sl:   hit = (\"SELL\", f\"Hard SL hit ({sl:.2f}) on D0\")\n",
    "            elif highD0 >= tp: hit = (\"SELL\", f\"Hard TP hit ({tp:.2f}) on D0\")\n",
    "        else:\n",
    "            if highD0 >= tp: hit = (\"SELL\", f\"Hard TP hit ({tp:.2f}) on D0\")\n",
    "            elif lowD0 <= sl:   hit = (\"SELL\", f\"Hard SL hit ({sl:.2f}) on D0\")\n",
    "\n",
    "        if hit is None:\n",
    "            st_red   = bool(row[\"st_dir\"] == -1)\n",
    "            rs_below = bool(row[\"rs55\"] < CFG.rs_zero)\n",
    "            rsi_below= bool(row[\"rsi\"]  < CFG.rsi_exit_min)\n",
    "            do_exit, why = exit_conditions(row, st_red, rs_below, rsi_below)\n",
    "            if do_exit:\n",
    "                hit = (\"SELL\", why)\n",
    "\n",
    "        if hit is not None:\n",
    "            side, why = hit\n",
    "            if (tkr, side) not in pending_pairs:\n",
    "                rows.append({\n",
    "                    \"planned_date\": next_bday(D0),\n",
    "                    \"side\": side,\n",
    "                    \"ticker\": tkr,\n",
    "                    \"reason\": f\"{why}; plan exit next open\",\n",
    "                })\n",
    "                state[\"pending_orders\"].append({\n",
    "                    \"planned_date\": next_bday(D0),\n",
    "                    \"side\": side,\n",
    "                    \"ticker\": tkr,\n",
    "                    \"reason\": why\n",
    "                })\n",
    "\n",
    "    # Also emit a snapshot of open positions\n",
    "    open_rows = []\n",
    "    for tkr, pos in state[\"open_positions\"].items():\n",
    "        open_rows.append({\n",
    "            \"ticker\": tkr,\n",
    "            \"entry_date\": pos[\"entry_date\"],\n",
    "            \"entry_px\": pos[\"entry_px\"],\n",
    "            \"shares\": pos[\"shares\"],\n",
    "            \"stop_px\": pos[\"stop_px\"],\n",
    "            \"target_px\": pos[\"target_px\"],\n",
    "        })\n",
    "\n",
    "    # Write outputs\n",
    "    stamp = pd.Timestamp.today(tz=\"Asia/Kolkata\").strftime(\"%Y%m%d\")\n",
    "    plan_path = os.path.join(CFG.out_dir, f\"plan_{stamp}.csv\")\n",
    "    open_path = os.path.join(CFG.out_dir, f\"open_positions.csv\")\n",
    "\n",
    "    plan_df = pd.DataFrame(rows, columns=[\"planned_date\",\"side\",\"ticker\",\"reason\"]).sort_values(\n",
    "        by=[\"planned_date\",\"side\",\"ticker\"]\n",
    "    )\n",
    "    if plan_df.empty:\n",
    "        # ensure file exists to inspect in automations\n",
    "        pd.DataFrame(columns=[\"planned_date\",\"side\",\"ticker\",\"reason\"]).to_csv(plan_path, index=False)\n",
    "    else:\n",
    "        plan_df.to_csv(plan_path, index=False)\n",
    "\n",
    "    pd.DataFrame(open_rows, columns=[\"ticker\",\"entry_date\",\"entry_px\",\"shares\",\"stop_px\",\"target_px\"]).to_csv(open_path, index=False)\n",
    "\n",
    "    log.info(\"Wrote plan → %s\", plan_path)\n",
    "    log.info(\"Open positions snapshot → %s\", open_path)\n",
    "    return plan_df\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    ensure_dirs(CFG.out_dir, CFG.state_dir, CFG.cache_dir)\n",
    "\n",
    "    # Universe\n",
    "    symbols = []\n",
    "    if CFG.static_symbols_path and os.path.exists(CFG.static_symbols_path):\n",
    "        with open(CFG.static_symbols_path, \"r\") as f:\n",
    "            symbols = [ln.strip() for ln in f if ln.strip()]\n",
    "    else:\n",
    "        symbols = CFG.static_symbols or []\n",
    "    symbols = _normalize_syms(symbols)\n",
    "\n",
    "    if not symbols:\n",
    "        raise RuntimeError(\"No symbols configured. Populate CFG.static_symbols or CFG.static_symbols_path.\")\n",
    "\n",
    "    # Data\n",
    "    start = CFG.start_date\n",
    "    end   = CFG.end_date or today_india_str()\n",
    "    data_map = fetch_prices(symbols, start, end)\n",
    "    bench_tkr, bench_df = pick_benchmark(CFG.benchmark_try, start, end)\n",
    "\n",
    "    # Load & promote state\n",
    "    state = load_state()\n",
    "    promote_pending_orders(state, data_map)\n",
    "\n",
    "    # Capacity guard\n",
    "    if len(state[\"open_positions\"]) > CFG.max_concurrent_positions:\n",
    "        log.warning(\"Currently %d positions open > max %d. Scheduler will still generate exits but limit new entries.\",\n",
    "                    len(state[\"open_positions\"]), CFG.max_concurrent_positions)\n",
    "\n",
    "    # Plan for next session\n",
    "    plan_df = generate_daily_plan(state, data_map, bench_df)\n",
    "\n",
    "    # Persist state\n",
    "    save_state(state)\n",
    "\n",
    "    # Log summary\n",
    "    log.info(\"Cash: %.2f | Open positions: %d | Pending orders: %d | New plan rows: %d\",\n",
    "             float(state.get(\"cash_inr\", 0.0)), len(state[\"open_positions\"]), len(state[\"pending_orders\"]), len(plan_df))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
