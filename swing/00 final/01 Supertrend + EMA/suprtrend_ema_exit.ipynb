{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0f5326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating exit for SBILIFE.NS ... EXIT ✅\n",
      "\n",
      "Saved: outputs/2025-09-21/exit_evaluations.csv\n",
      "Exits: 1 / 1\n",
      "[Telegram] (dry-run/creds-missing/requests-missing) Would send:\n",
      " <b>EXIT ALERT</b> — 2025-09-21 15:56\n",
      "Ticker: <b>SBILIFE.NS</b>\n",
      "Entry:  <b>1841.70</b>\n",
      "Now:    <b>1841.70</b>\n",
      "PnL:    <b>0.00%</b>\n",
      "Held:   <b>1</b> bars\n",
      "Reason: SUPERTREND_DN: supertrend_direction turned down\n",
      "[Telegram] (dry-run/creds-missing/requests-missing) Would send:\n",
      " <b>Exit Summary</b> — 2025-09-21 15:56\n",
      "Total exits: <b>1</b>\n",
      "\n",
      "• <b>SBILIFE.NS</b> @ 2025-09-19 00:00:00 | 1841.70 | 0.00% | SUPERTREND_DN: supertrend_direction turned down\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "exit_checker.py\n",
    "\n",
    "Reads buy_signals.csv produced by the scanner, checks exit rules for each ticker,\n",
    "and sends Telegram alerts with reasons when an exit is recommended.\n",
    "\n",
    "- Auto-detects latest outputs/YYYY-MM-DD/buy_signals.csv if INPUT_PATH=None.\n",
    "- Exit rules (configurable):\n",
    "    * STOP_LOSS_PCT: exit if Close <= entry_price * (1 - stop_loss_pct)\n",
    "    * TRAIL_ATR:     exit if Close <= (highest_close_since_entry - ATR*mult)\n",
    "    * MAX_HOLD_BARS: exit if bars_held >= max_hold_bars (trading bars)\n",
    "    * EMA_BEAR:      exit if EMA_fast < EMA_slow\n",
    "    * SMA30_DROP:    exit if Close < SMA(30)\n",
    "    * SUPERTREND_DN: exit if supertrend_direction turns -1\n",
    "\n",
    "- Telegram: uses env TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID if not set in config.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import datetime as dt\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "# Optional third-party: requests for Telegram\n",
    "try:\n",
    "    import requests\n",
    "except Exception:\n",
    "    requests = None\n",
    "\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "except Exception:\n",
    "    ZoneInfo = None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "CONFIG: Dict[str, Any] = {\n",
    "    # Path to buy_signals.csv (leave None to auto-pick latest under outputs/YYYY-MM-DD/)\n",
    "    \"INPUT_PATH\": None,  # e.g., \"outputs/2025-09-20/buy_signals.csv\"\n",
    "\n",
    "    # Data & indicators\n",
    "    \"YF_LOOKBACK_PAD_DAYS\": 30,   # extra history before entry date for indicators\n",
    "    \"EMA_FAST_LENGTH\": 9,\n",
    "    \"EMA_SLOW_LENGTH\": 15,\n",
    "    \"SMA30_LENGTH\": 30,\n",
    "    \"ATR_LENGTH\": 14,\n",
    "    \"ST_LENGTH\": 10,\n",
    "    \"ST_MULTIPLIER\": 3.0,\n",
    "\n",
    "    # Exit rule toggles\n",
    "    \"EXITS\": {\n",
    "        \"STOP_LOSS_PCT\": True,\n",
    "        \"TRAIL_ATR\": True,\n",
    "        \"MAX_HOLD_BARS\": True,\n",
    "        \"EMA_BEAR\": True,\n",
    "        \"SMA30_DROP\": True,\n",
    "        \"SUPERTREND_DN\": True,\n",
    "    },\n",
    "\n",
    "    # Exit rule params\n",
    "    \"STOP_LOSS_PCT\": 0.05,   # 5% below entry\n",
    "    \"TRAIL_ATR_MULT\": 2.5,   # Close <= HighestCloseSinceEntry - ATR*mult\n",
    "    \"MAX_HOLD_BARS\": 10,     # trading bars\n",
    "\n",
    "    # Exit decision combining: 'any' (recommended) or 'all'\n",
    "    \"COMBINE_MODE\": \"any\",\n",
    "\n",
    "    # Telegram settings\n",
    "    \"TELEGRAM\": {\n",
    "        \"ENABLE\": True,\n",
    "        \"BOT_TOKEN\": \"\",      # or env TELEGRAM_BOT_TOKEN\n",
    "        \"CHAT_ID\": \"\",        # or env TELEGRAM_CHAT_ID\n",
    "        \"PARSE_MODE\": \"HTML\",\n",
    "        \"DISABLE_WEB_PREVIEW\": True,\n",
    "        \"DRY_RUN\": False,     # force print instead of sending\n",
    "        \"SEND_SUMMARY\": True, # one summary after per-ticker alerts\n",
    "    },\n",
    "\n",
    "    # Output folder for today’s run\n",
    "    \"OUTPUT_ROOT\": \"outputs\",\n",
    "}\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def _now_ist_str():\n",
    "    try:\n",
    "        if ZoneInfo:\n",
    "            return dt.datetime.now(ZoneInfo(\"Asia/Kolkata\")).strftime(\"%Y-%m-%d %H:%M\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return dt.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "def _escape_html(s: str) -> str:\n",
    "    return (str(s).replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\"))\n",
    "\n",
    "def resolve_telegram_creds(tcfg: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    token = tcfg.get(\"BOT_TOKEN\") or os.getenv(\"TELEGRAM_BOT_TOKEN\", \"\")\n",
    "    chat_id = tcfg.get(\"CHAT_ID\") or os.getenv(\"TELEGRAM_CHAT_ID\", \"\")\n",
    "    return token, chat_id\n",
    "\n",
    "def send_telegram(text: str, tcfg: Dict[str, Any]):\n",
    "    token, chat_id = resolve_telegram_creds(tcfg)\n",
    "    if not tcfg.get(\"ENABLE\", True):\n",
    "        if VERBOSE: print(\"[Telegram] Disabled. Message:\\n\", text)\n",
    "        return\n",
    "    if tcfg.get(\"DRY_RUN\", False) or (not token) or (not chat_id) or (requests is None):\n",
    "        print(\"[Telegram] (dry-run/creds-missing/requests-missing) Would send:\\n\", text)\n",
    "        return\n",
    "\n",
    "    url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            url,\n",
    "            data={\n",
    "                \"chat_id\": chat_id,\n",
    "                \"text\": text,\n",
    "                \"parse_mode\": tcfg.get(\"PARSE_MODE\", \"HTML\"),\n",
    "                \"disable_web_page_preview\": \"true\" if tcfg.get(\"DISABLE_WEB_PREVIEW\", True) else \"false\",\n",
    "            },\n",
    "            timeout=15,\n",
    "        )\n",
    "        if resp.status_code != 200:\n",
    "            print(f\"[Telegram] Error {resp.status_code}: {resp.text[:200]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Telegram] Exception sending message: {e}\")\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Indicators\n",
    "# =========================\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def sma(series: pd.Series, length: int) -> pd.Series:\n",
    "    return series.rolling(window=length, min_periods=1).mean()\n",
    "\n",
    "def compute_atr(df: pd.DataFrame, length=14) -> pd.Series:\n",
    "    tr = pd.concat([\n",
    "        (df[\"High\"] - df[\"Low\"]).abs(),\n",
    "        (df[\"High\"] - df[\"Close\"].shift()).abs(),\n",
    "        (df[\"Low\"] - df[\"Close\"].shift()).abs(),\n",
    "    ], axis=1).max(axis=1)\n",
    "    return tr.rolling(length, min_periods=1).mean()\n",
    "\n",
    "def supertrend_fallback(df: pd.DataFrame, period=10, multiplier=3.0) -> pd.DataFrame:\n",
    "    hl2 = (df['High'] + df['Low']) / 2\n",
    "    atr = compute_atr(df, period)\n",
    "    upperband = hl2 + multiplier * atr\n",
    "    lowerband = hl2 - multiplier * atr\n",
    "\n",
    "    final_upper = upperband.copy().reset_index(drop=True)\n",
    "    final_lower = lowerband.copy().reset_index(drop=True)\n",
    "    close_vals = df['Close'].reset_index(drop=True)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        final_upper.iat[i] = upperband.iat[i] if (upperband.iat[i] < final_upper.iat[i-1]) or (close_vals.iat[i-1] > final_upper.iat[i-1]) else final_upper.iat[i-1]\n",
    "        final_lower.iat[i] = lowerband.iat[i] if (lowerband.iat[i] > final_lower.iat[i-1]) or (close_vals.iat[i-1] < final_lower.iat[i-1]) else final_lower.iat[i-1]\n",
    "\n",
    "    supertrend = pd.Series(index=df.index, dtype=float)\n",
    "    direction = pd.Series(index=df.index, dtype=int)\n",
    "    for i in range(len(df)):\n",
    "        if i == 0 or df['Close'].iat[i] <= final_upper.iat[i]:\n",
    "            supertrend.iat[i] = final_upper.iat[i]\n",
    "            direction.iat[i] = -1\n",
    "        else:\n",
    "            supertrend.iat[i] = final_lower.iat[i]\n",
    "            direction.iat[i] = 1\n",
    "\n",
    "    out = df.copy()\n",
    "    out['supertrend'] = supertrend\n",
    "    out['supertrend_direction'] = direction\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Core\n",
    "# =========================\n",
    "def locate_latest_buy_signals() -> Optional[str]:\n",
    "    \"\"\"Pick newest outputs/YYYY-MM-DD/buy_signals.csv by date in folder name.\"\"\"\n",
    "    candidates = sorted(glob.glob(os.path.join(\"outputs\", \"20??-??-??\", \"buy_signals.csv\")))\n",
    "    return candidates[-1] if candidates else None\n",
    "\n",
    "def read_buy_signals(input_path: Optional[str]) -> pd.DataFrame:\n",
    "    path = input_path or locate_latest_buy_signals()\n",
    "    if not path or not os.path.exists(path):\n",
    "        raise FileNotFoundError(\"buy_signals.csv not found. Set CONFIG['INPUT_PATH'] or ensure outputs/YYYY-MM-DD/buy_signals.csv exists.\")\n",
    "    df = pd.read_csv(path)\n",
    "    # Normalize expected columns\n",
    "    # Prefer 'entry_price' & 'entry_date' if present, else fallback to last_close/last_bar_date\n",
    "    if 'entry_price' not in df.columns and 'last_close' in df.columns:\n",
    "        df['entry_price'] = df['last_close']\n",
    "    if 'entry_date' not in df.columns and 'last_bar_date' in df.columns:\n",
    "        df['entry_date'] = df['last_bar_date']\n",
    "    if 'ticker' not in df.columns:\n",
    "        # sometimes 'symbol' is used\n",
    "        if 'symbol' in df.columns:\n",
    "            df = df.rename(columns={'symbol': 'ticker'})\n",
    "        else:\n",
    "            raise ValueError(\"Input CSV must contain 'ticker' or 'symbol' column.\")\n",
    "    return df[['ticker', 'entry_price', 'entry_date']].dropna()\n",
    "\n",
    "def fetch_history(ticker: str, start_date: dt.date, pad_days: int) -> pd.DataFrame:\n",
    "    start = (start_date - dt.timedelta(days=pad_days)).strftime(\"%Y-%m-%d\")\n",
    "    end = (dt.date.today() + dt.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    df = yf.download(ticker, start=start, end=end, interval=\"1d\", progress=False, auto_adjust=True, multi_level_index=False)\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    return df\n",
    "\n",
    "def evaluate_exits_for_ticker(\n",
    "    ticker: str,\n",
    "    entry_price: float,\n",
    "    entry_date_str: str,\n",
    "    cfg: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Return dict with exit boolean and reasons.\"\"\"\n",
    "    try:\n",
    "        entry_date = pd.to_datetime(entry_date_str).date()\n",
    "    except Exception:\n",
    "        # If parsing fails, assume we entered on the most recent bar in past\n",
    "        entry_date = (dt.date.today() - dt.timedelta(days=1))\n",
    "\n",
    "    df = fetch_history(ticker, entry_date, cfg[\"YF_LOOKBACK_PAD_DAYS\"])\n",
    "    if df.empty or len(df) < 2:\n",
    "        return {\"ticker\": ticker, \"exit\": False, \"reason\": \"insufficient_data\"}\n",
    "\n",
    "    close = df['Close']\n",
    "    high = df['High']\n",
    "    low = df['Low']\n",
    "\n",
    "    # Indicators\n",
    "    df['EMA_fast'] = ema(close, cfg[\"EMA_FAST_LENGTH\"])\n",
    "    df['EMA_slow'] = ema(close, cfg[\"EMA_SLOW_LENGTH\"])\n",
    "    df['SMA_30']   = sma(close, cfg[\"SMA30_LENGTH\"])\n",
    "    df['ATR']      = compute_atr(df, cfg[\"ATR_LENGTH\"])\n",
    "    st_df          = supertrend_fallback(df, cfg[\"ST_LENGTH\"], cfg[\"ST_MULTIPLIER\"])\n",
    "    df[['supertrend', 'supertrend_direction']] = st_df[['supertrend', 'supertrend_direction']]\n",
    "\n",
    "    # Subset from entry date onward (inclusive)\n",
    "    df_after = df.loc[df.index.date >= entry_date].copy()\n",
    "    if df_after.empty:\n",
    "        return {\"ticker\": ticker, \"exit\": False, \"reason\": \"no_bars_after_entry\"}\n",
    "\n",
    "    # Bars held & current state\n",
    "    bars_held = len(df_after)\n",
    "    cur = df_after.iloc[-1]\n",
    "    cur_close = float(cur['Close'])\n",
    "\n",
    "    # Highest close since entry for trailing\n",
    "    highest_close = float(df_after['Close'].cummax().iloc[-1])\n",
    "    last_atr = float(df_after['ATR'].iloc[-1])\n",
    "\n",
    "    # Rules\n",
    "    reasons = []\n",
    "\n",
    "    if CONFIG[\"EXITS\"].get(\"STOP_LOSS_PCT\", True):\n",
    "        sl_level = entry_price * (1.0 - CONFIG[\"STOP_LOSS_PCT\"])\n",
    "        if cur_close <= sl_level:\n",
    "            reasons.append(f\"STOP_LOSS_PCT: Close {cur_close:.2f} ≤ {sl_level:.2f} (−{CONFIG['STOP_LOSS_PCT']*100:.1f}%)\")\n",
    "\n",
    "    if CONFIG[\"EXITS\"].get(\"TRAIL_ATR\", True):\n",
    "        trail_level = highest_close - CONFIG[\"TRAIL_ATR_MULT\"] * last_atr\n",
    "        if cur_close <= trail_level:\n",
    "            reasons.append(f\"TRAIL_ATR: Close {cur_close:.2f} ≤ HighSinceEntry {highest_close:.2f} − {CONFIG['TRAIL_ATR_MULT']}×ATR {last_atr:.2f} = {trail_level:.2f}\")\n",
    "\n",
    "    if CONFIG[\"EXITS\"].get(\"MAX_HOLD_BARS\", True):\n",
    "        if bars_held >= CONFIG[\"MAX_HOLD_BARS\"]:\n",
    "            reasons.append(f\"MAX_HOLD_BARS: Held {bars_held} bars ≥ {CONFIG['MAX_HOLD_BARS']}\")\n",
    "\n",
    "    if CONFIG[\"EXITS\"].get(\"EMA_BEAR\", True):\n",
    "        if cur['EMA_fast'] < cur['EMA_slow']:\n",
    "            reasons.append(f\"EMA_BEAR: EMA{CONFIG['EMA_FAST_LENGTH']:.0f} < EMA{CONFIG['EMA_SLOW_LENGTH']:.0f}\")\n",
    "\n",
    "    if CONFIG[\"EXITS\"].get(\"SMA30_DROP\", True):\n",
    "        if cur_close < cur['SMA_30']:\n",
    "            reasons.append(f\"SMA30_DROP: Close {cur_close:.2f} < SMA{CONFIG['SMA30_LENGTH']} {float(cur['SMA_30']):.2f}\")\n",
    "\n",
    "    if CONFIG[\"EXITS\"].get(\"SUPERTREND_DN\", True):\n",
    "        if int(cur.get('supertrend_direction', 1)) == -1:\n",
    "            reasons.append(\"SUPERTREND_DN: supertrend_direction turned down\")\n",
    "\n",
    "    # Combine\n",
    "    exit_flag = False\n",
    "    if reasons:\n",
    "        mode = CONFIG.get(\"COMBINE_MODE\", \"any\").lower()\n",
    "        if mode == \"any\":\n",
    "            exit_flag = True\n",
    "        elif mode == \"all\":\n",
    "            # require all enabled rules to be triggered\n",
    "            enabled = [k for k, v in CONFIG[\"EXITS\"].items() if v]\n",
    "            # crude: if all enabled appear in reasons text; instead check per rule explicitly\n",
    "            # We'll compute count of triggered among enabled:\n",
    "            triggered = 0\n",
    "            if CONFIG[\"EXITS\"].get(\"STOP_LOSS_PCT\", True) and \"STOP_LOSS_PCT\" in \" \".join(reasons): triggered += 1\n",
    "            if CONFIG[\"EXITS\"].get(\"TRAIL_ATR\", True)     and \"TRAIL_ATR\" in \" \".join(reasons): triggered += 1\n",
    "            if CONFIG[\"EXITS\"].get(\"MAX_HOLD_BARS\", True) and \"MAX_HOLD_BARS\" in \" \".join(reasons): triggered += 1\n",
    "            if CONFIG[\"EXITS\"].get(\"EMA_BEAR\", True)      and \"EMA_BEAR\" in \" \".join(reasons): triggered += 1\n",
    "            if CONFIG[\"EXITS\"].get(\"SMA30_DROP\", True)    and \"SMA30_DROP\" in \" \".join(reasons): triggered += 1\n",
    "            if CONFIG[\"EXITS\"].get(\"SUPERTREND_DN\", True) and \"SUPERTREND_DN\" in \" \".join(reasons): triggered += 1\n",
    "            exit_flag = (triggered == len(enabled))\n",
    "\n",
    "    pnl_pct = (cur_close / entry_price - 1.0) * 100.0\n",
    "\n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"exit\": bool(exit_flag),\n",
    "        \"reasons\": \"; \".join(reasons),\n",
    "        \"as_of\": df_after.index[-1],\n",
    "        \"entry_price\": float(entry_price),\n",
    "        \"current_close\": cur_close,\n",
    "        \"pnl_pct\": float(pnl_pct),\n",
    "        \"bars_held\": int(bars_held),\n",
    "        \"highest_close_since_entry\": float(highest_close),\n",
    "        \"atr_last\": last_atr,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Run\n",
    "# =========================\n",
    "def main():\n",
    "    # Read inputs\n",
    "    signals_df = read_buy_signals(CONFIG[\"INPUT_PATH\"])\n",
    "\n",
    "    # Output dir for this run\n",
    "    run_date_str = dt.date.today().strftime(\"%Y-%m-%d\")\n",
    "    out_dir = os.path.join(CONFIG[\"OUTPUT_ROOT\"], run_date_str)\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    exits_triggered: List[Dict[str, Any]] = []\n",
    "\n",
    "    for _, row in signals_df.iterrows():\n",
    "        ticker = row[\"ticker\"]\n",
    "        entry_price = float(row[\"entry_price\"])\n",
    "        entry_date = str(row[\"entry_date\"])\n",
    "\n",
    "        if VERBOSE:\n",
    "            print(f\"Evaluating exit for {ticker} ...\", end=\"\", flush=True)\n",
    "\n",
    "        try:\n",
    "            res = evaluate_exits_for_ticker(ticker, entry_price, entry_date, CONFIG)\n",
    "            results.append(res)\n",
    "            if res[\"exit\"]:\n",
    "                exits_triggered.append(res)\n",
    "                if VERBOSE: print(\" EXIT ✅\")\n",
    "            else:\n",
    "                if VERBOSE: print(\" hold\")\n",
    "        except Exception as e:\n",
    "            if VERBOSE: print(f\" error: {e}\")\n",
    "            results.append({\"ticker\": ticker, \"exit\": False, \"reasons\": f\"error: {e}\"})\n",
    "\n",
    "    # Save CSVs\n",
    "    all_path = os.path.join(out_dir, \"exit_evaluations.csv\")\n",
    "    exits_path = os.path.join(out_dir, \"exit_alerts.csv\")\n",
    "\n",
    "    pd.DataFrame(results).to_csv(all_path, index=False)\n",
    "    pd.DataFrame(exits_triggered).to_csv(exits_path, index=False)\n",
    "\n",
    "    print(f\"\\nSaved: {all_path}\")\n",
    "    print(f\"Exits: {len(exits_triggered)} / {len(results)}\")\n",
    "\n",
    "    # Telegram alerts\n",
    "    tcfg = CONFIG[\"TELEGRAM\"]\n",
    "    if tcfg.get(\"ENABLE\", True):\n",
    "        # Per-exit alert\n",
    "        for res in exits_triggered:\n",
    "            text = (\n",
    "                f\"<b>EXIT ALERT</b> — {_escape_html(_now_ist_str())}\\n\"\n",
    "                f\"Ticker: <b>{_escape_html(res['ticker'])}</b>\\n\"\n",
    "                f\"Entry:  <b>{res['entry_price']:.2f}</b>\\n\"\n",
    "                f\"Now:    <b>{res['current_close']:.2f}</b>\\n\"\n",
    "                f\"PnL:    <b>{res['pnl_pct']:.2f}%</b>\\n\"\n",
    "                f\"Held:   <b>{res['bars_held']}</b> bars\\n\"\n",
    "                f\"Reason: {_escape_html(res['reasons'])}\"\n",
    "            )\n",
    "            send_telegram(text, tcfg)\n",
    "\n",
    "        # Optional summary\n",
    "        if tcfg.get(\"SEND_SUMMARY\", True):\n",
    "            if exits_triggered:\n",
    "                lines = []\n",
    "                for res in exits_triggered:\n",
    "                    lines.append(\n",
    "                        f\"• <b>{_escape_html(res['ticker'])}</b> \"\n",
    "                        f\"@ {_escape_html(res['as_of'])} | \"\n",
    "                        f\"{res['current_close']:.2f} | \"\n",
    "                        f\"{res['pnl_pct']:.2f}% | \"\n",
    "                        f\"{_escape_html(res['reasons'])}\"\n",
    "                    )\n",
    "                summary = (\n",
    "                    f\"<b>Exit Summary</b> — {_escape_html(_now_ist_str())}\\n\"\n",
    "                    f\"Total exits: <b>{len(exits_triggered)}</b>\\n\\n\" + \"\\n\".join(lines)\n",
    "                )\n",
    "            else:\n",
    "                summary = f\"<b>Exit Summary</b> — {_escape_html(_now_ist_str())}\\nNo exits today.\"\n",
    "            send_telegram(summary, tcfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
