{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac013dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (4.13.4)\n",
      "Requirement already satisfied: pandas in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting feedparser\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Collecting sgmllib3k (from feedparser)\n",
      "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow<2.21,>=2.20 (from tf-keras)\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.31.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading optree-0.17.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hemank/Documents/github/.talib/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl (200.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.5/200.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.74.0-cp312-cp312-macosx_11_0_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl (663 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m663.9/663.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl (39 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading optree-0.17.0-cp312-cp312-macosx_11_0_arm64.whl (351 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "\u001b[33m  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=9fcea06b94641155f360a3fb0e5cdfe951dc88d64d722a3271f7b7b33be2d33c\n",
      "  Stored in directory: /Users/hemank/Library/Caches/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, namex, mpmath, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, sympy, safetensors, optree, opt_einsum, networkx, ml_dtypes, mdurl, markdown, hf-xet, h5py, grpcio, google_pasta, gast, fsspec, filelock, feedparser, click, astunparse, absl-py, torch, tensorboard, nltk, markdown-it-py, huggingface-hub, tokenizers, rich, transformers, keras, tensorflow, tf-keras\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39/39\u001b[0m [tf-keras]/39\u001b[0m [tf-keras]w]s]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 click-8.2.1 feedparser-6.0.11 filelock-3.19.1 flatbuffers-25.2.10 fsspec-2025.9.0 gast-0.6.0 google_pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 hf-xet-1.1.9 huggingface-hub-0.34.4 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 mpmath-1.3.0 namex-0.1.0 networkx-3.5 nltk-3.9.1 opt_einsum-3.4.0 optree-0.17.0 rich-14.1.0 safetensors-0.6.2 sgmllib3k-1.0.0 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 tf-keras-2.20.1 tokenizers-0.22.0 torch-2.8.0 transformers-4.56.1 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch requests beautifulsoup4 pandas nltk feedparser tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d10394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Fetching top 50 headlines for 'POWERGRID' from Google Newsâ€¦\n",
      "âš ï¸  No headlines found.\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from datetime import datetime\n",
    "\n",
    "# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "STOCK       = \"POWERGRID\"    # stock ticker or name to search\n",
    "MAX_HEAD    = 50           # how many headlines to fetch\n",
    "MODEL_NAME  = \"ProsusAI/finbert\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1) Fetch Google News RSS for the stock\n",
    "def fetch_google_news_headlines(query, max_items=10):\n",
    "    \"\"\"\n",
    "    Uses Google News RSS to return the top headlines for a search query.\n",
    "    \"\"\"\n",
    "    # Google News RSS URL for search:\n",
    "    url = f\"https://news.google.com/rss/search?q={query}+stock+india&hl=en-IN&gl=IN&ceid=IN:en\"\n",
    "    feed = feedparser.parse(url)\n",
    "    headlines = []\n",
    "    for entry in feed.entries[:max_items]:\n",
    "        headlines.append(entry.title)\n",
    "    return headlines\n",
    "\n",
    "# 2) Load the FinBERT sentiment-analysis pipeline\n",
    "sentiment_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=MODEL_NAME,\n",
    "    tokenizer=MODEL_NAME\n",
    ")\n",
    "\n",
    "# 3) Score each headline\n",
    "def score_headlines(headlines):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with [timestamp, headline, label, score].\n",
    "    \"\"\"\n",
    "    results = sentiment_model(headlines)\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"headline\"]  = headlines\n",
    "    df[\"timestamp\"] = datetime.now()\n",
    "    # Ensure consistent column names\n",
    "    df = df.rename(columns={\n",
    "        df.columns[0]:\"label\",\n",
    "        df.columns[1]:\"score\"\n",
    "    })\n",
    "    return df[[\"timestamp\",\"headline\",\"label\",\"score\"]]\n",
    "\n",
    "# 4) Aggregate into a single weighted score\n",
    "def aggregate_score(df):\n",
    "    \"\"\"\n",
    "    Map labels to numerical values and compute a weighted mean.\n",
    "    \"\"\"\n",
    "    mapping = {\"positive\":1, \"neutral\":0, \"negative\":-1}\n",
    "    df[\"numeric\"] = df[\"label\"].map(mapping) * df[\"score\"]\n",
    "    return df[\"numeric\"].mean()\n",
    "\n",
    "# 5) End-to-end\n",
    "def sentiment_bot(stock):\n",
    "    print(f\"\\nðŸ”Ž Fetching top {MAX_HEAD} headlines for '{stock}' from Google Newsâ€¦\")\n",
    "    headlines = fetch_google_news_headlines(stock, max_items=MAX_HEAD)\n",
    "    if not headlines:\n",
    "        print(\"âš ï¸  No headlines found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ðŸ“° Headlines:\")\n",
    "    for i, h in enumerate(headlines, 1):\n",
    "        print(f\"  {i}. {h}\")\n",
    "    \n",
    "    df_scores = score_headlines(headlines)\n",
    "    avg = aggregate_score(df_scores)\n",
    "    \n",
    "    print(\"\\nðŸ’¬ Sentiment scores:\")\n",
    "    print(df_scores.to_string(index=False))\n",
    "    print(f\"\\nðŸ‘‰ Average weighted sentiment: {avg:.3f}\")\n",
    "    \n",
    "    if avg >  0.05:\n",
    "        print(\"Overall sentiment: ðŸ“ˆ POSITIVE â†’ consider LONG bias\")\n",
    "    elif avg < -0.05:\n",
    "        print(\"Overall sentiment: ðŸ“‰ NEGATIVE â†’ consider SHORT bias\")\n",
    "    else:\n",
    "        print(\"Overall sentiment: âž– NEUTRAL\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentiment_bot(STOCK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8971cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>bias</th>\n",
       "      <th>num_headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADANIPORTS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIANPAINT.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXISBANK.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAJAJ-AUTO.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAJAJFINSV.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BPCL.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BHARTIARTL.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BRITANNIA.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CIPLA.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COALINDIA.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DIVISLAB.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DRREDDY.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EICHERMOT.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GAIL.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GRASIM.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HDFCBANK.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HINDALCO.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HINDUNILVR.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HDFC.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HCLTECH.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ICICIBANK.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INDUSINDBK.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>INFY.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ITC.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JSWSTEEL.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KOTAKBANK.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LT.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>M&amp;M.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MARUTI.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NESTLEIND.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NTPC.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ONGC.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>POWERGRID.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SBILIFE.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SBIN.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SUNPHARMA.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TATAMOTORS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TATASTEEL.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TECHM.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TITAN.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ULTRACEMCO.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>UPL.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol  avg_score     bias  num_headlines\n",
       "0   ADANIPORTS.NS        0.0  NEUTRAL              0\n",
       "1   ASIANPAINT.NS        0.0  NEUTRAL              0\n",
       "2     AXISBANK.NS        0.0  NEUTRAL              0\n",
       "3   BAJAJ-AUTO.NS        0.0  NEUTRAL              0\n",
       "4   BAJFINANCE.NS        0.0  NEUTRAL              0\n",
       "5   BAJAJFINSV.NS        0.0  NEUTRAL              0\n",
       "6         BPCL.NS        0.0  NEUTRAL              0\n",
       "7   BHARTIARTL.NS        0.0  NEUTRAL              0\n",
       "8    BRITANNIA.NS        0.0  NEUTRAL              0\n",
       "9        CIPLA.NS        0.0  NEUTRAL              0\n",
       "10   COALINDIA.NS        0.0  NEUTRAL              0\n",
       "11    DIVISLAB.NS        0.0  NEUTRAL              0\n",
       "12     DRREDDY.NS        0.0  NEUTRAL              0\n",
       "13   EICHERMOT.NS        0.0  NEUTRAL              0\n",
       "14        GAIL.NS        0.0  NEUTRAL              0\n",
       "15      GRASIM.NS        0.0  NEUTRAL              0\n",
       "16    HDFCBANK.NS        0.0  NEUTRAL              0\n",
       "17    HINDALCO.NS        0.0  NEUTRAL              0\n",
       "18  HINDUNILVR.NS        0.0  NEUTRAL              0\n",
       "19        HDFC.NS        0.0  NEUTRAL              0\n",
       "20     HCLTECH.NS        0.0  NEUTRAL              0\n",
       "21   ICICIBANK.NS        0.0  NEUTRAL              0\n",
       "22  INDUSINDBK.NS        0.0  NEUTRAL              0\n",
       "23        INFY.NS        0.0  NEUTRAL              0\n",
       "24         ITC.NS        0.0  NEUTRAL              0\n",
       "25    JSWSTEEL.NS        0.0  NEUTRAL              0\n",
       "26   KOTAKBANK.NS        0.0  NEUTRAL              0\n",
       "27          LT.NS        0.0  NEUTRAL              0\n",
       "28         M&M.NS        0.0  NEUTRAL              0\n",
       "29      MARUTI.NS        0.0  NEUTRAL              0\n",
       "30   NESTLEIND.NS        0.0  NEUTRAL              0\n",
       "31        NTPC.NS        0.0  NEUTRAL              0\n",
       "32        ONGC.NS        0.0  NEUTRAL              0\n",
       "33   POWERGRID.NS        0.0  NEUTRAL              0\n",
       "34     SBILIFE.NS        0.0  NEUTRAL              0\n",
       "35        SBIN.NS        0.0  NEUTRAL              0\n",
       "36   SUNPHARMA.NS        0.0  NEUTRAL              0\n",
       "37  TATAMOTORS.NS        0.0  NEUTRAL              0\n",
       "38   TATASTEEL.NS        0.0  NEUTRAL              0\n",
       "39         TCS.NS        0.0  NEUTRAL              0\n",
       "40       TECHM.NS        0.0  NEUTRAL              0\n",
       "41       TITAN.NS        0.0  NEUTRAL              0\n",
       "42  ULTRACEMCO.NS        0.0  NEUTRAL              0\n",
       "43         UPL.NS        0.0  NEUTRAL              0\n",
       "44       WIPRO.NS        0.0  NEUTRAL              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from datetime import datetime\n",
    "\n",
    "# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# List of Nifty 50 tickers (Yahoo Finance format)\n",
    "nifty50 = [\n",
    "    'ADANIPORTS.NS','ASIANPAINT.NS','AXISBANK.NS','BAJAJ-AUTO.NS','BAJFINANCE.NS',\n",
    "    'BAJAJFINSV.NS','BPCL.NS','BHARTIARTL.NS','BRITANNIA.NS','CIPLA.NS',\n",
    "    'COALINDIA.NS','DIVISLAB.NS','DRREDDY.NS','EICHERMOT.NS','GAIL.NS',\n",
    "    'GRASIM.NS','HDFCBANK.NS','HINDALCO.NS','HINDUNILVR.NS','HDFC.NS',\n",
    "    'HCLTECH.NS','ICICIBANK.NS','INDUSINDBK.NS','INFY.NS','ITC.NS',\n",
    "    'JSWSTEEL.NS','KOTAKBANK.NS','LT.NS','M&M.NS','MARUTI.NS',\n",
    "    'NESTLEIND.NS','NTPC.NS','ONGC.NS','POWERGRID.NS','SBILIFE.NS',\n",
    "    'SBIN.NS','SUNPHARMA.NS','TATAMOTORS.NS','TATASTEEL.NS','TCS.NS',\n",
    "    'TECHM.NS','TITAN.NS','ULTRACEMCO.NS','UPL.NS','WIPRO.NS'\n",
    "]\n",
    "MAX_HEADLINES = 10\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Load FinBERT sentiment-analysis pipeline\n",
    "sentiment_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=MODEL_NAME,\n",
    "    tokenizer=MODEL_NAME\n",
    ")\n",
    "\n",
    "def fetch_google_news_headlines(query, max_items=MAX_HEADLINES):\n",
    "    \"\"\"\n",
    "    Fetch top headlines for a query via Google News RSS.\n",
    "    \"\"\"\n",
    "    url = f\"https://news.google.com/rss/search?q={query}+stock+india&hl=en-IN&gl=IN&ceid=IN:en\"\n",
    "    feed = feedparser.parse(url)\n",
    "    return [entry.title for entry in feed.entries[:max_items]]\n",
    "\n",
    "def score_headlines(headlines):\n",
    "    \"\"\"\n",
    "    Score headlines using FinBERT transformer.\n",
    "    Returns DataFrame with columns [timestamp, headline, label, score].\n",
    "    \"\"\"\n",
    "    if not headlines:\n",
    "        return pd.DataFrame(columns=[\"timestamp\",\"headline\",\"label\",\"score\"])\n",
    "    results = sentiment_model(headlines)\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"headline\"] = headlines\n",
    "    df[\"timestamp\"] = datetime.now()\n",
    "    # rename columns to standard names\n",
    "    df = df.rename(columns={df.columns[0]:\"label\", df.columns[1]:\"score\"})\n",
    "    return df[[\"timestamp\",\"headline\",\"label\",\"score\"]]\n",
    "\n",
    "def aggregate_score(df_scores):\n",
    "    \"\"\"\n",
    "    Compute average weighted sentiment: positive=1, neutral=0, negative=-1 times score.\n",
    "    \"\"\"\n",
    "    if df_scores.empty:\n",
    "        return 0.0\n",
    "    mapping = {\"positive\":1, \"neutral\":0, \"negative\":-1}\n",
    "    df_scores[\"numeric\"] = df_scores[\"label\"].map(mapping) * df_scores[\"score\"]\n",
    "    return df_scores[\"numeric\"].mean()\n",
    "\n",
    "# Main loop: process all Nifty 50\n",
    "records = []\n",
    "for ticker in nifty50:\n",
    "    query = ticker.split(\".\")[0]\n",
    "    headlines = fetch_google_news_headlines(query)\n",
    "    df_scores = score_headlines(headlines)\n",
    "    avg = aggregate_score(df_scores)\n",
    "    bias = \"LONG\" if avg > 0.05 else \"SHORT\" if avg < -0.05 else \"NEUTRAL\"\n",
    "    records.append({\n",
    "        \"symbol\": ticker,\n",
    "        \"avg_score\": avg,\n",
    "        \"bias\": bias,\n",
    "        \"num_headlines\": len(headlines)\n",
    "    })\n",
    "\n",
    "# Create final DataFrame\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
