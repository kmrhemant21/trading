{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c353356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat)\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.13.2)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl (358 kB)\n",
      "Installing collected packages: fastjsonschema, rpds-py, referencing, jsonschema-specifications, jsonschema, nbformat\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [nbformat]\n",
      "\u001b[1A\u001b[2KSuccessfully installed fastjsonschema-2.21.1 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 nbformat-5.10.4 referencing-0.36.2 rpds-py-0.26.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade nbformat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e147c0",
   "metadata": {},
   "source": [
    "Here’s a detailed, step-by-step walkthrough of what your script is doing:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Imports & Dependencies\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import vectorbt as vbt\n",
    "```\n",
    "\n",
    "* **NumPy & pandas** for array and DataFrame manipulation.\n",
    "* **yfinance** to download historical/intraday price data from Yahoo Finance.\n",
    "* **StandardScaler** to normalize your price series so the LSTM trains more smoothly.\n",
    "* **TensorFlow/Keras** (`Sequential`, `LSTM`, etc.) to build and train your recurrent neural network.\n",
    "* **vectorbt** for a quick, vectorized backtest of the generated signals.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. User-Defined Parameters\n",
    "\n",
    "```python\n",
    "SYMBOL     = \"AAPL\"    # which stock ticker to use\n",
    "PERIOD     = \"60d\"     # grab the last 60 days of data\n",
    "INTERVAL   = \"5m\"      # with 5-minute bars\n",
    "LOOKBACK   = 20        # use 20 past bars per LSTM input\n",
    "TEST_RATIO = 0.2       # reserve 20% of samples for testing\n",
    "EPOCHS     = 20        # max training epochs\n",
    "BATCH_SIZE = 64        # gradient-descent batch size\n",
    "```\n",
    "\n",
    "These let you quickly swap symbols, timeframes, or model hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Fetch Intraday Data\n",
    "\n",
    "```python\n",
    "data = yf.download(\n",
    "    SYMBOL,\n",
    "    period=PERIOD,\n",
    "    interval=INTERVAL,\n",
    "    progress=False\n",
    ")\n",
    "if data.empty:\n",
    "    raise ValueError(\"No intraday data – check your symbol/interval!\")\n",
    "close_series = data[\"Close\"].dropna()\n",
    "```\n",
    "\n",
    "* Calls `yf.download()` to pull Open/High/Low/Close/Volume at 5-minute intervals over the last 60 days.\n",
    "* Grabs only the **Close** column and drops any missing values.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Scale the Close Prices\n",
    "\n",
    "```python\n",
    "scaler  = StandardScaler()\n",
    "close_s = scaler.fit_transform(close_series.values.reshape(-1, 1)).ravel()\n",
    "```\n",
    "\n",
    "* Neural nets train more reliably on zero-mean, unit-variance data.\n",
    "* `StandardScaler` fits to your close prices and transforms them so they have mean = 0 and std = 1.\n",
    "* We keep both the **raw** `close_arr` (for PnL calculations) and the **scaled** `scaled_arr` (for LSTM inputs).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Build LSTM Input Sequences & Targets\n",
    "\n",
    "```python\n",
    "seqs, targets, idxs = [], [], []\n",
    "\n",
    "for i in range(LOOKBACK, len(close_arr) - 1):\n",
    "    seqs.append(scaled_arr[i - LOOKBACK : i])\n",
    "    # target is the next bar’s return: (next_close – this_close) / this_close\n",
    "    targets.append((close_arr[i + 1] - close_arr[i]) / close_arr[i])\n",
    "    idxs.append(close_series.index[i])\n",
    "```\n",
    "\n",
    "* **Sequences**: For each time *i*, grab the previous 20 normalized prices → shape `(20,)`.\n",
    "* **Targets**: The *actual* percentage return from bar *i* to *i+1*, computed on the raw price scale.\n",
    "* **Timestamps**: Keep the datetime index for later alignment in backtesting.\n",
    "\n",
    "You then reshape:\n",
    "\n",
    "```python\n",
    "X = np.array(seqs).reshape(-1, LOOKBACK, 1)  # (samples, timesteps, features)\n",
    "y = np.array(targets)                        # (samples,)\n",
    "idxs = pd.DatetimeIndex(idxs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Train/Test Split\n",
    "\n",
    "```python\n",
    "n_samples = len(X)\n",
    "split     = int(n_samples * (1 - TEST_RATIO))\n",
    "\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "idx_train, idx_test = idxs[:split], idxs[split:]\n",
    "```\n",
    "\n",
    "* The first 80% of rolling windows go to **training**, the last 20% to **testing**.\n",
    "* You keep the corresponding timestamps (`idx_train`, `idx_test`) for plotting/backtesting.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Define the LSTM Model\n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(LOOKBACK, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "```\n",
    "\n",
    "* **First LSTM layer**: 50 memory cells, returns a full sequence so the next LSTM layer can consume it.\n",
    "* **Dropout(0.2)** after each LSTM to guard against overfitting.\n",
    "* **Second LSTM layer**: Another 50 units, but returns only its final hidden state.\n",
    "* **Dense(1)**: A single output predicting the *next‐bar return*.\n",
    "* Trained with **mean squared error** and the **Adam** optimizer.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Train with Early Stopping\n",
    "\n",
    "```python\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "```\n",
    "\n",
    "* Monitors validation MSE and stops if it doesn’t improve for 5 epochs, restoring the best weights.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Predict & Flatten\n",
    "\n",
    "```python\n",
    "y_pred_raw = model.predict(X_test)       # shape (n_test, 1)\n",
    "y_pred = y_pred_raw.flatten()            # shape (n_test,)\n",
    "```\n",
    "\n",
    "* Runs your LSTM on the test windows to get predicted next-bar returns.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Build Trading Signals\n",
    "\n",
    "```python\n",
    "# Real close prices aligned to predictions:\n",
    "close_seq        = close_arr[LOOKBACK : -1]\n",
    "close_test       = close_seq[split:]\n",
    "# Align lengths and timestamp index:\n",
    "signals = pd.DataFrame({\n",
    "    \"Close\":    close_test.squeeze(),\n",
    "    \"pred_ret\": y_pred\n",
    "}, index=idx_test)\n",
    "# Simple rule: go long whenever predicted return > 0, exit otherwise\n",
    "entries = signals[\"pred_ret\"] > 0\n",
    "exits   = ~entries\n",
    "```\n",
    "\n",
    "* **`signals[\"Close\"]`** is your actual price series for the backtest.\n",
    "* **`pred_ret`** drives entry/exit decisions:\n",
    "\n",
    "  * **Entry** (`True`) when `pred_ret > 0`\n",
    "  * **Exit** when `pred_ret <= 0`\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Backtest with vectorbt\n",
    "\n",
    "```python\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    close=signals[\"Close\"],\n",
    "    entries=entries,\n",
    "    exits=exits,\n",
    "    init_cash=100_000,\n",
    "    fees=0.001,\n",
    "    freq=\"5T\"\n",
    ")\n",
    "```\n",
    "\n",
    "* **`from_signals`** consumes your price series plus boolean entry/exit masks.\n",
    "* **`init_cash`** = \\$100 000 starting capital.\n",
    "* **`fees=0.001`** imposes a 0.1% round-trip commission on each trade.\n",
    "* **`freq=\"5T\"`** tells vectorbt these are 5-minute intervals (important for annualized metrics).\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Performance Summary & Visualization\n",
    "\n",
    "```python\n",
    "print(\"Total Return      :\", pf.total_return() * 100, \"%\")\n",
    "print(\"Annualized Return :\", pf.annualized_return() * 100, \"%\")\n",
    "print(\"Sharpe Ratio      :\", pf.sharpe_ratio())\n",
    "print(\"Max Drawdown      :\", pf.max_drawdown() * 100, \"%\")\n",
    "\n",
    "pf.plot_cash_flow().show()\n",
    "```\n",
    "\n",
    "* **`total_return()`**: cumulative PnL as a percentage.\n",
    "* **`annualized_return()`**: compounds the 5-minute PnL up to a yearly figure.\n",
    "* **`sharpe_ratio()`**: risk-adjusted return (assumes zero risk-free).\n",
    "* **`max_drawdown()`**: deepest peak-to-trough equity decline.\n",
    "* **`plot_cash_flow()`**: a built-in vectorbt chart showing deposits/withdrawals and realized PnL over time.\n",
    "\n",
    "---\n",
    "\n",
    "### In a nutshell\n",
    "\n",
    "1. **Fetch** 5-minute Apple prices\n",
    "2. **Normalize** them and build rolling windows\n",
    "3. **Train** an LSTM to predict the next bar’s return\n",
    "4. **Signal**: if predicted return > 0, go long; otherwise close position\n",
    "5. **Backtest** that strategy vectorized with realistic fees\n",
    "6. **Report** your key metrics and plot your PnL curve\n",
    "\n",
    "This gives you an end-to-end pipeline—from raw data to neural prediction to strategy evaluation—all in a few dozen lines of Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "356dc76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_84865/2319827700.py:20: FutureWarning:\n",
      "\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 4642 bars from 2025-04-11 to 2025-07-09\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemank/Documents/github/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 9.1951e-06\n",
      "Epoch 2/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.9509e-04 - val_loss: 4.5775e-06\n",
      "Epoch 3/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.0134e-04 - val_loss: 5.7038e-06\n",
      "Epoch 4/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.6430e-05 - val_loss: 6.2807e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.1031e-05 - val_loss: 6.1444e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.8214e-05 - val_loss: 7.0878e-06\n",
      "Epoch 7/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.9945e-05 - val_loss: 3.7381e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2311e-05 - val_loss: 2.8209e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.4213e-05 - val_loss: 6.0481e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.9081e-05 - val_loss: 3.8352e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.3239e-05 - val_loss: 2.7327e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0230e-05 - val_loss: 3.0312e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.0308e-05 - val_loss: 4.3810e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.0535e-05 - val_loss: 4.0565e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.9458e-05 - val_loss: 2.9219e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5756e-05 - val_loss: 2.7533e-06\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Raw predictions shape: (925, 1)\n",
      "Flattened predictions shape: (925,)\n",
      "Test len: 925 predictions: (925,) closes: (925, 1)\n",
      "Aligned lengths - idx: 925, pred: 925, close: 925\n",
      "\n",
      "=== Performance Summary ===\n",
      "Total Return      : 2.70%\n",
      "Annualized Return : 1966.35%\n",
      "Sharpe Ratio      : 8.85\n",
      "Max Drawdown      : -1.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemank/Documents/github/.venv/lib/python3.11/site-packages/vectorbt/utils/datetime_.py:24: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version. Please use 'min' instead of 'T'.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 129\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSharpe Ratio      : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpf.sharpe_ratio()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax Drawdown      : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpf.max_drawdown()\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[43mpf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_cash_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/vectorbt/utils/figure.py:78\u001b[39m, in \u001b[36mFigureWidget.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m fig_kwargs = \u001b[38;5;28mdict\u001b[39m(width=\u001b[38;5;28mself\u001b[39m.layout.width, height=\u001b[38;5;28mself\u001b[39m.layout.height)\n\u001b[32m     77\u001b[39m show_kwargs = merge_dicts(fig_kwargs, plotting_cfg[\u001b[33m'\u001b[39m\u001b[33mshow_kwargs\u001b[39m\u001b[33m'\u001b[39m], kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[43m_Figure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshow_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/plotly/basedatatypes.py:3410\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3377\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3378\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3379\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3406\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3407\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3408\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/plotly/io/_renderers.py:394\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    390\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    391\u001b[39m         )\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    395\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    396\u001b[39m         )\n\u001b[32m    398\u001b[39m     ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import vectorbt as vbt\n",
    "\n",
    "# ────────── 1. PARAMETERS ──────────\n",
    "SYMBOL     = \"AAPL\"     # ticker to backtest\n",
    "PERIOD     = \"60d\"      # last 60 days of 5m data\n",
    "INTERVAL   = \"5m\"\n",
    "LOOKBACK   = 20         # bars per LSTM input sequence\n",
    "TEST_RATIO = 0.2\n",
    "EPOCHS     = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# ────────── 2. FETCH INTRADAY DATA ──────────\n",
    "data = yf.download(\n",
    "    SYMBOL,\n",
    "    period=PERIOD,\n",
    "    interval=INTERVAL,\n",
    "    progress=False\n",
    ")\n",
    "if data.empty:\n",
    "    raise ValueError(\"No intraday data – check your symbol/interval!\")\n",
    "close_series = data[\"Close\"].dropna()  # pandas Series (1-D)\n",
    "print(f\"Fetched {len(close_series)} bars from {close_series.index.min().date()} to {close_series.index.max().date()}\")\n",
    "\n",
    "# ────────── 3. SCALE CLOSE PRICE ──────────\n",
    "scaler    = StandardScaler()\n",
    "# Use .values.reshape(-1,1) to give scaler a 2-D array\n",
    "close_s   = scaler.fit_transform(close_series.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "close_arr  = close_series.values        # shape (N,)\n",
    "scaled_arr = close_s                    # shape (N,)\n",
    "\n",
    "# ────────── 4. BUILD SEQUENCES & TARGETS ──────────\n",
    "seqs, targets, idxs = [], [], []\n",
    "for i in range(LOOKBACK, len(close_arr) - 1):\n",
    "    seqs.append(scaled_arr[i - LOOKBACK : i])               # last LOOKBACK scalars\n",
    "    targets.append((close_arr[i + 1] - close_arr[i]) / close_arr[i])  # next-bar return\n",
    "    idxs.append(close_series.index[i])                      # timestamp\n",
    "\n",
    "X = np.array(seqs).reshape(-1, LOOKBACK, 1)  # (samples, timesteps, features)\n",
    "y = np.array(targets)                        # (samples,)\n",
    "idxs = pd.DatetimeIndex(idxs)\n",
    "\n",
    "# ────────── 5. TRAIN/TEST SPLIT ──────────\n",
    "n_samples = len(X)\n",
    "split     = int(n_samples * (1 - TEST_RATIO))\n",
    "\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "idx_train, idx_test = idxs[:split], idxs[split:]\n",
    "\n",
    "# ────────── 6. DEFINE LSTM MODEL ──────────\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(LOOKBACK, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# ────────── 7. TRAIN WITH EARLY STOPPING ──────────\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ────────── 8. PREDICT & FLATTEN ──────────\n",
    "y_pred_raw = model.predict(X_test)\n",
    "print(f\"Raw predictions shape: {y_pred_raw.shape}\")\n",
    "y_pred = y_pred_raw.flatten()  # Ensure 1D array\n",
    "print(f\"Flattened predictions shape: {y_pred.shape}\")\n",
    "\n",
    "# ────────── 9. BUILD SIGNALS ──────────\n",
    "# Align raw closes with our sequences:\n",
    "close_seq  = close_arr[LOOKBACK : -1]   # drop first LOOKBACK and last bar\n",
    "close_test = close_seq[split:]          # test portion\n",
    "\n",
    "# Verify both are 1-D and same length\n",
    "print(\"Test len:\", len(idx_test), \n",
    "      \"predictions:\", y_pred.shape, \n",
    "      \"closes:\", close_test.shape)\n",
    "\n",
    "# Ensure all arrays have matching lengths\n",
    "min_len = min(len(idx_test), len(y_pred), len(close_test))\n",
    "idx_test_aligned = idx_test[:min_len]\n",
    "y_pred_aligned = y_pred[:min_len]\n",
    "close_test_aligned = close_test[:min_len]\n",
    "\n",
    "print(f\"Aligned lengths - idx: {len(idx_test_aligned)}, pred: {len(y_pred_aligned)}, close: {len(close_test_aligned)}\")\n",
    "\n",
    "signals = pd.DataFrame({\n",
    "    \"Close\":    close_test_aligned.squeeze(),\n",
    "    \"pred_ret\": y_pred_aligned\n",
    "}, index=idx_test_aligned)\n",
    "\n",
    "entries = signals[\"pred_ret\"] > 0\n",
    "exits   = ~entries  # exit whenever pred_ret ≤ 0\n",
    "\n",
    "# ────────── 10. BACKTEST WITH VECTORBT ──────────\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    close=signals[\"Close\"],\n",
    "    entries=entries,\n",
    "    exits=exits,\n",
    "    init_cash=100_000,\n",
    "    fees=0.001,\n",
    "    freq=\"5T\"\n",
    ")\n",
    "\n",
    "# ────────── 11. PERFORMANCE & PLOT ──────────\n",
    "print(\"\\n=== Performance Summary ===\")\n",
    "print(f\"Total Return      : {pf.total_return() * 100:.2f}%\")\n",
    "print(f\"Annualized Return : {pf.annualized_return() * 100:.2f}%\")\n",
    "print(f\"Sharpe Ratio      : {pf.sharpe_ratio():.2f}\")\n",
    "print(f\"Max Drawdown      : {pf.max_drawdown() * 100:.2f}%\")\n",
    "\n",
    "pf.plot_cash_flow().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4afdf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.10.4\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "print(nbformat.__version__)  # should be ≥ 4.2.0\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"vscode\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
