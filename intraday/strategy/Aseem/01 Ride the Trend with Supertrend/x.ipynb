{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31767e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 00:44:42 | INFO | Capital/trade = ₹100,000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 368\u001b[39m\n\u001b[32m    365\u001b[39m     log.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrades=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(trades)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Winrate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwinrate\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% | Net P&L=₹\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m    354\u001b[39m     ensure_dir(CFG.out_dir)\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     trades = \u001b[43mrun_backtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m     out = os.path.join(CFG.out_dir, CFG.trades_csv)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trades.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 270\u001b[39m, in \u001b[36mrun_backtest\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    268\u001b[39m m, d = fetch_minute_and_daily(s)\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m m.empty \u001b[38;5;129;01mor\u001b[39;00m d.empty: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m piv = \u001b[43mdaily_pivots_from_prev_day\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m m = attach_pivots(m, piv)\n\u001b[32m    272\u001b[39m st = supertrend(m, CFG.st_atr_period, CFG.st_multiplier)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 189\u001b[39m, in \u001b[36mdaily_pivots_from_prev_day\u001b[39m\u001b[34m(daily)\u001b[39m\n\u001b[32m    186\u001b[39m r1 = \u001b[32m2\u001b[39m * pp - prev[\u001b[33m\"\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    187\u001b[39m s1 = \u001b[32m2\u001b[39m * pp - prev[\u001b[33m\"\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m piv = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mR1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mr1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mS1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m piv.index = daily.index  \u001b[38;5;66;03m# align dates with daily frame\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m piv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.talib/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.talib/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.talib/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.talib/lib/python3.12/site-packages/pandas/core/internals/construction.py:667\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    664\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIf using all scalar values, you must pass an index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[32m    670\u001b[39m     index = union_indexes(indexes)\n",
      "\u001b[31mValueError\u001b[39m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Supertrend + Pivot (R1/S1) Intraday Backtest — NIFTY50 (5m)\n",
    "-----------------------------------------------------------\n",
    "Entries\n",
    "  Long : Close crosses ABOVE R1 and Supertrend is GREEN\n",
    "  Short: Close crosses BELOW S1 and Supertrend is RED\n",
    "\n",
    "Exits\n",
    "  Supertrend stop/flip, optional SL/TP, EOD square-off\n",
    "\n",
    "Defaults\n",
    "  • Date range: last 60 days up to today (IST), 5-minute bars\n",
    "  • Capital: ₹1,00,000 with 5× intraday margin (deployable ₹5,00,000)\n",
    "  • Max concurrent trades: 5\n",
    "  • Long/Short toggles, SL/TP toggles\n",
    "  • Next-bar-open execution (realistic)\n",
    "  • Groww intraday cost model\n",
    "  • Trade log: outputs/trades.csv\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import math, os, sys, warnings, logging, datetime\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    import pytz\n",
    "except Exception:\n",
    "    print(\"Please install dependencies: pip install pandas numpy yfinance pytz\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =========================\n",
    "# LOGGING\n",
    "# =========================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"supertrend_pivot_backtest\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "def default_dates_last_60d_ist() -> tuple[str, str]:\n",
    "    tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "    today = datetime.datetime.now(tz).date()\n",
    "    start = (today - datetime.timedelta(days=60)).isoformat()\n",
    "    end = (today + datetime.timedelta(days=1)).isoformat()  # Yahoo end is exclusive\n",
    "    return start, end\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Dates\n",
    "    start_date, end_date = default_dates_last_60d_ist()\n",
    "    interval: str = \"5m\"\n",
    "    tz: str = \"Asia/Kolkata\"\n",
    "\n",
    "    # Universe\n",
    "    use_nifty50_universe: bool = True\n",
    "    tickers: Optional[List[str]] = None\n",
    "    append_suffix_ns: bool = True\n",
    "\n",
    "    # Strategy toggles\n",
    "    enable_longs: bool  = True\n",
    "    enable_shorts: bool = True\n",
    "    use_next_bar_open: bool = True\n",
    "    use_eod_squareoff: bool = True\n",
    "    eod_squareoff_time: str = \"15:25\"  # IST\n",
    "\n",
    "    # Supertrend\n",
    "    st_atr_period: int = 7\n",
    "    st_multiplier: float = 3.0\n",
    "\n",
    "    # Entry logic\n",
    "    require_close_cross: bool = True  # True=cross; False=touch or cross\n",
    "\n",
    "    # Risk & money management\n",
    "    account_rupees: float = 100_000.0\n",
    "    intraday_margin: float = 5.0\n",
    "    max_concurrent_trades: int = 5\n",
    "    capital_fraction_per_trade: Optional[float] = None  # None = equal split\n",
    "\n",
    "    # Optional SL/TP\n",
    "    enable_stop_loss: bool = True\n",
    "    stop_loss_pct: float = 0.01\n",
    "    enable_take_profit: bool = False\n",
    "    take_profit_pct: float = 0.02\n",
    "\n",
    "    # Costs & outputs\n",
    "    enable_costs: bool = True\n",
    "    out_dir: str = \"outputs\"\n",
    "    trades_csv: str = \"trades.csv\"\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# =========================\n",
    "# Groww intraday cost model\n",
    "# =========================\n",
    "def groww_intraday_charges(buy_turnover: float, sell_turnover: float) -> Dict[str, float]:\n",
    "    def brokerage(turnover):\n",
    "        fee = min(20.0, 0.001 * turnover)\n",
    "        return max(5.0, fee)  # floor ₹5\n",
    "    bro_buy  = brokerage(buy_turnover)\n",
    "    bro_sell = brokerage(sell_turnover)\n",
    "    exch_buy  = 0.0000297 * buy_turnover\n",
    "    exch_sell = 0.0000297 * sell_turnover\n",
    "    sebi_buy  = 0.000001 * buy_turnover\n",
    "    sebi_sell = 0.000001 * sell_turnover\n",
    "    ipft_buy  = 0.000001 * buy_turnover\n",
    "    ipft_sell = 0.000001 * sell_turnover\n",
    "    gst_buy  = 0.18 * (bro_buy  + exch_buy  + sebi_buy  + ipft_buy)\n",
    "    gst_sell = 0.18 * (bro_sell + exch_sell + sebi_sell + ipft_sell)\n",
    "    stt_sell = 0.00025 * sell_turnover\n",
    "    stamp_buy = 0.00003 * buy_turnover\n",
    "    total = (bro_buy + bro_sell + exch_buy + exch_sell +\n",
    "             sebi_buy + sebi_sell + ipft_buy + ipft_sell +\n",
    "             gst_buy + gst_sell + stt_sell + stamp_buy)\n",
    "    return {\"total_charges\": total}\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def ensure_dir(p: str): os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def make_nifty50() -> List[str]:\n",
    "    base = [\n",
    "        \"ADANIENT\",\"ADANIPORTS\",\"APOLLOHOSP\",\"ASIANPAINT\",\"AXISBANK\",\"BAJAJ-AUTO\",\"BAJFINANCE\",\n",
    "        \"BAJAJFINSV\",\"BHARTIARTL\",\"BPCL\",\"BRITANNIA\",\"CIPLA\",\"COALINDIA\",\"DIVISLAB\",\"DRREDDY\",\n",
    "        \"EICHERMOT\",\"GRASIM\",\"HCLTECH\",\"HDFCBANK\",\"HDFCLIFE\",\"HEROMOTOCO\",\"HINDALCO\",\"HINDUNILVR\",\n",
    "        \"ICICIBANK\",\"INDUSINDBK\",\"INFY\",\"ITC\",\"JSWSTEEL\",\"KOTAKBANK\",\"LT\",\"M&M\",\"MARUTI\",\n",
    "        \"NESTLEIND\",\"NTPC\",\"ONGC\",\"POWERGRID\",\"RELIANCE\",\"SBILIFE\",\"SBIN\",\"SUNPHARMA\",\"TATACONSUM\",\n",
    "        \"TATAMOTORS\",\"TATASTEEL\",\"TCS\",\"TECHM\",\"TITAN\",\"ULTRACEMCO\",\"UPL\",\"WIPRO\",\"SHRIRAMFIN\"\n",
    "    ]\n",
    "    return [s + \".NS\" for s in base] if CFG.append_suffix_ns else base\n",
    "\n",
    "def as_ist(ts: pd.Timestamp) -> pd.Timestamp:\n",
    "    return ts.tz_convert(CFG.tz) if ts.tzinfo else ts.tz_localize(\"UTC\").tz_convert(CFG.tz)\n",
    "\n",
    "# =========================\n",
    "# Indicators\n",
    "# =========================\n",
    "def atr(df: pd.DataFrame, period: int) -> pd.Series:\n",
    "    h, l, c = df[\"High\"], df[\"Low\"], df[\"Close\"]\n",
    "    prev_c = c.shift(1)\n",
    "    tr = pd.concat([(h - l), (h - prev_c).abs(), (l - prev_c).abs()], axis=1).max(axis=1)\n",
    "    return tr.rolling(period).mean()\n",
    "\n",
    "def supertrend(df: pd.DataFrame, period: int, mult: float) -> pd.DataFrame:\n",
    "    hl2 = (df[\"High\"] + df[\"Low\"]) / 2.0\n",
    "    _atr = atr(df, period)\n",
    "    up = hl2 + mult * _atr\n",
    "    dn = hl2 - mult * _atr\n",
    "    st = pd.Series(index=df.index, dtype=float)\n",
    "    dir_ = pd.Series(index=df.index, dtype=int)\n",
    "    st.iloc[0] = up.iloc[0]\n",
    "    dir_.iloc[0] = -1\n",
    "    for i in range(1, len(df)):\n",
    "        if dir_.iloc[i-1] == -1:\n",
    "            st_val = min(up.iloc[i], st.iloc[i-1])\n",
    "            st.iloc[i] = st_val\n",
    "            dir_.iloc[i] = -1 if df[\"Close\"].iloc[i] <= st_val else 1\n",
    "        else:\n",
    "            st_val = max(dn.iloc[i], st.iloc[i-1])\n",
    "            st.iloc[i] = st_val\n",
    "            dir_.iloc[i] = 1 if df[\"Close\"].iloc[i] >= st_val else -1\n",
    "    return pd.DataFrame({\"st\": st, \"st_dir\": dir_})\n",
    "\n",
    "# =========================\n",
    "# Pivots (from previous day's daily bar) — SAFE\n",
    "# =========================\n",
    "def daily_pivots_from_prev_day(daily: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute previous-day Classic pivots (R1/S1) robustly.\n",
    "    Returns empty df if daily history < 2 rows or columns missing.\n",
    "    \"\"\"\n",
    "    # Coerce to DataFrame if Series\n",
    "    if isinstance(daily, pd.Series):\n",
    "        daily = daily.to_frame().T\n",
    "\n",
    "    # Guard: need at least 2 rows to reference \"previous day\"\n",
    "    if daily is None or daily.empty or len(daily.index) < 2:\n",
    "        return pd.DataFrame(columns=[\"R1\", \"S1\"])\n",
    "\n",
    "    # Guard: must have these columns\n",
    "    required = {\"High\", \"Low\", \"Close\"}\n",
    "    if not required.issubset(set(daily.columns)):\n",
    "        return pd.DataFrame(columns=[\"R1\", \"S1\"])\n",
    "\n",
    "    prev = daily.shift(1)  # prior day values aligned to current index\n",
    "    pp = (prev[\"High\"] + prev[\"Low\"] + prev[\"Close\"]) / 3.0\n",
    "    r1 = 2 * pp - prev[\"Low\"]\n",
    "    s1 = 2 * pp - prev[\"High\"]\n",
    "\n",
    "    piv = pd.DataFrame({\"R1\": r1, \"S1\": s1})\n",
    "    piv.index = daily.index  # align dates\n",
    "    return piv\n",
    "\n",
    "def attach_pivots(mins: pd.DataFrame, pivots: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Broadcast prior-day R1/S1 to each intraday row of current day.\n",
    "    If pivots are empty, fills NaN (later bars with NaN levels are dropped).\n",
    "    \"\"\"\n",
    "    if mins.empty:\n",
    "        return mins\n",
    "    idx_ist = mins.index.tz_convert(CFG.tz)\n",
    "    days = idx_ist.normalize()\n",
    "    rows = []\n",
    "    for d in np.unique(days):\n",
    "        mask = (days == d)\n",
    "        # Use pivot row at current day (which contains prior day's values due to shift)\n",
    "        r1 = s1 = np.nan\n",
    "        if not pivots.empty and d in pivots.index:\n",
    "            r1 = pivots.at[d, \"R1\"]\n",
    "            s1 = pivots.at[d, \"S1\"]\n",
    "        blk = pd.DataFrame({\"R1\": r1, \"S1\": s1}, index=mins.index[mask])\n",
    "        rows.append(blk)\n",
    "    lv = pd.concat(rows) if rows else pd.DataFrame(index=mins.index, columns=[\"R1\", \"S1\"])\n",
    "    out = pd.concat([mins, lv], axis=1)\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# Download data (timezone-safe)\n",
    "# =========================\n",
    "def _tz_to_utc(index: pd.DatetimeIndex) -> pd.DatetimeIndex:\n",
    "    if getattr(index, \"tz\", None) is None:\n",
    "        return index.tz_localize(\"UTC\")\n",
    "    return index.tz_convert(\"UTC\")\n",
    "\n",
    "def fetch_minute_and_daily(sym: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = yf.download(\n",
    "        sym,\n",
    "        start=CFG.start_date,\n",
    "        end=CFG.end_date,\n",
    "        interval=CFG.interval,\n",
    "        auto_adjust=False,\n",
    "        progress=False,\n",
    "    )\n",
    "    if df.empty:\n",
    "        return df, df\n",
    "    df.index = _tz_to_utc(df.index)\n",
    "\n",
    "    daily = yf.download(\n",
    "        sym,\n",
    "        start=pd.to_datetime(CFG.start_date) - pd.Timedelta(days=5),\n",
    "        end=CFG.end_date,\n",
    "        interval=\"1d\",\n",
    "        auto_adjust=False,\n",
    "        progress=False,\n",
    "    )\n",
    "    if not daily.empty:\n",
    "        daily.index = _tz_to_utc(daily.index)\n",
    "\n",
    "    return df, daily\n",
    "\n",
    "# =========================\n",
    "# Core backtest\n",
    "# =========================\n",
    "class Position:\n",
    "    def __init__(self, sym, side, qty, t_in, p_in, r1, s1):\n",
    "        self.sym, self.side, self.qty = sym, side, qty\n",
    "        self.t_in, self.p_in, self.r1, self.s1 = t_in, p_in, r1, s1\n",
    "    def sign(self): return 1 if self.side == \"long\" else -1\n",
    "\n",
    "def capital_per_trade() -> float:\n",
    "    total = CFG.account_rupees * CFG.intraday_margin\n",
    "    return (total / CFG.max_concurrent_trades\n",
    "            if CFG.capital_fraction_per_trade is None\n",
    "            else total * CFG.capital_fraction_per_trade)\n",
    "\n",
    "def run_backtest() -> pd.DataFrame:\n",
    "    universe = make_nifty50() if CFG.use_nifty50_universe else (CFG.tickers or [])\n",
    "    if not universe:\n",
    "        raise ValueError(\"No tickers found.\")\n",
    "    ensure_dir(CFG.out_dir)\n",
    "\n",
    "    cap_each = capital_per_trade()\n",
    "    log.info(f\"Capital per trade (with {CFG.intraday_margin}x): ₹{cap_each:,.0f}\")\n",
    "\n",
    "    data, ts_union = {}, None\n",
    "    usable = 0\n",
    "\n",
    "    # Prep data\n",
    "    for s in universe:\n",
    "        m, d = fetch_minute_and_daily(s)\n",
    "        if m.empty or d.empty:\n",
    "            log.warning(f\"{s}: empty minute/daily; skipping.\")\n",
    "            continue\n",
    "        piv = daily_pivots_from_prev_day(d)\n",
    "        if piv.empty:\n",
    "            log.warning(f\"{s}: not enough daily history for pivots; skipping.\")\n",
    "            continue\n",
    "        m = attach_pivots(m, piv)\n",
    "        st = supertrend(m, CFG.st_atr_period, CFG.st_multiplier)\n",
    "        df = pd.concat([m, st], axis=1)\n",
    "        # Need valid levels and supertrend\n",
    "        df = df.dropna(subset=[\"R1\", \"S1\", \"st\", \"st_dir\"])\n",
    "        if df.empty:\n",
    "            log.warning(f\"{s}: indicators/levels NA; skipping.\")\n",
    "            continue\n",
    "        data[s] = df\n",
    "        ts_union = df.index if ts_union is None else ts_union.union(df.index)\n",
    "        usable += 1\n",
    "\n",
    "    if usable == 0:\n",
    "        log.error(\"No usable symbols after preparation. Adjust window/toggles.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    trades, openpos = [], {}\n",
    "    ts_union = ts_union.sort_values()\n",
    "    eod_hh, eod_mm = map(int, CFG.eod_squareoff_time.split(\":\"))\n",
    "\n",
    "    for ts in ts_union:\n",
    "        ts_local = ts.tz_convert(CFG.tz)\n",
    "        hhmm = (ts_local.hour, ts_local.minute)\n",
    "\n",
    "        # --------- Exits ----------\n",
    "        to_close = []\n",
    "        for s, pos in list(openpos.items()):\n",
    "            df = data[s]\n",
    "            if ts not in df.index:\n",
    "                continue\n",
    "            r = df.loc[ts]\n",
    "            c, o = r[\"Close\"], r[\"Open\"]\n",
    "            st, st_dir = r[\"st\"], int(r[\"st_dir\"])\n",
    "            px = o if CFG.use_next_bar_open else c\n",
    "\n",
    "            st_exit = (c < st or st_dir < 0) if pos.side == \"long\" else (c > st or st_dir > 0)\n",
    "            sl_hit = tp_hit = False\n",
    "            if CFG.enable_stop_loss:\n",
    "                sl = pos.p_in * (1 - CFG.stop_loss_pct * pos.sign())\n",
    "                sl_hit = (c <= sl) if pos.side == \"long\" else (c >= sl)\n",
    "            if CFG.enable_take_profit:\n",
    "                tp = pos.p_in * (1 + CFG.take_profit_pct * pos.sign())\n",
    "                tp_hit = (c >= tp) if pos.side == \"long\" else (c <= tp)\n",
    "\n",
    "            reason = None\n",
    "            if st_exit: reason = \"supertrend_exit\"\n",
    "            if CFG.enable_stop_loss and sl_hit: reason = \"stop_loss\"\n",
    "            if CFG.enable_take_profit and tp_hit: reason = \"take_profit\"\n",
    "            if CFG.use_eod_squareoff and hhmm >= (eod_hh, eod_mm): reason = \"eod_squareoff\"\n",
    "\n",
    "            if reason:\n",
    "                to_close.append((s, px, reason, ts))\n",
    "\n",
    "        for s, px, reason, tsx in to_close:\n",
    "            pos = openpos.pop(s)\n",
    "            q = pos.qty\n",
    "            if pos.side == \"long\":\n",
    "                buy_turn, sell_turn = pos.p_in*q, px*q\n",
    "                gross = (px - pos.p_in) * q\n",
    "            else:\n",
    "                buy_turn, sell_turn = px*q, pos.p_in*q\n",
    "                gross = (pos.p_in - px) * q\n",
    "            cost = groww_intraday_charges(buy_turn, sell_turn)[\"total_charges\"] if CFG.enable_costs else 0.0\n",
    "            net = gross - cost\n",
    "            trades.append(dict(\n",
    "                symbol=s, side=pos.side, qty=q,\n",
    "                entry_time=as_ist(pos.t_in), exit_time=as_ist(tsx),\n",
    "                entry_price=round(pos.p_in,2), exit_price=round(px,2),\n",
    "                gross_pnl=round(gross,2), charges=round(cost,2),\n",
    "                net_pnl=round(net,2), exit_reason=reason\n",
    "            ))\n",
    "            log.info(f\"CLOSE {s} {pos.side} x{q} @ {px:.2f} | {reason} | Net ₹{net:.2f}\")\n",
    "\n",
    "        # --------- Entries ----------\n",
    "        if len(openpos) >= CFG.max_concurrent_trades:\n",
    "            continue\n",
    "\n",
    "        candidates: List[Tuple[str, str, float, float]] = []\n",
    "        for s, df in data.items():\n",
    "            if s in openpos or ts not in df.index:\n",
    "                continue\n",
    "            r = df.loc[ts]\n",
    "            c = r[\"Close\"]\n",
    "            prev = df[\"Close\"].shift(1).reindex(df.index).loc[ts]\n",
    "            r1, s1, st_dir = r[\"R1\"], r[\"S1\"], int(r[\"st_dir\"])\n",
    "            px = r[\"Open\"] if CFG.use_next_bar_open else c\n",
    "\n",
    "            if CFG.enable_longs and st_dir > 0:\n",
    "                cond = (prev <= r1 and c > r1) if CFG.require_close_cross else (c >= r1)\n",
    "                if cond:\n",
    "                    candidates.append((s, \"long\", px, float(c - r1)))\n",
    "\n",
    "            if CFG.enable_shorts and st_dir < 0:\n",
    "                cond = (prev >= s1 and c < s1) if CFG.require_close_cross else (c <= s1)\n",
    "                if cond:\n",
    "                    candidates.append((s, \"short\", px, float(s1 - c)))\n",
    "\n",
    "        # Rank by distance from level (stronger break first)\n",
    "        candidates.sort(key=lambda x: x[3], reverse=True)\n",
    "        capacity = CFG.max_concurrent_trades - len(openpos)\n",
    "\n",
    "        for s, side, px, _ in candidates[:capacity]:\n",
    "            qty = int(capital_per_trade() // px)\n",
    "            if qty <= 0:\n",
    "                continue\n",
    "            r = data[s].loc[ts]\n",
    "            openpos[s] = Position(s, side, qty, ts, px, r[\"R1\"], r[\"S1\"])\n",
    "            log.info(f\"OPEN  {s} {side} x{qty} @ {px:.2f}\")\n",
    "\n",
    "    # No forced close at end (intraday focus), but you can add if desired\n",
    "    return pd.DataFrame(trades)\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "EXPECTED_COLS = [\n",
    "    \"symbol\",\"side\",\"qty\",\"entry_time\",\"exit_time\",\n",
    "    \"entry_price\",\"exit_price\",\"gross_pnl\",\"charges\",\"net_pnl\",\"exit_reason\"\n",
    "]\n",
    "\n",
    "def main():\n",
    "    ensure_dir(CFG.out_dir)\n",
    "    trades = run_backtest()\n",
    "    out = os.path.join(CFG.out_dir, CFG.trades_csv)\n",
    "\n",
    "    if trades.empty:\n",
    "        trades = pd.DataFrame(columns=EXPECTED_COLS)\n",
    "        trades.to_csv(out, index=False)\n",
    "        log.warning(\"No trades generated. Try: disable 'require_close_cross', enable both long & short, or widen the window.\")\n",
    "        return\n",
    "\n",
    "    if \"entry_time\" in trades.columns:\n",
    "        trades.sort_values(\"entry_time\", inplace=True)\n",
    "\n",
    "    trades.to_csv(out, index=False)\n",
    "    total = trades[\"net_pnl\"].sum()\n",
    "    winrate = (trades[\"net_pnl\"] > 0).mean() * 100\n",
    "    log.info(f\"Saved -> {out}\")\n",
    "    log.info(f\"Trades={len(trades)} | Winrate={winrate:.1f}% | Net P&L=₹{total:,.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
