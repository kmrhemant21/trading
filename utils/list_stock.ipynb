{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc339c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from: https://nsearchives.nseindia.com/content/indices/ind_nifty50list.csv\n",
      "\n",
      "‚úÖ Saved 50 records to: nifty50_symbols.csv\n",
      "\n",
      "Sample records:\n",
      "       symbol                                       name\n",
      "  ADANIENT.NS                     Adani Enterprises Ltd.\n",
      "ADANIPORTS.NS Adani Ports and Special Economic Zone Ltd.\n",
      "APOLLOHOSP.NS           Apollo Hospitals Enterprise Ltd.\n",
      "ASIANPAINT.NS                          Asian Paints Ltd.\n",
      "  AXISBANK.NS                             Axis Bank Ltd.\n",
      "BAJAJ-AUTO.NS                            Bajaj Auto Ltd.\n",
      "BAJFINANCE.NS                         Bajaj Finance Ltd.\n",
      "BAJAJFINSV.NS                         Bajaj Finserv Ltd.\n",
      "       BEL.NS                    Bharat Electronics Ltd.\n",
      "BHARTIARTL.NS                         Bharti Airtel Ltd.\n",
      "\n",
      "Python Array:\n",
      "['ADANIENT.NS', 'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'BEL.NS', 'BHARTIARTL.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DRREDDY.NS', 'EICHERMOT.NS', 'ETERNAL.NS', 'GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HINDALCO.NS', 'HINDUNILVR.NS', 'ICICIBANK.NS', 'ITC.NS', 'INFY.NS', 'INDIGO.NS', 'JSWSTEEL.NS', 'JIOFIN.NS', 'KOTAKBANK.NS', 'LT.NS', 'M&M.NS', 'MARUTI.NS', 'MAXHEALTH.NS', 'NTPC.NS', 'NESTLEIND.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'SHRIRAMFIN.NS', 'SBIN.NS', 'SUNPHARMA.NS', 'TCS.NS', 'TATACONSUM.NS', 'TMPV.NS', 'TATASTEEL.NS', 'TECHM.NS', 'TITAN.NS', 'TRENT.NS', 'ULTRACEMCO.NS', 'WIPRO.NS']\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "NSE Index Constituents Fetcher (Simplified + Symbol Array)\n",
    "==========================================================\n",
    "\n",
    "Fetches the latest constituent list for any NSE index (NIFTY 50, 500, etc.)\n",
    "and saves it into a CSV file with columns: symbol,name\n",
    "\n",
    "Also prints the list of symbols (with \".NS\" suffix) as a Python array.\n",
    "\n",
    "Example output:\n",
    "---------------\n",
    "‚úÖ Saved 500 records to: nifty500_symbols.csv\n",
    "\n",
    "Sample records:\n",
    "     symbol                         name\n",
    "  RELIANCE.NS         Reliance Industries\n",
    "   HDFCBANK.NS                    HDFC Bank\n",
    "        TCS.NS  Tata Consultancy Services\n",
    "\n",
    "Python Array:\n",
    "['RELIANCE.NS', 'HDFCBANK.NS', 'TCS.NS', ...]\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "# ==============================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================\n",
    "\n",
    "# Choose one of the following URLs:\n",
    "CSV_URL = \"https://nsearchives.nseindia.com/content/indices/ind_nifty50list.csv\"\n",
    "# CSV_URL = \"https://nsearchives.nseindia.com/content/indices/ind_niftynext50list.csv\"\n",
    "# CSV_URL = \"https://nsearchives.nseindia.com/content/indices/ind_niftybanklist.csv\"\n",
    "# CSV_URL = \"https://nsearchives.nseindia.com/content/indices/ind_nifty500list.csv\"\n",
    "# CSV_URL = \"https://nsearchives.nseindia.com/content/indices/ind_niftymidcap100list.csv\"\n",
    "# CSV_URL = \"https://nsearchives.nseindia.com/content/indices/ind_niftysmallcap100list.csv\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.nseindia.com/market-data/live-market-indices\"\n",
    "}\n",
    "\n",
    "# ==============================================================\n",
    "# 2. FETCH AND PARSE\n",
    "# ==============================================================\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "# Warm-up to get cookies\n",
    "session.get(\"https://www.nseindia.com\", timeout=5)\n",
    "\n",
    "print(f\"Fetching data from: {CSV_URL}\")\n",
    "response = session.get(CSV_URL, timeout=10)\n",
    "response.raise_for_status()\n",
    "\n",
    "df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "# ==============================================================\n",
    "# 3. CLEAN AND FORMAT\n",
    "# ==============================================================\n",
    "\n",
    "df.columns = [c.strip().title() for c in df.columns]\n",
    "if \"Symbol\" not in df.columns or \"Company Name\" not in df.columns:\n",
    "    raise ValueError(\"Expected columns not found in NSE CSV response.\")\n",
    "\n",
    "df[\"symbol\"] = df[\"Symbol\"].astype(str) + \".NS\"\n",
    "df[\"name\"] = df[\"Company Name\"]\n",
    "\n",
    "# ==============================================================\n",
    "# 4. SAVE OUTPUT\n",
    "# ==============================================================\n",
    "\n",
    "basename = os.path.basename(CSV_URL).replace(\"ind_\", \"\").replace(\"list.csv\", \"\")\n",
    "outfile = f\"{basename}_symbols.csv\"\n",
    "\n",
    "df_out = df[[\"symbol\", \"name\"]]\n",
    "df_out.to_csv(outfile, index=False)\n",
    "print(f\"\\n‚úÖ Saved {len(df_out)} records to: {outfile}\")\n",
    "\n",
    "# ==============================================================\n",
    "# 5. PRINT OUTPUT\n",
    "# ==============================================================\n",
    "\n",
    "# Preview first few rows\n",
    "print(\"\\nSample records:\")\n",
    "print(df_out.head(10).to_string(index=False))\n",
    "\n",
    "# Print Python array of symbols\n",
    "symbols = df_out[\"symbol\"].tolist()\n",
    "print(\"\\nPython Array:\")\n",
    "print(symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550d9c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['360ONE.NS', 'AADHARHFC.NS', 'AARTIIND.NS', 'ABCAPITAL.NS', 'ABREL.NS', 'ACC.NS', 'AEGISLOG.NS', 'AEGISVOPAK.NS', 'AFCONS.NS', 'AFFLE.NS', 'ALKEM.NS', 'AMBER.NS', 'ANANDRATHI.NS', 'ANANTRAJ.NS', 'ANGELONE.NS', 'APLAPOLLO.NS', 'APTUS.NS', 'ARE&M.NS', 'ASHOKLEY.NS', 'ASTERDM.NS', 'ASTRAL.NS', 'ATGL.NS', 'ATUL.NS', 'AUBANK.NS', 'AUROPHARMA.NS', 'BANDHANBNK.NS', 'BANKINDIA.NS', 'BDL.NS', 'BEML.NS', 'BHARATFORG.NS', 'BHARTIHEXA.NS', 'BHEL.NS', 'BIOCON.NS', 'BLS.NS', 'BLUESTARCO.NS', 'BRIGADE.NS', 'BSE.NS', 'CAMS.NS', 'CASTROLIND.NS', 'CDSL.NS', 'CESC.NS', 'CGCL.NS', 'CHAMBLFERT.NS', 'CHOLAHLDNG.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COLPAL.NS', 'CONCOR.NS', 'COROMANDEL.NS', 'CREDITACC.NS', 'CROMPTON.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DATAPATTNS.NS', 'DEEPAKFERT.NS', 'DELHIVERY.NS', 'DEVYANI.NS', 'DIXON.NS', 'EXIDEIND.NS', 'FEDERALBNK.NS', 'FIRSTCRY.NS', 'FIVESTAR.NS', 'FORTIS.NS', 'FSL.NS', 'GESHIP.NS', 'GILLETTE.NS', 'GLAND.NS', 'GLENMARK.NS', 'GMRAIRPORT.NS', 'GODFRYPHLP.NS', 'GODIGIT.NS', 'GODREJPROP.NS', 'GRSE.NS', 'HBLENGINE.NS', 'HDFCAMC.NS', 'HEROMOTOCO.NS', 'HINDCOPPER.NS', 'HINDPETRO.NS', 'HSCL.NS', 'HUDCO.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFCI.NS', 'IGIL.NS', 'IGL.NS', 'IIFL.NS', 'IKS.NS', 'INDIANB.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INOXWIND.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'IREDA.NS', 'ITCHOTELS.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JINDALSAW.NS', 'JUBLFOOD.NS', 'JWL.NS', 'JYOTICNC.NS', 'KAJARIACER.NS', 'KALYANKJIL.NS', 'KARURVYSYA.NS', 'KAYNES.NS', 'KEC.NS', 'KEI.NS', 'KFINTECH.NS', 'KPIL.NS', 'KPITTECH.NS', 'LALPATHLAB.NS', 'LAURUSLABS.NS', 'LICHSGFIN.NS', 'LTF.NS', 'LUPIN.NS', 'M&MFIN.NS', 'MANAPPURAM.NS', 'MANKIND.NS', 'MARICO.NS', 'MCX.NS', 'MFSL.NS', 'MGL.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MRF.NS', 'MRPL.NS', 'MUTHOOTFIN.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAVINFLUOR.NS', 'NBCC.NS', 'NCC.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NH.NS', 'NHPC.NS', 'NMDC.NS', 'NTPCGREEN.NS', 'NUVAMA.NS', 'NYKAA.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLAELEC.NS', 'PAGEIND.NS', 'PATANJALI.NS', 'PAYTM.NS', 'PCBL.NS', 'PERSISTENT.NS', 'PGEL.NS', 'PHOENIXLTD.NS', 'PIIND.NS', 'PNBHOUSING.NS', 'POLICYBZR.NS', 'POLYCAB.NS', 'POONAWALLA.NS', 'POWERINDIA.NS', 'PPLPHARMA.NS', 'PREMIERENE.NS', 'PRESTIGE.NS', 'RADICO.NS', 'RAMCOCEM.NS', 'REDINGTON.NS', 'RPOWER.NS', 'RVNL.NS', 'SAGILITY.NS', 'SAIL.NS', 'SBICARD.NS', 'SHYAMMETL.NS', 'SIGNATURE.NS', 'SONACOMS.NS', 'SRF.NS', 'STARHEALTH.NS', 'SUPREMEIND.NS', 'SUZLON.NS', 'SWANCORP.NS', 'SWIGGY.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATAELXSI.NS', 'TATATECH.NS', 'TEJASNET.NS', 'TIINDIA.NS', 'TORNTPOWER.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'UNIONBANK.NS', 'UPL.NS', 'VMM.NS', 'VOLTAS.NS', 'WAAREEENER.NS', 'WELCORP.NS', 'WHIRLPOOL.NS', 'WOCKPHARMA.NS', 'YESBANK.NS', 'ZENSARTECH.NS', 'ZENTEC.NS']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "INDEX_URLS = [\n",
    "    # \"https://nsearchives.nseindia.com/content/indices/ind_nifty500list.csv\",\n",
    "    \"https://nsearchives.nseindia.com/content/indices/ind_niftymidcap100list.csv\",\n",
    "    \"https://nsearchives.nseindia.com/content/indices/ind_niftysmallcap100list.csv\",\n",
    "]\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.nseindia.com/market-data/live-market-indices\"\n",
    "}\n",
    "\n",
    "def fetch_symbols(session: requests.Session, url: str) -> list[str]:\n",
    "    \"\"\"Fetch a CSV from NSE and return a list of uppercased symbols.\"\"\"\n",
    "    resp = session.get(url, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    df = pd.read_csv(StringIO(resp.text))\n",
    "    symbol_col = None\n",
    "    for col in df.columns:\n",
    "        if col.strip().lower() in {\"symbol\", \"symbols\"}:\n",
    "            symbol_col = col\n",
    "            break\n",
    "    if symbol_col is None:\n",
    "        raise ValueError(f\"Could not find 'Symbol' column in CSV: {url}\")\n",
    "    syms = (\n",
    "        df[symbol_col]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()\n",
    "        .tolist()\n",
    "    )\n",
    "    return syms\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "session.get(\"https://www.nseindia.com\", timeout=10)\n",
    "all_syms = []\n",
    "for url in INDEX_URLS:\n",
    "    try:\n",
    "        all_syms.extend(fetch_symbols(session, url))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to fetch {url}: {e}\")\n",
    "unique_syms = list(dict.fromkeys(all_syms))\n",
    "final_list = [s if s.endswith(\".NS\") else f\"{s}.NS\" for s in unique_syms]\n",
    "final_list = sorted(final_list)\n",
    "print(final_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44947acf",
   "metadata": {},
   "source": [
    "# NIFTY 200 Momentum Stocks 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f0b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BSE.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'BDL.NS', 'BEL.NS', 'BHARTIARTL.NS', 'CHOLAFIN.NS', 'COFORGE.NS', 'DIVISLAB.NS', 'DIXON.NS', 'NYKAA.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'ICICIBANK.NS', 'INDHOTEL.NS', 'INDIGO.NS', 'KOTAKBANK.NS', 'MFSL.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MUTHOOTFIN.NS', 'PAYTM.NS', 'PERSISTENT.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SRF.NS', 'SHREECEM.NS', 'SOLARINDS.NS', 'TVSMOTOR.NS', 'UNITDSPR.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemank/Documents/github/.talib/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.niftyindices.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import ssl\n",
    "\n",
    "URL = \"https://www.niftyindices.com/IndexConstituent/ind_nifty200Momentum30_list.csv\"\n",
    "\n",
    "# Use the requests session that's already set up in previous cells\n",
    "response = session.get(URL, verify=False, timeout=15)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Read from the response content\n",
    "df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "# Find the symbol column (varies; usually 'Symbol' or first col)\n",
    "sym_col = next((c for c in df.columns if str(c).strip().lower().startswith(\"symbol\")), df.columns[0])\n",
    "\n",
    "# Make the .NS list\n",
    "symbols = [(str(s).strip().upper() + (\"\" if str(s).strip().upper().endswith(\".NS\") else \".NS\"))\n",
    "           for s in df[sym_col] if str(s).strip()]\n",
    "\n",
    "print(symbols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c49877",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e3d12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping NSE F&O underlyings (stocks) starting from the Underlyings page...\n",
      "‚úÖ Done. Stocks in F&O: 213\n",
      "üìÑ Saved: fno_stocks.csv, fno_stocks.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Scrape NSE: List of F&O Underlyings (Stocks) starting from:\n",
    "https://www.nseindia.com/products-services/equity-derivatives-list-underlyings-information\n",
    "\n",
    "Flow\n",
    "----\n",
    "1) Open the given page to get NSE cookies (anti-bot requires this warm-up).\n",
    "2) From there, hop to \"Contract Information\" and auto-find the anchor\n",
    "   \"Permitted lot size (.csv)\" (official file listing all F&O underlyings & lots).\n",
    "3) Download the CSV, normalize columns, and filter to stock derivatives only:\n",
    "   FUTSTK / OPTSTK (excludes index derivatives like NIFTY, BANKNIFTY, etc.)\n",
    "4) Save outputs:\n",
    "   - fno_stocks.csv  (symbol, lot_size, instrument, underlying)\n",
    "   - fno_stocks.txt  (symbols only)\n",
    "\n",
    "Why this route?\n",
    "---------------\n",
    "The \"List of Underlyings and Information\" page is client-side rendered and\n",
    "does not expose a direct JSON. The official & maintained CSV link is surfaced\n",
    "under \"Contract Information\" as \"Permitted lot size (.csv)\". Using that file\n",
    "is the most stable way to scrape/collect the F&O underlyings programmatically.\n",
    "\n",
    "Requirements\n",
    "------------\n",
    "pip install requests pandas beautifulsoup4\n",
    "\n",
    "Author\n",
    "------\n",
    "GPT-5 ‚Äî 2025-11-02 (IST)\n",
    "\"\"\"\n",
    "\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import typing as t\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "START_URL = \"https://www.nseindia.com/products-services/equity-derivatives-list-underlyings-information\"\n",
    "HOME_URL  = \"https://www.nseindia.com/\"\n",
    "\n",
    "HDRS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "# Fallback known archive path pattern if the on-page link isn‚Äôt directly found\n",
    "ARCHIVE_HOSTS = [\n",
    "    \"https://nsearchives.nseindia.com/\",\n",
    "    \"https://archives.nseindia.com/\"  # historical alias sometimes used\n",
    "]\n",
    "CSV_CANDIDATES = [\n",
    "    \"content/fo/fo_mktlots.csv\",        # Permitted lot size (current)\n",
    "    \"content/fo/fo_mktlots_*.csv\",      # Dated variants if present\n",
    "]\n",
    "\n",
    "INDEX_TICKERS = {\"NIFTY\", \"BANKNIFTY\", \"FINNIFTY\", \"MIDCPNIFTY\", \"NIFTYNXT50\"}\n",
    "\n",
    "def _get(session: requests.Session, url: str, timeout: int = 20) -> requests.Response:\n",
    "    \"\"\"GET with cookie warm-up and light retry/backoff.\"\"\"\n",
    "    backoff = 1.0\n",
    "    for _ in range(5):\n",
    "        try:\n",
    "            r = session.get(url, headers=HDRS, timeout=timeout)\n",
    "            if r.status_code == 200 and r.content:\n",
    "                return r\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "        # Warm cookies and backoff\n",
    "        try:\n",
    "            session.get(HOME_URL, headers=HDRS, timeout=timeout)\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "        time.sleep(backoff)\n",
    "        backoff = min(backoff * 2, 8.0)\n",
    "    raise RuntimeError(f\"Failed to GET {url}\")\n",
    "\n",
    "def _discover_contract_info_and_csv(session: requests.Session) -> str:\n",
    "    \"\"\"\n",
    "    From START_URL, find the 'Contract Information' page and then locate\n",
    "    the 'Permitted lot size (.csv)' link. Return CSV absolute URL.\n",
    "    \"\"\"\n",
    "    # 1) Open start page (sets cookies)\n",
    "    _get(session, START_URL)\n",
    "\n",
    "    # 2) Try the Contract Information page directly (it‚Äôs the canonical hub)\n",
    "    contract_info_url = \"https://www.nseindia.com/products-services/equity-derivatives-contract-information\"\n",
    "    resp = _get(session, contract_info_url)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # 3) Find anchor whose text contains 'Permitted lot size' and ends with .csv\n",
    "    a_tags = soup.find_all(\"a\", href=True)\n",
    "    for a in a_tags:\n",
    "        text = (a.get_text() or \"\").strip().lower()\n",
    "        href = a[\"href\"]\n",
    "        if \"permitted\" in text and \"lot\" in text and href.lower().endswith(\".csv\"):\n",
    "            return urljoin(contract_info_url, href)\n",
    "\n",
    "    # 4) Fallback: try known archive paths\n",
    "    for host in ARCHIVE_HOSTS:\n",
    "        for pattern in CSV_CANDIDATES:\n",
    "            candidate = urljoin(host, pattern)\n",
    "            try:\n",
    "                r = _get(session, candidate)\n",
    "                if r.status_code == 200 and r.content:\n",
    "                    return candidate\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    raise RuntimeError(\"Could not locate 'Permitted lot size (.csv)' link.\")\n",
    "\n",
    "def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns={c: c.strip().lower().replace(\" \", \"_\") for c in df.columns})\n",
    "    if \"symbol\" not in df.columns:\n",
    "        # common alt: 'underlying'\n",
    "        if \"underlying\" in df.columns:\n",
    "            df[\"symbol\"] = df[\"underlying\"].astype(str).str.strip()\n",
    "        else:\n",
    "            # take first object column as symbol\n",
    "            obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "            if obj_cols:\n",
    "                df[\"symbol\"] = df[obj_cols[0]].astype(str).str.strip()\n",
    "    if \"instrument\" not in df.columns:\n",
    "        for alt in (\"inst\", \"inst_type\", \"instrument_type\"):\n",
    "            if alt in df.columns:\n",
    "                df[\"instrument\"] = df[alt]\n",
    "                break\n",
    "    if \"lot_size\" not in df.columns:\n",
    "        for alt in (\"market_lot\", \"mktlot\", \"fo_lot\", \"qty\", \"quantity_freeze\"):\n",
    "            if alt in df.columns:\n",
    "                df[\"lot_size\"] = df[alt]\n",
    "                break\n",
    "    if \"underlying\" not in df.columns and \"symbol\" in df.columns:\n",
    "        df[\"underlying\"] = df[\"symbol\"]\n",
    "    return df\n",
    "\n",
    "def fetch_fno_stock_list() -> pd.DataFrame:\n",
    "    with requests.Session() as s:\n",
    "        # Warm cookies (helps with NSE bot-guard)\n",
    "        try:\n",
    "            s.get(HOME_URL, headers=HDRS, timeout=15)\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "\n",
    "        csv_url = _discover_contract_info_and_csv(s)\n",
    "        r = _get(s, csv_url)\n",
    "        raw = r.content.decode(\"utf-8\", errors=\"ignore\")\n",
    "        df = pd.read_csv(io.StringIO(raw))\n",
    "\n",
    "    df = _normalize_columns(df)\n",
    "\n",
    "    # Filter STOCK derivatives only: FUTSTK/OPTSTK. If instrument is missing,\n",
    "    # exclude known index underlyings as a heuristic fallback.\n",
    "    if \"instrument\" in df.columns:\n",
    "        mask = df[\"instrument\"].astype(str).str.contains(\"STK\", case=False, na=False)\n",
    "        out = df.loc[mask].copy()\n",
    "    else:\n",
    "        out = df.loc[~df[\"symbol\"].astype(str).str.upper().isin(INDEX_TICKERS)].copy()\n",
    "\n",
    "    out[\"symbol\"] = out[\"symbol\"].astype(str).str.upper().str.strip()\n",
    "    if \"lot_size\" in out.columns:\n",
    "        out[\"lot_size\"] = pd.to_numeric(out[\"lot_size\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    keep = [c for c in [\"symbol\", \"lot_size\", \"instrument\", \"underlying\"] if c in out.columns]\n",
    "    out = out[keep].drop_duplicates().sort_values(\"symbol\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Scraping NSE F&O underlyings (stocks) starting from the Underlyings page...\")\n",
    "        df = fetch_fno_stock_list()\n",
    "        if df.empty:\n",
    "            raise RuntimeError(\"Empty result after filtering FUTSTK/OPTSTK.\")\n",
    "        df.to_csv(\"fno_stocks.csv\", index=False)\n",
    "        df[\"symbol\"].to_csv(\"fno_stocks.txt\", index=False, header=False)\n",
    "        print(f\"‚úÖ Done. Stocks in F&O: {len(df)}\")\n",
    "        print(\"üìÑ Saved: fno_stocks.csv, fno_stocks.txt\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
