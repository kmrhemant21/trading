{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ddc23bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing INFY.NS ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:183: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  last_price = float(df[\"Close\"].iloc[-1])\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:91: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  mu_step   = float(log_ret.mean())\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:92: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  sigma_step = float(log_ret.std(ddof=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TCS.NS ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:183: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  last_price = float(df[\"Close\"].iloc[-1])\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:91: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  mu_step   = float(log_ret.mean())\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:92: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  sigma_step = float(log_ret.std(ddof=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RELIANCE.NS ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:183: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  last_price = float(df[\"Close\"].iloc[-1])\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:91: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  mu_step   = float(log_ret.mean())\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:92: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  sigma_step = float(log_ret.std(ddof=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HDFCBANK.NS ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:183: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  last_price = float(df[\"Close\"].iloc[-1])\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:91: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  mu_step   = float(log_ret.mean())\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:92: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  sigma_step = float(log_ret.std(ddof=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ICICIBANK.NS ...\n",
      "\n",
      "=== Intraday Monte Carlo Screen ===\n",
      "      ticker status  last_price   mu_step  sigma_step  est_daily_vol_from_5m  long_p_tp_first  long_p_sl_first  long_p_none  long_exp_edge_bps  short_p_tp_first  short_p_sl_first  short_p_none  short_exp_edge_bps  prob_abs_move_ge_80bps best_side  best_edge_bps  best_p_tp  passes_filter\n",
      " HDFCBANK.NS     ok  944.500000 -0.000027    0.000977                   0.01            0.152            0.522        0.326             -19.41             0.274             0.352         0.374                7.00                   0.629    SHORT*           7.00      0.274          False\n",
      "ICICIBANK.NS     ok 1390.900024 -0.000027    0.000972                   0.01            0.151            0.520        0.329             -19.40             0.272             0.350         0.378                6.89                   0.625    SHORT*           6.89      0.272          False\n",
      "     INFY.NS     ok 1495.000000 -0.000023    0.001466                   0.01            0.295            0.610        0.095             -13.36             0.383             0.519         0.098                1.45                   0.900    SHORT*           1.45      0.383          False\n",
      " RELIANCE.NS     ok 1366.500000 -0.000018    0.001313                   0.01            0.271            0.582        0.147             -13.01             0.350             0.495         0.155                0.84                   0.839    SHORT*           0.84      0.350          False\n",
      "      TCS.NS     ok 3111.500000 -0.000007    0.001055                   0.01            0.221            0.490        0.290             -10.11             0.251             0.442         0.307               -2.93                   0.681    SHORT*          -2.93      0.251          False\n",
      "\n",
      "Saved: intraday_mc_screen.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:183: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  last_price = float(df[\"Close\"].iloc[-1])\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:91: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  mu_step   = float(log_ret.mean())\n",
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_88436/3233869685.py:92: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  sigma_step = float(log_ret.std(ddof=1))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Intraday Monte Carlo Stock Filter (NSE/US etc.)\n",
    "\n",
    "- Inputs:\n",
    "    TICKERS: list of symbols (e.g., [\"INFY.NS\", \"TCS.NS\"])\n",
    "    INTERVAL/PERIOD: intraday history for estimating μ, σ (default: 5m, 30d)\n",
    "    HORIZON_MIN: minutes to simulate (e.g., full session for NSE ~375 min)\n",
    "    BAR_SIZE_MIN: intraday bar size (should match INTERVAL, e.g., 5 minutes)\n",
    "    PATHS: Monte Carlo paths\n",
    "    TAKE_PROFIT_BPS / STOP_LOSS_BPS: TP/SL in basis points (1% = 100 bps)\n",
    "    FEES_BPS / SLIPPAGE_BPS: round-trip cost\n",
    "    FILTERS: min expected edge, min probability of reaching target move, etc.\n",
    "\n",
    "- Output:\n",
    "    A ranked pandas DataFrame with probabilities & expected edge (bps) for\n",
    "    long/short, and a \"best_side\" recommendation.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import time\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# ==============================\n",
    "# CONFIG (edit these)\n",
    "# ==============================\n",
    "TICKERS        = [\"INFY.NS\", \"TCS.NS\", \"RELIANCE.NS\", \"HDFCBANK.NS\", \"ICICIBANK.NS\"]\n",
    "INTERVAL       = \"5m\"        # 1m/2m/5m/15m/30m/60m/90m/1h (YF rules apply)\n",
    "PERIOD         = \"30d\"       # YF intraday limits: 5m allows up to 60d, etc.\n",
    "\n",
    "# Intraday horizon to simulate\n",
    "HORIZON_MIN    = 375         # NSE ~ 9:15–15:30 => 6h15m = 375 minutes\n",
    "BAR_SIZE_MIN   = 5           # must match INTERVAL above\n",
    "PATHS          = 10_000\n",
    "SEED           = 42\n",
    "\n",
    "# Trading rules (bps = basis points)\n",
    "TAKE_PROFIT_BPS = 100        # 1.00% TP\n",
    "STOP_LOSS_BPS   = 60         # 0.60% SL\n",
    "FEES_BPS        = 5          # 0.05% total round-trip (brokerage + taxes)\n",
    "SLIPPAGE_BPS    = 3          # 0.03% round-trip slippage\n",
    "\n",
    "# Filtering thresholds (tune these)\n",
    "MIN_EDGE_BPS     = 2.0       # require expected edge > 2 bps\n",
    "MIN_PROB_TP      = 0.48      # require P(TP before SL) >= 48% on chosen side\n",
    "MOVE_TEST_BPS    = 80        # check prob(|move| >= 0.80% intraday)\n",
    "MIN_PROB_MOVE    = 0.60\n",
    "\n",
    "# Save results?\n",
    "SAVE_CSV_PATH    = \"intraday_mc_screen.csv\"\n",
    "# ==============================\n",
    "\n",
    "\n",
    "def download_intraday(ticker: str, interval: str, period: str, max_retries: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Download intraday OHLCV for one ticker using yfinance.\"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            df = yf.download(\n",
    "                ticker,\n",
    "                period=period,\n",
    "                interval=interval,\n",
    "                auto_adjust=True,\n",
    "                progress=False,\n",
    "                threads=False,\n",
    "            )\n",
    "            if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "                df = df.dropna()\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries:\n",
    "                print(f\"[{ticker}] download failed: {e}\")\n",
    "                return pd.DataFrame()\n",
    "        time.sleep(0.8 * attempt)  # gentle backoff\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def estimate_mu_sigma_from_intraday(df: pd.DataFrame) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Estimate per-step (bar-to-bar) μ and σ from intraday log returns.\n",
    "    Returns (mu_step, sigma_step) for the given INTERVAL.\n",
    "    \"\"\"\n",
    "    if df.empty or \"Close\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame empty or missing Close column.\")\n",
    "    px = df[\"Close\"].astype(float)\n",
    "    log_ret = np.log(px).diff().dropna()\n",
    "    mu_step   = float(log_ret.mean())\n",
    "    sigma_step = float(log_ret.std(ddof=1))\n",
    "    return mu_step, sigma_step\n",
    "\n",
    "\n",
    "def simulate_gbm_paths(S0: float, mu_step: float, sigma_step: float, steps: int, paths: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate GBM with per-step parameters (already in step units, not annualized).\n",
    "    S shape: (steps+1, paths)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Z = rng.standard_normal((steps, paths))\n",
    "    inc = (mu_step - 0.5 * sigma_step**2) + sigma_step * Z\n",
    "    log_cum = np.vstack([np.zeros(paths), np.cumsum(inc, axis=0)])\n",
    "    S = S0 * np.exp(log_cum)\n",
    "    return S\n",
    "\n",
    "\n",
    "def first_cross_idx(S: np.ndarray, level: float, direction: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns the FIRST index (0..steps) where S crosses level in the given direction (\"up\" or \"down\").\n",
    "    If never crosses, returns steps+1 (a sentinel > last index).\n",
    "    \"\"\"\n",
    "    if direction == \"up\":\n",
    "        cond = S >= level\n",
    "    elif direction == \"down\":\n",
    "        cond = S <= level\n",
    "    else:\n",
    "        raise ValueError(\"direction must be 'up' or 'down'\")\n",
    "\n",
    "    # axis=0 is time, axis=1 is path -> we want time along axis 0 ➜ cond.shape == (steps+1, paths)\n",
    "    # But we usually don't consider step 0 as a \"hit\" for entry, so allow from step 1:\n",
    "    cond[0, :] = False\n",
    "\n",
    "    idx = cond.argmax(axis=0)  # returns 0 if never True, so fix that next\n",
    "    never = ~cond.any(axis=0)\n",
    "    idx[never] = S.shape[0]  # steps+1 sentinel\n",
    "    return idx\n",
    "\n",
    "\n",
    "def edge_from_barriers(S: np.ndarray, S0: float, tp_pct: float, sl_pct: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute TP/SL first-hit probabilities and expected edge for a LONG position.\n",
    "    For SHORT, call with mirrored barriers on S (see wrapper below).\n",
    "\n",
    "    Returns dict with:\n",
    "        p_tp_first, p_sl_first, p_none, exp_edge_bps, prob_abs_move_ge_X (uses MOVE_TEST_BPS)\n",
    "    \"\"\"\n",
    "    steps, paths = S.shape[0] - 1, S.shape[1]\n",
    "    tp_level = S0 * (1.0 + tp_pct)\n",
    "    sl_level = S0 * (1.0 - sl_pct)\n",
    "\n",
    "    idx_tp = first_cross_idx(S, tp_level, \"up\")\n",
    "    idx_sl = first_cross_idx(S, sl_level, \"down\")\n",
    "\n",
    "    tp_first = idx_tp < idx_sl\n",
    "    sl_first = idx_sl < idx_tp\n",
    "    none     = (idx_tp > steps) & (idx_sl > steps)\n",
    "\n",
    "    p_tp = tp_first.mean()\n",
    "    p_sl = sl_first.mean()\n",
    "    p_none = none.mean()\n",
    "\n",
    "    # Return at end for \"no-hit\" paths\n",
    "    end_ret = S[-1, :] / S0 - 1.0\n",
    "    mean_ret_nohit = float(np.mean(end_ret[none])) if p_none > 0 else 0.0\n",
    "\n",
    "    # Costs\n",
    "    total_cost = (FEES_BPS + SLIPPAGE_BPS) / 10_000.0  # convert bps → fraction\n",
    "\n",
    "    exp_edge = p_tp * tp_pct - p_sl * sl_pct + p_none * mean_ret_nohit - total_cost\n",
    "    exp_edge_bps = exp_edge * 10_000.0\n",
    "\n",
    "    # Probability of an absolute move (up OR down) by MOVE_TEST_BPS\n",
    "    move_up   = (S >= S0 * (1 + MOVE_TEST_BPS / 10_000.0)).any(axis=0)\n",
    "    move_down = (S <= S0 * (1 - MOVE_TEST_BPS / 10_000.0)).any(axis=0)\n",
    "    prob_move = float(np.mean(move_up | move_down))\n",
    "\n",
    "    return {\n",
    "        \"p_tp_first\": float(p_tp),\n",
    "        \"p_sl_first\": float(p_sl),\n",
    "        \"p_none\": float(p_none),\n",
    "        \"exp_edge_bps\": float(exp_edge_bps),\n",
    "        \"prob_abs_move_ge_test\": prob_move,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_ticker(ticker: str) -> Dict[str, float]:\n",
    "    df = download_intraday(ticker, INTERVAL, PERIOD)\n",
    "    if df.empty:\n",
    "        return {\"ticker\": ticker, \"status\": \"no_data\"}\n",
    "\n",
    "    last_price = float(df[\"Close\"].iloc[-1])\n",
    "\n",
    "    try:\n",
    "        mu_step, sigma_step = estimate_mu_sigma_from_intraday(df)\n",
    "    except Exception as e:\n",
    "        return {\"ticker\": ticker, \"status\": f\"param_error: {e}\"}\n",
    "\n",
    "    steps = max(1, int(HORIZON_MIN // BAR_SIZE_MIN))\n",
    "\n",
    "    # Simulate\n",
    "    S = simulate_gbm_paths(last_price, mu_step, sigma_step, steps, PATHS, SEED)\n",
    "\n",
    "    # LONG side (tp up, sl down)\n",
    "    long_stats = edge_from_barriers(\n",
    "        S=S,\n",
    "        S0=last_price,\n",
    "        tp_pct=TAKE_PROFIT_BPS / 10_000.0,\n",
    "        sl_pct=STOP_LOSS_BPS / 10_000.0,\n",
    "    )\n",
    "\n",
    "    # SHORT side: mirror logic by flipping sign (or use price barriers accordingly)\n",
    "    # Easiest: reuse the same price paths; for short, TP is DOWN move, SL is UP move.\n",
    "    # So just map with reversed roles by reusing the helper on inverted series:\n",
    "    # Instead of flipping S, compute barriers directly for short:\n",
    "    # TP when S <= S0*(1 - tp), SL when S >= S0*(1 + sl)\n",
    "    tp_level_short = last_price * (1.0 - TAKE_PROFIT_BPS / 10_000.0)\n",
    "    sl_level_short = last_price * (1.0 + STOP_LOSS_BPS / 10_000.0)\n",
    "    idx_tp_short = first_cross_idx(S, tp_level_short, \"down\")\n",
    "    idx_sl_short = first_cross_idx(S, sl_level_short, \"up\")\n",
    "    steps_tot = S.shape[0] - 1\n",
    "\n",
    "    tp_first_short = idx_tp_short < idx_sl_short\n",
    "    sl_first_short = idx_sl_short < idx_tp_short\n",
    "    none_short     = (idx_tp_short > steps_tot) & (idx_sl_short > steps_tot)\n",
    "\n",
    "    p_tp_short = tp_first_short.mean()\n",
    "    p_sl_short = sl_first_short.mean()\n",
    "    p_none_short = none_short.mean()\n",
    "    end_ret = S[-1, :] / last_price - 1.0\n",
    "    # For shorts, profit when return is negative\n",
    "    mean_ret_nohit_short = float(np.mean(-end_ret[none_short])) if p_none_short > 0 else 0.0\n",
    "    total_cost = (FEES_BPS + SLIPPAGE_BPS) / 10_000.0\n",
    "    exp_edge_short = p_tp_short * (TAKE_PROFIT_BPS / 10_000.0) - p_sl_short * (STOP_LOSS_BPS / 10_000.0) + p_none_short * mean_ret_nohit_short - total_cost\n",
    "    exp_edge_short_bps = exp_edge_short * 10_000.0\n",
    "\n",
    "    # Dailyized realized vol estimate from 5m bars (approx)\n",
    "    bars_per_day = int(round((60 * 24) / BAR_SIZE_MIN))  # rough; for comparison only\n",
    "    # Better: compute within a trading session; but OK as a quick proxy\n",
    "    daily_vol_est = sigma_step * math.sqrt(steps)\n",
    "\n",
    "    # Decide best side\n",
    "    side_long_pass  = (long_stats[\"exp_edge_bps\"] >= MIN_EDGE_BPS) and (long_stats[\"p_tp_first\"] >= MIN_PROB_TP) and (long_stats[\"prob_abs_move_ge_test\"] >= MIN_PROB_MOVE)\n",
    "    side_short_pass = (exp_edge_short_bps >= MIN_EDGE_BPS) and (p_tp_short >= MIN_PROB_TP) and (long_stats[\"prob_abs_move_ge_test\"] >= MIN_PROB_MOVE)\n",
    "\n",
    "    if (exp_edge_short_bps > long_stats[\"exp_edge_bps\"]) and side_short_pass:\n",
    "        best_side = \"SHORT\"\n",
    "        best_edge = exp_edge_short_bps\n",
    "        best_p_tp = float(p_tp_short)\n",
    "    elif side_long_pass:\n",
    "        best_side = \"LONG\"\n",
    "        best_edge = long_stats[\"exp_edge_bps\"]\n",
    "        best_p_tp = float(long_stats[\"p_tp_first\"])\n",
    "    else:\n",
    "        # Pick the higher edge for info but mark as not passing\n",
    "        if exp_edge_short_bps > long_stats[\"exp_edge_bps\"]:\n",
    "            best_side, best_edge, best_p_tp = \"SHORT*\", exp_edge_short_bps, float(p_tp_short)\n",
    "        else:\n",
    "            best_side, best_edge, best_p_tp = \"LONG*\", long_stats[\"exp_edge_bps\"], float(long_stats[\"p_tp_first\"])\n",
    "\n",
    "    out = {\n",
    "        \"ticker\": ticker,\n",
    "        \"status\": \"ok\",\n",
    "        \"last_price\": last_price,\n",
    "        \"mu_step\": mu_step,\n",
    "        \"sigma_step\": sigma_step,\n",
    "        \"est_daily_vol_from_5m\": daily_vol_est,\n",
    "        # Long stats\n",
    "        \"long_p_tp_first\": long_stats[\"p_tp_first\"],\n",
    "        \"long_p_sl_first\": long_stats[\"p_sl_first\"],\n",
    "        \"long_p_none\": long_stats[\"p_none\"],\n",
    "        \"long_exp_edge_bps\": long_stats[\"exp_edge_bps\"],\n",
    "        # Short stats\n",
    "        \"short_p_tp_first\": float(p_tp_short),\n",
    "        \"short_p_sl_first\": float(p_sl_short),\n",
    "        \"short_p_none\": float(p_none_short),\n",
    "        \"short_exp_edge_bps\": float(exp_edge_short_bps),\n",
    "        # Movement test\n",
    "        \"prob_abs_move_ge_{}bps\".format(MOVE_TEST_BPS): long_stats[\"prob_abs_move_ge_test\"],\n",
    "        # Decision\n",
    "        \"best_side\": best_side,     # LONG, SHORT, or * if not passing filters\n",
    "        \"best_edge_bps\": best_edge,\n",
    "        \"best_p_tp\": best_p_tp,\n",
    "        # Pass filter?\n",
    "        \"passes_filter\": best_side in (\"LONG\", \"SHORT\"),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "def main():\n",
    "    rows = []\n",
    "    for t in TICKERS:\n",
    "        print(f\"Processing {t} ...\")\n",
    "        res = evaluate_ticker(t)\n",
    "        rows.append(res)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        # Order by best_edge desc, then by vol desc\n",
    "        df = df.sort_values(by=[\"passes_filter\", \"best_edge_bps\", \"est_daily_vol_from_5m\"], ascending=[False, False, False])\n",
    "        # Nice rounding\n",
    "        for col in [c for c in df.columns if c.endswith(\"_bps\") or c.startswith(\"est_daily_vol\")]:\n",
    "            df[col] = df[col].astype(float).round(2)\n",
    "        for col in [c for c in df.columns if c.startswith((\"long_p_\", \"short_p_\", \"best_p_tp\", \"prob_abs_move\"))]:\n",
    "            df[col] = df[col].astype(float).round(3)\n",
    "\n",
    "        print(\"\\n=== Intraday Monte Carlo Screen ===\")\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "        if SAVE_CSV_PATH:\n",
    "            df.to_csv(SAVE_CSV_PATH, index=False)\n",
    "            print(f\"\\nSaved: {SAVE_CSV_PATH}\")\n",
    "    else:\n",
    "        print(\"No results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de10b7",
   "metadata": {},
   "source": [
    "Great—this table is your **intraday Monte Carlo screen**, one row per ticker. Here’s how to read it.\n",
    "\n",
    "# What each column means\n",
    "\n",
    "* **ticker / status** – symbol and whether data/params were OK.\n",
    "* **last\\_price** – latest close from the intraday feed (auto-adjusted).\n",
    "* **mu\\_step, sigma\\_step** – mean and stdev of **log-returns per bar** (here 5-minute bars) estimated from the lookback (30d).\n",
    "* **est\\_daily\\_vol\\_from\\_5m** – rough dailyized vol from the 5-minute σ (≈ σ\\_step·√steps). `0.01` ≈ **1%** daily vol.\n",
    "* **long\\_p\\_tp\\_first** – probability the **LONG** side hits Take-Profit before Stop-Loss.\n",
    "* **long\\_p\\_sl\\_first** – probability LONG hits Stop-Loss before Take-Profit.\n",
    "* **long\\_p\\_none** – neither TP nor SL hit by the end of the horizon; we then use the ending P/L for those paths.\n",
    "* **long\\_exp\\_edge\\_bps** – **expected edge** for LONG in basis points after **fees+slippage**, using\n",
    "  `E = pTP·TP − pSL·SL + pNone·E[return | none] − costs`.\n",
    "* **short\\_p\\_* / short\\_exp\\_edge\\_bps*\\* – same, but for **SHORT** (TP is a down move; SL is up).\n",
    "* **prob\\_abs\\_move\\_ge\\_80bps** – probability price touches **±0.80%** at any point during the horizon.\n",
    "* **best\\_side** – the side (LONG/SHORT) with the **higher** expected edge. An asterisk `*` means it **failed your filters**.\n",
    "* **best\\_edge\\_bps** – edge on that best side.\n",
    "* **best\\_p\\_tp** – its P(TP before SL).\n",
    "* **passes\\_filter** – `True` only if it meets **all** your thresholds:\n",
    "\n",
    "  * `best_edge_bps ≥ 2 bps`\n",
    "  * `best_p_tp ≥ 0.48`\n",
    "  * `prob_abs_move_ge_80bps ≥ 0.60`\n",
    "\n",
    "# How to interpret your rows\n",
    "\n",
    "* **HDFCBANK.NS**:\n",
    "  LONG looks poor (edge **−19.41 bps**; TP-first only **15.2%**).\n",
    "  SHORT has small **+7.0 bps** expected edge with **27.4%** TP-first, but that’s **below** your `MIN_PROB_TP=0.48`.\n",
    "  → `best_side = SHORT*`, `passes_filter = False`. Informational short bias, but not strong enough.\n",
    "\n",
    "* **ICICIBANK.NS**: Same story as HDFC—slight short bias (+6.89 bps), fails probability filter.\n",
    "\n",
    "* **INFY.NS / RELIANCE.NS**: High chance of seeing a ±0.8% move intraday (**90%** for INFY, **84%** for RELIANCE), but SHORT TP-first is only **38–35%** → doesn’t meet 0.48 threshold. Edges are small.\n",
    "\n",
    "* **TCS.NS**: Both sides weak; best is SHORT but **negative** edge (−2.93 bps) → clearly avoid.\n",
    "\n",
    "# Why many “SHORT\\*” and “False”?\n",
    "\n",
    "* Your **risk\\:reward** is **TP 1.0% / SL 0.6%** (\\~1.67R). With near-zero drift and today’s vols (\\~1%), it’s **hard** to hit TP before SL ≥48% of the time.\n",
    "* Fees/slippage, even small, drag the expected edge down further.\n",
    "* Filters are intentionally strict (good!); they’ll often return **no trades** unless momentum/vol expand.\n",
    "\n",
    "# Quick tweaks if you want more candidates\n",
    "\n",
    "* **Loosen filters:** e.g., `MIN_PROB_TP=0.45` or `MIN_EDGE_BPS=0`.\n",
    "* **Adjust barriers:** try `TP=80 bps`, `SL=60 bps` (1.33R) or `TP=60, SL=50`.\n",
    "* **Shorter horizon:** simulate next **120 minutes** if you only trade the morning—this can change hit probabilities.\n",
    "* **Vol-adaptive TP/SL:** set TP/SL as multiples of recent ATR/σ per bar.\n",
    "* **Liquidity screen:** add ADV/turnover to avoid slippage spikes.\n",
    "\n",
    "If you tell me your preferred TP/SL, time window (e.g., first 90–120 min), and markets, I’ll tweak the script so it starts surfacing **passes\\_filter = True** candidates that match your style.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
