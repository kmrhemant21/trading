{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d49d0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No exits triggered today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_4788/3293788840.py:251: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end = (datetime.utcnow() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n"
     ]
    }
   ],
   "source": [
    "# screener_dma2green_exits.py\n",
    "\"\"\"\n",
    "Exit checker for positions generated by screener_dma2green_entries.py\n",
    "\n",
    "Reads portfolio/open_positions.csv and checks exits on the latest bar:\n",
    "  Priority: HSL -> TSL -> Time (>= max_hold_days) -> TwoRedBelow20 -> Protective\n",
    "\n",
    "Sends Telegram alerts for any positions that meet exit conditions.\n",
    "\n",
    "ENV required for Telegram:\n",
    "  TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID\n",
    "\n",
    "Run:\n",
    "  python screener_dma2green_exits.py\n",
    "\n",
    "Option:\n",
    "  AUTO_REMOVE_ON_ALERT = True to remove exited positions automatically.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "\n",
    "# ----------- USER CONFIG -----------\n",
    "AUTO_REMOVE_ON_ALERT = False  # set True to auto-remove positions after alert\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = None  # None -> today\n",
    "DMA_FAST = 10\n",
    "DMA_SLOW = 20\n",
    "\n",
    "# Telegram\n",
    "ENABLE_TELEGRAM = True\n",
    "TELEGRAM_BOT_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\", \"\")\n",
    "TELEGRAM_CHAT_ID = os.getenv(\"TELEGRAM_CHAT_ID\", \"\")\n",
    "\n",
    "# Paths\n",
    "CACHE_DIR = pathlib.Path(\"cache\")\n",
    "PORTFOLIO_DIR = pathlib.Path(\"portfolio\")\n",
    "OPEN_POSITIONS_CSV = PORTFOLIO_DIR / \"open_positions.csv\"\n",
    "EXIT_ALERTS_DIR = pathlib.Path(\"alerts\"); EXIT_ALERTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PORTFOLIO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------- Helpers (same as entry script) -----------\n",
    "def normalize_df_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if hasattr(df, \"columns\") and getattr(df.columns, \"nlevels\", 1) > 1:\n",
    "        df.columns = [\"_\".join([str(c) for c in col if c is not None]).strip() for c in df.columns.values]\n",
    "    cols = list(df.columns)\n",
    "    mapping = {}\n",
    "    lower_map = {c.lower(): c for c in cols}\n",
    "    for name in ['close','high','low','open','volume']:\n",
    "        if name in lower_map:\n",
    "            mapping[lower_map[name]] = name.capitalize()\n",
    "        else:\n",
    "            match = next((c for c in cols if name in c.lower()), None)\n",
    "            if match:\n",
    "                mapping[match] = name.capitalize()\n",
    "    if mapping:\n",
    "        df = df.rename(columns=mapping)\n",
    "    return df\n",
    "\n",
    "def collapse_duplicate_columns_take_first(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.columns.duplicated().any():\n",
    "        df = df.groupby(df.columns, axis=1).first()\n",
    "    return df\n",
    "\n",
    "def _cache_path_for_ticker(ticker: str) -> pathlib.Path:\n",
    "    safe = ticker.replace('/', '_').replace(':', '_')\n",
    "    return CACHE_DIR / f\"{safe}.csv\"\n",
    "\n",
    "def _read_cache(ticker: str) -> pd.DataFrame:\n",
    "    p = _cache_path_for_ticker(ticker)\n",
    "    if p.exists() and p.stat().st_size > 0:\n",
    "        try:\n",
    "            return pd.read_csv(p, index_col=0, parse_dates=True)\n",
    "        except Exception:\n",
    "            try: p.unlink()\n",
    "            except Exception: pass\n",
    "    return None\n",
    "\n",
    "def _write_cache(ticker: str, df: pd.DataFrame) -> None:\n",
    "    p = _cache_path_for_ticker(ticker)\n",
    "    try:\n",
    "        df.to_csv(p)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def download_with_retry(ticker: str, start: str, end: str, interval=\"1d\", max_retries=3, backoff_sec=2):\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, interval=interval, end=end,\n",
    "                             auto_adjust=True, progress=False, threads=True, multi_level_index=False)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            time.sleep(backoff_sec * attempt)\n",
    "    return None\n",
    "\n",
    "def sma(series: pd.Series, length: int) -> pd.Series:\n",
    "    return series.rolling(length).mean()\n",
    "\n",
    "def two_red(df: pd.DataFrame) -> pd.Series:\n",
    "    red_prev = df['Close'].shift(1) < df['Open'].shift(1)\n",
    "    red_now  = df['Close'] < df['Open']\n",
    "    return (red_prev & red_now)\n",
    "\n",
    "def build_base_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['DMA_fast'] = sma(df['Close'], DMA_FAST)\n",
    "    df['DMA_slow'] = sma(df['Close'], DMA_SLOW)\n",
    "    df['two_red'] = two_red(df)\n",
    "    return df\n",
    "\n",
    "def get_stock_data(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
    "    raw = _read_cache(ticker)\n",
    "    if raw is None:\n",
    "        raw = download_with_retry(ticker, start, end, interval=\"1d\", max_retries=3, backoff_sec=2)\n",
    "        if raw is None or raw.empty:\n",
    "            return None\n",
    "        raw = normalize_df_columns(raw)\n",
    "        raw = collapse_duplicate_columns_take_first(raw)\n",
    "        _write_cache(ticker, raw)\n",
    "\n",
    "    df = raw.copy()\n",
    "    df = normalize_df_columns(df)\n",
    "    df = collapse_duplicate_columns_take_first(df)\n",
    "\n",
    "    for c in ['Close','High','Low','Open','Volume']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    df = build_base_signals(df)\n",
    "    df.dropna(inplace=True)\n",
    "    return df if not df.empty else None\n",
    "\n",
    "def send_telegram(text: str) -> None:\n",
    "    if not ENABLE_TELEGRAM:\n",
    "        print(\"[DRY] Telegram disabled. Message would be:\\n\", text)\n",
    "        return\n",
    "    token = TELEGRAM_BOT_TOKEN\n",
    "    chat_id = TELEGRAM_CHAT_ID\n",
    "    if not token or not chat_id:\n",
    "        print(\"Telegram ENV missing; skipping send.\")\n",
    "        print(text)\n",
    "        return\n",
    "    url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n",
    "    try:\n",
    "        requests.post(url, data={\"chat_id\": chat_id, \"text\": text, \"parse_mode\": \"Markdown\"})\n",
    "    except Exception as e:\n",
    "        print(\"Telegram send error:\", e)\n",
    "        print(text)\n",
    "\n",
    "# ----------- Exit logic -----------\n",
    "def check_exit_for_position(row_pos: pd.Series, df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    row_pos: one row from open_positions.csv\n",
    "    df: full daily df for ticker with DMA and two_red\n",
    "    Returns dict with 'should_exit', 'reason', 'trigger_price', 'as_of_date', 'days_held', 'peak_price'\n",
    "    \"\"\"\n",
    "    ticker = row_pos['ticker']\n",
    "    entry_date = pd.to_datetime(row_pos['entry_date']).date()\n",
    "    entry_price = float(row_pos['entry_price'])\n",
    "\n",
    "    protective_exit = bool(row_pos.get('protective_exit', True))\n",
    "    use_hsl = bool(row_pos.get('use_hard_stop', False))\n",
    "    hsl_pct = float(row_pos.get('hard_stop_pct', 5.0))\n",
    "    use_tsl = bool(row_pos.get('use_trailing_stop', False))\n",
    "    tsl_pct = float(row_pos.get('trailing_stop_pct', 10.0))\n",
    "    max_hold_days = int(row_pos.get('max_hold_days', 10))\n",
    "    prev_peak = float(row_pos.get('peak_price', entry_price))\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        return {\"should_exit\": False}\n",
    "\n",
    "    # restrict to bars since entry\n",
    "    df_since = df[df.index.date >= entry_date]\n",
    "    if df_since.empty:\n",
    "        return {\"should_exit\": False}\n",
    "\n",
    "    # compute peak high since entry\n",
    "    peak_price = max(prev_peak, float(df_since['High'].max()))\n",
    "\n",
    "    # evaluate on the latest bar\n",
    "    cur = df.iloc[-1]\n",
    "    as_of_date = cur.name.date()\n",
    "    days_held = (df_since.shape[0] - 1)  # bars since entry, excluding entry bar\n",
    "\n",
    "    # thresholds\n",
    "    hard_stop_price = entry_price * (1.0 - hsl_pct/100.0) if use_hsl else None\n",
    "    trailing_stop_price = peak_price * (1.0 - tsl_pct/100.0) if use_tsl else None\n",
    "\n",
    "    # priority: HSL -> TSL -> Time -> TwoRedBelow20 -> Protective\n",
    "    # 1) HSL\n",
    "    if use_hsl and (cur['Low'] <= hard_stop_price):\n",
    "        return {\n",
    "            \"should_exit\": True, \"reason\": \"HSL\",\n",
    "            \"trigger_price\": hard_stop_price, \"as_of_date\": as_of_date,\n",
    "            \"days_held\": days_held, \"peak_price\": peak_price\n",
    "        }\n",
    "\n",
    "    # 2) TSL\n",
    "    if use_tsl and (cur['Low'] <= trailing_stop_price):\n",
    "        return {\n",
    "            \"should_exit\": True, \"reason\": \"TSL\",\n",
    "            \"trigger_price\": trailing_stop_price, \"as_of_date\": as_of_date,\n",
    "            \"days_held\": days_held, \"peak_price\": peak_price\n",
    "        }\n",
    "\n",
    "    # 3) Time\n",
    "    if days_held >= max_hold_days:\n",
    "        return {\n",
    "            \"should_exit\": True, \"reason\": \"Time\",\n",
    "            \"trigger_price\": float(cur['Close']), \"as_of_date\": as_of_date,\n",
    "            \"days_held\": days_held, \"peak_price\": peak_price\n",
    "        }\n",
    "\n",
    "    # 4) TwoRedBelow20\n",
    "    if bool(cur['two_red'] and (cur['Close'] < cur['DMA_slow'])):\n",
    "        return {\n",
    "            \"should_exit\": True, \"reason\": \"TwoRedBelow20\",\n",
    "            \"trigger_price\": float(cur['Close']), \"as_of_date\": as_of_date,\n",
    "            \"days_held\": days_held, \"peak_price\": peak_price\n",
    "        }\n",
    "\n",
    "    # 5) Protective\n",
    "    if protective_exit and (cur['Close'] < cur['DMA_slow']):\n",
    "        return {\n",
    "            \"should_exit\": True, \"reason\": \"Protective\",\n",
    "            \"trigger_price\": float(cur['Close']), \"as_of_date\": as_of_date,\n",
    "            \"days_held\": days_held, \"peak_price\": peak_price\n",
    "        }\n",
    "\n",
    "    # no exit\n",
    "    return {\n",
    "        \"should_exit\": False, \"reason\": None,\n",
    "        \"as_of_date\": as_of_date, \"days_held\": days_held, \"peak_price\": peak_price\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    end = END_DATE\n",
    "    if end is None:\n",
    "        end = (datetime.utcnow() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    if not OPEN_POSITIONS_CSV.exists():\n",
    "        print(\"No open positions file found:\", OPEN_POSITIONS_CSV)\n",
    "        return\n",
    "\n",
    "    open_df = pd.read_csv(OPEN_POSITIONS_CSV, parse_dates=['entry_date'])\n",
    "    if open_df.empty:\n",
    "        print(\"No open positions to check.\")\n",
    "        return\n",
    "\n",
    "    # group by ticker to minimize downloads\n",
    "    tickers = sorted(open_df['ticker'].unique().tolist())\n",
    "    data_by_ticker = {}\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            df = get_stock_data(t, START_DATE, end)\n",
    "        except Exception as e:\n",
    "            print(f\"[{t}] error: {e}\\n{traceback.format_exc()}\")\n",
    "            df = None\n",
    "        data_by_ticker[t] = df\n",
    "\n",
    "    alerts = []\n",
    "    keep_rows = []\n",
    "    for _, pos in open_df.iterrows():\n",
    "        t = pos['ticker']\n",
    "        df = data_by_ticker.get(t)\n",
    "        res = check_exit_for_position(pos, df)\n",
    "\n",
    "        # always update peak & days_held in the stored file\n",
    "        pos['peak_price'] = res.get('peak_price', pos.get('peak_price', pos['entry_price']))\n",
    "        pos['days_held_calc'] = res.get('days_held', 0)\n",
    "\n",
    "        if res.get('should_exit', False):\n",
    "            alerts.append((t, res['reason'], res['as_of_date'], float(res['trigger_price'])))\n",
    "            if not AUTO_REMOVE_ON_ALERT:\n",
    "                keep_rows.append(pos)  # keep but mark? You can add a status field if you prefer.\n",
    "        else:\n",
    "            keep_rows.append(pos)\n",
    "\n",
    "    # Save updated open positions (with peak & days_held_calc)\n",
    "    pd.DataFrame(keep_rows).to_csv(OPEN_POSITIONS_CSV, index=False)\n",
    "\n",
    "    # Send Telegram grouped by date\n",
    "    if alerts:\n",
    "        # write per-date CSV and message\n",
    "        per_date = {}\n",
    "        for (t, reason, d, price) in alerts:\n",
    "            per_date.setdefault(d, []).append((t, reason, price))\n",
    "\n",
    "        for d, items in sorted(per_date.items()):\n",
    "            out = pd.DataFrame([{\"ticker\": t, \"reason\": r, \"trigger_price\": price} for (t, r, price) in items])\n",
    "            outpath = EXIT_ALERTS_DIR / f\"exits_{d}.csv\"\n",
    "            out.to_csv(outpath, index=False)\n",
    "\n",
    "        # single message summary\n",
    "        lines = [\"*Exit Alerts — DMA(10,20)+2-Green*\"]\n",
    "        for d, items in sorted(per_date.items()):\n",
    "            tick_str = \", \".join([f\"{t}({r})\" for (t, r, _) in items])\n",
    "            lines.append(f\"*{d}* — {tick_str}\")\n",
    "        send_telegram(\"\\n\".join(lines))\n",
    "\n",
    "        print(\"Alerts sent.\")\n",
    "    else:\n",
    "        print(\"No exits triggered today.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
