{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7076fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:11:36] === Loading data (cache) ===\n",
      "[10:11:44] [cache] downloading 25/500: AGARWALEYE.NS\n",
      "[10:11:53] [cache] downloading 50/500: ASTRAL.NS\n",
      "[10:12:03] [cache] downloading 75/500: BEML.NS\n",
      "[10:12:12] [cache] downloading 100/500: CCL.NS\n",
      "[10:12:22] [cache] downloading 125/500: CRAFTSMAN.NS\n",
      "[10:12:30] [cache] downloading 150/500: EIHOTEL.NS\n",
      "[10:12:38] [cache] downloading 175/500: GILLETTE.NS\n",
      "[10:12:47] [cache] downloading 200/500: HCLTECH.NS\n",
      "[10:12:57] [cache] downloading 225/500: IEX.NS\n",
      "[10:13:05] [cache] downloading 250/500: IRFC.NS\n",
      "[10:13:14] [cache] downloading 275/500: KALYANKJIL.NS\n",
      "[10:13:23] [cache] downloading 300/500: LTFOODS.NS\n",
      "[10:13:31] [cache] downloading 325/500: MOTILALOFS.NS\n",
      "[10:13:39] [cache] downloading 350/500: NTPC.NS\n",
      "[10:13:47] [cache] downloading 375/500: PNB.NS\n",
      "[10:13:57] [cache] downloading 400/500: RITES.NS\n",
      "[10:14:04] [cache] downloading 425/500: SKFINDIA.NS\n",
      "[10:14:13] [cache] downloading 450/500: TATAPOWER.NS\n",
      "[10:14:22] [cache] downloading 475/500: UNIONBANK.NS\n",
      "[10:14:30] [cache] downloading 500/500: ZYDUSLIFE.NS\n",
      "[10:14:31] [cache] requested: 500, loaded: 500, missing: 0, extended_head: 0, extended_tail: 0\n",
      "[10:14:31] Loaded 500 symbols.\n",
      "[10:14:31] === Building indicators ===\n",
      "[10:14:31] Building/loading indicator caches for all symbols...\n",
      "[10:14:31] [ind-cache] computing indicators for 360ONE.NS\n",
      "[10:14:31] [ind-cache] computing indicators for 3MINDIA.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AADHARHFC.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AARTIIND.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AAVAS.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ABB.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ABBOTINDIA.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ABCAPITAL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ABFRL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ABLBL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ABREL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ABSLAMC.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ACC.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ACE.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ACMESOLAR.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ADANIENSOL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ADANIENT.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ADANIGREEN.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ADANIPORTS.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ADANIPOWER.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AEGISLOG.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AEGISVOPAK.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AFCONS.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AFFLE.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AGARWALEYE.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AIAENG.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AIIL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AJANTPHARM.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AKUMS.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AKZOINDIA.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ALKEM.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ALKYLAMINE.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ALOKINDS.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AMBER.NS\n",
      "[10:14:31] [ind-cache] computing indicators for AMBUJACEM.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ANANDRATHI.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ANANTRAJ.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ANGELONE.NS\n",
      "[10:14:31] [ind-cache] computing indicators for APARINDS.NS\n",
      "[10:14:31] [ind-cache] computing indicators for APLAPOLLO.NS\n",
      "[10:14:31] [ind-cache] computing indicators for APLLTD.NS\n",
      "[10:14:31] [ind-cache] computing indicators for APOLLOHOSP.NS\n",
      "[10:14:31] [ind-cache] computing indicators for APOLLOTYRE.NS\n",
      "[10:14:31] [ind-cache] computing indicators for APTUS.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ARE&M.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ASAHIINDIA.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ASHOKLEY.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ASIANPAINT.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ASTERDM.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ASTRAL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ASTRAZEN.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ATGL.NS\n",
      "[10:14:31] [ind-cache] computing indicators for ATHERENERG.NS\n",
      "[10:14:32] [ind-cache] computing indicators for ATUL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for AUBANK.NS\n",
      "[10:14:32] [ind-cache] computing indicators for AUROPHARMA.NS\n",
      "[10:14:32] [ind-cache] computing indicators for AWL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for AXISBANK.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BAJAJ-AUTO.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BAJAJFINSV.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BAJAJHFL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BAJAJHLDNG.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BAJFINANCE.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BALKRISIND.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BALRAMCHIN.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BANDHANBNK.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BANKBARODA.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BANKINDIA.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BASF.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BATAINDIA.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BAYERCROP.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BBTC.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BDL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BEL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BEML.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BERGEPAINT.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BHARATFORG.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BHARTIARTL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BHARTIHEXA.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BHEL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BIKAJI.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BIOCON.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BLS.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BLUEDART.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BLUEJET.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BLUESTARCO.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BOSCHLTD.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BPCL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BRIGADE.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BRITANNIA.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BSE.NS\n",
      "[10:14:32] [ind-cache] computing indicators for BSOFT.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CAMPUS.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CAMS.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CANBK.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CANFINHOME.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CAPLIPOINT.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CARBORUNIV.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CASTROLIND.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CCL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CDSL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CEATLTD.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CENTRALBK.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CENTURYPLY.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CERA.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CESC.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CGCL.NS\n",
      "[10:14:32] [ind-cache] computing indicators for CGPOWER.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CHALET.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CHAMBLFERT.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CHENNPETRO.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CHOICEIN.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CHOLAFIN.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CHOLAHLDNG.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CIPLA.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CLEAN.NS\n",
      "[10:14:33] [ind-cache] computing indicators for COALINDIA.NS\n",
      "[10:14:33] [ind-cache] computing indicators for COCHINSHIP.NS\n",
      "[10:14:33] [ind-cache] computing indicators for COFORGE.NS\n",
      "[10:14:33] [ind-cache] computing indicators for COHANCE.NS\n",
      "[10:14:33] [ind-cache] computing indicators for COLPAL.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CONCOR.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CONCORDBIO.NS\n",
      "[10:14:33] [ind-cache] computing indicators for COROMANDEL.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CRAFTSMAN.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CREDITACC.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CRISIL.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CROMPTON.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CUB.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CUMMINSIND.NS\n",
      "[10:14:33] [ind-cache] computing indicators for CYIENT.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DABUR.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DALBHARAT.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DATAPATTNS.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DBREALTY.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DCMSHRIRAM.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DEEPAKFERT.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DEEPAKNTR.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DELHIVERY.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DEVYANI.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DIVISLAB.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DIXON.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DLF.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DMART.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DOMS.NS\n",
      "[10:14:33] [ind-cache] computing indicators for DRREDDY.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ECLERX.NS\n",
      "[10:14:33] [ind-cache] computing indicators for EICHERMOT.NS\n",
      "[10:14:33] [ind-cache] computing indicators for EIDPARRY.NS\n",
      "[10:14:33] [ind-cache] computing indicators for EIHOTEL.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ELECON.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ELGIEQUIP.NS\n",
      "[10:14:33] [ind-cache] computing indicators for EMAMILTD.NS\n",
      "[10:14:33] [ind-cache] computing indicators for EMCURE.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ENDURANCE.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ENGINERSIN.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ENRIN.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ERIS.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ESCORTS.NS\n",
      "[10:14:33] [ind-cache] computing indicators for ETERNAL.NS\n",
      "[10:14:33] [ind-cache] computing indicators for EXIDEIND.NS\n",
      "[10:14:33] [ind-cache] computing indicators for FACT.NS\n",
      "[10:14:33] [ind-cache] computing indicators for FEDERALBNK.NS\n",
      "[10:14:33] [ind-cache] computing indicators for FINCABLES.NS\n",
      "[10:14:33] [ind-cache] computing indicators for FINPIPE.NS\n",
      "[10:14:33] [ind-cache] computing indicators for FIRSTCRY.NS\n",
      "[10:14:33] [ind-cache] computing indicators for FIVESTAR.NS\n",
      "[10:14:33] [ind-cache] computing indicators for FLUOROCHEM.NS\n",
      "[10:14:34] [ind-cache] computing indicators for FORCEMOT.NS\n",
      "[10:14:34] [ind-cache] computing indicators for FORTIS.NS\n",
      "[10:14:34] [ind-cache] computing indicators for FSL.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GAIL.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GESHIP.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GICRE.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GILLETTE.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GLAND.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GLAXO.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GLENMARK.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GMDCLTD.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GMRAIRPORT.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GODFRYPHLP.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GODIGIT.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GODREJAGRO.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GODREJCP.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GODREJIND.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GODREJPROP.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GPIL.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GRANULES.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GRAPHITE.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GRASIM.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GRAVITA.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GRSE.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GSPL.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GUJGASLTD.NS\n",
      "[10:14:34] [ind-cache] computing indicators for GVT&D.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HAL.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HAPPSTMNDS.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HAVELLS.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HBLENGINE.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HCLTECH.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HDFCAMC.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HDFCBANK.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HDFCLIFE.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HEG.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HEROMOTOCO.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HEXT.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HFCL.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HINDALCO.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HINDCOPPER.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HINDPETRO.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HINDUNILVR.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HINDZINC.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HOMEFIRST.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HONASA.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HONAUT.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HSCL.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HUDCO.NS\n",
      "[10:14:34] [ind-cache] computing indicators for HYUNDAI.NS\n",
      "[10:14:34] [ind-cache] computing indicators for ICICIBANK.NS\n",
      "[10:14:34] [ind-cache] computing indicators for ICICIGI.NS\n",
      "[10:14:34] [ind-cache] computing indicators for ICICIPRULI.NS\n",
      "[10:14:34] [ind-cache] computing indicators for IDBI.NS\n",
      "[10:14:34] [ind-cache] computing indicators for IDEA.NS\n",
      "[10:14:34] [ind-cache] computing indicators for IDFCFIRSTB.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IEX.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IFCI.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IGIL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IGL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IIFL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IKS.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDGN.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDHOTEL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDIACEM.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDIAMART.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDIANB.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDIGO.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDUSINDBK.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INDUSTOWER.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INFY.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INOXINDIA.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INOXWIND.NS\n",
      "[10:14:35] [ind-cache] computing indicators for INTELLECT.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IOB.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IOC.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IPCALAB.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IRB.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IRCON.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IRCTC.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IREDA.NS\n",
      "[10:14:35] [ind-cache] computing indicators for IRFC.NS\n",
      "[10:14:35] [ind-cache] computing indicators for ITC.NS\n",
      "[10:14:35] [ind-cache] computing indicators for ITCHOTELS.NS\n",
      "[10:14:35] [ind-cache] computing indicators for ITI.NS\n",
      "[10:14:35] [ind-cache] computing indicators for J&KBANK.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JBCHEPHARM.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JBMA.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JINDALSAW.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JINDALSTEL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JIOFIN.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JKCEMENT.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JKTYRE.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JMFINANCIL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JPPOWER.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JSL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JSWENERGY.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JSWINFRA.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JSWSTEEL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JUBLFOOD.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JUBLINGREA.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JUBLPHARMA.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JWL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JYOTHYLAB.NS\n",
      "[10:14:35] [ind-cache] computing indicators for JYOTICNC.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KAJARIACER.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KALYANKJIL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KARURVYSYA.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KAYNES.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KEC.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KEI.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KFINTECH.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KIMS.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KIRLOSBROS.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KIRLOSENG.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KOTAKBANK.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KPIL.NS\n",
      "[10:14:35] [ind-cache] computing indicators for KPITTECH.NS\n",
      "[10:14:36] [ind-cache] computing indicators for KPRMILL.NS\n",
      "[10:14:36] [ind-cache] computing indicators for KSB.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LALPATHLAB.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LATENTVIEW.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LAURUSLABS.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LEMONTREE.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LICHSGFIN.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LICI.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LINDEINDIA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LLOYDSME.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LODHA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LT.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LTF.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LTFOODS.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LTIM.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LTTS.NS\n",
      "[10:14:36] [ind-cache] computing indicators for LUPIN.NS\n",
      "[10:14:36] [ind-cache] computing indicators for M&M.NS\n",
      "[10:14:36] [ind-cache] computing indicators for M&MFIN.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MAHABANK.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MAHSCOOTER.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MAHSEAMLES.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MANAPPURAM.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MANKIND.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MANYAVAR.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MAPMYINDIA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MARICO.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MARUTI.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MAXHEALTH.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MAZDOCK.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MCX.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MEDANTA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for METROPOLIS.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MFSL.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MGL.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MINDACORP.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MMTC.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MOTHERSON.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MOTILALOFS.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MPHASIS.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MRF.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MRPL.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MSUMI.NS\n",
      "[10:14:36] [ind-cache] computing indicators for MUTHOOTFIN.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NAM-INDIA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NATCOPHARM.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NATIONALUM.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NAUKRI.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NAVA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NAVINFLUOR.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NBCC.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NCC.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NESTLEIND.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NETWEB.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NEULANDLAB.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NEWGEN.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NH.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NHPC.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NIACL.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NIVABUPA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NLCINDIA.NS\n",
      "[10:14:36] [ind-cache] computing indicators for NMDC.NS\n",
      "[10:14:37] [ind-cache] computing indicators for NSLNISP.NS\n",
      "[10:14:37] [ind-cache] computing indicators for NTPC.NS\n",
      "[10:14:37] [ind-cache] computing indicators for NTPCGREEN.NS\n",
      "[10:14:37] [ind-cache] computing indicators for NUVAMA.NS\n",
      "[10:14:37] [ind-cache] computing indicators for NUVOCO.NS\n",
      "[10:14:37] [ind-cache] computing indicators for NYKAA.NS\n",
      "[10:14:37] [ind-cache] computing indicators for OBEROIRLTY.NS\n",
      "[10:14:37] [ind-cache] computing indicators for OFSS.NS\n",
      "[10:14:37] [ind-cache] computing indicators for OIL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for OLAELEC.NS\n",
      "[10:14:37] [ind-cache] computing indicators for OLECTRA.NS\n",
      "[10:14:37] [ind-cache] computing indicators for ONESOURCE.NS\n",
      "[10:14:37] [ind-cache] computing indicators for ONGC.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PAGEIND.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PATANJALI.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PAYTM.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PCBL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PERSISTENT.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PETRONET.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PFC.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PFIZER.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PGEL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PGHH.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PHOENIXLTD.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PIDILITIND.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PIIND.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PNB.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PNBHOUSING.NS\n",
      "[10:14:37] [ind-cache] computing indicators for POLICYBZR.NS\n",
      "[10:14:37] [ind-cache] computing indicators for POLYCAB.NS\n",
      "[10:14:37] [ind-cache] computing indicators for POLYMED.NS\n",
      "[10:14:37] [ind-cache] computing indicators for POONAWALLA.NS\n",
      "[10:14:37] [ind-cache] computing indicators for POWERGRID.NS\n",
      "[10:14:37] [ind-cache] computing indicators for POWERINDIA.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PPLPHARMA.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PRAJIND.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PREMIERENE.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PRESTIGE.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PTCIL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for PVRINOX.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RADICO.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RAILTEL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RAINBOW.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RAMCOCEM.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RBLBANK.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RCF.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RECLTD.NS\n",
      "[10:14:37] [ind-cache] computing indicators for REDINGTON.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RELIANCE.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RELINFRA.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RHIM.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RITES.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RKFORGE.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RPOWER.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RRKABEL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for RVNL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for SAGILITY.NS\n",
      "[10:14:37] [ind-cache] computing indicators for SAIL.NS\n",
      "[10:14:37] [ind-cache] computing indicators for SAILIFE.NS\n",
      "[10:14:37] [ind-cache] computing indicators for SAMMAANCAP.NS\n",
      "[10:14:37] [ind-cache] computing indicators for SAPPHIRE.NS\n",
      "[10:14:37] [ind-cache] computing indicators for SARDAEN.NS\n",
      "[10:14:37] [ind-cache] computing indicators for SAREGAMA.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SBFC.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SBICARD.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SBILIFE.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SBIN.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SCHAEFFLER.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SCHNEIDER.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SCI.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SHREECEM.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SHRIRAMFIN.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SHYAMMETL.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SIEMENS.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SIGNATURE.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SJVN.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SKFINDIA.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SOBHA.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SOLARINDS.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SONACOMS.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SONATSOFTW.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SRF.NS\n",
      "[10:14:38] [ind-cache] computing indicators for STARHEALTH.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SUMICHEM.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SUNDARMFIN.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SUNDRMFAST.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SUNPHARMA.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SUNTV.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SUPREMEIND.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SUZLON.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SWANCORP.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SWIGGY.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SYNGENE.NS\n",
      "[10:14:38] [ind-cache] computing indicators for SYRMA.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TARIL.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATACHEM.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATACOMM.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATACONSUM.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATAELXSI.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATAINVEST.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATAMOTORS.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATAPOWER.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATASTEEL.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TATATECH.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TBOTEK.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TCS.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TECHM.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TECHNOE.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TEJASNET.NS\n",
      "[10:14:38] [ind-cache] computing indicators for THELEELA.NS\n",
      "[10:14:38] [ind-cache] computing indicators for THERMAX.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TIINDIA.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TIMKEN.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TITAGARH.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TITAN.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TORNTPHARM.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TORNTPOWER.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TRENT.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TRIDENT.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TRITURBINE.NS\n",
      "[10:14:38] [ind-cache] computing indicators for TRIVENI.NS\n",
      "[10:14:39] [ind-cache] computing indicators for TTML.NS\n",
      "[10:14:39] [ind-cache] computing indicators for TVSMOTOR.NS\n",
      "[10:14:39] [ind-cache] computing indicators for UBL.NS\n",
      "[10:14:39] [ind-cache] computing indicators for UCOBANK.NS\n",
      "[10:14:39] [ind-cache] computing indicators for ULTRACEMCO.NS\n",
      "[10:14:39] [ind-cache] computing indicators for UNIONBANK.NS\n",
      "[10:14:39] [ind-cache] computing indicators for UNITDSPR.NS\n",
      "[10:14:39] [ind-cache] computing indicators for UNOMINDA.NS\n",
      "[10:14:39] [ind-cache] computing indicators for UPL.NS\n",
      "[10:14:39] [ind-cache] computing indicators for USHAMART.NS\n",
      "[10:14:39] [ind-cache] computing indicators for UTIAMC.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VBL.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VEDL.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VENTIVE.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VGUARD.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VIJAYA.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VMM.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VOLTAS.NS\n",
      "[10:14:39] [ind-cache] computing indicators for VTL.NS\n",
      "[10:14:39] [ind-cache] computing indicators for WAAREEENER.NS\n",
      "[10:14:39] [ind-cache] computing indicators for WELCORP.NS\n",
      "[10:14:39] [ind-cache] computing indicators for WELSPUNLIV.NS\n",
      "[10:14:39] [ind-cache] computing indicators for WHIRLPOOL.NS\n",
      "[10:14:39] [ind-cache] computing indicators for WIPRO.NS\n",
      "[10:14:39] [ind-cache] computing indicators for WOCKPHARMA.NS\n",
      "[10:14:39] [ind-cache] computing indicators for YESBANK.NS\n",
      "[10:14:39] [ind-cache] computing indicators for ZEEL.NS\n",
      "[10:14:39] [ind-cache] computing indicators for ZENSARTECH.NS\n",
      "[10:14:39] [ind-cache] computing indicators for ZENTEC.NS\n",
      "[10:14:39] [ind-cache] computing indicators for ZFCVINDIA.NS\n",
      "[10:14:39] [ind-cache] computing indicators for ZYDUSLIFE.NS\n",
      "[10:14:39] Indicator caches ready for 500 symbols.\n",
      "[10:14:39] === Parameters ===\n",
      "[10:14:39]   Ranking: enabled=False, rebalance=W-FRI, TopN(cap)=4, exit>rank=40\n",
      "[10:14:39]   Eligibility: within 20% of 52w high & > SMA200 (applied in both modes)\n",
      "[10:14:39]   Entry: MACD↑ + W%R↑(from -80) + hist>0 & rising\n",
      "[10:14:39]   Exit: WR/MACD gate (OR=True, cross=True), StopLoss=4.0%\n",
      "[10:14:39]   Fees=True, Slippage=0bps, ProtectBullishOnRebal=False\n",
      "[10:14:39] === Simulating TRAIN (2015-01-01..2020-12-31) ===\n",
      "[10:15:05] TRAIN trades: 173\n",
      "[10:15:05] Final TRAIN metrics: {'trades': 173, 'win_rate_pct': 39.884393063583815, 'profit_factor': 0.8590706300768581, 'sharpe': -0.3963618848035405, 'cagr_pct': -2.9821197575153557, 'max_dd_pct': -27.530194084311198}\n",
      "[10:15:05] === Simulating TEST (2021-01-01..2025-07-01) ===\n",
      "[10:15:36] TEST trades: 231\n",
      "[10:15:36] Final TEST metrics: {'trades': 231, 'win_rate_pct': 30.735930735930737, 'profit_factor': 0.6271808727942036, 'sharpe': -1.0955174072841418, 'cagr_pct': -17.11826755508481, 'max_dd_pct': -57.00405793131136}\n",
      "[10:15:36] === Writing CSVs ===\n",
      "[10:15:36] Wrote: outputs/trades_train.csv (rows=173)\n",
      "[10:15:36] Wrote: outputs/trades_test.csv (rows=231)\n",
      "[10:15:36] Wrote: outputs/pnl_monthly_train.csv (rows=50)\n",
      "[10:15:36] Wrote: outputs/pnl_monthly_test.csv (rows=49)\n",
      "[10:15:36] === Done ===\n"
     ]
    }
   ],
   "source": [
    "# williams_macd_rank_or_fcfs_rsi_vol.py\n",
    "# Daily strategy with optional ranking, RSI filter, and volume breakout.\n",
    "# Entry (hard): MACD cross-up + W%R cross-up from < -80 + MACD hist > 0 and rising.\n",
    "# Optional filters: RSI >= threshold, Volume breakout vs MA.\n",
    "# Exit: daily technical gate (MACD/W%R) + strict stop-loss. No min-hold/grace.\n",
    "# If RANKING_ENABLED=False -> \"first come first serve\" up to cap, no rank exits.\n",
    "\n",
    "import os, re, math, datetime, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections.abc import Iterable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# ---------------- Logging ----------------\n",
    "def log(msg: str):\n",
    "    ts = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{ts}] {msg}\", flush=True)\n",
    "\n",
    "def fmt_metrics(m: Dict) -> Dict:\n",
    "    out = {}\n",
    "    for k, v in (m or {}).items():\n",
    "        if isinstance(v, (np.floating, np.integer)):\n",
    "            v = v.item()\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "# ============== CONFIG ===================\n",
    "OUTDIR   = \"outputs\"\n",
    "DATADIR  = \"data\"\n",
    "FORCE_REFRESH = False\n",
    "\n",
    "# ---- Universe (replace with your full list) ----\n",
    "UNIVERSE = ['360ONE.NS', '3MINDIA.NS', 'AADHARHFC.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ABB.NS', 'ABBOTINDIA.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'ABLBL.NS', 'ABREL.NS', 'ABSLAMC.NS', 'ACC.NS', 'ACE.NS', 'ACMESOLAR.NS', 'ADANIENSOL.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'AEGISLOG.NS', 'AEGISVOPAK.NS', 'AFCONS.NS', 'AFFLE.NS', 'AGARWALEYE.NS', 'AIAENG.NS', 'AIIL.NS', 'AJANTPHARM.NS', 'AKUMS.NS', 'AKZOINDIA.NS', 'ALKEM.NS', 'ALKYLAMINE.NS', 'ALOKINDS.NS', 'AMBER.NS', 'AMBUJACEM.NS', 'ANANDRATHI.NS', 'ANANTRAJ.NS', 'ANGELONE.NS', 'APARINDS.NS', 'APLAPOLLO.NS', 'APLLTD.NS', 'APOLLOHOSP.NS', 'APOLLOTYRE.NS', 'APTUS.NS', 'ARE&M.NS', 'ASAHIINDIA.NS', 'ASHOKLEY.NS', 'ASIANPAINT.NS', 'ASTERDM.NS', 'ASTRAL.NS', 'ASTRAZEN.NS', 'ATGL.NS', 'ATHERENERG.NS', 'ATUL.NS', 'AUBANK.NS', 'AUROPHARMA.NS', 'AWL.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJAJFINSV.NS', 'BAJAJHFL.NS', 'BAJAJHLDNG.NS', 'BAJFINANCE.NS', 'BALKRISIND.NS', 'BALRAMCHIN.NS', 'BANDHANBNK.NS', 'BANKBARODA.NS', 'BANKINDIA.NS', 'BASF.NS', 'BATAINDIA.NS', 'BAYERCROP.NS', 'BBTC.NS', 'BDL.NS', 'BEL.NS', 'BEML.NS', 'BERGEPAINT.NS', 'BHARATFORG.NS', 'BHARTIARTL.NS', 'BHARTIHEXA.NS', 'BHEL.NS', 'BIKAJI.NS', 'BIOCON.NS', 'BLS.NS', 'BLUEDART.NS', 'BLUEJET.NS', 'BLUESTARCO.NS', 'BOSCHLTD.NS', 'BPCL.NS', 'BRIGADE.NS', 'BRITANNIA.NS', 'BSE.NS', 'BSOFT.NS', 'CAMPUS.NS', 'CAMS.NS', 'CANBK.NS', 'CANFINHOME.NS', 'CAPLIPOINT.NS', 'CARBORUNIV.NS', 'CASTROLIND.NS', 'CCL.NS', 'CDSL.NS', 'CEATLTD.NS', 'CENTRALBK.NS', 'CENTURYPLY.NS', 'CERA.NS', 'CESC.NS', 'CGCL.NS', 'CGPOWER.NS', 'CHALET.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CHOICEIN.NS', 'CHOLAFIN.NS', 'CHOLAHLDNG.NS', 'CIPLA.NS', 'CLEAN.NS', 'COALINDIA.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COHANCE.NS', 'COLPAL.NS', 'CONCOR.NS', 'CONCORDBIO.NS', 'COROMANDEL.NS', 'CRAFTSMAN.NS', 'CREDITACC.NS', 'CRISIL.NS', 'CROMPTON.NS', 'CUB.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DALBHARAT.NS', 'DATAPATTNS.NS', 'DBREALTY.NS', 'DCMSHRIRAM.NS', 'DEEPAKFERT.NS', 'DEEPAKNTR.NS', 'DELHIVERY.NS', 'DEVYANI.NS', 'DIVISLAB.NS', 'DIXON.NS', 'DLF.NS', 'DMART.NS', 'DOMS.NS', 'DRREDDY.NS', 'ECLERX.NS', 'EICHERMOT.NS', 'EIDPARRY.NS', 'EIHOTEL.NS', 'ELECON.NS', 'ELGIEQUIP.NS', 'EMAMILTD.NS', 'EMCURE.NS', 'ENDURANCE.NS', 'ENGINERSIN.NS', 'ENRIN.NS', 'ERIS.NS', 'ESCORTS.NS', 'ETERNAL.NS', 'EXIDEIND.NS', 'FACT.NS', 'FEDERALBNK.NS', 'FINCABLES.NS', 'FINPIPE.NS', 'FIRSTCRY.NS', 'FIVESTAR.NS', 'FLUOROCHEM.NS', 'FORCEMOT.NS', 'FORTIS.NS', 'FSL.NS', 'GAIL.NS', 'GESHIP.NS', 'GICRE.NS', 'GILLETTE.NS', 'GLAND.NS', 'GLAXO.NS', 'GLENMARK.NS', 'GMDCLTD.NS', 'GMRAIRPORT.NS', 'GODFRYPHLP.NS', 'GODIGIT.NS', 'GODREJAGRO.NS', 'GODREJCP.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GPIL.NS', 'GRANULES.NS', 'GRAPHITE.NS', 'GRASIM.NS', 'GRAVITA.NS', 'GRSE.NS', 'GSPL.NS', 'GUJGASLTD.NS', 'GVT&D.NS', 'HAL.NS', 'HAPPSTMNDS.NS', 'HAVELLS.NS', 'HBLENGINE.NS', 'HCLTECH.NS', 'HDFCAMC.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEG.NS', 'HEROMOTOCO.NS', 'HEXT.NS', 'HFCL.NS', 'HINDALCO.NS', 'HINDCOPPER.NS', 'HINDPETRO.NS', 'HINDUNILVR.NS', 'HINDZINC.NS', 'HOMEFIRST.NS', 'HONASA.NS', 'HONAUT.NS', 'HSCL.NS', 'HUDCO.NS', 'HYUNDAI.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'IDBI.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFCI.NS', 'IGIL.NS', 'IGL.NS', 'IIFL.NS', 'IKS.NS', 'INDGN.NS', 'INDHOTEL.NS', 'INDIACEM.NS', 'INDIAMART.NS', 'INDIANB.NS', 'INDIGO.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INFY.NS', 'INOXINDIA.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'IOB.NS', 'IOC.NS', 'IPCALAB.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'IREDA.NS', 'IRFC.NS', 'ITC.NS', 'ITCHOTELS.NS', 'ITI.NS', 'J&KBANK.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JINDALSAW.NS', 'JINDALSTEL.NS', 'JIOFIN.NS', 'JKCEMENT.NS', 'JKTYRE.NS', 'JMFINANCIL.NS', 'JPPOWER.NS', 'JSL.NS', 'JSWENERGY.NS', 'JSWINFRA.NS', 'JSWSTEEL.NS', 'JUBLFOOD.NS', 'JUBLINGREA.NS', 'JUBLPHARMA.NS', 'JWL.NS', 'JYOTHYLAB.NS', 'JYOTICNC.NS', 'KAJARIACER.NS', 'KALYANKJIL.NS', 'KARURVYSYA.NS', 'KAYNES.NS', 'KEC.NS', 'KEI.NS', 'KFINTECH.NS', 'KIMS.NS', 'KIRLOSBROS.NS', 'KIRLOSENG.NS', 'KOTAKBANK.NS', 'KPIL.NS', 'KPITTECH.NS', 'KPRMILL.NS', 'KSB.NS', 'LALPATHLAB.NS', 'LATENTVIEW.NS', 'LAURUSLABS.NS', 'LEMONTREE.NS', 'LICHSGFIN.NS', 'LICI.NS', 'LINDEINDIA.NS', 'LLOYDSME.NS', 'LODHA.NS', 'LT.NS', 'LTF.NS', 'LTFOODS.NS', 'LTIM.NS', 'LTTS.NS', 'LUPIN.NS', 'M&M.NS', 'M&MFIN.NS', 'MAHABANK.NS', 'MAHSCOOTER.NS', 'MAHSEAMLES.NS', 'MANAPPURAM.NS', 'MANKIND.NS', 'MANYAVAR.NS', 'MAPMYINDIA.NS', 'MARICO.NS', 'MARUTI.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MCX.NS', 'MEDANTA.NS', 'METROPOLIS.NS', 'MFSL.NS', 'MGL.NS', 'MINDACORP.NS', 'MMTC.NS', 'MOTHERSON.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MRF.NS', 'MRPL.NS', 'MSUMI.NS', 'MUTHOOTFIN.NS', 'NAM-INDIA.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAUKRI.NS', 'NAVA.NS', 'NAVINFLUOR.NS', 'NBCC.NS', 'NCC.NS', 'NESTLEIND.NS', 'NETWEB.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NH.NS', 'NHPC.NS', 'NIACL.NS', 'NIVABUPA.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NSLNISP.NS', 'NTPC.NS', 'NTPCGREEN.NS', 'NUVAMA.NS', 'NUVOCO.NS', 'NYKAA.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLAELEC.NS', 'OLECTRA.NS', 'ONESOURCE.NS', 'ONGC.NS', 'PAGEIND.NS', 'PATANJALI.NS', 'PAYTM.NS', 'PCBL.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PFC.NS', 'PFIZER.NS', 'PGEL.NS', 'PGHH.NS', 'PHOENIXLTD.NS', 'PIDILITIND.NS', 'PIIND.NS', 'PNB.NS', 'PNBHOUSING.NS', 'POLICYBZR.NS', 'POLYCAB.NS', 'POLYMED.NS', 'POONAWALLA.NS', 'POWERGRID.NS', 'POWERINDIA.NS', 'PPLPHARMA.NS', 'PRAJIND.NS', 'PREMIERENE.NS', 'PRESTIGE.NS', 'PTCIL.NS', 'PVRINOX.NS', 'RADICO.NS', 'RAILTEL.NS', 'RAINBOW.NS', 'RAMCOCEM.NS', 'RBLBANK.NS', 'RCF.NS', 'RECLTD.NS', 'REDINGTON.NS', 'RELIANCE.NS', 'RELINFRA.NS', 'RHIM.NS', 'RITES.NS', 'RKFORGE.NS', 'RPOWER.NS', 'RRKABEL.NS', 'RVNL.NS', 'SAGILITY.NS', 'SAIL.NS', 'SAILIFE.NS', 'SAMMAANCAP.NS', 'SAPPHIRE.NS', 'SARDAEN.NS', 'SAREGAMA.NS', 'SBFC.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SBIN.NS', 'SCHAEFFLER.NS', 'SCHNEIDER.NS', 'SCI.NS', 'SHREECEM.NS', 'SHRIRAMFIN.NS', 'SHYAMMETL.NS', 'SIEMENS.NS', 'SIGNATURE.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SOBHA.NS', 'SOLARINDS.NS', 'SONACOMS.NS', 'SONATSOFTW.NS', 'SRF.NS', 'STARHEALTH.NS', 'SUMICHEM.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUNPHARMA.NS', 'SUNTV.NS', 'SUPREMEIND.NS', 'SUZLON.NS', 'SWANCORP.NS', 'SWIGGY.NS', 'SYNGENE.NS', 'SYRMA.NS', 'TARIL.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATACONSUM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TATATECH.NS', 'TBOTEK.NS', 'TCS.NS', 'TECHM.NS', 'TECHNOE.NS', 'TEJASNET.NS', 'THELEELA.NS', 'THERMAX.NS', 'TIINDIA.NS', 'TIMKEN.NS', 'TITAGARH.NS', 'TITAN.NS', 'TORNTPHARM.NS', 'TORNTPOWER.NS', 'TRENT.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'TRIVENI.NS', 'TTML.NS', 'TVSMOTOR.NS', 'UBL.NS', 'UCOBANK.NS', 'ULTRACEMCO.NS', 'UNIONBANK.NS', 'UNITDSPR.NS', 'UNOMINDA.NS', 'UPL.NS', 'USHAMART.NS', 'UTIAMC.NS', 'VBL.NS', 'VEDL.NS', 'VENTIVE.NS', 'VGUARD.NS', 'VIJAYA.NS', 'VMM.NS', 'VOLTAS.NS', 'VTL.NS', 'WAAREEENER.NS', 'WELCORP.NS', 'WELSPUNLIV.NS', 'WHIRLPOOL.NS', 'WIPRO.NS', 'WOCKPHARMA.NS', 'YESBANK.NS', 'ZEEL.NS', 'ZENSARTECH.NS', 'ZENTEC.NS', 'ZFCVINDIA.NS', 'ZYDUSLIFE.NS']\n",
    "TRAIN_START = \"2015-01-01\"\n",
    "TRAIN_END   = \"2020-12-31\"\n",
    "TEST_START  = \"2021-01-01\"\n",
    "TEST_END    = \"2025-07-01\"\n",
    "\n",
    "STARTING_CAPITAL = 200_000.0\n",
    "SLIPPAGE_BPS     = 00\n",
    "APPLY_FEES       = True  # uses Groww NSE delivery model (no UPI mandate)\n",
    "\n",
    "# ---- Portfolio capacity (used in both modes) ----\n",
    "RANK_TOP_N             = 4   # acts as capacity cap even if ranking is disabled\n",
    "\n",
    "# ---- Ranking mode toggle ----\n",
    "RANKING_ENABLED        = False    # << Toggle here\n",
    "REBALANCE_FREQ         = \"W-FRI\" # \"W-FRI\",\"2W-FRI\",\"3W-FRI\",\"M\"\n",
    "RANK_EXIT_THRESHOLD    = 40      # ignored if ranking disabled\n",
    "RANK_LOOKBACK_DAYS     = 252\n",
    "WITHIN_52W             = 0.20    # eligible if Close >= (1-WITHIN_52W)*52w high AND Close > SMA200\n",
    "\n",
    "# ---- Option: protect bullish holdings from rank exit (only when ranking enabled) ----\n",
    "PRIORITIZE_BULLISH_ON_REBAL = True\n",
    "BULLISH_HOLD_REQUIRE_LINE_GT_SIG  = True\n",
    "BULLISH_HOLD_REQUIRE_HIST_POS     = True\n",
    "BULLISH_HOLD_REQUIRE_HIST_RISE    = False\n",
    "BULLISH_HOLD_WILLR_LEVEL          = -50\n",
    "\n",
    "# ---- Entry bundle (hard) ----\n",
    "WILLR_N          = 14\n",
    "WILLR_ENTER      = -80\n",
    "WILLR_EXIT       = -20\n",
    "MACD_FAST        = 12\n",
    "MACD_SLOW        = 26\n",
    "MACD_SIGNAL      = 9\n",
    "\n",
    "# ---- Daily exit gate ----\n",
    "USE_WR_MACD_EXITGATE = True\n",
    "EXIT_REQUIRE_CROSS   = True    # cross-down semantics\n",
    "EXIT_GATE_OR         = True    # OR between MACD & W%R exit\n",
    "\n",
    "# ---- Intraday stop-loss ----\n",
    "USE_STOP_LOSS = True\n",
    "STOP_LOSS_PCT = 0.04           # strict 4% stop (configurable)\n",
    "\n",
    "# ---- Optional RSI & Volume filters (toggles) ----\n",
    "USE_RSI_FILTER   = False\n",
    "RSI_LEN          = 14\n",
    "RSI_MIN          = 55.0        # require RSI >= 55\n",
    "\n",
    "USE_VOL_BREAKOUT = False\n",
    "VOL_LOOKBACK     = 20\n",
    "VOL_MULTIPLIER   = 1.5         # require Volume >= 1.5 × VOL_MA\n",
    "\n",
    "# ---- Optional 4h confirm (kept available; OFF by default) ----\n",
    "USE_MTF_CONFIRM  = False\n",
    "MTF_STRICT       = False\n",
    "\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "os.makedirs(DATADIR, exist_ok=True)\n",
    "\n",
    "# ============== Helpers & Data Cache ==============\n",
    "def sanitize_ticker(t) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]\", \"_\", str(t))\n",
    "\n",
    "def _flatten_tickers(tickers):\n",
    "    if isinstance(tickers, (str, bytes)): return [str(tickers)]\n",
    "    flat=[]\n",
    "    for x in tickers:\n",
    "        if isinstance(x, (str, bytes)): flat.append(str(x))\n",
    "        elif isinstance(x, Iterable):\n",
    "            for y in x: flat.append(str(y))\n",
    "        else:\n",
    "            flat.append(str(x))\n",
    "    flat=[t for t in flat if t and t.strip()]\n",
    "    seen=set(); out=[]\n",
    "    for t in flat:\n",
    "        if t not in seen: out.append(t); seen.add(t)\n",
    "    return out\n",
    "\n",
    "def yf_download(ticker: str, start: str, end: str, attempts: int=3, sleep_s: float=0.8) -> pd.DataFrame:\n",
    "    end_inc = (pd.to_datetime(end) + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    for k in range(1, attempts+1):\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end_inc, auto_adjust=True,\n",
    "                             progress=False, multi_level_index=False)\n",
    "            if df is not None and not df.empty:\n",
    "                df = df.rename(columns=lambda c: c.strip().title())\n",
    "                if \"Adj Close\" not in df.columns and \"Close\" in df.columns:\n",
    "                    df[\"Adj Close\"] = df[\"Close\"]\n",
    "                if \"Volume\" not in df.columns:\n",
    "                    df[\"Volume\"] = 0\n",
    "                keep = [c for c in [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"] if c in df.columns]\n",
    "                df = df[keep]\n",
    "                df.index = pd.to_datetime(df.index).normalize()\n",
    "                df = df[~df.index.duplicated(keep=\"last\")]\n",
    "                return df.sort_index()\n",
    "        except Exception:\n",
    "            pass\n",
    "        if k < attempts: time.sleep(sleep_s)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def load_or_download_prices(tickers, start: str, end: str, force_refresh: bool=False) -> Dict[str,pd.DataFrame]:\n",
    "    tickers = _flatten_tickers(tickers)\n",
    "    data = {}; missing = []; extended_head = 0; extended_tail = 0\n",
    "    for i, t in enumerate(tickers, start=1):\n",
    "        fn = os.path.join(DATADIR, f\"{sanitize_ticker(t)}.csv\")\n",
    "        if force_refresh or (not os.path.exists(fn)):\n",
    "            if i % 25 == 0: log(f\"[cache] downloading {i}/{len(tickers)}: {t}\")\n",
    "            df = yf_download(t, start, end)\n",
    "            if df.empty: missing.append(t); continue\n",
    "            df.to_csv(fn, index=True); data[t] = df; continue\n",
    "        df_local = pd.read_csv(fn, index_col=0, parse_dates=True).sort_index()\n",
    "        df_local.index = pd.to_datetime(df_local.index).normalize()\n",
    "        if \"Adj Close\" not in df_local.columns and \"Close\" in df_local.columns:\n",
    "            df_local[\"Adj Close\"] = df_local[\"Close\"]\n",
    "        if \"Volume\" not in df_local.columns:\n",
    "            df_local[\"Volume\"] = 0\n",
    "        have_min, have_max = df_local.index.min(), df_local.index.max()\n",
    "        want_min, want_max = pd.to_datetime(start), pd.to_datetime(end)\n",
    "        if have_min > want_min:\n",
    "            df_head = yf_download(t, start, (have_min - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
    "            if not df_head.empty:\n",
    "                df_local = pd.concat([df_head, df_local]).sort_index(); extended_head += 1\n",
    "        if have_max < want_max:\n",
    "            df_tail = yf_download(t, (have_max + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"), end)\n",
    "            if not df_tail.empty:\n",
    "                df_local = pd.concat([df_local, df_tail]).sort_index(); extended_tail += 1\n",
    "        if df_local.empty: missing.append(t); continue\n",
    "        df_local.to_csv(fn, index=True)\n",
    "        data[t] = df_local.loc[(df_local.index >= want_min) & (df_local.index <= want_max)]\n",
    "    log(f\"[cache] requested: {len(tickers)}, loaded: {len(data)}, missing: {len(missing)}, extended_head: {extended_head}, extended_tail: {extended_tail}\")\n",
    "    if missing:\n",
    "        pd.DataFrame({\"ticker\": missing}).to_csv(os.path.join(OUTDIR,\"missing_tickers.csv\"), index=False)\n",
    "        log(f\"[cache] wrote list of missing/empty tickers.\")\n",
    "    pd.DataFrame({\"ticker\": list(data.keys())}).to_csv(os.path.join(OUTDIR,\"loaded_tickers.csv\"), index=False)\n",
    "    return data\n",
    "\n",
    "# ============== Indicators =================\n",
    "def sma(s: pd.Series, n: int) -> pd.Series:\n",
    "    return s.rolling(n, min_periods=n).mean()\n",
    "\n",
    "def ema(s: pd.Series, span: int) -> pd.Series:\n",
    "    return s.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "\n",
    "def macd_parts(close: pd.Series, fast: int, slow: int, signal: int):\n",
    "    e_f = ema(close, fast); e_s = ema(close, slow)\n",
    "    macd_line = e_f - e_s\n",
    "    macd_signal = ema(macd_line, signal)\n",
    "    macd_hist = macd_line - macd_signal\n",
    "    return macd_line, macd_signal, macd_hist\n",
    "\n",
    "def williams_r(h: pd.Series, l: pd.Series, c: pd.Series, n: int) -> pd.Series:\n",
    "    hh = h.rolling(n, min_periods=n).max()\n",
    "    ll = l.rolling(n, min_periods=n).min()\n",
    "    return -100 * (hh - c) / (hh - ll)\n",
    "\n",
    "def rsi_wilder(close: pd.Series, n: int=14) -> pd.Series:\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    roll_up = up.ewm(alpha=1/n, adjust=False).mean()\n",
    "    roll_down = down.ewm(alpha=1/n, adjust=False).mean()\n",
    "    rs = roll_up / roll_down.replace(0, np.nan)\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def compute_indicators_df(price_df: pd.DataFrame, rank_lookback: int) -> pd.DataFrame:\n",
    "    close, high, low, vol = price_df[\"Close\"], price_df[\"High\"], price_df[\"Low\"], price_df[\"Volume\"]\n",
    "    macd_line, macd_sig, macd_hist = macd_parts(close, MACD_FAST, MACD_SLOW, MACD_SIGNAL)\n",
    "    out = {\n",
    "        \"SMA_200\":  sma(close, 200),\n",
    "        \"HIGH_252\": high.rolling(252, min_periods=252).max(),\n",
    "        \"RETN\":     (close / close.shift(rank_lookback)) - 1.0,\n",
    "        \"MACD_LINE\": macd_line,\n",
    "        \"MACD_SIG\":  macd_sig,\n",
    "        \"MACD_HIST\": macd_hist,\n",
    "        \"WILLR\":     williams_r(high, low, close, WILLR_N),\n",
    "        \"RSI\":       rsi_wilder(close, RSI_LEN),\n",
    "        \"VOL_MA\":    vol.rolling(VOL_LOOKBACK, min_periods=VOL_LOOKBACK).mean(),\n",
    "    }\n",
    "    return pd.DataFrame(out, index=price_df.index)\n",
    "\n",
    "def load_or_build_indicators_for_ticker(ticker: str, price_df: pd.DataFrame, rank_lookback: int, force_refresh: bool=False) -> pd.DataFrame:\n",
    "    ind_fn = os.path.join(DATADIR, f\"indicators_{sanitize_ticker(ticker)}.csv\")\n",
    "    need_cols = [\"SMA_200\",\"HIGH_252\",\"RETN\",\"MACD_LINE\",\"MACD_SIG\",\"MACD_HIST\",\"WILLR\",\"RSI\",\"VOL_MA\"]\n",
    "    need_rebuild = force_refresh or (not os.path.exists(ind_fn))\n",
    "    if not need_rebuild:\n",
    "        try:\n",
    "            ind = pd.read_csv(ind_fn, index_col=0, parse_dates=True)\n",
    "            ind.index = pd.to_datetime(ind.index).normalize()\n",
    "            if (ind.index.max() >= price_df.index.max()) and all(c in ind.columns for c in need_cols):\n",
    "                return ind.reindex(price_df.index)\n",
    "            else:\n",
    "                need_rebuild = True\n",
    "        except Exception:\n",
    "            need_rebuild = True\n",
    "    log(f\"[ind-cache] computing indicators for {ticker}\")\n",
    "    ind = compute_indicators_df(price_df, rank_lookback)\n",
    "    ind.to_csv(ind_fn, index=True)\n",
    "    return ind.reindex(price_df.index)\n",
    "\n",
    "def build_indicator_caches(price_map: Dict[str,pd.DataFrame], rank_lookback: int, force_refresh: bool=False) -> Dict[str,Dict[str,pd.Series]]:\n",
    "    log(\"Building/loading indicator caches for all symbols...\")\n",
    "    caches = {}\n",
    "    for t, df in price_map.items():\n",
    "        ind_df = load_or_build_indicators_for_ticker(t, df, rank_lookback, force_refresh=force_refresh)\n",
    "        caches[t] = {col: ind_df[col] for col in ind_df.columns}\n",
    "    log(f\"Indicator caches ready for {len(caches)} symbols.\")\n",
    "    return caches\n",
    "\n",
    "# ============== Groww Fees (NSE Delivery) ==============\n",
    "def calc_fees(turnover_buy: float, turnover_sell: float) -> float:\n",
    "    if not APPLY_FEES: return 0.0\n",
    "    # Brokerage 0.1% each leg, min ₹5, max ₹20 per leg\n",
    "    BROKER_PCT = 0.001\n",
    "    BROKER_MIN = 5.0\n",
    "    BROKER_CAP = 20.0\n",
    "    # Taxes & charges\n",
    "    STT_PCT = 0.001            # on buy & sell\n",
    "    STAMP_BUY_PCT = 0.00015    # on buy only\n",
    "    EXCH_PCT = 0.0000297\n",
    "    SEBI_PCT = 0.000001\n",
    "    IPFT_PCT = 0.000001\n",
    "    GST_PCT = 0.18\n",
    "    DP_SELL = 20.0 if turnover_sell >= 100 else 0.0\n",
    "\n",
    "    def _broker(turnover):\n",
    "        if turnover <= 0: return 0.0\n",
    "        fee = turnover * BROKER_PCT\n",
    "        fee = max(BROKER_MIN, min(fee, BROKER_CAP))\n",
    "        return fee\n",
    "\n",
    "    br_buy  = _broker(turnover_buy)\n",
    "    br_sell = _broker(turnover_sell)\n",
    "    stt   = STT_PCT * (turnover_buy + turnover_sell)\n",
    "    stamp = STAMP_BUY_PCT * turnover_buy\n",
    "    exch  = EXCH_PCT * (turnover_buy + turnover_sell)\n",
    "    sebi  = SEBI_PCT * (turnover_buy + turnover_sell)\n",
    "    ipft  = IPFT_PCT * (turnover_buy + turnover_sell)\n",
    "    dp    = DP_SELL\n",
    "    gst_base = br_buy + br_sell + dp + exch + sebi + ipft\n",
    "    gst   = GST_PCT * gst_base\n",
    "    return float((br_buy + br_sell) + stt + stamp + exch + sebi + ipft + dp + gst)\n",
    "\n",
    "# ============== Rebalance scheduling (for ranking mode) ==============\n",
    "def compute_rebalance_dates(dates: pd.DatetimeIndex, freq: str) -> List[pd.Timestamp]:\n",
    "    dates = pd.DatetimeIndex(dates).sort_values()\n",
    "    if freq == \"M\":\n",
    "        temp = pd.Series(1, index=dates)\n",
    "        return list(pd.to_datetime(temp.groupby(dates.to_period(\"M\")).apply(lambda s: s.index.max()).values))\n",
    "    m = re.match(r\"^(\\d*)W-([A-Z]{3})$\", freq.upper())\n",
    "    if not m: raise ValueError(f\"Unsupported REBALANCE_FREQ: {freq}\")\n",
    "    n = int(m.group(1)) if m.group(1) else 1\n",
    "    anchor = m.group(2)\n",
    "    temp = pd.Series(1, index=dates)\n",
    "    weekly_ends = list(pd.to_datetime(temp.groupby(dates.to_period(f\"W-{anchor}\")).apply(lambda s: s.index.max()).values))\n",
    "    return weekly_ends if n <= 1 else weekly_ends[::n]\n",
    "\n",
    "# ============== Ranking (for ranking mode) ==============\n",
    "def build_rank_table(date_d: pd.Timestamp,\n",
    "                     data: Dict[str,pd.DataFrame],\n",
    "                     caches: Dict[str,Dict[str,pd.Series]]) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for t, df in data.items():\n",
    "        if date_d not in df.index: continue\n",
    "        c = float(df.at[date_d, \"Close\"])\n",
    "        try:\n",
    "            high252 = float(caches[t][\"HIGH_252\"].loc[date_d])\n",
    "            sma200  = float(caches[t][\"SMA_200\"].loc[date_d])\n",
    "            retN    = float(caches[t][\"RETN\"].loc[date_d])\n",
    "        except Exception:\n",
    "            continue\n",
    "        if any(map(np.isnan, [c, high252, sma200, retN])): continue\n",
    "        within = (c >= (1.0 - WITHIN_52W) * high252)\n",
    "        above  = (c > sma200)\n",
    "        eligible = bool(within and above)\n",
    "        rows.append({\"ticker\":t,\"close\":c,\"elig\":eligible,\"ret\":retN})\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"ticker\",\"close\",\"elig\",\"ret\",\"rank\"])\n",
    "    tab = pd.DataFrame(rows)\n",
    "    tab.sort_values([\"elig\",\"ret\"], ascending=[False, False], inplace=True)\n",
    "    tab[\"rank\"] = np.arange(1, len(tab)+1)\n",
    "    return tab\n",
    "\n",
    "# ============== Gates ==============\n",
    "def _cross_up(a: pd.Series, b: pd.Series, d: pd.Timestamp) -> bool:\n",
    "    try:\n",
    "        return bool((a.shift(1).loc[d] <= b.shift(1).loc[d]) and (a.loc[d] > b.loc[d]))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _cross_down(a: pd.Series, b: pd.Series, d: pd.Timestamp) -> bool:\n",
    "    try:\n",
    "        return bool((a.shift(1).loc[d] >= b.shift(1).loc[d]) and (a.loc[d] < b.loc[d]))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def bullish_entry_bundle(sym: str, d: pd.Timestamp, daily_ind: Dict[str,pd.Series], return_values=False):\n",
    "    \"\"\"Strict entry: MACD cross-up + W%R cross-up from <-80 + hist > 0 and rising.\"\"\"\n",
    "    try:\n",
    "        W = float(daily_ind[\"WILLR\"].loc[d])\n",
    "        W_prev = float(daily_ind[\"WILLR\"].shift(1).loc[d])\n",
    "        L = float(daily_ind[\"MACD_LINE\"].loc[d])\n",
    "        S = float(daily_ind[\"MACD_SIG\"].loc[d])\n",
    "        H = float(daily_ind[\"MACD_HIST\"].loc[d])\n",
    "        H_prev = float(daily_ind[\"MACD_HIST\"].shift(1).loc[d])\n",
    "    except Exception:\n",
    "        vals = (np.nan,np.nan,np.nan,np.nan)\n",
    "        return (False, *vals) if return_values else False\n",
    "\n",
    "    conds = [\n",
    "        _cross_up(daily_ind[\"MACD_LINE\"], daily_ind[\"MACD_SIG\"], d),\n",
    "        (W_prev < WILLR_ENTER) and (W >= WILLR_ENTER),\n",
    "        (H > 0.0),\n",
    "        (H > H_prev)\n",
    "    ]\n",
    "    ok = all(conds)\n",
    "    return (ok, W, L, S, H) if return_values else ok\n",
    "\n",
    "def extra_entry_filters(sym: str, d: pd.Timestamp, daily_ind: Dict[str,pd.Series], price_df: pd.DataFrame) -> bool:\n",
    "    # RSI filter\n",
    "    if USE_RSI_FILTER:\n",
    "        try:\n",
    "            r = float(daily_ind[\"RSI\"].loc[d])\n",
    "            if np.isnan(r) or (r < RSI_MIN): return False\n",
    "        except Exception:\n",
    "            return False\n",
    "    # Volume breakout\n",
    "    if USE_VOL_BREAKOUT:\n",
    "        try:\n",
    "            v = float(price_df.at[d, \"Volume\"])\n",
    "            vma = float(daily_ind[\"VOL_MA\"].loc[d])\n",
    "            if np.isnan(vma) or v < VOL_MULTIPLIER * vma: return False\n",
    "        except Exception:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_bullish_now_for_hold(daily_ind: Dict[str, pd.Series], d: pd.Timestamp) -> bool:\n",
    "    \"\"\"Bullish state for rank-exit protection (not a cross event).\"\"\"\n",
    "    try:\n",
    "        L = float(daily_ind[\"MACD_LINE\"].loc[d])\n",
    "        S = float(daily_ind[\"MACD_SIG\"].loc[d])\n",
    "        H = float(daily_ind[\"MACD_HIST\"].loc[d])\n",
    "        H_prev = float(daily_ind[\"MACD_HIST\"].shift(1).loc[d])\n",
    "        W = float(daily_ind[\"WILLR\"].loc[d])\n",
    "    except Exception:\n",
    "        return False\n",
    "    conds = []\n",
    "    if BULLISH_HOLD_REQUIRE_LINE_GT_SIG: conds.append(L > S)\n",
    "    if BULLISH_HOLD_REQUIRE_HIST_POS:    conds.append(H >= 0.0)\n",
    "    if BULLISH_HOLD_REQUIRE_HIST_RISE:   conds.append(H > H_prev)\n",
    "    if BULLISH_HOLD_WILLR_LEVEL is not None: conds.append(W > BULLISH_HOLD_WILLR_LEVEL)\n",
    "    return all(conds)\n",
    "\n",
    "def gate_exit_hit(sym: str, d: pd.Timestamp, daily_ind: Dict[str,pd.Series]) -> bool:\n",
    "    if not USE_WR_MACD_EXITGATE:\n",
    "        return False\n",
    "    try:\n",
    "        if EXIT_REQUIRE_CROSS:\n",
    "            macd_dn = _cross_down(daily_ind[\"MACD_LINE\"], daily_ind[\"MACD_SIG\"], d)\n",
    "            willr_dn = bool((daily_ind[\"WILLR\"].shift(1).loc[d] > WILLR_EXIT) and\n",
    "                            (daily_ind[\"WILLR\"].loc[d] <= WILLR_EXIT))\n",
    "        else:\n",
    "            macd_dn = bool(daily_ind[\"MACD_LINE\"].loc[d] < daily_ind[\"MACD_SIG\"].loc[d])\n",
    "            willr_dn = bool(daily_ind[\"WILLR\"].loc[d] <= WILLR_EXIT)\n",
    "    except Exception:\n",
    "        return False\n",
    "    return (macd_dn or willr_dn) if EXIT_GATE_OR else (macd_dn and willr_dn)\n",
    "\n",
    "# ============== Engine ==============\n",
    "@dataclass\n",
    "class SimplePos:\n",
    "    ticker: str\n",
    "    entry_date: pd.Timestamp\n",
    "    entry_price: float\n",
    "    shares: int\n",
    "    reason_entry: str\n",
    "    signal_date: pd.Timestamp\n",
    "    sig_willr: float\n",
    "    sig_macd_line: float\n",
    "    sig_macd_sig: float\n",
    "    sig_macd_hist: float\n",
    "    entry_idx: int\n",
    "\n",
    "@dataclass\n",
    "class PendingOrder:\n",
    "    side: str\n",
    "    ticker: str\n",
    "    exec_date: pd.Timestamp\n",
    "    budget: float = 0.0\n",
    "    reason: str = \"\"\n",
    "    signal_date: Optional[pd.Timestamp] = None\n",
    "    sig_willr: float = np.nan\n",
    "    sig_macd_line: float = np.nan\n",
    "    sig_macd_sig: float = np.nan\n",
    "    sig_macd_hist: float = np.nan\n",
    "\n",
    "def simulate_engine(data: Dict[str,pd.DataFrame],\n",
    "                    caches: Dict[str,Dict[str,pd.Series]],\n",
    "                    start: str, end: str):\n",
    "    # Timeline\n",
    "    all_dates = None\n",
    "    for df in data.values():\n",
    "        all_dates = df.index if all_dates is None else all_dates.union(df.index)\n",
    "    dates = all_dates.sort_values()\n",
    "    dates = dates[(dates>=pd.to_datetime(start)) & (dates<=pd.to_datetime(end))]\n",
    "    if len(dates)==0: return pd.DataFrame(), pd.Series(dtype=float)\n",
    "\n",
    "    # Daily indicators for gates\n",
    "    daily = {\n",
    "        t: {\"MACD_LINE\": caches[t][\"MACD_LINE\"].reindex(dates),\n",
    "            \"MACD_SIG\":  caches[t][\"MACD_SIG\"].reindex(dates),\n",
    "            \"MACD_HIST\": caches[t][\"MACD_HIST\"].reindex(dates),\n",
    "            \"WILLR\":     caches[t][\"WILLR\"].reindex(dates),\n",
    "            \"RSI\":       caches[t][\"RSI\"].reindex(dates),\n",
    "            \"VOL_MA\":    caches[t][\"VOL_MA\"].reindex(dates)}\n",
    "        for t in data.keys()\n",
    "    }\n",
    "\n",
    "    # Rebalance snapshots (only if ranking enabled)\n",
    "    if RANKING_ENABLED:\n",
    "        rebal_dates = compute_rebalance_dates(dates, REBALANCE_FREQ)\n",
    "        rebal_set = set(rebal_dates)\n",
    "        current_rank = pd.DataFrame()\n",
    "    else:\n",
    "        rebal_dates = []\n",
    "        rebal_set   = set()\n",
    "        current_rank= pd.DataFrame()\n",
    "\n",
    "    # State\n",
    "    cash = STARTING_CAPITAL\n",
    "    positions: Dict[str, SimplePos] = {}\n",
    "    pending: List[PendingOrder] = []\n",
    "    equity_series = []\n",
    "    trades_rows = []\n",
    "\n",
    "    def equity_on_close(d):\n",
    "        val = cash\n",
    "        for sym, pos in positions.items():\n",
    "            if d in data[sym].index:\n",
    "                val += float(data[sym].at[d,\"Close\"]) * pos.shares\n",
    "        return float(val)\n",
    "\n",
    "    for d in dates:\n",
    "        # 1) Open: execute queued (sells → buys)\n",
    "        if pending:\n",
    "            todays = [o for o in pending if o.exec_date == d]\n",
    "            if todays:\n",
    "                # Sells first\n",
    "                for o in [x for x in todays if x.side==\"sell\"]:\n",
    "                    sym = o.ticker\n",
    "                    if sym not in positions or d not in data[sym].index: continue\n",
    "                    open_px = float(data[sym].at[d,\"Open\"])\n",
    "                    eff_sell = open_px * (1 - SLIPPAGE_BPS/10_000.0)\n",
    "                    pos = positions[sym]\n",
    "                    t_buy  = pos.entry_price * pos.shares\n",
    "                    t_sell = eff_sell * pos.shares\n",
    "                    fees = calc_fees(t_buy, t_sell)\n",
    "                    pnl  = (eff_sell - pos.entry_price) * pos.shares - fees\n",
    "                    cash += (eff_sell * pos.shares) - fees\n",
    "                    trades_rows.append({\n",
    "                        \"ticker\": sym,\n",
    "                        \"entry_date\": pos.entry_date.date(),\n",
    "                        \"exit_date\": d.date(),\n",
    "                        \"entry_price\": round(pos.entry_price,2),\n",
    "                        \"exit_price\":  round(eff_sell,2),\n",
    "                        \"shares\": pos.shares,\n",
    "                        \"gross_pnl\": round((eff_sell - pos.entry_price) * pos.shares,2),\n",
    "                        \"fees\": round(fees,2),\n",
    "                        \"net_pnl\": round(pnl,2),\n",
    "                        \"reason_entry\": pos.reason_entry,\n",
    "                        \"reason_exit\": o.reason or \"exit_gate\",\n",
    "                        \"signal_date\": pos.signal_date.date(),\n",
    "                        \"sig_willr\": pos.sig_willr,\n",
    "                        \"sig_macd_line\": pos.sig_macd_line,\n",
    "                        \"sig_macd_sig\": pos.sig_macd_sig,\n",
    "                        \"sig_macd_hist\": pos.sig_macd_hist,\n",
    "                    })\n",
    "                    positions.pop(sym, None)\n",
    "                # Buys then\n",
    "                for o in [x for x in todays if x.side==\"buy\"]:\n",
    "                    sym = o.ticker\n",
    "                    if sym in positions or d not in data[sym].index: continue\n",
    "                    open_px = float(data[sym].at[d,\"Open\"])\n",
    "                    eff_buy = open_px * (1 + SLIPPAGE_BPS/10_000.0)\n",
    "                    per_cap = max(0.0, o.budget)\n",
    "                    shares = math.floor(per_cap / eff_buy)\n",
    "                    if shares <= 0: continue\n",
    "                    cost = eff_buy * shares\n",
    "                    fees = calc_fees(cost, 0.0)\n",
    "                    if cost + fees > cash:\n",
    "                        shares = math.floor((cash / (1 + SLIPPAGE_BPS/10_000.0)) / eff_buy)\n",
    "                        if shares <= 0: continue\n",
    "                        cost = eff_buy * shares\n",
    "                        fees = calc_fees(cost, 0.0)\n",
    "                        if cost + fees > cash: continue\n",
    "                    cash -= (cost + fees)\n",
    "                    positions[sym] = SimplePos(\n",
    "                        ticker=sym, entry_date=d, entry_price=eff_buy, shares=shares,\n",
    "                        reason_entry=o.reason or \"entry_bull_bundle\",\n",
    "                        signal_date=o.signal_date or d, sig_willr=o.sig_willr,\n",
    "                        sig_macd_line=o.sig_macd_line, sig_macd_sig=o.sig_macd_sig, sig_macd_hist=o.sig_macd_hist,\n",
    "                        entry_idx=dates.get_loc(d)\n",
    "                    )\n",
    "                pending = [o for o in pending if o.exec_date != d]\n",
    "\n",
    "        # 2) Intraday stop\n",
    "        if USE_STOP_LOSS and positions:\n",
    "            to_stop=[]\n",
    "            for sym, pos in positions.items():\n",
    "                if d not in data[sym].index: continue\n",
    "                day_low = float(data[sym].at[d,\"Low\"])\n",
    "                stop_px = pos.entry_price * (1.0 - STOP_LOSS_PCT)\n",
    "                if not np.isnan(day_low) and day_low <= stop_px:\n",
    "                    eff_sell = stop_px * (1 - SLIPPAGE_BPS/10_000.0)\n",
    "                    t_buy  = pos.entry_price * pos.shares\n",
    "                    t_sell = eff_sell * pos.shares\n",
    "                    fees = calc_fees(t_buy, t_sell)\n",
    "                    pnl  = (eff_sell - pos.entry_price) * pos.shares - fees\n",
    "                    cash += (eff_sell * pos.shares) - fees\n",
    "                    trades_rows.append({\n",
    "                        \"ticker\": sym,\n",
    "                        \"entry_date\": pos.entry_date.date(),\n",
    "                        \"exit_date\": d.date(),\n",
    "                        \"entry_price\": round(pos.entry_price,2),\n",
    "                        \"exit_price\":  round(eff_sell,2),\n",
    "                        \"shares\": pos.shares,\n",
    "                        \"gross_pnl\": round((eff_sell - pos.entry_price) * pos.shares,2),\n",
    "                        \"fees\": round(fees,2),\n",
    "                        \"net_pnl\": round(pnl,2),\n",
    "                        \"reason_entry\": pos.reason_entry,\n",
    "                        \"reason_exit\": f\"stop_loss_{int(STOP_LOSS_PCT*100)}pct\",\n",
    "                        \"signal_date\": pos.signal_date.date(),\n",
    "                        \"sig_willr\": pos.sig_willr,\n",
    "                        \"sig_macd_line\": pos.sig_macd_line,\n",
    "                        \"sig_macd_sig\": pos.sig_macd_sig,\n",
    "                        \"sig_macd_hist\": pos.sig_macd_hist,\n",
    "                    })\n",
    "                    to_stop.append(sym)\n",
    "            for sym in to_stop: positions.pop(sym, None)\n",
    "\n",
    "        # 3) Rebalance (only if ranking enabled)\n",
    "        if RANKING_ENABLED and d in rebal_set:\n",
    "            current_rank = build_rank_table(d, data, caches)\n",
    "            log(f\"[rebalance] rank snapshot built for {d.date()} (rows={len(current_rank)})\")\n",
    "            if not current_rank.empty and RANK_EXIT_THRESHOLD is not None:\n",
    "                rank_map = {row.ticker:int(row.rank) for row in current_rank.itertuples()}\n",
    "                elig_map = {row.ticker:bool(row.elig) for row in current_rank.itertuples()}\n",
    "                idx_today = dates.get_loc(d)\n",
    "                exec_d = dates[idx_today+1] if (idx_today+1) < len(dates) else None\n",
    "                if exec_d is not None:\n",
    "                    for sym in list(positions.keys()):\n",
    "                        r = rank_map.get(sym, 10**9)\n",
    "                        elig = elig_map.get(sym, False)\n",
    "                        # protect bullish positions if enabled\n",
    "                        if PRIORITIZE_BULLISH_ON_REBAL and is_bullish_now_for_hold(daily[sym], d):\n",
    "                            log(f\"[rebalance] protect {sym}: bullish_now; skip rank exit (r={r}, eligible={elig})\")\n",
    "                            continue\n",
    "                        if (r > RANK_EXIT_THRESHOLD) or (not elig):\n",
    "                            if not any(o.side==\"sell\" and o.ticker==sym and o.exec_date==exec_d for o in pending):\n",
    "                                pending.append(PendingOrder(side=\"sell\", ticker=sym, exec_date=exec_d,\n",
    "                                                            reason=f\"rank_exit(r={r}, eligible={elig})\"))\n",
    "\n",
    "        # 4) Daily technical exit\n",
    "        if USE_WR_MACD_EXITGATE and positions:\n",
    "            idx_today = dates.get_loc(d)\n",
    "            exec_d = dates[idx_today+1] if (idx_today+1) < len(dates) else None\n",
    "            if exec_d is not None:\n",
    "                for sym, pos in positions.items():\n",
    "                    if gate_exit_hit(sym, d, daily[sym]):\n",
    "                        if not any(o.side==\"sell\" and o.ticker==sym and o.exec_date==exec_d for o in pending):\n",
    "                            pending.append(PendingOrder(side=\"sell\", ticker=sym, exec_date=exec_d,\n",
    "                                                        reason=\"exit_gate(W%R+MACD)\"))\n",
    "\n",
    "        # 5) Daily entries\n",
    "        idx_today = dates.get_loc(d)\n",
    "        exec_d = dates[idx_today+1] if (idx_today+1) < len(dates) else None\n",
    "        if exec_d is not None:\n",
    "            have = set(positions.keys())\n",
    "            future_hold = len(positions) - sum(1 for o in pending if o.exec_date==exec_d and o.side==\"sell\")\n",
    "            need = max(0, RANK_TOP_N - future_hold)\n",
    "            if need > 0:\n",
    "                # build candidate list depending on ranking mode\n",
    "                cands: List[str] = []\n",
    "                if RANKING_ENABLED:\n",
    "                    if 'current_rank' in locals() and not current_rank.empty:\n",
    "                        # eligible & within Top-N scanning window\n",
    "                        scan = current_rank[current_rank[\"elig\"]].copy()\n",
    "                        scan.sort_values(\"rank\", inplace=True)\n",
    "                        # we scan up to max(rank) to find signals; cap is RANK_TOP_N * 3 to allow replacements\n",
    "                        limit = max(RANK_TOP_N * 3, 50)\n",
    "                        scan = scan[scan[\"rank\"] <= limit]\n",
    "                        cands = [row.ticker for row in scan.itertuples()]\n",
    "                else:\n",
    "                    # first-come-first-serve: UNIVERSE order\n",
    "                    cands = list(UNIVERSE)\n",
    "\n",
    "                if cands:\n",
    "                    per_cap = equity_on_close(d) / max(1, RANK_TOP_N)\n",
    "                    for sym in cands:\n",
    "                        if need <= 0: break\n",
    "                        if sym in have: continue\n",
    "                        if any(o.side==\"buy\" and o.ticker==sym and o.exec_date==exec_d for o in pending): continue\n",
    "                        if d not in data[sym].index: continue\n",
    "\n",
    "                        # If ranking disabled, still enforce base eligibility (within 52w & > SMA200)\n",
    "                        try:\n",
    "                            c = float(data[sym].at[d, \"Close\"])\n",
    "                            h = float(caches[sym][\"HIGH_252\"].loc[d])\n",
    "                            s = float(caches[sym][\"SMA_200\"].loc[d])\n",
    "                            elig = (c >= (1.0 - WITHIN_52W)*h) and (c > s)\n",
    "                        except Exception:\n",
    "                            elig = False\n",
    "                        if not elig: continue\n",
    "\n",
    "                        ok, W, L, S, H = bullish_entry_bundle(sym, d, daily[sym], return_values=True)\n",
    "                        if not ok: continue\n",
    "                        if not extra_entry_filters(sym, d, daily[sym], data[sym]): continue\n",
    "\n",
    "                        pending.append(PendingOrder(\n",
    "                            side=\"buy\", ticker=sym, exec_date=exec_d, budget=per_cap,\n",
    "                            reason=(f\"entry_bull_bundle({'ranked' if RANKING_ENABLED else 'fcfs'};\"\n",
    "                                    f\" elig(within{int(WITHIN_52W*100)}%+SMA200)\"\n",
    "                                    f\"{' +RSI' if USE_RSI_FILTER else ''}{' +VOL' if USE_VOL_BREAKOUT else ''})\"),\n",
    "                            signal_date=d, sig_willr=W, sig_macd_line=L, sig_macd_sig=S, sig_macd_hist=H\n",
    "                        ))\n",
    "                        need -= 1\n",
    "\n",
    "        # EOD equity mark\n",
    "        equity_series.append((d, equity_on_close(d)))\n",
    "\n",
    "    # Liquidate at final close\n",
    "    if len(dates) > 0:\n",
    "        last_d = dates[-1]\n",
    "        for sym, pos in list(positions.items()):\n",
    "            if last_d in data[sym].index:\n",
    "                px = float(data[sym].at[last_d, \"Close\"])\n",
    "            else:\n",
    "                continue\n",
    "            eff_sell = px * (1 - SLIPPAGE_BPS/10_000.0)\n",
    "            t_buy  = pos.entry_price * pos.shares\n",
    "            t_sell = eff_sell * pos.shares\n",
    "            fees = calc_fees(t_buy, t_sell)\n",
    "            pnl  = (eff_sell - pos.entry_price) * pos.shares - fees\n",
    "            trades_rows.append({\n",
    "                \"ticker\": sym,\n",
    "                \"entry_date\": pos.entry_date.date(),\n",
    "                \"exit_date\": last_d.date(),\n",
    "                \"entry_price\": round(pos.entry_price,2),\n",
    "                \"exit_price\":  round(eff_sell,2),\n",
    "                \"shares\": pos.shares,\n",
    "                \"gross_pnl\": round((eff_sell - pos.entry_price) * pos.shares,2),\n",
    "                \"fees\": round(fees,2),\n",
    "                \"net_pnl\": round(pnl,2),\n",
    "                \"reason_entry\": pos.reason_entry,\n",
    "                \"reason_exit\": \"liq_eod\",\n",
    "                \"signal_date\": pos.signal_date.date(),\n",
    "                \"sig_willr\": pos.sig_willr,\n",
    "                \"sig_macd_line\": pos.sig_macd_line,\n",
    "                \"sig_macd_sig\": pos.sig_macd_sig,\n",
    "                \"sig_macd_hist\": pos.sig_macd_hist,\n",
    "            })\n",
    "        positions.clear()\n",
    "        equity_series.append((last_d, equity_on_close(last_d)))\n",
    "\n",
    "    eq = pd.Series({d: v for d, v in equity_series}).sort_index()\n",
    "    trades_df = pd.DataFrame(trades_rows)\n",
    "    return trades_df, eq\n",
    "\n",
    "# ============== Metrics & Writers ==============\n",
    "def compute_metrics(trades_df: pd.DataFrame, equity: pd.Series, start: str, end: str):\n",
    "    if equity is None or len(equity) == 0:\n",
    "        return {\"trades\":0,\"win_rate_pct\":0.0,\"profit_factor\":0.0,\"sharpe\":0.0,\"cagr_pct\":0.0,\"max_dd_pct\":0.0}\n",
    "    eq = equity.sort_index().ffill()\n",
    "    ret = eq.pct_change().dropna()\n",
    "    sharpe = (ret.mean()/ret.std()) * np.sqrt(252) if ret.std() > 0 else 0.0\n",
    "    rollmax = eq.cummax()\n",
    "    max_dd_pct = float(((eq/rollmax - 1.0).min()) * 100.0)\n",
    "    years = max(1e-9, (pd.to_datetime(end) - pd.to_datetime(start)).days/365.25)\n",
    "    cagr = (eq.iloc[-1]/eq.iloc[0])**(1/years) - 1 if eq.iloc[0] > 0 else 0.0\n",
    "    if trades_df is None or trades_df.empty:\n",
    "        trades=0; wr=0.0; pf=0.0\n",
    "    else:\n",
    "        trades = len(trades_df)\n",
    "        wins = (trades_df[\"net_pnl\"] > 0).sum()\n",
    "        wr = 100.0 * wins / max(1, trades)\n",
    "        gains = trades_df[\"net_pnl\"].clip(lower=0).sum()\n",
    "        losses= -trades_df[\"net_pnl\"].clip(upper=0).sum()\n",
    "        pf = (gains / losses) if losses > 0 else (np.inf if gains > 0 else 0.0)\n",
    "    return {\"trades\":int(trades),\"win_rate_pct\":float(wr),\"profit_factor\":float(pf),\n",
    "            \"sharpe\":float(sharpe),\"cagr_pct\":float(cagr*100.0),\"max_dd_pct\":float(max_dd_pct)}\n",
    "\n",
    "def write_trades_csv(df_trades: pd.DataFrame, filepath: str):\n",
    "    cols = [\"ticker\",\"entry_date\",\"exit_date\",\"hold_days\",\"entry_price\",\"exit_price\",\n",
    "            \"shares\",\"gross_pnl\",\"fees\",\"net_pnl\",\n",
    "            \"reason_entry\",\"reason_exit\",\n",
    "            \"start_capital\",\"ranking_enabled\",\"rebalance_freq\",\"rank_top_n\",\"rank_exit_threshold\",\n",
    "            \"rank_lookback_days\",\"within_52w\",\"prioritize_bullish_on_rebal\",\n",
    "            \"use_rsi_filter\",\"rsi_len\",\"rsi_min\",\n",
    "            \"use_vol_breakout\",\"vol_lookback\",\"vol_multiplier\",\n",
    "            \"use_wr_macd_exitgate\",\"exit_require_cross\",\"exit_gate_or\",\n",
    "            \"use_stop_loss\",\"stop_loss_pct\",\n",
    "            \"signal_date\",\"sig_willr\",\"sig_macd_line\",\"sig_macd_sig\",\"sig_macd_hist\"]\n",
    "    if df_trades is None or df_trades.empty:\n",
    "        pd.DataFrame(columns=cols).to_csv(filepath, index=False); log(f\"Wrote (empty): {filepath}\"); return\n",
    "    out = df_trades.copy()\n",
    "    out[\"entry_date\"]=pd.to_datetime(out[\"entry_date\"]); out[\"exit_date\"]=pd.to_datetime(out[\"exit_date\"])\n",
    "    out[\"hold_days\"]=(out[\"exit_date\"]-out[\"entry_date\"]).dt.days\n",
    "    out[\"start_capital\"]=STARTING_CAPITAL\n",
    "    out[\"ranking_enabled\"]=RANKING_ENABLED\n",
    "    out[\"rebalance_freq\"]=REBALANCE_FREQ\n",
    "    out[\"rank_top_n\"]=RANK_TOP_N\n",
    "    out[\"rank_exit_threshold\"]=RANK_EXIT_THRESHOLD\n",
    "    out[\"rank_lookback_days\"]=RANK_LOOKBACK_DAYS\n",
    "    out[\"within_52w\"]=WITHIN_52W\n",
    "    out[\"prioritize_bullish_on_rebal\"]=PRIORITIZE_BULLISH_ON_REBAL\n",
    "    out[\"use_rsi_filter\"]=USE_RSI_FILTER\n",
    "    out[\"rsi_len\"]=RSI_LEN\n",
    "    out[\"rsi_min\"]=RSI_MIN\n",
    "    out[\"use_vol_breakout\"]=USE_VOL_BREAKOUT\n",
    "    out[\"vol_lookback\"]=VOL_LOOKBACK\n",
    "    out[\"vol_multiplier\"]=VOL_MULTIPLIER\n",
    "    out[\"use_wr_macd_exitgate\"]=USE_WR_MACD_EXITGATE\n",
    "    out[\"exit_require_cross\"]=EXIT_REQUIRE_CROSS\n",
    "    out[\"exit_gate_or\"]=EXIT_GATE_OR\n",
    "    out[\"use_stop_loss\"]=USE_STOP_LOSS\n",
    "    out[\"stop_loss_pct\"]=STOP_LOSS_PCT\n",
    "    out = out.reindex(columns=cols)\n",
    "    out.to_csv(filepath, index=False); log(f\"Wrote: {filepath} (rows={len(out)})\")\n",
    "\n",
    "def write_monthly_pnl_csv(df_trades: pd.DataFrame, filepath: str):\n",
    "    cols = [\"month\",\"net_pnl\"]\n",
    "    if df_trades is None or df_trades.empty:\n",
    "        pd.DataFrame(columns=cols).to_csv(filepath, index=False); log(f\"Wrote (empty): {filepath}\"); return\n",
    "    df = df_trades.copy()\n",
    "    df[\"exit_date\"]=pd.to_datetime(df[\"exit_date\"])\n",
    "    monthly = df.groupby(df[\"exit_date\"].dt.to_period(\"M\"))[\"net_pnl\"].sum().reset_index()\n",
    "    monthly[\"month\"]=monthly[\"exit_date\"].astype(str)\n",
    "    monthly = monthly[[\"month\",\"net_pnl\"]]\n",
    "    monthly.to_csv(filepath, index=False); log(f\"Wrote: {filepath} (rows={len(monthly)})\")\n",
    "\n",
    "# ============== Main ==============\n",
    "def run_pipeline(force_refresh: bool=False):\n",
    "    log(\"=== Loading data (cache) ===\")\n",
    "    data = load_or_download_prices(UNIVERSE, TRAIN_START, TEST_END, force_refresh=force_refresh)\n",
    "    if not data: raise RuntimeError(\"No stock data available.\")\n",
    "    log(f\"Loaded {len(data)} symbols.\")\n",
    "    log(\"=== Building indicators ===\")\n",
    "    caches = build_indicator_caches(data, RANK_LOOKBACK_DAYS, force_refresh=force_refresh)\n",
    "\n",
    "    def run_period(label, start, end):\n",
    "        log(f\"=== Simulating {label} ({start}..{end}) ===\")\n",
    "        trades_df, eq = simulate_engine(data, caches, start, end)\n",
    "        log(f\"{label} trades: {0 if trades_df is None else len(trades_df)}\")\n",
    "        m = compute_metrics(trades_df, eq, start, end)\n",
    "        log(f\"Final {label} metrics: {fmt_metrics(m)}\")\n",
    "        return trades_df, eq, m\n",
    "\n",
    "    log(\"=== Parameters ===\")\n",
    "    log(f\"  Ranking: enabled={RANKING_ENABLED}, rebalance={REBALANCE_FREQ}, TopN(cap)={RANK_TOP_N}, exit>rank={RANK_EXIT_THRESHOLD}\")\n",
    "    log(f\"  Eligibility: within {int(WITHIN_52W*100)}% of 52w high & > SMA200 (applied in both modes)\")\n",
    "    log(f\"  Entry: MACD↑ + W%R↑(from {WILLR_ENTER}) + hist>0 & rising\"\n",
    "        f\"{' +RSI' if USE_RSI_FILTER else ''}{' +VOL' if USE_VOL_BREAKOUT else ''}\")\n",
    "    log(f\"  Exit: WR/MACD gate (OR={EXIT_GATE_OR}, cross={EXIT_REQUIRE_CROSS}), StopLoss={STOP_LOSS_PCT*100:.1f}%\")\n",
    "    log(f\"  Fees={APPLY_FEES}, Slippage={SLIPPAGE_BPS}bps, ProtectBullishOnRebal={PRIORITIZE_BULLISH_ON_REBAL and RANKING_ENABLED}\")\n",
    "\n",
    "    train_trades, train_eq, _ = run_period(\"TRAIN\", TRAIN_START, TRAIN_END)\n",
    "    test_trades,  test_eq,  _ = run_period(\"TEST\",  TEST_START,  TEST_END)\n",
    "\n",
    "    log(\"=== Writing CSVs ===\")\n",
    "    write_trades_csv(train_trades, os.path.join(OUTDIR, \"trades_train.csv\"))\n",
    "    write_trades_csv(test_trades,  os.path.join(OUTDIR, \"trades_test.csv\"))\n",
    "    write_monthly_pnl_csv(train_trades, os.path.join(OUTDIR, \"pnl_monthly_train.csv\"))\n",
    "    write_monthly_pnl_csv(test_trades,  os.path.join(OUTDIR, \"pnl_monthly_test.csv\"))\n",
    "    log(\"=== Done ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline(force_refresh=FORCE_REFRESH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
