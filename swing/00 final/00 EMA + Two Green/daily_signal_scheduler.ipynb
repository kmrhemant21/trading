{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638c2710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:04:48 | INFO | Fetching data for 506 tickers...\n",
      "2025-10-27 19:06:04 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-27 19:06:04 | ERROR | ['HONAUT.NS']: Timeout('Failed to perform, curl: (28) Operation timed out after 10001 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "2025-10-27 19:07:23 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-27 19:07:23 | ERROR | ['^CNX500']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "2025-10-27 19:07:24 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-27 19:07:24 | ERROR | ['^NSE500']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "2025-10-27 19:07:25 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-27 19:07:25 | ERROR | ['^NIFTY500']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "2025-10-27 19:07:25 | ERROR | \n",
      "1 Failed download:\n",
      "2025-10-27 19:07:25 | ERROR | ['^BSE500']: YFPricesMissingError('possibly delisted; no price data found  (1d 2024-03-06 -> 2025-10-27)')\n",
      "2025-10-27 19:07:25 | INFO | Benchmark for ranking: ^CRSLDX\n",
      "2025-10-27 19:07:27 | WARNING | Telegram not configured (missing token/chat). Skipping.\n",
      "2025-10-27 19:07:27 | INFO | Written: outputs/actionable_buys_ranked_20251027.csv, outputs/actionable_buys_selected_20251027.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Daily Scheduler â€” aligned with backtest pipeline (VOLAáµ£ â†’ slots â†’ MVO â†’ deploy cap)\n",
    "\n",
    "ENTRY (D0 signal, D1 execution)\n",
    "  â€¢ EMA10 > EMA20\n",
    "  â€¢ Two strict green candles (D-1, D0) AND D0â€™s O/H/L/C > D-1â€™s O/H/L/C\n",
    "  â€¢ â‰¥1 confirm: RSI>50 | MACD>Signal | ADX>20 & +DI>-DI | Close>SMA50 | Close>BBmid\n",
    "  â€¢ Optional 52w filter: Close â‰¥ within_pct_of_52w_high Ã— 52w-high\n",
    "\n",
    "PORTFOLIO (matches backtest)\n",
    "  1) Rank survivors by VOLAáµ£ vs benchmark (252d).\n",
    "  2) slots = max_concurrent_positions â€“ open_positions (from positions.csv)\n",
    "  3) pick = head(min(top_k_daily, slots))\n",
    "  4) MVO (long-only) on 252d returns â†’ weights\n",
    "  5) deployable cash = deploy_cash_frac Ã— current_cash\n",
    "     - current_cash = initial_capital â€“ MTM invested (or override CURRENT_CASH_INR env)\n",
    "\n",
    "EXIT checks for open positions (latest completed bar)\n",
    "  â€¢ HSL (Low â‰¤ SL) â†’ plan SELL@SL\n",
    "  â€¢ TP  (High â‰¥ TP) â†’ plan SELL@TP\n",
    "  â€¢ Trend reverse (EMA10<EMA20) â†’ plan SELL@next open\n",
    "\n",
    "OUTPUTS\n",
    "  outputs/actionable_buys_ranked_YYYYMMDD.csv\n",
    "  outputs/actionable_buys_selected_YYYYMMDD.csv (mvo_weight, alloc_inr, est_shares)\n",
    "  outputs/actionable_sells_YYYYMMDD.csv\n",
    "\n",
    "TELEGRAM\n",
    "  â€¢ Set TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID; toggle via TELEGRAM_ENABLED=0/1 or CFG.telegram_enabled\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, math, logging, warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    import requests\n",
    "except Exception as e:\n",
    "    print(\"Missing deps. Install:\\n  pip install yfinance requests pandas numpy\", file=sys.stderr)\n",
    "    raise\n",
    "\n",
    "# ---------------- Logging ----------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"daily_scheduler\")\n",
    "\n",
    "# ---------------- Config -----------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Universe\n",
    "    static_symbols: Optional[List[str]] = None\n",
    "    static_symbols_path: Optional[str] = \"nifty500.txt\"   # one symbol per line\n",
    "\n",
    "    # Data\n",
    "    lookback_days: int = 400\n",
    "    out_dir: str = \"outputs\"\n",
    "\n",
    "    # Positions ledger (YOU maintain this)\n",
    "    positions_csv: str = \"positions.csv\"\n",
    "\n",
    "    # Strategy (aligned to backtester)\n",
    "    ema_fast: int = 10\n",
    "    ema_slow: int = 20\n",
    "    rsi_len: int = 14\n",
    "    macd_fast: int = 12\n",
    "    macd_slow: int = 26\n",
    "    macd_signal: int = 9\n",
    "    bb_len: int = 20\n",
    "    bb_std: float = 2.0\n",
    "    sma_confirm_len: int = 50\n",
    "    adx_len: int = 14\n",
    "    adx_min: float = 20.0\n",
    "\n",
    "    # Filters\n",
    "    filter_52w_window: int = 252\n",
    "    within_pct_of_52w_high: float = 0.50  # 50%\n",
    "\n",
    "    # Exits (for SELL evaluation only)\n",
    "    stop_loss_pct: float = 0.10\n",
    "    target_pct: float = 0.10\n",
    "\n",
    "    # Portfolio controls (aligned to your backtest)\n",
    "    initial_capital: float = 500_000.0\n",
    "    deploy_cash_frac: float = 0.30\n",
    "    max_concurrent_positions: int = 5\n",
    "    volar_lookback: int = 252\n",
    "    top_k_daily: int = 300\n",
    "\n",
    "    # Telegram\n",
    "    telegram_enabled: bool = True  # toggle on/off\n",
    "    telegram_bot_token: Optional[str] = None\n",
    "    telegram_chat_id: Optional[str] = None\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# ---------------- Utils ------------------\n",
    "def ensure_dirs(*paths):\n",
    "    for p in paths:\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def today_stamp():\n",
    "    return pd.Timestamp.today(tz=\"Asia/Kolkata\").strftime(\"%Y%m%d\")\n",
    "\n",
    "def load_universe(cfg: Config) -> List[str]:\n",
    "    if cfg.static_symbols:\n",
    "        syms = [s.strip().upper() for s in cfg.static_symbols if s.strip()]\n",
    "    elif cfg.static_symbols_path and os.path.exists(cfg.static_symbols_path):\n",
    "        with open(cfg.static_symbols_path, \"r\") as f:\n",
    "            syms = [line.strip().upper() for line in f if line.strip()]\n",
    "    else:\n",
    "        raise ValueError(\"Provide static_symbols or static_symbols_path for the universe.\")\n",
    "    out = []\n",
    "    for s in syms:\n",
    "        if not s.endswith(\".NS\") and not s.startswith(\"^\"):\n",
    "            s = f\"{s}.NS\"\n",
    "        out.append(s)\n",
    "    seen, uniq = set(), []\n",
    "    for s in out:\n",
    "        if s not in seen:\n",
    "            uniq.append(s); seen.add(s)\n",
    "    return uniq\n",
    "\n",
    "def fetch_prices(tickers: List[str], days: int) -> Dict[str, pd.DataFrame]:\n",
    "    end = pd.Timestamp.today(tz=\"Asia/Kolkata\").normalize()\n",
    "    start = end - pd.Timedelta(days=days*1.5)\n",
    "    start, end_s = start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\")\n",
    "    data = {}\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            df = yf.download(t, start=start, end=end_s, auto_adjust=True, progress=False, multi_level_index=False)\n",
    "            if df is None or df.empty:\n",
    "                continue\n",
    "            df = df.rename(columns=str.title)[['Open','High','Low','Close','Volume']].dropna()\n",
    "            df.index.name = \"date\"\n",
    "            data[t] = df\n",
    "        except Exception:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "# ------------- Indicators ----------------\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "\n",
    "def sma(series: pd.Series, window: int) -> pd.Series:\n",
    "    return series.rolling(window).mean()\n",
    "\n",
    "def rsi(series: pd.Series, length: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0.0).rolling(length).mean()\n",
    "    loss = (-delta.where(delta < 0, 0.0)).rolling(length).mean()\n",
    "    rs = gain / loss.replace(0.0, np.nan)\n",
    "    out = 100 - (100 / (1 + rs))\n",
    "    return out.fillna(50.0)\n",
    "\n",
    "def macd(series: pd.Series, fast=12, slow=26, signal=9):\n",
    "    ef = series.ewm(span=fast, adjust=False, min_periods=slow).mean()\n",
    "    es = series.ewm(span=slow, adjust=False, min_periods=slow).mean()\n",
    "    line = ef - es\n",
    "    sig = line.ewm(span=signal, adjust=False, min_periods=signal).mean()\n",
    "    hist = line - sig\n",
    "    return line, sig, hist\n",
    "\n",
    "def _true_range(high, low, prev_close):\n",
    "    return pd.concat([(high - low).abs(), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
    "\n",
    "def dmi_adx(high: pd.Series, low: pd.Series, close: pd.Series, length: int = 14):\n",
    "    ph, pl, pc = high.shift(1), low.shift(1), close.shift(1)\n",
    "    up, dn = high - ph, pl - low\n",
    "    plus_dm  = up.where((up > dn) & (up > 0), 0.0)\n",
    "    minus_dm = dn.where((dn > up) & (dn > 0), 0.0)\n",
    "    tr = _true_range(high, low, pc)\n",
    "    a = 1.0 / length\n",
    "    atr = tr.ewm(alpha=a, adjust=False, min_periods=length).mean()\n",
    "    plus_di  = 100 * (plus_dm.ewm(alpha=a, adjust=False, min_periods=length).mean() / atr)\n",
    "    minus_di = 100 * (minus_dm.ewm(alpha=a, adjust=False, min_periods=length).mean() / atr)\n",
    "    dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di).replace(0, np.nan)\n",
    "    adx_series = dx.ewm(alpha=a, adjust=False, min_periods=length).mean()\n",
    "    return plus_di, minus_di, adx_series\n",
    "\n",
    "def bollinger(series: pd.Series, length=20, nstd=2.0):\n",
    "    mid = series.rolling(length).mean()\n",
    "    sd  = series.rolling(length).std(ddof=0)\n",
    "    upper = mid + nstd * sd\n",
    "    lower = mid - nstd * sd\n",
    "    return mid, upper, lower\n",
    "\n",
    "def compute_indicators(df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d[\"ema_fast\"] = ema(d[\"Close\"], cfg.ema_fast)\n",
    "    d[\"ema_slow\"] = ema(d[\"Close\"], cfg.ema_slow)\n",
    "    d[\"sma50\"]    = sma(d[\"Close\"], cfg.sma_confirm_len)\n",
    "    d[\"rsi\"]      = rsi(d[\"Close\"], cfg.rsi_len)\n",
    "    macd_line, macd_signal, macd_hist = macd(d[\"Close\"], cfg.macd_fast, cfg.macd_slow, cfg.macd_signal)\n",
    "    d[\"macd_line\"], d[\"macd_signal\"], d[\"macd_hist\"] = macd_line, macd_signal, macd_hist\n",
    "    d[\"bb_mid\"], d[\"bb_up\"], d[\"bb_low\"] = bollinger(d[\"Close\"], cfg.bb_len, cfg.bb_std)\n",
    "    d[\"+DI\"], d[\"-DI\"], d[\"ADX\"] = dmi_adx(d[\"High\"], d[\"Low\"], d[\"Close\"], cfg.adx_len)\n",
    "    d[\"high_52w\"] = d[\"Close\"].rolling(cfg.filter_52w_window).max()\n",
    "    d[\"avg_vol_20\"] = d[\"Volume\"].rolling(20).mean()\n",
    "    return d.dropna()\n",
    "\n",
    "# ------------- Entry/Exit logic ----------\n",
    "def two_green_strict(prev_row: pd.Series, row: pd.Series) -> bool:\n",
    "    g1 = prev_row[\"Close\"] > prev_row[\"Open\"]\n",
    "    g2 = row[\"Close\"] > row[\"Open\"]\n",
    "    strictly_above = (row[\"Open\"]  > prev_row[\"Open\"]) and \\\n",
    "                     (row[\"High\"]  > prev_row[\"High\"]) and \\\n",
    "                     (row[\"Low\"]   > prev_row[\"Low\"])  and \\\n",
    "                     (row[\"Close\"] > prev_row[\"Close\"])\n",
    "    return bool(g1 and g2 and strictly_above)\n",
    "\n",
    "def confirmation_any(row: pd.Series, cfg: Config) -> Tuple[bool, str]:\n",
    "    checks = [\n",
    "        (\"RSI>50\", row[\"rsi\"] > 50.0),\n",
    "        (\"MACD>Signal\", row[\"macd_hist\"] > 0.0),\n",
    "        (\"ADX>20 & +DI>-DI\", (row[\"ADX\"] > cfg.adx_min) and (row[\"+DI\"] > row[\"-DI\"])),\n",
    "        (\"Close>SMA50\", row[\"Close\"] > row[\"sma50\"]),\n",
    "        (\"Close>BBmid\", row[\"Close\"] > row[\"bb_mid\"]),\n",
    "    ]\n",
    "    passed = [name for name, ok in checks if ok]\n",
    "    return (len(passed) >= 1, \", \".join(passed) if passed else \"none\")\n",
    "\n",
    "def volar_score(series: pd.Series, bench: pd.Series, lookback: int) -> float:\n",
    "    r_s = series.pct_change().dropna().iloc[-lookback:]\n",
    "    r_b = bench.pct_change().dropna().iloc[-lookback:]\n",
    "    common = pd.concat([r_s, r_b], axis=1).dropna()\n",
    "    if common.shape[0] < max(20, int(0.4*lookback)):\n",
    "        return 0.0\n",
    "    excess = common.iloc[:,0] - common.iloc[:,1]\n",
    "    vol = common.iloc[:,0].std(ddof=0)\n",
    "    return 0.0 if vol <= 1e-8 else float((excess.mean() / vol) * math.sqrt(252.0))\n",
    "\n",
    "# --------------- Telegram ----------------\n",
    "def send_telegram(text: str, cfg: Config):\n",
    "    # toggle via config or env TELEGRAM_ENABLED=0/1\n",
    "    env_toggle = os.getenv(\"TELEGRAM_ENABLED\")\n",
    "    if env_toggle is not None:\n",
    "        try:\n",
    "            enabled = bool(int(env_toggle))\n",
    "        except Exception:\n",
    "            enabled = cfg.telegram_enabled\n",
    "    else:\n",
    "        enabled = cfg.telegram_enabled\n",
    "\n",
    "    if not enabled:\n",
    "        log.info(\"Telegram disabled. Skipping message.\")\n",
    "        return\n",
    "\n",
    "    token = cfg.telegram_bot_token or os.getenv(\"TELEGRAM_BOT_TOKEN\", \"\")\n",
    "    chat  = cfg.telegram_chat_id or os.getenv(\"TELEGRAM_CHAT_ID\", \"\")\n",
    "    if not token or not chat:\n",
    "        log.warning(\"Telegram not configured (missing token/chat). Skipping.\")\n",
    "        return\n",
    "    url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n",
    "    try:\n",
    "        requests.post(url, data={\"chat_id\": chat, \"text\": text, \"parse_mode\": \"Markdown\"}, timeout=20)\n",
    "    except Exception as e:\n",
    "        log.warning(\"Telegram send failed: %s\", e)\n",
    "\n",
    "# ------------- Positions ledger ----------\n",
    "def ensure_positions_csv(path: str):\n",
    "    if os.path.exists(path): return\n",
    "    cols = [\"ticker\",\"entry_date\",\"entry_price\",\"shares\",\"sl_pct\",\"tp_pct\",\"sl_price\",\"tp_price\",\"notes\",\"status\"]\n",
    "    pd.DataFrame(columns=cols).to_csv(path, index=False)\n",
    "    log.info(\"Created blank %s. Add your taken trades as rows.\", path)\n",
    "\n",
    "def load_positions(path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path):\n",
    "        return pd.DataFrame(columns=[\"ticker\",\"entry_date\",\"entry_price\",\"shares\",\"sl_pct\",\"tp_pct\",\"sl_price\",\"tp_price\",\"notes\",\"status\"])\n",
    "    df = pd.read_csv(path)\n",
    "    for c in [\"sl_pct\",\"tp_pct\"]:\n",
    "        if c not in df.columns: df[c] = np.nan\n",
    "    for c in [\"sl_price\",\"tp_price\"]:\n",
    "        if c not in df.columns: df[c] = np.nan\n",
    "    if \"status\" not in df.columns:\n",
    "        df[\"status\"] = \"open\"\n",
    "    # normalize tickers\n",
    "    df[\"ticker\"] = df[\"ticker\"].astype(str).str.upper().apply(lambda s: s if s.endswith(\".NS\") or s.startswith(\"^\") else f\"{s}.NS\")\n",
    "    return df\n",
    "\n",
    "def finalize_sl_tp(df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"sl_pct\"] = df[\"sl_pct\"].fillna(cfg.stop_loss_pct)\n",
    "    df[\"tp_pct\"] = df[\"tp_pct\"].fillna(cfg.target_pct)\n",
    "    df[\"sl_price\"] = df[\"sl_price\"].fillna(df[\"entry_price\"] * (1 - df[\"sl_pct\"]))\n",
    "    df[\"tp_price\"] = df[\"tp_price\"].fillna(df[\"entry_price\"] * (1 + df[\"tp_pct\"]))\n",
    "    return df\n",
    "\n",
    "# --------------- MVO tools ---------------\n",
    "def markowitz_long_only(mu: np.ndarray, Sigma: np.ndarray) -> np.ndarray:\n",
    "    n = len(mu)\n",
    "    eps = 1e-6\n",
    "    Sigma = Sigma + eps*np.eye(n)\n",
    "\n",
    "    def solve_lambda(lmbd: float, active_mask=None):\n",
    "        if active_mask is None:\n",
    "            A = np.block([[2*lmbd*Sigma, np.ones((n,1))],[np.ones((1,n)), np.zeros((1,1))]])\n",
    "            b = np.concatenate([mu, np.array([1.0])])\n",
    "            try:\n",
    "                sol = np.linalg.solve(A, b)\n",
    "                w = sol[:n]\n",
    "            except np.linalg.LinAlgError:\n",
    "                w = np.full(n, 1.0/n)\n",
    "            return w\n",
    "        else:\n",
    "            idx = np.where(active_mask)[0]\n",
    "            if len(idx)==0: return np.full(n, 1.0/n)\n",
    "            S = Sigma[np.ix_(idx, idx)]\n",
    "            o = np.ones(len(idx))\n",
    "            m = mu[idx]\n",
    "            A = np.block([[2*lmbd*S, o[:,None]],[o[None,:], np.zeros((1,1))]])\n",
    "            b = np.concatenate([m, np.array([1.0])])\n",
    "            try:\n",
    "                sol = np.linalg.solve(A, b)\n",
    "                w_sub = sol[:len(idx)]\n",
    "            except np.linalg.LinAlgError:\n",
    "                w_sub = np.full(len(idx), 1.0/len(idx))\n",
    "            w = np.zeros(n); w[idx] = w_sub\n",
    "            return w\n",
    "\n",
    "    best_w = np.full(n, 1.0/n)\n",
    "    best_sr = -1e9\n",
    "    for lmbd in np.logspace(-3, 3, 31):\n",
    "        active = np.ones(n, dtype=bool)\n",
    "        w = None\n",
    "        for _ in range(n):\n",
    "            w = solve_lambda(lmbd, active_mask=active)\n",
    "            if not (w < 0).any(): break\n",
    "            worst = np.argmin(w)\n",
    "            active[worst] = False\n",
    "        if w is None: continue\n",
    "        w = np.clip(w, 0, None)\n",
    "        if w.sum() <= 0: continue\n",
    "        w = w / w.sum()\n",
    "        mu_p = float(mu @ w)\n",
    "        vol_p = float(np.sqrt(w @ Sigma @ w))\n",
    "        if vol_p <= 1e-8: continue\n",
    "        sr = mu_p / vol_p\n",
    "        if sr > best_sr:\n",
    "            best_sr = sr\n",
    "            best_w = w.copy()\n",
    "    return best_w\n",
    "\n",
    "def estimate_current_cash(pos_open: pd.DataFrame, data_map: Dict[str,pd.DataFrame], cfg: Config) -> float:\n",
    "    # Prefer an explicit override (captures realized P&L)\n",
    "    env_cash = os.getenv(\"CURRENT_CASH_INR\", \"\")\n",
    "    if env_cash:\n",
    "        try:\n",
    "            return max(0.0, float(env_cash))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    # Approx: initial_capital minus MTM of holdings\n",
    "    invested = 0.0\n",
    "    for _, pos in pos_open.iterrows():\n",
    "        t = pos[\"ticker\"]; sh = float(pos.get(\"shares\", 0) or 0)\n",
    "        df = data_map.get(t)\n",
    "        if df is None or df.empty: continue\n",
    "        last_close = float(df[\"Close\"].iloc[-1])\n",
    "        invested += sh * last_close\n",
    "    return max(0.0, cfg.initial_capital - invested)\n",
    "\n",
    "# --------------- Scanners ----------------\n",
    "def scan_buys(universe: List[str], data_map: Dict[str,pd.DataFrame], cfg: Config,\n",
    "              bench_df: Optional[pd.DataFrame]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for t in universe:\n",
    "        df = data_map.get(t)\n",
    "        if df is None or df.empty: \n",
    "            continue\n",
    "        d = compute_indicators(df, cfg)\n",
    "        if d.empty or len(d) < 60: \n",
    "            continue\n",
    "        idx = list(d.index)\n",
    "        if len(idx) < 2: \n",
    "            continue\n",
    "        dt, prev_dt = idx[-1], idx[-2]\n",
    "        row, prev_row = d.loc[dt], d.loc[prev_dt]\n",
    "\n",
    "        ema_ok = row[\"ema_fast\"] > row[\"ema_slow\"]\n",
    "        two_ok = two_green_strict(prev_row, row)\n",
    "        conf_ok, conf_str = confirmation_any(row, cfg)\n",
    "        if not (ema_ok and two_ok and conf_ok):\n",
    "            continue\n",
    "\n",
    "        # 52w filter (as in backtest pipeline)\n",
    "        high_52w = float(row[\"high_52w\"]); close_val = float(row[\"Close\"])\n",
    "        if not (high_52w > 0 and close_val >= cfg.within_pct_of_52w_high * high_52w):\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"ticker\": t, \"signal_date\": dt, \"close\": close_val,\n",
    "            \"ema10\": float(row[\"ema_fast\"]), \"ema20\": float(row[\"ema_slow\"]),\n",
    "            \"rsi\": float(row[\"rsi\"]), \"macd_hist\": float(row[\"macd_hist\"]), \"adx\": float(row[\"ADX\"]),\n",
    "            \"pdi\": float(row[\"+DI\"]), \"mdi\": float(row[\"-DI\"]),\n",
    "            \"sma50\": float(row[\"sma50\"]), \"bb_mid\": float(row[\"bb_mid\"]),\n",
    "            \"confirm\": conf_str,\n",
    "            \"sig_reason\": f\"EMA10>EMA20 & 2xGreenStrict; confirms: {conf_str}\",\n",
    "            \"high_52w\": high_52w,\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # VOLAáµ£ ranking (252d) â€” same selection signal as backtest\n",
    "    if bench_df is not None and not bench_df.empty:\n",
    "        bench_ser = bench_df[\"Close\"]\n",
    "        df[\"volar\"] = [\n",
    "            volar_score(data_map[t][\"Close\"], bench_ser, cfg.volar_lookback)\n",
    "            for t in df[\"ticker\"]\n",
    "        ]\n",
    "        df = df.sort_values(\"volar\", ascending=False)\n",
    "\n",
    "    if cfg.top_k_daily and len(df) > cfg.top_k_daily:\n",
    "        df = df.head(cfg.top_k_daily)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def scan_sells(positions_open: pd.DataFrame, data_map: Dict[str,pd.DataFrame], cfg: Config) -> pd.DataFrame:\n",
    "    if positions_open.empty:\n",
    "        return pd.DataFrame(columns=[\"ticker\",\"signal_date\",\"plan\",\"reason\",\"last_close\",\"entry_price\",\"sl_price\",\"tp_price\"])\n",
    "    rows = []\n",
    "    for _, pos in positions_open.iterrows():\n",
    "        t = pos[\"ticker\"]\n",
    "        df = data_map.get(t)\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "        d = compute_indicators(df, cfg)\n",
    "        if d.empty: \n",
    "            continue\n",
    "        idx = list(d.index)\n",
    "        if len(idx) < 2: \n",
    "            continue\n",
    "        dt, prev_dt = idx[-1], idx[-2]\n",
    "        row, prev_row = d.loc[dt], d.loc[prev_dt]\n",
    "\n",
    "        entry_px = float(pos[\"entry_price\"])\n",
    "        sl_price = float(pos[\"sl_price\"]) if not pd.isna(pos[\"sl_price\"]) else entry_px*(1-cfg.stop_loss_pct)\n",
    "        tp_price = float(pos[\"tp_price\"]) if not pd.isna(pos[\"tp_price\"]) else entry_px*(1+cfg.target_pct)\n",
    "\n",
    "        day_low  = float(row[\"Low\"])\n",
    "        day_high = float(row[\"High\"])\n",
    "        last_close = float(row[\"Close\"])\n",
    "\n",
    "        # Priority like backtest: if both touch, treat as TP (optimistic)\n",
    "        hit = None; plan_price = None\n",
    "        if (day_low <= sl_price) and (day_high >= tp_price):\n",
    "            hit, plan_price = \"target\", tp_price\n",
    "        elif (day_low <= sl_price):\n",
    "            hit, plan_price = \"stop\", sl_price\n",
    "        elif (day_high >= tp_price):\n",
    "            hit, plan_price = \"target\", tp_price\n",
    "        else:\n",
    "            if row[\"ema_fast\"] < row[\"ema_slow\"]:\n",
    "                hit, plan_price = \"trend_reverse\", None\n",
    "\n",
    "        if hit is None:\n",
    "            continue\n",
    "\n",
    "        pnl_pct_est = (plan_price / entry_px - 1.0) * 100.0 if plan_price is not None else (last_close / entry_px - 1.0) * 100.0\n",
    "\n",
    "        if hit == \"stop\":\n",
    "            reason = (f\"StopLoss hit ({pos.get('sl_pct', cfg.stop_loss_pct)*100:.1f}%). \"\n",
    "                      f\"today H/L={day_high:.2f}/{day_low:.2f}, SL={sl_price:.2f}; \"\n",
    "                      f\"plan=Exit@SL, retâ‰ˆ{pnl_pct_est:.2f}%\")\n",
    "            plan = f\"SELL @ {sl_price:.2f}\"\n",
    "        elif hit == \"target\":\n",
    "            reason = (f\"TakeProfit hit ({pos.get('tp_pct', cfg.target_pct)*100:.1f}%). \"\n",
    "                      f\"today H/L={day_high:.2f}/{day_low:.2f}, TP={tp_price:.2f}; \"\n",
    "                      f\"plan=Exit@TP, retâ‰ˆ{pnl_pct_est:.2f}%\")\n",
    "            plan = f\"SELL @ {tp_price:.2f}\"\n",
    "        else:\n",
    "            crossdown = (prev_row[\"ema_fast\"] >= prev_row[\"ema_slow\"]) and (row[\"ema_fast\"] < row[\"ema_slow\"])\n",
    "            cx = \" crossâ†“\" if crossdown else \"\"\n",
    "            reason = (f\"Trend reverse: EMA10{cx} below EMA20 (10={row['ema_fast']:.2f}, 20={row['ema_slow']:.2f}); \"\n",
    "                      f\"plan=Exit@next open, retâ‰ˆ{pnl_pct_est:.2f}% (vs last close)\")\n",
    "            plan = \"SELL @ next open\"\n",
    "\n",
    "        rows.append({\n",
    "            \"ticker\": t, \"signal_date\": dt, \"plan\": plan, \"reason\": reason,\n",
    "            \"last_close\": last_close, \"entry_price\": entry_px, \"sl_price\": sl_price, \"tp_price\": tp_price\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values([\"ticker\"]).reset_index(drop=True)\n",
    "\n",
    "# --------------- MAIN --------------------\n",
    "def main():\n",
    "    ensure_dirs(CFG.out_dir)\n",
    "    ensure_positions_csv(CFG.positions_csv)\n",
    "\n",
    "    # Universe & positions\n",
    "    universe = load_universe(CFG)\n",
    "    pos = load_positions(CFG.positions_csv)\n",
    "    pos = finalize_sl_tp(pos, CFG)\n",
    "    pos_open = pos[pos[\"status\"].astype(str).str.lower().eq(\"open\")].copy()\n",
    "\n",
    "    # Pull data for union(universe, open positions, candidate benchmarks)\n",
    "    bench_try = (\"^CRSLDX\",\"^CNX500\",\"^NSE500\",\"^NIFTY500\",\"^BSE500\",\"^NSEI\")\n",
    "    extra = [t for t in pos_open[\"ticker\"].unique().tolist() if t not in universe]\n",
    "    tickers = list(dict.fromkeys(universe + extra + list(bench_try)))\n",
    "    log.info(\"Fetching data for %d tickers...\", len(tickers))\n",
    "    data_map = fetch_prices(tickers, CFG.lookback_days)\n",
    "\n",
    "    # Benchmark for VOLAáµ£\n",
    "    bench_tkr = next((t for t in bench_try if t in data_map), None)\n",
    "    bench_df = data_map.get(bench_tkr) if bench_tkr else None\n",
    "    if bench_tkr: log.info(\"Benchmark for ranking: %s\", bench_tkr)\n",
    "\n",
    "    # BUY scan (D0 signals for D1 execution)\n",
    "    buys_ranked = scan_buys(universe, data_map, CFG, bench_df if bench_tkr else None)\n",
    "\n",
    "    # SELL scan on open positions\n",
    "    sells = scan_sells(pos_open, data_map, CFG)\n",
    "\n",
    "    # Selection capacity (like backtest)\n",
    "    open_count = pos_open.shape[0]\n",
    "    slots = max(0, CFG.max_concurrent_positions - open_count)\n",
    "    if slots > 0 and not buys_ranked.empty:\n",
    "        buys_sel = buys_ranked.head(min(slots, len(buys_ranked))).copy()\n",
    "    else:\n",
    "        buys_sel = buys_ranked.iloc[0:0].copy()\n",
    "\n",
    "    # MVO sizing over selected names\n",
    "    if not buys_sel.empty:\n",
    "        names = buys_sel[\"ticker\"].tolist()\n",
    "        rets = []\n",
    "        for t in names:\n",
    "            ser = data_map[t][\"Close\"].pct_change().dropna().iloc[-CFG.volar_lookback:]\n",
    "            rets.append(ser.rename(t))\n",
    "        R = pd.concat(rets, axis=1).dropna()\n",
    "        if R.empty or R.shape[0] < max(20, int(0.4*CFG.volar_lookback)) or R.shape[1] == 0:\n",
    "            weights = np.full(len(names), 1.0/len(names))\n",
    "        else:\n",
    "            mu = R.mean().values\n",
    "            Sigma = R.cov().values\n",
    "            weights = markowitz_long_only(mu, Sigma)\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        current_cash = estimate_current_cash(pos_open, data_map, CFG)\n",
    "        deploy_cash  = max(0.0, current_cash) * CFG.deploy_cash_frac\n",
    "\n",
    "        buys_sel[\"mvo_weight\"] = weights\n",
    "        buys_sel[\"alloc_inr\"]  = buys_sel[\"mvo_weight\"] * deploy_cash\n",
    "        buys_sel[\"est_shares\"] = (buys_sel[\"alloc_inr\"] / buys_sel[\"close\"]).apply(\n",
    "            lambda x: int(math.floor(x)) if np.isfinite(x) else 0\n",
    "        )\n",
    "\n",
    "    # Write outputs\n",
    "    stamp = today_stamp()\n",
    "    ranked_path = os.path.join(CFG.out_dir, f\"actionable_buys_ranked_{stamp}.csv\")\n",
    "    select_path = os.path.join(CFG.out_dir, f\"actionable_buys_selected_{stamp}.csv\")\n",
    "    sells_path  = os.path.join(CFG.out_dir, f\"actionable_sells_{stamp}.csv\")\n",
    "\n",
    "    if not buys_ranked.empty: buys_ranked.to_csv(ranked_path, index=False)\n",
    "    if not buys_sel.empty:    buys_sel.to_csv(select_path, index=False)\n",
    "    if not sells.empty:       sells.to_csv(sells_path, index=False)\n",
    "\n",
    "    # Telegram summaries (toggle-able)\n",
    "    if (buys_sel.empty and sells.empty):\n",
    "        send_telegram(\"ðŸ“­ No new BUY or SELL signals today.\", CFG)\n",
    "    else:\n",
    "        if not buys_sel.empty:\n",
    "            lines = [f\"ðŸ“ˆ *BUY (selected & MVO-sized)* â€” slots={slots}, deploy={CFG.deploy_cash_frac*100:.0f}% of cash\"]\n",
    "            for _, r in buys_sel.iterrows():\n",
    "                alloc = f\"â‚¹{r['alloc_inr']:.0f}\" if np.isfinite(r.get(\"alloc_inr\", np.nan)) else \"n/a\"\n",
    "                wtxt  = f\"{r['mvo_weight']*100:.1f}%\" if np.isfinite(r.get(\"mvo_weight\", np.nan)) else \"n/a\"\n",
    "                lines.append(f\"â€¢ {r['ticker']} â€” {wtxt}, allocâ‰ˆ{alloc}, est_sharesâ‰ˆ{int(r['est_shares'])} â€” {r['sig_reason']}\")\n",
    "            send_telegram(\"\\n\".join(lines), CFG)\n",
    "        if not sells.empty:\n",
    "            lines = [f\"ðŸ“‰ *SELL signals* ({len(sells)})\"]\n",
    "            for _, r in sells.iterrows():\n",
    "                lines.append(f\"â€¢ {r['ticker']} â€” {r['plan']}\\n   {r['reason']}\")\n",
    "            send_telegram(\"\\n\".join(lines), CFG)\n",
    "\n",
    "    log.info(\"Written: %s%s%s\",\n",
    "             ranked_path if not buys_ranked.empty else \"(no ranked buys)\",\n",
    "             f\", {select_path}\" if not buys_sel.empty else \"\",\n",
    "             f\", {sells_path}\" if not sells.empty else \"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Allow env overrides\n",
    "    CFG.telegram_bot_token = os.getenv(\"TELEGRAM_BOT_TOKEN\", None)\n",
    "    CFG.telegram_chat_id   = os.getenv(\"TELEGRAM_CHAT_ID\", None)\n",
    "    env_toggle = os.getenv(\"TELEGRAM_ENABLED\")\n",
    "    if env_toggle is not None:\n",
    "        try: CFG.telegram_enabled = bool(int(env_toggle))\n",
    "        except Exception: pass\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
