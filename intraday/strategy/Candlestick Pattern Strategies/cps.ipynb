{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f049dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 18:45:01,658 | INFO | ===== Backtest Summary =====\n",
      "2025-10-19 18:45:01,659 | INFO | date: 2025-10-16\n",
      "2025-10-19 18:45:01,659 | INFO | n_trades: 131\n",
      "2025-10-19 18:45:01,659 | INFO | win_rate_pct: 31.3\n",
      "2025-10-19 18:45:01,659 | INFO | profitable_trades: 41\n",
      "2025-10-19 18:45:01,660 | INFO | avg_pnl_pct: -0.018\n",
      "2025-10-19 18:45:01,660 | INFO | total_pnl_inr: -480.0\n",
      "2025-10-19 18:45:01,660 | INFO | Sample trades:\n",
      "2025-10-19 18:45:01,665 | INFO | Profitable trades: 41 out of 131 (31.3% win rate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          symbol   side                entry_time       entry_time_ist  \\\n",
      "0    HINDALCO.NS   LONG 2025-10-16 03:55:00+00:00  2025-10-16 09:25:00   \n",
      "1  HINDUNILVR.NS  SHORT 2025-10-16 03:55:00+00:00  2025-10-16 09:25:00   \n",
      "2    HDFCBANK.NS   LONG 2025-10-16 03:55:00+00:00  2025-10-16 09:25:00   \n",
      "3   COALINDIA.NS  SHORT 2025-10-16 03:55:00+00:00  2025-10-16 09:25:00   \n",
      "4       WIPRO.NS  SHORT 2025-10-16 03:55:00+00:00  2025-10-16 09:25:00   \n",
      "\n",
      "         entry         exit exit_reason    pnl         reason  \n",
      "0   767.750000   772.356500          TP  0.006  BullishEngulf  \n",
      "1  2524.699951  2509.551751          TP  0.006   ShootingStar  \n",
      "2   983.200012   989.099212          TP  0.006  BullishEngulf  \n",
      "3   385.700012   386.857112          SL -0.003   ShootingStar  \n",
      "4   250.250000   251.000750          SL -0.003  BearishEngulf  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Multi-Symbol Intraday Candlestick Strategy (Backtest + Live)\n",
    "with Telegram Alerts + CSV Logging + IST timestamps + EMA200 Trend Filter\n",
    "\n",
    "Patterns:\n",
    "  - Hammer (bullish reversal)\n",
    "  - Shooting Star (bearish reversal)\n",
    "  - Bullish / Bearish Engulfing\n",
    "  - Inside Bar breakout (up/down)\n",
    "\n",
    "Features:\n",
    "  - WATCHLIST of NSE symbols (.NS) or indices (^NSEI, ^NSEBANK)\n",
    "  - Backtest a specific trading date (5m candles), IST-aware day filter\n",
    "  - Live loop uses last COMPLETED candle only (alert/paper-trade)\n",
    "  - Fixed SL/TP, one-position-per-symbol, portfolio cap\n",
    "  - Reason strings (pattern + context near prev-day H/L + EMA trend tag)\n",
    "  - Telegram alerts for entries/exits (optional)\n",
    "  - CSV logging for backtest & live sessions\n",
    "  - **IST timestamps in CSVs** (entry_time_ist / ts_bar_close_ist)\n",
    "  - **EMA200 trend filter toggle** (use_ema200)\n",
    "\n",
    "NOTE: Yahoo intraday can be delayed; treat live loop as alerting/paper mode.\n",
    "\"\"\"\n",
    "\n",
    "import os, time, logging, warnings, json\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "log = logging.getLogger(\"px_candle_system\")\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    raise SystemExit(\"Please install yfinance: pip install yfinance\") from e\n",
    "\n",
    "# Optional: requests for Telegram; fallback to urllib if unavailable\n",
    "try:\n",
    "    import requests  # type: ignore\n",
    "except Exception:\n",
    "    requests = None  # we'll fallback\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    # ---- Data & Universe ----\n",
    "    watchlist: List[str] = field(default_factory=lambda: [\n",
    "        'ADANIENT.NS','ADANIPORTS.NS','APOLLOHOSP.NS','ASIANPAINT.NS','AXISBANK.NS',\n",
    "        'BAJAJ-AUTO.NS','BAJFINANCE.NS','BAJAJFINSV.NS','BEL.NS','BHARTIARTL.NS',\n",
    "        'CIPLA.NS','COALINDIA.NS','DRREDDY.NS','EICHERMOT.NS','GRASIM.NS',\n",
    "        'HCLTECH.NS','HDFCBANK.NS','HDFCLIFE.NS','HINDALCO.NS','HINDUNILVR.NS',\n",
    "        'ICICIBANK.NS','ITC.NS','INFY.NS','INDIGO.NS','JSWSTEEL.NS',\n",
    "        'JIOFIN.NS','KOTAKBANK.NS','LT.NS','M&M.NS','MARUTI.NS',\n",
    "        'MAXHEALTH.NS','NTPC.NS','NESTLEIND.NS','ONGC.NS','POWERGRID.NS',\n",
    "        'RELIANCE.NS','SBILIFE.NS','SHRIRAMFIN.NS','SBIN.NS','SUNPHARMA.NS',\n",
    "        'TCS.NS','TATACONSUM.NS','TATAMOTORS.NS','TATASTEEL.NS','TECHM.NS',\n",
    "        'TITAN.NS','TRENT.NS','ULTRACEMCO.NS','WIPRO.NS'\n",
    "    ])\n",
    "    interval: str = \"5m\"                  # '1m' (7 days) or '5m' (60 days)\n",
    "\n",
    "    # ---- Backtest (single day) ----\n",
    "    backtest_date: str = \"2025-10-16\"     # YYYY-MM-DD\n",
    "\n",
    "    # ---- Live loop ----\n",
    "    live_mode: bool = False               # Set True to run live\n",
    "    poll_seconds: int = 40\n",
    "    market_open_hhmm: str = \"09:15\"       # IST\n",
    "    market_close_hhmm: str = \"15:30\"      # IST\n",
    "\n",
    "    # ---- Risk / Trade Management ----\n",
    "    stop_loss_pct: float = 0.003          # 0.30%\n",
    "    target_pct: float = 0.006             # 0.60%\n",
    "    capital_inr: float = 200000.0\n",
    "    capital_per_trade_frac: float = 0.10  # 10% notional per trade for P&L calc\n",
    "    max_positions_total: int = 10         # portfolio-level cap\n",
    "\n",
    "    # ---- Filters / Context ----\n",
    "    use_prev_day_levels: bool = True      # tag signals near prev-day H/L\n",
    "    use_ema200: bool = True               # *** NEW: toggle EMA trend filter\n",
    "    ema_len: int = 200                    # EMA length (default 200)\n",
    "\n",
    "    # ---- Logging / Outputs ----\n",
    "    outputs_dir: str = \"outputs\"          # CSVs under outputs/YYYY-MM-DD\n",
    "    print_first_trades: int = 5\n",
    "\n",
    "    # ---- Safety ----\n",
    "    one_position_per_symbol: bool = True  # avoid pyramiding without exits\n",
    "\n",
    "    # ---- Telegram (optional) ----\n",
    "    TELEGRAM_BOT_TOKEN: str = \"\"          # e.g. \"123456:ABC-DEF...\"\n",
    "    TELEGRAM_CHAT_ID: str = \"\"            # e.g. your_chat_id or @channelusername\n",
    "    TELEGRAM_ENABLED: bool = False        # set True after filling token & chat_id\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TIMEZONE HELPERS (Robust)\n",
    "# =========================\n",
    "def _to_utc_index(idx: pd.DatetimeIndex) -> pd.DatetimeIndex:\n",
    "    if getattr(idx, \"tz\", None) is None:\n",
    "        return idx.tz_localize(\"UTC\")\n",
    "    return idx.tz_convert(\"UTC\")\n",
    "\n",
    "def _to_ist_index(idx: pd.DatetimeIndex) -> pd.DatetimeIndex:\n",
    "    if getattr(idx, \"tz\", None) is None:\n",
    "        return idx.tz_localize(\"UTC\").tz_convert(\"Asia/Kolkata\")\n",
    "    return idx.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "def ist_now() -> pd.Timestamp:\n",
    "    return pd.Timestamp.utcnow().tz_localize(\"UTC\").tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "def _hhmm_to_time(hhmm: str) -> pd.Timestamp:\n",
    "    hh, mm = map(int, hhmm.split(\":\"))\n",
    "    return pd.Timestamp(2000, 1, 1, hh, mm, tz=\"Asia/Kolkata\")\n",
    "\n",
    "def is_market_open_ist(now_ist: Optional[pd.Timestamp] = None) -> bool:\n",
    "    now_ist = now_ist or ist_now()\n",
    "    t = now_ist.tz_localize(\"Asia/Kolkata\") if now_ist.tz is None else now_ist\n",
    "    open_t = _hhmm_to_time(cfg.market_open_hhmm).time()\n",
    "    close_t = _hhmm_to_time(cfg.market_close_hhmm).time()\n",
    "    return open_t <= t.time() <= close_t\n",
    "\n",
    "def date_range_pad(d: str, days_before=1, days_after=1) -> Tuple[str, str]:\n",
    "    start = (pd.Timestamp(d) - pd.Timedelta(days=days_before)).strftime(\"%Y-%m-%d\")\n",
    "    end   = (pd.Timestamp(d) + pd.Timedelta(days=days_after)).strftime(\"%Y-%m-%d\")\n",
    "    return start, end\n",
    "\n",
    "def ts_to_ist_str(ts: pd.Timestamp) -> str:\n",
    "    \"\"\"Format any timestamp to IST string 'YYYY-MM-DD HH:MM:SS'.\"\"\"\n",
    "    if isinstance(ts, str):\n",
    "        try:\n",
    "            ts = pd.Timestamp(ts)\n",
    "        except Exception:\n",
    "            return str(ts)\n",
    "    if ts.tz is None:\n",
    "        ts = ts.tz_localize(\"UTC\")\n",
    "    return ts.tz_convert(\"Asia/Kolkata\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# IO / TELEGRAM HELPERS\n",
    "# =========================\n",
    "def ensure_outdir_for_day(day: str) -> str:\n",
    "    out_dir = os.path.join(cfg.outputs_dir, day)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return out_dir\n",
    "\n",
    "def csv_append(path: str, df_row: pd.DataFrame):\n",
    "    header = not os.path.exists(path)\n",
    "    df_row.to_csv(path, index=False, mode=\"a\", header=header, encoding=\"utf-8\")\n",
    "\n",
    "def send_telegram(text: str):\n",
    "    if not cfg.TELEGRAM_ENABLED:\n",
    "        return\n",
    "    if not cfg.TELEGRAM_BOT_TOKEN or not cfg.TELEGRAM_CHAT_ID:\n",
    "        log.warning(\"Telegram enabled but BOT_TOKEN/CHAT_ID missing.\")\n",
    "        return\n",
    "    url = f\"https://api.telegram.org/bot{cfg.TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
    "    payload = {\"chat_id\": cfg.TELEGRAM_CHAT_ID, \"text\": text, \"parse_mode\": \"HTML\", \"disable_web_page_preview\": True}\n",
    "    try:\n",
    "        if requests is not None:\n",
    "            r = requests.post(url, data=payload, timeout=10)\n",
    "            if r.status_code != 200:\n",
    "                log.warning(f\"Telegram send failed: {r.status_code} {r.text}\")\n",
    "        else:\n",
    "            import urllib.request, urllib.parse\n",
    "            data = urllib.parse.urlencode(payload).encode()\n",
    "            req = urllib.request.Request(url, data=data)\n",
    "            with urllib.request.urlopen(req, timeout=10) as resp:\n",
    "                if resp.status != 200:\n",
    "                    log.warning(f\"Telegram send failed (urllib): {resp.status}\")\n",
    "    except Exception as e:\n",
    "        log.warning(f\"Telegram send exception: {e}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATA DOWNLOAD\n",
    "# =========================\n",
    "def yf_download_multi(symbols: List[str], start: str, end: str, interval: str) -> Dict[str, pd.DataFrame]:\n",
    "    if not symbols:\n",
    "        return {}\n",
    "    data = yf.download(\n",
    "        tickers=\" \".join(symbols), start=start, end=end, interval=interval,\n",
    "        auto_adjust=False, group_by=\"ticker\", progress=False, threads=True\n",
    "    )\n",
    "\n",
    "    out: Dict[str, pd.DataFrame] = {}\n",
    "    if isinstance(data, pd.DataFrame) and isinstance(data.columns, pd.MultiIndex):\n",
    "        for sym in symbols:\n",
    "            if sym in data.columns.get_level_values(0):\n",
    "                df = data[sym].copy()\n",
    "                if not df.empty:\n",
    "                    df = df.rename(columns=str.title).dropna()\n",
    "                    out[sym] = df\n",
    "    elif isinstance(data, pd.DataFrame) and not data.empty:\n",
    "        sym = symbols[0]\n",
    "        out[sym] = data.rename(columns=str.title).dropna()\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CONTEXT: PREV-DAY LEVELS\n",
    "# =========================\n",
    "def attach_prev_day_levels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    idx_ist = _to_ist_index(df.index)\n",
    "    day_ist = pd.to_datetime(idx_ist.date)\n",
    "    out = df.copy()\n",
    "    out[\"__day_ist\"] = day_ist\n",
    "    daily = out.groupby(\"__day_ist\").agg(PrevHigh=(\"High\", \"max\"),\n",
    "                                         PrevLow=(\"Low\", \"min\"))\n",
    "    daily[\"PrevHigh_shift\"] = daily[\"PrevHigh\"].shift(1)\n",
    "    daily[\"PrevLow_shift\"]  = daily[\"PrevLow\"].shift(1)\n",
    "    out = out.join(daily[[\"PrevHigh_shift\", \"PrevLow_shift\"]], on=\"__day_ist\")\n",
    "    out = out.rename(columns={\"PrevHigh_shift\": \"PrevDayHigh\",\n",
    "                              \"PrevLow_shift\": \"PrevDayLow\"})\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PATTERN DETECTION + EMA\n",
    "# =========================\n",
    "def add_ema(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add EMA column for trend filter.\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    out = df.copy()\n",
    "    out[f\"EMA{cfg.ema_len}\"] = out[\"Close\"].ewm(span=cfg.ema_len, adjust=False, min_periods=cfg.ema_len).mean()\n",
    "    return out\n",
    "\n",
    "def detect_patterns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    o, h, l, c = df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"]\n",
    "    body = (c - o).abs().clip(lower=1e-9)\n",
    "    real_body_top = np.maximum(o, c)\n",
    "    real_body_bottom = np.minimum(o, c)\n",
    "    upper_wick = h - real_body_top\n",
    "    lower_wick = real_body_bottom - l\n",
    "\n",
    "    # Hammer (bullish)\n",
    "    df[\"is_hammer\"] = (lower_wick >= 2 * body) & (upper_wick <= 0.5 * body) & (c > o)\n",
    "\n",
    "    # Shooting Star (bearish)\n",
    "    df[\"is_shooting_star\"] = (upper_wick >= 2 * body) & (lower_wick <= 0.5 * body) & (c < o)\n",
    "\n",
    "    # Engulfing\n",
    "    prev_o, prev_c = o.shift(1), c.shift(1)\n",
    "    df[\"is_bullish_engulf\"] = (c > o) & (prev_c < prev_o) & (c >= prev_o) & (o <= prev_c)\n",
    "    df[\"is_bearish_engulf\"] = (c < o) & (prev_c > prev_o) & (c <= prev_o) & (o >= prev_c)\n",
    "\n",
    "    # Inside Bar\n",
    "    prev_h, prev_l = h.shift(1), l.shift(1)\n",
    "    df[\"is_inside_bar\"] = (h <= prev_h) & (l >= prev_l)\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# SIGNALS (with EMA filter)\n",
    "# =========================\n",
    "def reason_text(row: pd.Series, prev: Optional[pd.Series]) -> str:\n",
    "    parts = []\n",
    "    if row.get(\"is_hammer\"): parts.append(\"Hammer\")\n",
    "    if row.get(\"is_shooting_star\"): parts.append(\"ShootingStar\")\n",
    "    if row.get(\"is_bullish_engulf\"): parts.append(\"BullishEngulf\")\n",
    "    if row.get(\"is_bearish_engulf\"): parts.append(\"BearishEngulf\")\n",
    "    if prev is not None and prev.get(\"is_inside_bar\"):\n",
    "        if row[\"Close\"] > prev[\"High\"]:\n",
    "            parts.append(\"InsideBreakUp\")\n",
    "        elif row[\"Close\"] < prev[\"Low\"]:\n",
    "            parts.append(\"InsideBreakDown\")\n",
    "    if cfg.use_prev_day_levels:\n",
    "        pH = row.get(\"PrevDayHigh\", np.nan); pL = row.get(\"PrevDayLow\", np.nan)\n",
    "        if not pd.isna(pH) and abs((row[\"Close\"] - pH) / pH) < 0.002:\n",
    "            parts.append(\"nearPrevDayHigh\")\n",
    "        if not pd.isna(pL) and abs((row[\"Close\"] - pL) / pL) < 0.002:\n",
    "            parts.append(\"nearPrevDayLow\")\n",
    "    # EMA tag\n",
    "    ema = row.get(f\"EMA{cfg.ema_len}\", np.nan)\n",
    "    if cfg.use_ema200 and not pd.isna(ema):\n",
    "        if row[\"Close\"] >= ema:\n",
    "            parts.append(f\"EMA{cfg.ema_len}Up\")\n",
    "        else:\n",
    "            parts.append(f\"EMA{cfg.ema_len}Down\")\n",
    "    return \"+\".join(parts) if parts else \"Pattern/Context\"\n",
    "\n",
    "def generate_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"signal\"] = np.nan\n",
    "    df[\"signal_reason\"] = \"\"\n",
    "    ema_col = f\"EMA{cfg.ema_len}\" if cfg.use_ema200 else None\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        row = df.iloc[i]\n",
    "        prev = df.iloc[i - 1]\n",
    "        sig = None\n",
    "\n",
    "        # Base pattern logic\n",
    "        if row[\"is_hammer\"] or row[\"is_bullish_engulf\"]:\n",
    "            sig = \"BUY\"\n",
    "        elif row[\"is_shooting_star\"] or row[\"is_bearish_engulf\"]:\n",
    "            sig = \"SELL\"\n",
    "        elif prev[\"is_inside_bar\"]:\n",
    "            if row[\"Close\"] > prev[\"High\"]:\n",
    "                sig = \"BUY\"\n",
    "            elif row[\"Close\"] < prev[\"Low\"]:\n",
    "                sig = \"SELL\"\n",
    "\n",
    "        # EMA trend filter\n",
    "        if sig and cfg.use_ema200 and ema_col in df.columns and not pd.isna(row[ema_col]):\n",
    "            if sig == \"BUY\" and not (row[\"Close\"] >= row[ema_col]):\n",
    "                sig = None  # reject longs below EMA\n",
    "            elif sig == \"SELL\" and not (row[\"Close\"] <= row[ema_col]):\n",
    "                sig = None  # reject shorts above EMA\n",
    "\n",
    "        if sig:\n",
    "            df.loc[df.index[i], \"signal\"] = sig\n",
    "            df.loc[df.index[i], \"signal_reason\"] = reason_text(row, prev)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# BACKTEST (SINGLE DAY)\n",
    "# =========================\n",
    "def backtest_single_day(symbols: List[str], date: str, interval: str):\n",
    "    start, end = date_range_pad(date, 1, 1)\n",
    "    frames: Dict[str, pd.DataFrame] = yf_download_multi(symbols, start, end, interval)\n",
    "\n",
    "    all_trades = []\n",
    "    for sym, df in frames.items():\n",
    "        df = df.copy().sort_index()\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        # Filter to chosen IST day\n",
    "        df_ist_index = _to_ist_index(df.index)\n",
    "        df[\"__date_ist\"] = pd.to_datetime(df_ist_index.date)\n",
    "        wanted = pd.Timestamp(date)\n",
    "        df = df[df[\"__date_ist\"] == wanted]\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        if cfg.use_prev_day_levels:\n",
    "            df = attach_prev_day_levels(df)\n",
    "        # Add EMA and patterns\n",
    "        df = add_ema(df)\n",
    "        df = detect_patterns(df)\n",
    "        df = generate_signals(df)\n",
    "\n",
    "        # One-position-per-symbol simulator using next-bar-open entries\n",
    "        position = None\n",
    "        for i in range(len(df) - 1):\n",
    "            row = df.iloc[i]\n",
    "            nxt = df.iloc[i + 1]\n",
    "            if position is None:\n",
    "                if row[\"signal\"] == \"BUY\":\n",
    "                    entry = float(nxt[\"Open\"])\n",
    "                    sl = entry * (1 - cfg.stop_loss_pct)\n",
    "                    tp = entry * (1 + cfg.target_pct)\n",
    "                    position = dict(symbol=sym, side=\"LONG\", entry=entry, sl=sl, tp=tp,\n",
    "                                    reason=row[\"signal_reason\"], entry_time=nxt.name)\n",
    "                elif row[\"signal\"] == \"SELL\":\n",
    "                    entry = float(nxt[\"Open\"])\n",
    "                    sl = entry * (1 + cfg.stop_loss_pct)\n",
    "                    tp = entry * (1 - cfg.target_pct)\n",
    "                    position = dict(symbol=sym, side=\"SHORT\", entry=entry, sl=sl, tp=tp,\n",
    "                                    reason=row[\"signal_reason\"], entry_time=nxt.name)\n",
    "            else:\n",
    "                h, l = float(row[\"High\"]), float(row[\"Low\"])\n",
    "                if position[\"side\"] == \"LONG\":\n",
    "                    if l <= position[\"sl\"]:\n",
    "                        pnl = (position[\"sl\"] - position[\"entry\"]) / position[\"entry\"]\n",
    "                        all_trades.append({**position, \"exit\": position[\"sl\"], \"pnl\": pnl, \"exit_reason\": \"SL\"})\n",
    "                        position = None\n",
    "                    elif h >= position[\"tp\"]:\n",
    "                        pnl = (position[\"tp\"] - position[\"entry\"]) / position[\"entry\"]\n",
    "                        all_trades.append({**position, \"exit\": position[\"tp\"], \"pnl\": pnl, \"exit_reason\": \"TP\"})\n",
    "                        position = None\n",
    "                else:\n",
    "                    if h >= position[\"sl\"]:\n",
    "                        pnl = (position[\"entry\"] - position[\"sl\"]) / position[\"entry\"]\n",
    "                        all_trades.append({**position, \"exit\": position[\"sl\"], \"pnl\": pnl, \"exit_reason\": \"SL\"})\n",
    "                        position = None\n",
    "                    elif l <= position[\"tp\"]:\n",
    "                        pnl = (position[\"entry\"] - position[\"tp\"]) / position[\"entry\"]\n",
    "                        all_trades.append({**position, \"exit\": position[\"tp\"], \"pnl\": pnl, \"exit_reason\": \"TP\"})\n",
    "                        position = None\n",
    "\n",
    "    trades = pd.DataFrame(all_trades)\n",
    "    # Save CSV + summary JSON (with IST timestamps)\n",
    "    out_dir = ensure_outdir_for_day(date)\n",
    "    if trades.empty:\n",
    "        summary = dict(date=date, n_trades=0, win_rate_pct=0.0, profitable_trades=0,\n",
    "                       avg_pnl_pct=0.0, total_pnl_inr=0.0)\n",
    "        trades.to_csv(os.path.join(out_dir, \"backtest_trades.csv\"), index=False)\n",
    "        with open(os.path.join(out_dir, \"backtest_summary.json\"), \"w\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        return trades, summary\n",
    "\n",
    "    # enrich with IST strings\n",
    "    trades = trades.sort_values(\"entry_time\").reset_index(drop=True)\n",
    "    trades[\"entry_time_ist\"] = trades[\"entry_time\"].apply(ts_to_ist_str)\n",
    "\n",
    "    notion = cfg.capital_inr * cfg.capital_per_trade_frac\n",
    "    trades[\"pnl_inr\"] = trades[\"pnl\"] * notion\n",
    "    win_rate = float((trades[\"pnl\"] > 0).mean() * 100.0)\n",
    "    profitable = int((trades[\"pnl\"] > 0).sum())\n",
    "    summary = dict(\n",
    "        date=date,\n",
    "        n_trades=int(len(trades)),\n",
    "        win_rate_pct=round(win_rate, 2),\n",
    "        profitable_trades=profitable,\n",
    "        avg_pnl_pct=round(float(trades[\"pnl\"].mean() * 100.0), 3),\n",
    "        total_pnl_inr=round(float(trades[\"pnl_inr\"].sum()), 2),\n",
    "    )\n",
    "    trades.to_csv(os.path.join(out_dir, \"backtest_trades.csv\"), index=False)\n",
    "    with open(os.path.join(out_dir, \"backtest_summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    return trades, summary\n",
    "\n",
    "\n",
    "# =========================\n",
    "# LIVE LOOP (ALERT/PAPER + CSV, IST fields)\n",
    "# =========================\n",
    "def floor_to_prev_completed(ts_utc: pd.Timestamp, interval: str) -> pd.Timestamp:\n",
    "    if ts_utc.tz is None:\n",
    "        ts_utc = ts_utc.tz_localize(\"UTC\")\n",
    "    minutes = int(interval.replace(\"m\", \"\")) if interval.endswith(\"m\") else 5\n",
    "    floored = ts_utc - pd.Timedelta(\n",
    "        minutes=ts_utc.minute % minutes,\n",
    "        seconds=ts_utc.second,\n",
    "        microseconds=ts_utc.microsecond\n",
    "    )\n",
    "    return floored\n",
    "\n",
    "def live_loop():\n",
    "    log.info(f\"Starting LIVE loop | interval={cfg.interval} | symbols={len(cfg.watchlist)}\")\n",
    "    positions: Dict[str, Optional[Dict]] = {}   # sym -> position or None\n",
    "    last_bar_seen: Dict[str, pd.Timestamp] = {}\n",
    "\n",
    "    today_str = ist_now().strftime(\"%Y-%m-%d\")\n",
    "    out_dir = ensure_outdir_for_day(today_str)\n",
    "    live_csv = os.path.join(out_dir, \"live_trades.csv\")\n",
    "\n",
    "    while True:\n",
    "        now_ist = ist_now()\n",
    "        if not is_market_open_ist(now_ist):\n",
    "            log.info(\"Market not open (IST). Sleeping 60s.\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        start = (pd.Timestamp.utcnow() - pd.Timedelta(days=2)).strftime(\"%Y-%m-%d\")\n",
    "        end   = (pd.Timestamp.utcnow() + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        data = yf_download_multi(cfg.watchlist, start, end, cfg.interval)\n",
    "\n",
    "        for sym, df in data.items():\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            if cfg.use_prev_day_levels:\n",
    "                df = attach_prev_day_levels(df)\n",
    "            # EMA + patterns + signals\n",
    "            df = add_ema(df)\n",
    "            df = detect_patterns(df)\n",
    "            df = generate_signals(df)\n",
    "\n",
    "            df = df.copy()\n",
    "            df.index = _to_utc_index(df.index)\n",
    "\n",
    "            now_utc = pd.Timestamp.utcnow().tz_localize(\"UTC\")\n",
    "            last_completed_close = floor_to_prev_completed(now_utc, cfg.interval)\n",
    "            bar = df[df.index <= last_completed_close].tail(1)\n",
    "            if bar.empty:\n",
    "                continue\n",
    "\n",
    "            bar_ts = bar.index[-1]\n",
    "            if last_bar_seen.get(sym) == bar_ts:\n",
    "                continue\n",
    "            last_bar_seen[sym] = bar_ts\n",
    "\n",
    "            row = bar.iloc[-1]\n",
    "            signal = row.get(\"signal\")\n",
    "            reason = row.get(\"signal_reason\", \"\")\n",
    "            pos = positions.get(sym)\n",
    "\n",
    "            # ENTRY\n",
    "            if signal and (pos is None) and (sum(p is not None for p in positions.values()) < cfg.max_positions_total):\n",
    "                entry = float(row[\"Close\"])  # alert-level entry; realistic trading: next open\n",
    "                if signal == \"BUY\":\n",
    "                    sl = entry * (1 - cfg.stop_loss_pct)\n",
    "                    tp = entry * (1 + cfg.target_pct)\n",
    "                    positions[sym] = dict(side=\"LONG\", entry=entry, sl=sl, tp=tp,\n",
    "                                          entry_time=str(bar_ts), reason=reason)\n",
    "                    msg = f\"üü¢ [ENTRY] {sym} LONG @~{entry:.2f}\\nSL {sl:.2f} | TP {tp:.2f}\\n{reason}\"\n",
    "                else:\n",
    "                    sl = entry * (1 + cfg.stop_loss_pct)\n",
    "                    tp = entry * (1 - cfg.target_pct)\n",
    "                    positions[sym] = dict(side=\"SHORT\", entry=entry, sl=sl, tp=tp,\n",
    "                                          entry_time=str(bar_ts), reason=reason)\n",
    "                    msg = f\"üî¥ [ENTRY] {sym} SHORT @~{entry:.2f}\\nSL {sl:.2f} | TP {tp:.2f}\\n{reason}\"\n",
    "\n",
    "                log.info(msg.replace(\"\\n\", \" | \"))\n",
    "                send_telegram(msg)\n",
    "\n",
    "                # CSV append entry (IST field included)\n",
    "                row_df = pd.DataFrame([{\n",
    "                    \"ts_bar_close_utc\": str(bar_ts),\n",
    "                    \"ts_bar_close_ist\": ts_to_ist_str(bar_ts),\n",
    "                    \"symbol\": sym,\n",
    "                    \"event\": \"ENTRY\",\n",
    "                    \"side\": positions[sym][\"side\"],\n",
    "                    \"price\": entry,\n",
    "                    \"sl\": sl,\n",
    "                    \"tp\": tp,\n",
    "                    \"reason\": reason\n",
    "                }])\n",
    "                csv_append(live_csv, row_df)\n",
    "\n",
    "            # EXIT mgmt on just-closed bar range\n",
    "            pos = positions.get(sym)\n",
    "            if pos:\n",
    "                hi, lo = float(row[\"High\"]), float(row[\"Low\"])\n",
    "                if pos[\"side\"] == \"LONG\":\n",
    "                    if lo <= pos[\"sl\"]:\n",
    "                        pnl = (pos[\"sl\"] - pos[\"entry\"]) / pos[\"entry\"]\n",
    "                        msg = f\"‚ö†Ô∏è [EXIT SL] {sym} LONG @ {pos['sl']:.2f} | PnL {pnl*100:.2f}%\\n{pos['reason']}\"\n",
    "                        log.info(msg.replace(\"\\n\", \" | \"))\n",
    "                        send_telegram(msg)\n",
    "                        positions[sym] = None\n",
    "                        csv_append(live_csv, pd.DataFrame([{\n",
    "                            \"ts_bar_close_utc\": str(bar_ts),\n",
    "                            \"ts_bar_close_ist\": ts_to_ist_str(bar_ts),\n",
    "                            \"symbol\": sym, \"event\": \"EXIT_SL\", \"side\": \"LONG\",\n",
    "                            \"price\": pos[\"sl\"], \"pnl_pct\": pnl*100.0, \"reason\": pos[\"reason\"]\n",
    "                        }]))\n",
    "                    elif hi >= pos[\"tp\"]:\n",
    "                        pnl = (pos[\"tp\"] - pos[\"entry\"]) / pos[\"entry\"]\n",
    "                        msg = f\"‚úÖ [EXIT TP] {sym} LONG @ {pos['tp']:.2f} | PnL {pnl*100:.2f}%\\n{pos['reason']}\"\n",
    "                        log.info(msg.replace(\"\\n\", \" | \"))\n",
    "                        send_telegram(msg)\n",
    "                        positions[sym] = None\n",
    "                        csv_append(live_csv, pd.DataFrame([{\n",
    "                            \"ts_bar_close_utc\": str(bar_ts),\n",
    "                            \"ts_bar_close_ist\": ts_to_ist_str(bar_ts),\n",
    "                            \"symbol\": sym, \"event\": \"EXIT_TP\", \"side\": \"LONG\",\n",
    "                            \"price\": pos[\"tp\"], \"pnl_pct\": pnl*100.0, \"reason\": pos[\"reason\"]\n",
    "                        }]))\n",
    "                else:\n",
    "                    if hi >= pos[\"sl\"]:\n",
    "                        pnl = (pos[\"entry\"] - pos[\"sl\"]) / pos[\"entry\"]\n",
    "                        msg = f\"‚ö†Ô∏è [EXIT SL] {sym} SHORT @ {pos['sl']:.2f} | PnL {pnl*100:.2f}%\\n{pos['reason']}\"\n",
    "                        log.info(msg.replace(\"\\n\", \" | \"))\n",
    "                        send_telegram(msg)\n",
    "                        positions[sym] = None\n",
    "                        csv_append(live_csv, pd.DataFrame([{\n",
    "                            \"ts_bar_close_utc\": str(bar_ts),\n",
    "                            \"ts_bar_close_ist\": ts_to_ist_str(bar_ts),\n",
    "                            \"symbol\": sym, \"event\": \"EXIT_SL\", \"side\": \"SHORT\",\n",
    "                            \"price\": pos[\"sl\"], \"pnl_pct\": pnl*100.0, \"reason\": pos[\"reason\"]\n",
    "                        }]))\n",
    "                    elif lo <= pos[\"tp\"]:\n",
    "                        pnl = (pos[\"entry\"] - pos[\"tp\"]) / pos[\"entry\"]\n",
    "                        msg = f\"‚úÖ [EXIT TP] {sym} SHORT @ {pos['tp']:.2f} | PnL {pnl*100:.2f}%\\n{pos['reason']}\"\n",
    "                        log.info(msg.replace(\"\\n\", \" | \"))\n",
    "                        send_telegram(msg)\n",
    "                        positions[sym] = None\n",
    "                        csv_append(live_csv, pd.DataFrame([{\n",
    "                            \"ts_bar_close_utc\": str(bar_ts),\n",
    "                            \"ts_bar_close_ist\": ts_to_ist_str(bar_ts),\n",
    "                            \"symbol\": sym, \"event\": \"EXIT_TP\", \"side\": \"SHORT\",\n",
    "                            \"price\": pos[\"tp\"], \"pnl_pct\": pnl*100.0, \"reason\": pos[\"reason\"]\n",
    "                        }]))\n",
    "\n",
    "        time.sleep(cfg.poll_seconds)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    # BACKTEST\n",
    "    trades, summary = backtest_single_day(cfg.watchlist, cfg.backtest_date, cfg.interval)\n",
    "    log.info(\"===== Backtest Summary =====\")\n",
    "    for k, v in summary.items():\n",
    "        log.info(f\"{k}: {v}\")\n",
    "    if not trades.empty:\n",
    "        log.info(\"Sample trades:\")\n",
    "        print(trades.head(cfg.print_first_trades)[\n",
    "            [\"symbol\",\"side\",\"entry_time\",\"entry_time_ist\",\"entry\",\"exit\",\"exit_reason\",\"pnl\",\"reason\"]\n",
    "        ])\n",
    "        log.info(f\"Profitable trades: {summary['profitable_trades']} out of {summary['n_trades']} \"\n",
    "                 f\"({summary['win_rate_pct']}% win rate)\")\n",
    "        # Telegram summary (optional)\n",
    "        if cfg.TELEGRAM_ENABLED:\n",
    "            send_telegram(\n",
    "                f\"üìä Backtest {summary['date']}\\n\"\n",
    "                f\"Trades: {summary['n_trades']}\\n\"\n",
    "                f\"Profitable: {summary['profitable_trades']}\\n\"\n",
    "                f\"Win%: {summary['win_rate_pct']} | AvgPnL%: {summary['avg_pnl_pct']}\\n\"\n",
    "                f\"Total PnL (‚Çπ): {summary['total_pnl_inr']}\\n\"\n",
    "                f\"EMA Filter: {'ON' if cfg.use_ema200 else 'OFF'} (len={cfg.ema_len})\"\n",
    "            )\n",
    "    else:\n",
    "        log.info(\"No trades on this date.\")\n",
    "\n",
    "    # LIVE (optional)\n",
    "    if cfg.live_mode:\n",
    "        live_loop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
