{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34bd61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 13:51:52 | INFO | Universe (11): ^NSEBANK, ^CNXIT, ^CNXAUTO, ^CNXPHARMA, ^CNXFMCG, ^CNXMETAL, ^CNXREALTY, ^CNXINFRA, ^CNXENERGY, ^CNXMEDIA, ^NSEI | Benchmark=^NSEI\n",
      "2025-11-09 13:51:54 | INFO | Saved: outputs/india_sector_rotation/2025-11-09/sector_scores.csv\n",
      "2025-11-09 13:51:54 | INFO | Saved: outputs/india_sector_rotation/2025-11-09/returns_table.csv\n",
      "2025-11-09 13:51:54 | INFO | Saved: outputs/india_sector_rotation/2025-11-09/latest_prices.csv\n",
      "2025-11-09 13:51:54 | INFO | Saved: outputs/india_sector_rotation/2025-11-09/ta_scores.csv\n",
      "2025-11-09 13:51:54 | INFO | Saved: outputs/india_sector_rotation/2025-11-09/signals.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ INDIA: TOP SECTOR OUTPERFORMERS (Momentum) ================\n",
      "           score_composite score_percentile  ret_1m  ret_3m  ret_6m   ret_1y sharpe rs_vs_bench\n",
      "^CNXMETAL             2.40           10.00%   2.66%  11.68%  23.71%   11.79%   0.16      13.48%\n",
      "^CNXAUTO              3.25           20.00%  -0.57%  12.16%  18.11%   13.88%   0.44      10.91%\n",
      "^CNXREALTY            3.30           30.00%   6.13%   4.25%  12.16%   -5.32%   0.19       3.98%\n",
      "^NSEBANK              3.35           40.00%   2.91%   4.55%   6.46%   12.44%   0.36       1.28%\n",
      "^CNXINFRA             4.10           50.00%   2.67%   3.88%   7.53%    6.46%   0.25       1.49%\n",
      "^CNXPHARMA            6.20           60.00%   1.35%   0.91%   5.00%   -2.49%   0.30      -1.27%\n",
      "^CNXENERGY            6.55           70.00%   0.90%   2.51%   6.73%   -8.94%   0.29       0.40%\n",
      "^CNXFMCG              7.70           80.00%   1.23%  -0.53%  -1.04%   -6.36%   0.40      -5.01%\n",
      "^CNXIT                8.40           90.00%   1.18%   0.24%  -2.46%  -13.09%   0.07      -5.33%\n",
      "^CNXMEDIA             9.75          100.00%  -5.90%  -9.17%  -2.45%  -26.22%  -0.14     -10.03%\n",
      "==========================================================================\n",
      "\n",
      "Leaders (TA-weighted strong-now):\n",
      "           leaders_score rs_vs_bench rs_momentum   ppo    adx regime_bull breakout_20 breakout_55 dist_52w bbw_pct\n",
      "symbol                                                                                                            \n",
      "^CNXPHARMA         11.55      -0.01%       -0.00  0.00  36.08           1           0           0   -0.06%    0.02\n",
      "^CNXENERGY         10.90       0.00%        0.00  0.01  25.76           1           0           0   -0.10%    0.57\n",
      "^CNXAUTO           10.30       0.11%        0.00  0.00  28.63           1           0           0   -0.02%    0.27\n",
      "^NSEBANK            9.85       0.01%        0.00  0.01  55.87           1           0           0   -0.01%    0.61\n",
      "^CNXINFRA           9.10       0.01%        0.00  0.01  61.19           1           0           0   -0.03%    0.84\n",
      "\n",
      "Next-Up (building strength / likely to boom):\n",
      "           nextup_score rs_momentum ppo_slope adx_rising di_plus_gt breakout_20 breakout_55 dist_52w bbw_pct rs_vs_bench\n",
      "symbol                                                                                                                  \n",
      "^CNXPHARMA        15.95       -0.00      0.00          1          1           0           0   -0.06%    0.02      -0.01%\n",
      "^CNXMEDIA         13.05       -0.00      0.00          1          0           0           0   -0.29%    0.35      -0.10%\n",
      "^CNXENERGY        12.15        0.00      0.00          1          0           0           0   -0.10%    0.57       0.00%\n",
      "^CNXAUTO          11.95        0.00     -0.00          1          0           0           0   -0.02%    0.27       0.11%\n",
      "^CNXINFRA          9.10        0.00      0.00          0          1           0           0   -0.03%    0.84       0.01%\n",
      "\n",
      "Benchmark snapshot (NIFTY 50):\n",
      "ret_1m ret_3m ret_6m ret_1y ret_ytd sharpe\n",
      " 1.53%  3.42%  5.02%  5.32%   7.81%   0.39\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "India Sector Outperformance + TA Strength Scanner (Yahoo Finance)\n",
    "\n",
    "Adds TA diagnostics to identify:\n",
    "- Current Leaders (already strong)\n",
    "- Next-Up (strength building, likely to boom next)\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "outputs/india_sector_rotation/YYYY-MM-DD/sector_scores.csv      # momentum ranks (as before)\n",
    "outputs/india_sector_rotation/YYYY-MM-DD/returns_table.csv       # returns & stats (as before)\n",
    "outputs/india_sector_rotation/YYYY-MM-DD/latest_prices.csv       # last prices (as before)\n",
    "outputs/india_sector_rotation/YYYY-MM-DD/ta_scores.csv           # TA metrics per sector\n",
    "outputs/india_sector_rotation/YYYY-MM-DD/signals.csv             # Leaders / Next-Up ranks\n",
    "\n",
    "Deps\n",
    "----\n",
    "pip install yfinance pandas numpy\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception:\n",
    "    raise SystemExit(\"Please: pip install yfinance pandas numpy\")\n",
    "\n",
    "# =========================\n",
    "# LOGGING\n",
    "# =========================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"india_sector_scanner_ta\")\n",
    "\n",
    "# Columns we store as percentages (numeric*100)\n",
    "PCT_COLS = [\n",
    "    \"ret_1w\", \"ret_1m\", \"ret_3m\", \"ret_6m\", \"ret_1y\",\n",
    "    \"ret_ytd\", \"cagr\", \"vol_ann\", \"rs_vs_bench\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    start_date: str = \"2012-01-01\"\n",
    "    end_date: Optional[str] = None\n",
    "\n",
    "    symbols: List[str] = field(default_factory=lambda: [\n",
    "        \"^NSEBANK\", \"^CNXIT\", \"^CNXAUTO\", \"^CNXPHARMA\", \"^CNXFMCG\",\n",
    "        \"^CNXMETAL\", \"^CNXREALTY\", \"^CNXINFRA\", \"^CNXENERGY\",\n",
    "        \"^CNXMEDIA\"\n",
    "    ])\n",
    "    symbols_path: Optional[str] = None\n",
    "    benchmark: str = \"^NSEI\"\n",
    "\n",
    "    lookbacks_days: Optional[Dict[str, int]] = None\n",
    "    composite_weights: Optional[Dict[str, float]] = None\n",
    "\n",
    "    risk_free_rate_annual: float = 0.06\n",
    "    trading_days_per_year: int = 252\n",
    "\n",
    "    out_root: str = \"outputs/india_sector_rotation\"\n",
    "    top_n: int = 5\n",
    "    save_latest_prices: bool = True\n",
    "\n",
    "    max_retries: int = 3\n",
    "    retry_sleep_sec: float = 2.5\n",
    "    threads: bool = True\n",
    "\n",
    "    tz_display: str = \"Asia/Kolkata\"\n",
    "\n",
    "    # TA Params\n",
    "    sma_fast: int = 50\n",
    "    sma_slow: int = 200\n",
    "    ema_fast: int = 12\n",
    "    ema_slow: int = 26\n",
    "    bb_len: int = 20\n",
    "    bb_k: float = 2.0\n",
    "    adx_len: int = 14\n",
    "    rrg_window: int = 63      # days for RS momentum slope\n",
    "    breakout_short: int = 20\n",
    "    breakout_long: int = 55\n",
    "    dist_52w_len: int = 252\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.lookbacks_days is None:\n",
    "            self.lookbacks_days = {\n",
    "                \"ret_1w\": 5,\n",
    "                \"ret_1m\": 21,\n",
    "                \"ret_3m\": 63,\n",
    "                \"ret_6m\": 126,\n",
    "                \"ret_1y\": 252,\n",
    "            }\n",
    "        if self.composite_weights is None:\n",
    "            self.composite_weights = {\n",
    "                \"ret_1m\": 0.25,\n",
    "                \"ret_3m\": 0.35,\n",
    "                \"ret_6m\": 0.25,\n",
    "                \"ret_1y\": 0.15,\n",
    "            }\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "# =========================\n",
    "# UTILITIES\n",
    "# =========================\n",
    "def ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def today_folder(root: str, tz: str) -> str:\n",
    "    now = pd.Timestamp.now(tz)\n",
    "    d = os.path.join(root, now.strftime(\"%Y-%m-%d\"))\n",
    "    ensure_dir(d)\n",
    "    return d\n",
    "\n",
    "def read_symbols_from_file(path: str) -> List[str]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "def yahoo_download(tickers: List[str], start: str, end: Optional[str],\n",
    "                   max_retries: int, sleep_s: float, threads: bool) -> pd.DataFrame:\n",
    "    last_err = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            return yf.download(\n",
    "                tickers=tickers,\n",
    "                start=start if start else None,\n",
    "                end=end,\n",
    "                auto_adjust=False,\n",
    "                actions=False,\n",
    "                group_by=\"ticker\",\n",
    "                threads=threads,\n",
    "                progress=False,\n",
    "                multi_level_index=False,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            log.warning(f\"Download attempt {attempt}/{max_retries} failed: {e}\")\n",
    "            time.sleep(sleep_s)\n",
    "    raise RuntimeError(f\"Yahoo download failed after {max_retries} retries: {last_err}\")\n",
    "\n",
    "def extract_wide(download_df: pd.DataFrame, tickers: List[str]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Return dict with wide DataFrames: Adj Close, Close, High, Low (Date x Ticker).\"\"\"\n",
    "    out = {}\n",
    "    if isinstance(download_df.columns, pd.MultiIndex):\n",
    "        for field in [\"Adj Close\", \"Close\", \"High\", \"Low\"]:\n",
    "            frames = []\n",
    "            for t in tickers:\n",
    "                if (t, field) in download_df.columns:\n",
    "                    frames.append(download_df[(t, field)].rename(t))\n",
    "            out[field] = pd.concat(frames, axis=1).sort_index() if frames else pd.DataFrame()\n",
    "    else:\n",
    "        # Single ticker fallback\n",
    "        for field in [\"Adj Close\", \"Close\", \"High\", \"Low\"]:\n",
    "            if field in download_df.columns and len(tickers) == 1:\n",
    "                out[field] = download_df[field].to_frame(tickers[0])\n",
    "            else:\n",
    "                out[field] = pd.DataFrame()\n",
    "    # Clean & ffill\n",
    "    for k in out:\n",
    "        out[k] = out[k].dropna(how=\"all\", axis=1).ffill()\n",
    "    return out\n",
    "\n",
    "def ytd_anchor_idx(prices: pd.Series) -> Optional[pd.Timestamp]:\n",
    "    if prices.empty:\n",
    "        return None\n",
    "    idx = prices.index\n",
    "    this_year = idx[idx.year == idx[-1].year]\n",
    "    if len(this_year) == 0:\n",
    "        return None\n",
    "    first_this_year = this_year[0]\n",
    "    pos = idx.get_loc(first_this_year)\n",
    "    return idx[pos - 1] if pos > 0 else None\n",
    "\n",
    "# =========================\n",
    "# CORE METRICS (same as before)\n",
    "# =========================\n",
    "def compute_returns_table(adj: pd.DataFrame, benchmark: str,\n",
    "                          lookbacks: Dict[str, int], rfr: float, tdpy: int) -> pd.DataFrame:\n",
    "    if adj.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    adj = adj.sort_index().dropna(how=\"all\")\n",
    "    latest_prices = adj.iloc[-1]\n",
    "\n",
    "    lr = np.log(adj / adj.shift(1))\n",
    "    vol_ann = lr.std(skipna=True) * math.sqrt(tdpy)\n",
    "\n",
    "    def col_cagr(col: pd.Series) -> float:\n",
    "        col = col.dropna()\n",
    "        if len(col) < 2:\n",
    "            return np.nan\n",
    "        start_val, end_val = col.iloc[0], col.iloc[-1]\n",
    "        years = (col.index[-1] - col.index[0]).days / 365.25\n",
    "        return (end_val / start_val) ** (1 / years) - 1 if years > 0 else np.nan\n",
    "\n",
    "    cagr = adj.apply(col_cagr, axis=0)\n",
    "\n",
    "    daily_excess = lr.sub(rfr / tdpy, axis=0)\n",
    "    sharpe = (daily_excess.mean(skipna=True) / daily_excess.std(skipna=True)) * math.sqrt(tdpy)\n",
    "\n",
    "    rets = {name: adj.iloc[-1] / adj.shift(n).iloc[-1] - 1 for name, n in lookbacks.items()}\n",
    "\n",
    "    ytd_vals: Dict[str, float] = {}\n",
    "    for t in adj.columns:\n",
    "        anchor = ytd_anchor_idx(adj[t])\n",
    "        ytd_vals[t] = adj[t].iloc[-1] / adj[t].loc[anchor] - 1 if anchor is not None else np.nan\n",
    "    ret_ytd = pd.Series(ytd_vals, name=\"ret_ytd\")\n",
    "\n",
    "    # RS vs benchmark (3M/6M blend)\n",
    "    if benchmark in adj.columns:\n",
    "        try:\n",
    "            b3 = adj[benchmark].iloc[-1] / adj[benchmark].shift(63).iloc[-1] - 1\n",
    "            b6 = adj[benchmark].iloc[-1] / adj[benchmark].shift(126).iloc[-1] - 1\n",
    "            base = 0.5 * b3 + 0.5 * b6\n",
    "        except Exception:\n",
    "            base = np.nan\n",
    "    else:\n",
    "        base = np.nan\n",
    "\n",
    "    rs_vals: Dict[str, float] = {}\n",
    "    for t in adj.columns:\n",
    "        try:\n",
    "            r3 = adj[t].iloc[-1] / adj[t].shift(63).iloc[-1] - 1\n",
    "            r6 = adj[t].iloc[-1] / adj[t].shift(126).iloc[-1] - 1\n",
    "            rs_vals[t] = 0.5 * r3 + 0.5 * r6 - base\n",
    "        except Exception:\n",
    "            rs_vals[t] = np.nan\n",
    "    rs_vs_bench = pd.Series(rs_vals, name=\"rs_vs_bench\")\n",
    "\n",
    "    out = pd.DataFrame(index=adj.columns)\n",
    "    out[\"price_latest\"] = latest_prices\n",
    "    for k, v in rets.items():\n",
    "        out[k] = v\n",
    "    out[\"ret_ytd\"] = ret_ytd\n",
    "    out[\"vol_ann\"] = vol_ann\n",
    "    out[\"cagr\"] = cagr\n",
    "    out[\"sharpe\"] = sharpe\n",
    "    out[\"rs_vs_bench\"] = rs_vs_bench\n",
    "    return out\n",
    "\n",
    "def rank_and_score(df: pd.DataFrame, weights: Dict[str, float]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    cols = [c for c in weights.keys() if c in df.columns]\n",
    "    if not cols:\n",
    "        raise ValueError(\"No ranking columns found; check composite_weights vs computed columns.\")\n",
    "    for c in cols:\n",
    "        df[f\"rank_{c}\"] = df[c].rank(ascending=False, method=\"min\")\n",
    "    sw = sum(weights[c] for c in cols)\n",
    "    norm_w = {c: weights[c] / sw for c in cols}\n",
    "    df[\"score_composite\"] = sum(norm_w[c] * df[f\"rank_{c}\"] for c in cols)\n",
    "    df[\"score_percentile\"] = (df[\"score_composite\"].rank(ascending=True) / len(df)) * 100.0\n",
    "    return df.sort_values([\"score_composite\", \"sharpe\"], ascending=[True, False])\n",
    "\n",
    "def to_percent_inplace(df: pd.DataFrame, cols: List[str]) -> None:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c] * 100.0\n",
    "\n",
    "# =========================\n",
    "# TA HELPERS\n",
    "# =========================\n",
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "\n",
    "def sma(series: pd.Series, length: int) -> pd.Series:\n",
    "    return series.rolling(length, min_periods=length).mean()\n",
    "\n",
    "def bb_width(close: pd.Series, length: int, k: float) -> pd.Series:\n",
    "    ma = sma(close, length)\n",
    "    sd = close.rolling(length, min_periods=length).std()\n",
    "    upper = ma + k * sd\n",
    "    lower = ma - k * sd\n",
    "    return (upper - lower) / ma\n",
    "\n",
    "def pct_rank(series: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"Percentile rank of last value within a rolling window (0-1).\"\"\"\n",
    "    def pr(x):\n",
    "        if len(x) < 2:\n",
    "            return np.nan\n",
    "        return (x.rank(pct=True).iloc[-1])\n",
    "    return series.rolling(window).apply(pr, raw=False)\n",
    "\n",
    "def linear_slope(y: pd.Series) -> float:\n",
    "    \"\"\"Slope via linear regression over index 0..n-1 (nan-safe).\"\"\"\n",
    "    y = y.dropna()\n",
    "    n = len(y)\n",
    "    if n < 3:\n",
    "        return np.nan\n",
    "    x = np.arange(n, dtype=float)\n",
    "    # slope of y on x\n",
    "    num = (x - x.mean()) @ (y.values - y.mean())\n",
    "    den = ((x - x.mean()) ** 2).sum()\n",
    "    return float(num / den) if den != 0 else np.nan\n",
    "\n",
    "def true_range(h: pd.Series, l: pd.Series, c: pd.Series) -> pd.Series:\n",
    "    prev_c = c.shift(1)\n",
    "    return pd.concat([(h - l), (h - prev_c).abs(), (l - prev_c).abs()], axis=1).max(axis=1)\n",
    "\n",
    "def adx_series(h: pd.Series, l: pd.Series, c: pd.Series, n: int = 14) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
    "    \"\"\"Classic Welles Wilder ADX with DI+, DI- (nan-safe).\"\"\"\n",
    "    up = h.diff()\n",
    "    dn = -l.diff()\n",
    "    plus_dm = np.where((up > dn) & (up > 0), up, 0.0)\n",
    "    minus_dm = np.where((dn > up) & (dn > 0), dn, 0.0)\n",
    "\n",
    "    tr = true_range(h, l, c)\n",
    "    atr = tr.rolling(n, min_periods=n).mean()\n",
    "\n",
    "    plus_di = (pd.Series(plus_dm, index=h.index).rolling(n, min_periods=n).mean() / atr) * 100.0\n",
    "    minus_di = (pd.Series(minus_dm, index=h.index).rolling(n, min_periods=n).mean() / atr) * 100.0\n",
    "\n",
    "    dx = ( (plus_di - minus_di).abs() / (plus_di + minus_di) ) * 100.0\n",
    "    adx = dx.rolling(n, min_periods=n).mean()\n",
    "    return adx, plus_di, minus_di\n",
    "\n",
    "# =========================\n",
    "# TA PANEL\n",
    "# =========================\n",
    "def compute_ta_panel(close: pd.DataFrame, high: pd.DataFrame, low: pd.DataFrame,\n",
    "                     bench_close: pd.Series, cfg: Config) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a per-symbol table of TA metrics at the last date.\n",
    "    \"\"\"\n",
    "    # Align all\n",
    "    idx = close.index\n",
    "    bench_close = bench_close.reindex(idx).ffill()\n",
    "\n",
    "    rows = []\n",
    "    for t in close.columns:\n",
    "        cl = close[t].dropna()\n",
    "        if len(cl) < max(cfg.sma_slow, cfg.dist_52w_len) + 5:\n",
    "            continue\n",
    "\n",
    "        h = high[t].reindex(cl.index).ffill()\n",
    "        l = low[t].reindex(cl.index).ffill()\n",
    "\n",
    "        # MAs & regime\n",
    "        sma_f = sma(cl, cfg.sma_fast)\n",
    "        sma_s = sma(cl, cfg.sma_slow)\n",
    "        regime_bull = int((cl.iloc[-1] > sma_f.iloc[-1] > sma_s.iloc[-1]) if not np.isnan(sma_f.iloc[-1]) and not np.isnan(sma_s.iloc[-1]) else 0)\n",
    "        above_50 = int(cl.iloc[-1] > sma_f.iloc[-1]) if not np.isnan(sma_f.iloc[-1]) else 0\n",
    "        above_200 = int(cl.iloc[-1] > sma_s.iloc[-1]) if not np.isnan(sma_s.iloc[-1]) else 0\n",
    "\n",
    "        # PPO & slope\n",
    "        ema_f = ema(cl, cfg.ema_fast)\n",
    "        ema_s = ema(cl, cfg.ema_slow)\n",
    "        ppo = ((ema_f - ema_s) / ema_s).iloc[-1] if not np.isnan(ema_s.iloc[-1]) and ema_s.iloc[-1] != 0 else np.nan\n",
    "        ppo_slope = linear_slope(((ema_f - ema_s) / ema_s).dropna().tail(cfg.rrg_window))\n",
    "\n",
    "        # RS vs benchmark + RS momentum (slope)\n",
    "        rs_series = (cl / bench_close.reindex(cl.index)).dropna()\n",
    "        rs_level = (rs_series.iloc[-1] / rs_series.shift(63).iloc[-1] - 1) if len(rs_series) > 63 else np.nan\n",
    "        rs_momentum = linear_slope(rs_series.tail(cfg.rrg_window))  # slope of RS line\n",
    "\n",
    "        # Breakouts\n",
    "        hh20 = cl.rolling(cfg.breakout_short, min_periods=cfg.breakout_short).max()\n",
    "        hh55 = cl.rolling(cfg.breakout_long,  min_periods=cfg.breakout_long).max()\n",
    "        brk20 = int(cl.iloc[-1] > hh20.iloc[-1]) if not np.isnan(hh20.iloc[-1]) else 0\n",
    "        brk55 = int(cl.iloc[-1] > hh55.iloc[-1]) if not np.isnan(hh55.iloc[-1]) else 0\n",
    "\n",
    "        # Distance to 52W high\n",
    "        hh52 = cl.rolling(cfg.dist_52w_len, min_periods=cfg.dist_52w_len).max()\n",
    "        dist_52w = (cl.iloc[-1] / hh52.iloc[-1] - 1) if not np.isnan(hh52.iloc[-1]) and hh52.iloc[-1] != 0 else np.nan\n",
    "\n",
    "        # BB width (contraction percentile over ~6 months)\n",
    "        bbw = bb_width(cl, cfg.bb_len, cfg.bb_k)\n",
    "        bbw_pct = pct_rank(bbw, 126).iloc[-1]  # 0..1; low => contraction\n",
    "\n",
    "        # ADX & ADX rising\n",
    "        adx, di_p, di_m = adx_series(h, l, cl, n=cfg.adx_len)\n",
    "        adx_val = adx.iloc[-1] if len(adx.dropna()) else np.nan\n",
    "        adx_rising = int(adx.diff().iloc[-1] > 0) if not np.isnan(adx_val) else 0\n",
    "        di_plus_gt = int(di_p.iloc[-1] > di_m.iloc[-1]) if di_p.notna().iloc[-1] and di_m.notna().iloc[-1] else 0\n",
    "\n",
    "        # % bars above 50DMA in last month (stability)\n",
    "        last21 = cl.tail(21)\n",
    "        sma_f_last = sma_f.reindex(last21.index)\n",
    "        pct_above50_last21 = float((last21 > sma_f_last).mean()) if sma_f_last.notna().all() else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"symbol\": t,\n",
    "            \"ppo\": ppo,\n",
    "            \"ppo_slope\": ppo_slope,\n",
    "            \"rs_level_3m\": rs_level,       # ~3M RS change\n",
    "            \"rs_momentum\": rs_momentum,    # slope of RS line\n",
    "            \"regime_bull\": regime_bull,\n",
    "            \"above_50\": above_50,\n",
    "            \"above_200\": above_200,\n",
    "            \"breakout_20\": brk20,\n",
    "            \"breakout_55\": brk55,\n",
    "            \"dist_52w\": dist_52w,          # <= 0 close to high; negative means below high\n",
    "            \"bbw_pct\": bbw_pct,            # 0..1; lower => tighter\n",
    "            \"adx\": adx_val,\n",
    "            \"adx_rising\": adx_rising,\n",
    "            \"di_plus_gt\": di_plus_gt,\n",
    "            \"pct_above50_last21\": pct_above50_last21,\n",
    "        })\n",
    "\n",
    "    ta = pd.DataFrame(rows).set_index(\"symbol\").sort_index()\n",
    "    return ta\n",
    "\n",
    "# =========================\n",
    "# SIGNALS / SCORING\n",
    "# =========================\n",
    "def rank_series(s: pd.Series, ascending: bool) -> pd.Series:\n",
    "    return s.rank(ascending=ascending, method=\"min\")\n",
    "\n",
    "def build_signals(ta: pd.DataFrame, table: pd.DataFrame, benchmark: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build 'leaders' and 'next-up' composite scores.\n",
    "    Returns a DataFrame with both scores and flags.\n",
    "    \"\"\"\n",
    "    df = ta.join(table[[\"rs_vs_bench\", \"sharpe\"]], how=\"left\")\n",
    "\n",
    "    # Normalize/guard\n",
    "    for col in [\"ppo\", \"ppo_slope\", \"rs_level_3m\", \"rs_momentum\", \"adx\", \"rs_vs_bench\", \"dist_52w\", \"bbw_pct\"]:\n",
    "        if col not in df:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    # Leaders composite: strong now\n",
    "    # Higher better: rs_vs_bench, rs_momentum, ppo, adx\n",
    "    # Bonuses: regime_bull, breakout flags, near 52w high (dist_52w close to 0 but >= -0.05)\n",
    "    leaders_score = (\n",
    "        rank_series(df[\"rs_vs_bench\"], ascending=False) * 0.30 +\n",
    "        rank_series(df[\"rs_momentum\"], ascending=False)  * 0.20 +\n",
    "        rank_series(df[\"ppo\"], ascending=False)          * 0.20 +\n",
    "        rank_series(df[\"adx\"], ascending=False)          * 0.15 +\n",
    "        (df[\"regime_bull\"].fillna(0) * 0.5 +\n",
    "         df[\"breakout_20\"].fillna(0) * 0.25 +\n",
    "         df[\"breakout_55\"].fillna(0) * 0.25)             * 10 +\n",
    "        # closeness to 52w high: penalize far below; reward within 5% of high\n",
    "        rank_series(-df[\"dist_52w\"].clip(lower=-0.20, upper=0.0), ascending=False) * 0.15\n",
    "    )\n",
    "\n",
    "    # Next-Up composite: improvement & setup > absolute strength\n",
    "    nextup_score = (\n",
    "        rank_series(df[\"rs_momentum\"], ascending=False)  * 0.30 +\n",
    "        rank_series(df[\"ppo_slope\"], ascending=False)    * 0.25 +\n",
    "        # ADX rising signal & DI+ leadership\n",
    "        (df[\"adx_rising\"].fillna(0) * 0.7 + df[\"di_plus_gt\"].fillna(0) * 0.3) * 10 +\n",
    "        # Volatility contraction (lower bbw_pct better) + near breakout\n",
    "        rank_series(-df[\"bbw_pct\"], ascending=False)     * 0.20 +\n",
    "        (df[\"breakout_20\"].fillna(0) * 0.2 + df[\"breakout_55\"].fillna(0) * 0.3) * 10 +\n",
    "        # Not too far from 52w high\n",
    "        rank_series(-df[\"dist_52w\"].clip(lower=-0.25, upper=0.0), ascending=False) * 0.15 +\n",
    "        # Some absolute RS helps\n",
    "        rank_series(df[\"rs_vs_bench\"], ascending=False)  * 0.10\n",
    "    )\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"leaders_score\"] = leaders_score\n",
    "    out[\"nextup_score\"] = nextup_score\n",
    "\n",
    "    # Order best-first (highest scores to top)\n",
    "    out = out.sort_values([\"leaders_score\", \"nextup_score\"], ascending=[False, False])\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    # ===== Universe =====\n",
    "    symbols = CFG.symbols\n",
    "    if CFG.symbols_path:\n",
    "        symbols = read_symbols_from_file(CFG.symbols_path)\n",
    "    symbols = list(dict.fromkeys([s.strip().upper() for s in symbols if s.strip()]))\n",
    "    if CFG.benchmark.upper() not in symbols:\n",
    "        symbols.append(CFG.benchmark.upper())\n",
    "\n",
    "    log.info(f\"Universe ({len(symbols)}): {', '.join(symbols)} | Benchmark={CFG.benchmark}\")\n",
    "\n",
    "    # ===== Download =====\n",
    "    dl = yahoo_download(\n",
    "        tickers=symbols,\n",
    "        start=CFG.start_date,\n",
    "        end=CFG.end_date,\n",
    "        max_retries=CFG.max_retries,\n",
    "        sleep_s=CFG.retry_sleep_sec,\n",
    "        threads=CFG.threads,\n",
    "    )\n",
    "    wide = extract_wide(dl, tickers=symbols)\n",
    "    adj, close, high, low = wide[\"Adj Close\"], wide[\"Close\"], wide[\"High\"], wide[\"Low\"]\n",
    "    if adj.empty or close.empty:\n",
    "        raise SystemExit(\"No data downloaded. Check tickers/date range.\")\n",
    "\n",
    "    # Drop short-history columns (>15% NaNs) consistently across panels\n",
    "    valid_frac = adj.notna().mean()\n",
    "    keep_cols = valid_frac[valid_frac > 0.85].index.tolist()\n",
    "    dropped = [c for c in adj.columns if c not in keep_cols]\n",
    "    if dropped:\n",
    "        log.warning(f\"Dropping short-history/illiquid symbols (NaNs>15%): {', '.join(dropped)}\")\n",
    "    adj = adj[keep_cols]\n",
    "    close = close[keep_cols]\n",
    "    high = high[keep_cols]\n",
    "    low = low[keep_cols]\n",
    "\n",
    "    # ===== CORE METRICS =====\n",
    "    table = compute_returns_table(\n",
    "        adj=adj,\n",
    "        benchmark=CFG.benchmark.upper(),\n",
    "        lookbacks=CFG.lookbacks_days,\n",
    "        rfr=CFG.risk_free_rate_annual,\n",
    "        tdpy=CFG.trading_days_per_year,\n",
    "    )\n",
    "    if table.empty or len(table) < 2:\n",
    "        raise SystemExit(\"Insufficient data after filtering; adjust universe or dates.\")\n",
    "\n",
    "    # ===== MOMENTUM RANKING (exclude benchmark) =====\n",
    "    rank_df = table.copy()\n",
    "    if CFG.benchmark.upper() in rank_df.index:\n",
    "        rank_df_no_bm = rank_df.drop(index=[CFG.benchmark.upper()])\n",
    "    else:\n",
    "        rank_df_no_bm = rank_df\n",
    "    ranked = rank_and_score(rank_df_no_bm, CFG.composite_weights)\n",
    "\n",
    "    # ===== TA PANEL =====\n",
    "    bench_close = close[CFG.benchmark.upper()] if CFG.benchmark.upper() in close.columns else pd.Series(index=close.index, dtype=float)\n",
    "    ta = compute_ta_panel(close.drop(columns=[CFG.benchmark.upper()], errors=\"ignore\"),\n",
    "                          high.drop(columns=[CFG.benchmark.upper()], errors=\"ignore\"),\n",
    "                          low.drop(columns=[CFG.benchmark.upper()], errors=\"ignore\"),\n",
    "                          bench_close, CFG)\n",
    "\n",
    "    # ===== SIGNALS =====\n",
    "    signals = build_signals(ta, rank_df_no_bm, CFG.benchmark.upper())\n",
    "    leaders = signals.sort_values(\"leaders_score\", ascending=False).head(CFG.top_n)\n",
    "    nextup = signals.sort_values(\"nextup_score\", ascending=False).head(CFG.top_n)\n",
    "\n",
    "    # ===== Convert to % where applicable (numeric) =====\n",
    "    to_percent_inplace(table, PCT_COLS)\n",
    "    to_percent_inplace(ranked, [c for c in PCT_COLS if c in ranked.columns])\n",
    "    # TA has some percentage-like fields; keep them raw except dist_52w which is a return\n",
    "    if \"dist_52w\" in ta.columns:\n",
    "        ta[\"dist_52w\"] = ta[\"dist_52w\"] * 100.0\n",
    "\n",
    "    # ===== Outputs =====\n",
    "    out_dir = today_folder(CFG.out_root, CFG.tz_display)\n",
    "    returns_csv = os.path.join(out_dir, \"returns_table.csv\")\n",
    "    ranked_csv = os.path.join(out_dir, \"sector_scores.csv\")\n",
    "    latest_csv = os.path.join(out_dir, \"latest_prices.csv\")\n",
    "    ta_csv = os.path.join(out_dir, \"ta_scores.csv\")\n",
    "    sig_csv = os.path.join(out_dir, \"signals.csv\")\n",
    "\n",
    "    table.sort_index().to_csv(returns_csv, float_format=\"%.2f\")\n",
    "    ranked.to_csv(ranked_csv, float_format=\"%.2f\")\n",
    "    if CFG.save_latest_prices:\n",
    "        pd.DataFrame({\"price_latest\": adj.iloc[-1]}).sort_index().to_csv(latest_csv, float_format=\"%.2f\")\n",
    "    ta.to_csv(ta_csv, float_format=\"%.6f\")\n",
    "    signals.to_csv(sig_csv, float_format=\"%.6f\")\n",
    "\n",
    "    log.info(f\"Saved: {ranked_csv}\")\n",
    "    log.info(f\"Saved: {returns_csv}\")\n",
    "    if CFG.save_latest_prices:\n",
    "        log.info(f\"Saved: {latest_csv}\")\n",
    "    log.info(f\"Saved: {ta_csv}\")\n",
    "    log.info(f\"Saved: {sig_csv}\")\n",
    "\n",
    "    # ===== Console summary =====\n",
    "    print(\"\\n================ INDIA: TOP SECTOR OUTPERFORMERS (Momentum) ================\")\n",
    "    disp_cols = [\"score_composite\", \"score_percentile\", \"ret_1m\", \"ret_3m\", \"ret_6m\", \"ret_1y\", \"sharpe\", \"rs_vs_bench\"]\n",
    "    disp = ranked[disp_cols].copy().astype(object)\n",
    "    for c in [\"score_percentile\", \"ret_1m\", \"ret_3m\", \"ret_6m\", \"ret_1y\", \"rs_vs_bench\"]:\n",
    "        if c in disp.columns:\n",
    "            disp[c] = disp[c].map(lambda x: f\"{float(x):.2f}%\")\n",
    "    if \"sharpe\" in disp.columns:\n",
    "        disp[\"sharpe\"] = disp[\"sharpe\"].map(lambda x: f\"{float(x):.2f}\")\n",
    "    if \"score_composite\" in disp.columns:\n",
    "        disp[\"score_composite\"] = disp[\"score_composite\"].map(lambda x: f\"{float(x):.2f}\")\n",
    "    print(disp.to_string())\n",
    "    print(\"==========================================================================\\n\")\n",
    "\n",
    "    print(\"Leaders (TA-weighted strong-now):\")\n",
    "    ld = leaders[[\"leaders_score\",\"rs_vs_bench\",\"rs_momentum\",\"ppo\",\"adx\",\"regime_bull\",\"breakout_20\",\"breakout_55\",\"dist_52w\",\"bbw_pct\"]].copy().astype(object)\n",
    "    # pretty format % lookers\n",
    "    for c in [\"rs_vs_bench\", \"dist_52w\"]:\n",
    "        if c in ld.columns:\n",
    "            ld[c] = ld[c].map(lambda x: f\"{float(x):.2f}%\" if pd.notna(x) else \"nan\")\n",
    "    for c in [\"ppo\",\"rs_momentum\",\"adx\",\"leaders_score\",\"bbw_pct\"]:\n",
    "        if c in ld.columns:\n",
    "            ld[c] = ld[c].map(lambda x: f\"{float(x):.2f}\" if pd.notna(x) else \"nan\")\n",
    "    print(ld.to_string())\n",
    "    print()\n",
    "\n",
    "    print(\"Next-Up (building strength / likely to boom):\")\n",
    "    nu = nextup[[\"nextup_score\",\"rs_momentum\",\"ppo_slope\",\"adx_rising\",\"di_plus_gt\",\"breakout_20\",\"breakout_55\",\"dist_52w\",\"bbw_pct\",\"rs_vs_bench\"]].copy().astype(object)\n",
    "    for c in [\"dist_52w\",\"rs_vs_bench\"]:\n",
    "        if c in nu.columns:\n",
    "            nu[c] = nu[c].map(lambda x: f\"{float(x):.2f}%\" if pd.notna(x) else \"nan\")\n",
    "    for c in [\"ppo_slope\",\"rs_momentum\",\"nextup_score\",\"bbw_pct\"]:\n",
    "        if c in nu.columns:\n",
    "            nu[c] = nu[c].map(lambda x: f\"{float(x):.2f}\" if pd.notna(x) else \"nan\")\n",
    "    print(nu.to_string())\n",
    "\n",
    "    # Benchmark snapshot\n",
    "    if CFG.benchmark.upper() in table.index:\n",
    "        bm = table.loc[CFG.benchmark.upper(), [\"ret_1m\",\"ret_3m\",\"ret_6m\",\"ret_1y\",\"ret_ytd\",\"sharpe\"]].copy()\n",
    "        bm_disp = bm.astype(object)\n",
    "        for c in [\"ret_1m\",\"ret_3m\",\"ret_6m\",\"ret_1y\",\"ret_ytd\"]:\n",
    "            if c in bm_disp.index:\n",
    "                bm_disp[c] = f\"{float(bm[c]):.2f}%\"\n",
    "        if \"sharpe\" in bm_disp.index:\n",
    "            bm_disp[\"sharpe\"] = f\"{float(bm['sharpe']):.2f}\"\n",
    "        print(\"\\nBenchmark snapshot (NIFTY 50):\")\n",
    "        print(pd.DataFrame(bm_disp).T.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
