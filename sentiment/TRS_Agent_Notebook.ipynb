{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866e8670",
   "metadata": {},
   "source": [
    "\n",
    "# Trade Readiness Score (TRS) â€” Fundamentals Ã— Sentiment Ã— News\n",
    "\n",
    "**Created:** 2025-09-09 18:17 UTC  \n",
    "**Purpose:** Daily pipeline to generate a **Topâ€‘N list** of trade candidates by fusing:\n",
    "- **Fundamentals Analyst:** quality/valuation/red flags â†’ *Q score (0â€“100)*\n",
    "- **Sentiment Analyst:** finance + social text sentiment â†’ *S score (âˆ’1 to +1 â†’ scaled)*\n",
    "- **News Analyst:** event/catalyst & macro risk tagging â†’ *N score (0â€“100)*\n",
    "- **Fusion:** `TRS = 0.45Â·Q + 0.35Â·S' + 0.20Â·N'`\n",
    "\n",
    "**Outputs**\n",
    "- `trs_signals.csv`: Ticker, TRS, sub-scores, price/ATR/DMA, entry/stop/targets, position size\n",
    "- On-screen **Topâ€‘N** table\n",
    "\n",
    "> ðŸš¦ Designed to be robust: all external sources are **optional** with graceful fallbacks.  \n",
    "> If you don't set any API keys, it still runs with Google News RSS + price data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dc005",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5015eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running first time, uncomment the next cell to install requirements.\n",
    "# (Keep them commented if your environment already has these packages.)\n",
    "# %pip install -q --upgrade pandas numpy yfinance transformers torch scikit-learn #     feedparser beautifulsoup4 lxml requests_cache duckdb python-dateutil tqdm nltk\n",
    "#\n",
    "# Optional (for charts):\n",
    "# %pip install -q matplotlib\n",
    "#\n",
    "# Note: Transformers models (FinBERT, Tweet-RoBERTa) will download on first use.\n",
    "# !pip install requests_cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94bcdf1",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff85c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading vader_lexicon: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, math, time, json, re, gc, logging, textwrap, itertools, statistics, hashlib\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import requests_cache\n",
    "import feedparser\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from dateutil import parser as dateparser\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Optional plotting (disable if headless):\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAVE_MPL = True\n",
    "except Exception:\n",
    "    HAVE_MPL = False\n",
    "\n",
    "# NLP (lazy import later to speed cold start)\n",
    "TRANSFORMERS_AVAILABLE = True\n",
    "try:\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "except Exception as e:\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "\n",
    "# Optional VADER fallback\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    nltk.download('vader_lexicon', quiet=True)\n",
    "    HAVE_VADER = True\n",
    "except Exception:\n",
    "    HAVE_VADER = False\n",
    "\n",
    "# Cache HTTP\n",
    "requests_cache.install_cache('trs_cache', expire_after=300)  # 5 minutes\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')\n",
    "logger = logging.getLogger(\"TRS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf613e16",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= USER CONFIG =========\n",
    "\n",
    "# Universe (NSE examples â€” you can mix in US tickers as well)\n",
    "TICKERS = [\n",
    "        \"ATUL.NS\",\n",
    "    \"CENTRALBK.NS\",\n",
    "    \"COCHINSHIP.NS\",\n",
    "    \"FACT.NS\",\n",
    "    \"GSPL.NS\",\n",
    "    \"HINDPETRO.NS\",\n",
    "    \"IRFC.NS\",\n",
    "    \"LUPIN.NS\",\n",
    "    \"NBCC.NS\",\n",
    "    \"TARIL.NS\",\n",
    "    \"UCOBANK.NS\"\n",
    "]\n",
    "\n",
    "# Output\n",
    "TOP_N = 10\n",
    "OUTPUT_CSV = \"trs_signals.csv\"\n",
    "\n",
    "# Risk & Sizing\n",
    "CAPITAL = 1_000_000  # total portfolio in INR (or your base currency)\n",
    "RISK_PER_TRADE = 0.0075  # 0.75% of equity risk per trade\n",
    "ATR_MULT_STOP = 1.5\n",
    "ATR_MULT_TARGET = 2.5\n",
    "\n",
    "# Price data\n",
    "HISTORY_PERIOD = \"9mo\"\n",
    "PRICE_INTERVAL = \"1d\"\n",
    "\n",
    "# TRS Weights\n",
    "W_Q = 0.45\n",
    "W_S = 0.35\n",
    "W_N = 0.20\n",
    "\n",
    "# Sentiment windows\n",
    "SENTIMENT_LOOKBACK_HOURS = 72  # aggregate sentiment over last 72 hours\n",
    "ROLLING_SENT_PERCENTILE_DAYS = 90  # map S to rolling percentile\n",
    "\n",
    "# Macro blackout\n",
    "MACRO_BLACKOUT_HOURS = 6  # suppress signals around major macro events\n",
    "\n",
    "# API Keys (optional)\n",
    "ALPHA_VANTAGE_KEY = os.getenv(\"ALPHA_VANTAGE_KEY\", \"\")   # Fundamentals + News\n",
    "NEWSAPI_KEY       = os.getenv(\"NEWSAPI_KEY\", \"\") \n",
    "# Reddit social is fetched via public JSON (no key), but can be flaky.\n",
    "\n",
    "# NLP model choices (change if you like)\n",
    "MODEL_FINBERT = \"ProsusAI/finbert\"\n",
    "MODEL_TWEET   = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Region for macro events (manual list below). Set to [] to disable.\n",
    "REGION = \"IN\"\n",
    "\n",
    "# Macro events (manual list). You can add your local calendars here.\n",
    "MANUAL_MACRO_EVENTS = [\n",
    "    # Example format: (\"IN\", \"RBI MPC Policy\", \"2025-10-04 10:00\", \"Asia/Kolkata\"),\n",
    "    # (\"IN\", \"MoSPI CPI Release\", \"2025-09-12 17:30\", \"Asia/Kolkata\"),\n",
    "]\n",
    "\n",
    "# ==============================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f78f5",
   "metadata": {},
   "source": [
    "## 3. Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d3b9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ts_now_utc():\n",
    "    return datetime.now(timezone.utc)\n",
    "\n",
    "def to_utc(dt):\n",
    "    if dt.tzinfo is None:\n",
    "        return dt.replace(tzinfo=timezone.utc)\n",
    "    return dt.astimezone(timezone.utc)\n",
    "\n",
    "def parse_when(s):\n",
    "    try:\n",
    "        return to_utc(dateparser.parse(s))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def safe_pct(a, b):\n",
    "    try:\n",
    "        if b == 0 or pd.isna(b): return np.nan\n",
    "        return 100.0 * (a - b) / b\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def winsorize(series, lower=0.01, upper=0.99):\n",
    "    if len(series) == 0:\n",
    "        return series\n",
    "    lo = series.quantile(lower)\n",
    "    hi = series.quantile(upper)\n",
    "    return series.clip(lo, hi)\n",
    "\n",
    "def zscore(series):\n",
    "    s = series.astype(float)\n",
    "    return (s - s.mean()) / (s.std(ddof=0) + 1e-9)\n",
    "\n",
    "def percentile_rank(x, vec):\n",
    "    # returns 0..100 percentile rank of x within vec\n",
    "    vec = np.array(vec, dtype=float)\n",
    "    if len(vec) == 0 or np.all(np.isnan(vec)):\n",
    "        return 50.0\n",
    "    return float(np.sum(vec <= x)) / len(vec) * 100.0\n",
    "\n",
    "def rolling_percentile(series, window=90):\n",
    "    out = []\n",
    "    for i in range(len(series)):\n",
    "        ref = series[max(0, i - window):i+1]\n",
    "        out.append(percentile_rank(series.iloc[i], ref))\n",
    "    return pd.Series(out, index=series.index)\n",
    "\n",
    "def ema(series, span=20):\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def atr(df, period=14):\n",
    "    high = df[\"High\"]\n",
    "    low = df[\"Low\"]\n",
    "    close = df[\"Close\"]\n",
    "    prev_close = close.shift(1)\n",
    "    tr = pd.concat([high - low, (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
    "    return tr.rolling(period).mean()\n",
    "\n",
    "def position_size(capital, risk_per_trade, stop_distance):\n",
    "    if stop_distance <= 0 or pd.isna(stop_distance):\n",
    "        return 0.0\n",
    "    risk_amt = capital * risk_per_trade\n",
    "    return math.floor(risk_amt / stop_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4771d0ad",
   "metadata": {},
   "source": [
    "## 4. Fundamentals Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccd50837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AV_BASE = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "def av_get(function, **params):\n",
    "    if not ALPHA_VANTAGE_KEY:\n",
    "        return None, \"No Alpha Vantage key\"\n",
    "    p = dict(apikey=ALPHA_VANTAGE_KEY, function=function)\n",
    "    p.update(params)\n",
    "    try:\n",
    "        r = requests.get(AV_BASE, params=p, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        if \"Note\" in data or \"Error Message\" in data:\n",
    "            return None, data.get(\"Note\") or data.get(\"Error Message\")\n",
    "        return data, None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def fundamentals_overview(symbol):\n",
    "    data, err = av_get(\"OVERVIEW\", symbol=symbol)\n",
    "    if err or not data:\n",
    "        return None\n",
    "    # Keep key ratios as floats where possible\n",
    "    keep = [\n",
    "        \"EBITDA\", \"PERatio\", \"PEGRatio\", \"BookValue\", \"DividendYield\", \"ProfitMargin\",\n",
    "        \"OperatingMarginTTM\", \"ReturnOnEquityTTM\", \"ReturnOnAssetsTTM\", \"QuarterlyEarningsGrowthYOY\",\n",
    "        \"QuarterlyRevenueGrowthYOY\", \"AnalystTargetPrice\", \"TrailingPE\", \"ForwardPE\",\n",
    "        \"PriceToBookRatio\", \"EVToEBITDA\", \"EVToRevenue\", \"Beta\"\n",
    "    ]\n",
    "    out = {}\n",
    "    for k in keep:\n",
    "        v = data.get(k, None)\n",
    "        try:\n",
    "            out[k] = float(v) if v not in (None, \"None\", \"null\", \"\") else np.nan\n",
    "        except Exception:\n",
    "            out[k] = np.nan\n",
    "    return out\n",
    "\n",
    "def fundamentals_score(symbols):\n",
    "    # Returns Q score per symbol (0..100), robust to missing data\n",
    "    rows = []\n",
    "    for s in symbols:\n",
    "        row = {\"symbol\": s}\n",
    "        f = fundamentals_overview(s)\n",
    "        if f is None:\n",
    "            row.update({\"Q_raw\": np.nan, \"Q\": 50.0, \"Q_detail\": {\"note\": \"No AV data\"}})\n",
    "        else:\n",
    "            # Simple composite: quality + profitability + valuation (lower EV/EBITDA better)\n",
    "            prof = winsorize(pd.Series([\n",
    "                f.get(\"ReturnOnEquityTTM\"),\n",
    "                f.get(\"ReturnOnAssetsTTM\"),\n",
    "                f.get(\"OperatingMarginTTM\"),\n",
    "                f.get(\"ProfitMargin\"),\n",
    "            ], dtype=float), 0.05, 0.95).mean()\n",
    "\n",
    "            growth = winsorize(pd.Series([\n",
    "                f.get(\"QuarterlyEarningsGrowthYOY\"),\n",
    "                f.get(\"QuarterlyRevenueGrowthYOY\"),\n",
    "            ], dtype=float), 0.05, 0.95).mean()\n",
    "\n",
    "            # Valuation inverse (cheaper â†’ better). Use EV/EBITDA + P/B if available.\n",
    "            val = winsorize(pd.Series([\n",
    "                -f.get(\"EVToEBITDA\", np.nan),  # negative because lower is better\n",
    "                -f.get(\"PriceToBookRatio\", np.nan),\n",
    "                -f.get(\"TrailingPE\", np.nan)\n",
    "            ], dtype=float), 0.05, 0.95).mean()\n",
    "\n",
    "            components = [x for x in [prof, growth, val] if not pd.isna(x)]\n",
    "            if len(components) == 0:\n",
    "                raw = np.nan\n",
    "            else:\n",
    "                raw = np.nanmean(components)\n",
    "\n",
    "            # Rank across universe\n",
    "            row[\"Q_raw\"] = raw\n",
    "            row[\"Q_detail\"] = {\"prof\": float(prof) if not pd.isna(prof) else None,\n",
    "                               \"growth\": float(growth) if not pd.isna(growth) else None,\n",
    "                               \"val\": float(val) if not pd.isna(val) else None,\n",
    "                               \"beta\": f.get(\"Beta\", None)}\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df[\"Q_raw\"].notna().sum() >= 2:\n",
    "        # Convert to 0..100 via percentile rank\n",
    "        vals = df[\"Q_raw\"].fillna(df[\"Q_raw\"].median())\n",
    "        ranks = vals.rank(pct=True)\n",
    "        df[\"Q\"] = (ranks * 100).clip(0, 100)\n",
    "    else:\n",
    "        df[\"Q\"] = 50.0\n",
    "\n",
    "    # Keep columns\n",
    "    df = df[[\"symbol\", \"Q\", \"Q_raw\", \"Q_detail\"]]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc4a1a",
   "metadata": {},
   "source": [
    "## 5. News Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a456ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def google_news_rss(query, hours=72, lang=\"en\"):\n",
    "    # Build Google News RSS query (no API key required)\n",
    "    url = f\"https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl={lang}\"\n",
    "    try:\n",
    "        d = feedparser.parse(url)\n",
    "        cutoff = ts_now_utc() - timedelta(hours=hours)\n",
    "        items = []\n",
    "        for e in d.entries:\n",
    "            # Parse published date if present\n",
    "            pub = e.get(\"published\", \"\") or e.get(\"updated\", \"\")\n",
    "            when = parse_when(pub) or ts_now_utc()\n",
    "            if when < cutoff:\n",
    "                continue\n",
    "            link = e.get(\"link\", \"\")\n",
    "            title = e.get(\"title\", \"\")\n",
    "            summary = e.get(\"summary\", \"\")\n",
    "            items.append({\"title\": title, \"summary\": summary, \"link\": link, \"published\": when})\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Google RSS error for {query}: {e}\")\n",
    "        return []\n",
    "\n",
    "def newsapi_search(query, hours=72):\n",
    "    if not NEWSAPI_KEY:\n",
    "        return []\n",
    "    cutoff = ts_now_utc() - timedelta(hours=hours)\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": 100,\n",
    "        \"apiKey\": NEWSAPI_KEY,\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        out = []\n",
    "        for a in data.get(\"articles\", []):\n",
    "            when = parse_when(a.get(\"publishedAt\")) or ts_now_utc()\n",
    "            if when < cutoff: \n",
    "                continue\n",
    "            out.append({\n",
    "                \"title\": a.get(\"title\", \"\"),\n",
    "                \"summary\": a.get(\"description\", \"\"),\n",
    "                \"link\": a.get(\"url\", \"\"),\n",
    "                \"published\": when\n",
    "            })\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"NewsAPI error for {query}: {e}\")\n",
    "        return []\n",
    "\n",
    "def tag_news_event(text):\n",
    "    t = text.lower()\n",
    "    tags = []\n",
    "    if any(k in t for k in [\"guidance cut\", \"profit warning\", \"probe\", \"fraud\", \"litigation\", \"default\", \"insolvency\", \"bankruptcy\", \"pledge shares\", \"pledged shares\"]):\n",
    "        tags.append((\"NEG_REGULATORY\", -30))\n",
    "    if any(k in t for k in [\"downgrade\", \"cut to\", \"revised down\", \"misses estimates\"]):\n",
    "        tags.append((\"NEG_ANALYST\", -15))\n",
    "    if any(k in t for k in [\"upgrade\", \"raises price target\", \"beats estimates\", \"record revenue\"]):\n",
    "        tags.append((\"POS_ANALYST\", +12))\n",
    "    if any(k in t for k in [\"merger\", \"acquisition\", \"stake buy\", \"promoter buying\"]):\n",
    "        tags.append((\"MNA\", +10))\n",
    "    if any(k in t for k in [\"mgmt change\", \"resigns\", \"ceo resigns\", \"cfo resigns\"]):\n",
    "        tags.append((\"MGMT_CHANGE\", -5))\n",
    "    if any(k in t for k in [\"pledge\", \"pledged\"]):\n",
    "        tags.append((\"PLEDGE\", -10))\n",
    "    return tags\n",
    "\n",
    "def macro_blackout_multiplier(events, hours=MACRO_BLACKOUT_HOURS, region=REGION):\n",
    "    # Reduce N score if close to macro events\n",
    "    now = ts_now_utc()\n",
    "    for (reg, name, when_str, tz) in events:\n",
    "        if region and reg != region: \n",
    "            continue\n",
    "        when = parse_when(when_str)\n",
    "        if not when:\n",
    "            continue\n",
    "        if abs((when - now).total_seconds()) <= hours * 3600:\n",
    "            return 0.7  # 30% penalty\n",
    "    return 1.0\n",
    "\n",
    "def news_score_for_ticker(ticker, hours=72):\n",
    "    # Query building\n",
    "    q1 = f\"{ticker} stock\"\n",
    "    q2 = ticker.replace(\".NS\", \"\")  # try bare name for Indian tickers\n",
    "\n",
    "    items = []\n",
    "    items += google_news_rss(q1, hours=hours)\n",
    "    items += google_news_rss(q2, hours=hours)\n",
    "    items += newsapi_search(q1, hours=hours)\n",
    "    items += newsapi_search(q2, hours=hours)\n",
    "\n",
    "    # Deduplicate by title hash\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for it in items:\n",
    "        h = hashlib.md5((it[\"title\"] or \"\").encode(\"utf-8\")).hexdigest()\n",
    "        if h not in seen:\n",
    "            seen.add(h)\n",
    "            uniq.append(it)\n",
    "\n",
    "    # Sentiment via FinBERT (headline-level)\n",
    "    s_score = 0.0\n",
    "    n = 0\n",
    "    tags = []\n",
    "    texts = []\n",
    "    for it in uniq:\n",
    "        title = it.get(\"title\") or \"\"\n",
    "        summary = it.get(\"summary\") or \"\"\n",
    "        texts.append(title + \". \" + summary)\n",
    "        tags.extend(tag_news_event(title + \" \" + summary))\n",
    "    # Sentiment model run\n",
    "    if len(texts) > 0:\n",
    "        s = classify_finbert(texts)  # returns list in -1..+1\n",
    "        if len(s) > 0:\n",
    "            s_score = float(np.mean(s))\n",
    "            n = len(s)\n",
    "    # Base N score 50 + 40*sentiment, then apply tag adjustments and macro penalty\n",
    "    base = 50.0 + 40.0 * s_score\n",
    "    for (tag, delta) in tags:\n",
    "        base += delta\n",
    "    base = float(np.clip(base, 0, 100))\n",
    "\n",
    "    # Macro blackout penalty\n",
    "    mult = macro_blackout_multiplier(MANUAL_MACRO_EVENTS, hours=MACRO_BLACKOUT_HOURS, region=REGION)\n",
    "    base *= mult\n",
    "    base = float(np.clip(base, 0, 100))\n",
    "\n",
    "    detail = {\n",
    "        \"headline_count\": int(n),\n",
    "        \"avg_headline_sent\": float(s_score),\n",
    "        \"tags\": tags,\n",
    "        \"macro_mult\": mult\n",
    "    }\n",
    "    return base, detail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2e4da",
   "metadata": {},
   "source": [
    "## 6. Sentiment Analyst (Finance + Social)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93568b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_FINBERT = {\"tok\": None, \"model\": None}\n",
    "_TWEET  = {\"tok\": None, \"model\": None}\n",
    "_VADER  = {\"sid\": None}\n",
    "\n",
    "def _load_finbert():\n",
    "    if _FINBERT[\"tok\"] is None and TRANSFORMERS_AVAILABLE:\n",
    "        _FINBERT[\"tok\"] = AutoTokenizer.from_pretrained(MODEL_FINBERT)\n",
    "        _FINBERT[\"model\"] = AutoModelForSequenceClassification.from_pretrained(MODEL_FINBERT)\n",
    "    return _FINBERT[\"tok\"], _FINBERT[\"model\"]\n",
    "\n",
    "def _load_tweet():\n",
    "    if _TWEET[\"tok\"] is None and TRANSFORMERS_AVAILABLE:\n",
    "        _TWEET[\"tok\"] = AutoTokenizer.from_pretrained(MODEL_TWEET)\n",
    "        _TWEET[\"model\"] = AutoModelForSequenceClassification.from_pretrained(MODEL_TWEET)\n",
    "    return _TWEET[\"tok\"], _TWEET[\"model\"]\n",
    "\n",
    "def _load_vader():\n",
    "    if _VADER[\"sid\"] is None and HAVE_VADER:\n",
    "        _VADER[\"sid\"] = SentimentIntensityAnalyzer()\n",
    "    return _VADER[\"sid\"]\n",
    "\n",
    "def softmax(x):\n",
    "    e = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e / np.sum(e, axis=-1, keepdims=True)\n",
    "\n",
    "def classify_finbert(texts):\n",
    "    # Returns list of sentiment scores in [-1, +1] using FinBERT (pos-neg)\n",
    "    try:\n",
    "        tok, model = _load_finbert()\n",
    "        if tok is None or model is None:\n",
    "            raise RuntimeError(\"Transformers not available; using VADER fallback\")\n",
    "        enc = tok(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            out = model(**enc).logits.numpy()\n",
    "        probs = softmax(out)\n",
    "        # FinBERT labels: 0=negative, 1=neutral, 2=positive (ProsusAI/finbert)\n",
    "        score = probs[:,2] - probs[:,0]\n",
    "        return score.tolist()\n",
    "    except Exception as e:\n",
    "        # Fallback to VADER compound\n",
    "        sid = _load_vader()\n",
    "        if sid is None:\n",
    "            return [0.0] * len(texts)\n",
    "        out = []\n",
    "        for t in texts:\n",
    "            out.append(sid.polarity_scores(t).get(\"compound\", 0.0))\n",
    "        return out\n",
    "\n",
    "def classify_tweet_roberta(texts):\n",
    "    # Returns [-1,+1] using cardiffnlp/twitter-roberta-base-sentiment-latest\n",
    "    try:\n",
    "        tok, model = _load_tweet()\n",
    "        if tok is None or model is None:\n",
    "            raise RuntimeError(\"Transformers not available; using VADER fallback\")\n",
    "        enc = tok(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            out = model(**enc).logits.numpy()\n",
    "        probs = softmax(out)\n",
    "        # labels: 0=negative, 1=neutral, 2=positive\n",
    "        score = probs[:,2] - probs[:,0]\n",
    "        return score.tolist()\n",
    "    except Exception as e:\n",
    "        sid = _load_vader()\n",
    "        if sid is None:\n",
    "            return [0.0] * len(texts)\n",
    "        out = []\n",
    "        for t in texts:\n",
    "            out.append(sid.polarity_scores(t).get(\"compound\", 0.0))\n",
    "        return out\n",
    "\n",
    "def reddit_search_posts(sub, query, hours=72, limit=50):\n",
    "    # Public JSON search; may rate-limit. Use headers.\n",
    "    url = f\"https://www.reddit.com/r/{sub}/search.json\"\n",
    "    params = {\"q\": query, \"restrict_sr\": \"1\", \"sort\": \"new\", \"t\": \"week\", \"limit\": str(limit)}\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 TRS-Agent/1.0\"}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        js = r.json()\n",
    "        out = []\n",
    "        cutoff = ts_now_utc() - timedelta(hours=hours)\n",
    "        for c in js.get(\"data\", {}).get(\"children\", []):\n",
    "            d = c.get(\"data\", {})\n",
    "            created = datetime.fromtimestamp(d.get(\"created_utc\", time.time()), tz=timezone.utc)\n",
    "            if created < cutoff: \n",
    "                continue\n",
    "            title = d.get(\"title\", \"\")\n",
    "            selftext = d.get(\"selftext\", \"\")\n",
    "            score = d.get(\"score\", 0)\n",
    "            num_comments = d.get(\"num_comments\", 0)\n",
    "            out.append({\"title\": title, \"body\": selftext, \"created\": created, \"score\": score, \"num_comments\": num_comments})\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Reddit error for r/{sub} {query}: {e}\")\n",
    "        return []\n",
    "\n",
    "REDDIT_SUBS = [\"IndianStreetBets\", \"IndianStockMarket\", \"stocks\"]\n",
    "\n",
    "def social_sentiment_for_ticker(ticker, hours=72):\n",
    "    q = ticker.replace(\".NS\",\"\")\n",
    "    texts = []\n",
    "    for sub in REDDIT_SUBS:\n",
    "        posts = reddit_search_posts(sub, q, hours=hours, limit=40)\n",
    "        for p in posts:\n",
    "            t = (p[\"title\"] + \" \" + (p[\"body\"] or \"\")).strip()\n",
    "            if len(t) > 0:\n",
    "                texts.append(t)\n",
    "    if len(texts) == 0:\n",
    "        return 0.0, {\"posts\": 0, \"avg\": 0.0}\n",
    "    s = classify_tweet_roberta(texts)\n",
    "    if len(s) == 0:\n",
    "        return 0.0, {\"posts\": 0, \"avg\": 0.0}\n",
    "    # Weighted by engagement proxy (we don't have engagement here -> simple mean)\n",
    "    avg = float(np.mean(s))\n",
    "    return avg, {\"posts\": int(len(s)), \"avg\": avg}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768e52cd",
   "metadata": {},
   "source": [
    "## 7. Price/TA & TRS Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572d9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_price(ticker, period=HISTORY_PERIOD, interval=PRICE_INTERVAL):\n",
    "    try:\n",
    "        df = yf.download(ticker, period=period, interval=interval, auto_adjust=False, progress=False, multi_level_index=False)\n",
    "        if df is None or df.empty:\n",
    "            return None\n",
    "        df = df.rename_axis(\"Date\").reset_index()\n",
    "        if \"Adj Close\" not in df.columns:\n",
    "            df[\"Adj Close\"] = df[\"Close\"]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Price fetch error {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "def enrich_ta(df):\n",
    "    df = df.copy()\n",
    "    df[\"SMA50\"] = df[\"Close\"].rolling(50).mean()\n",
    "    df[\"SMA200\"] = df[\"Close\"].rolling(200).mean()\n",
    "    df[\"ATR14\"] = atr(df.set_index(\"Date\"), 14).values\n",
    "    return df\n",
    "\n",
    "def map_sentiment_to_percentile_series(scores_series, window_days=ROLLING_SENT_PERCENTILE_DAYS):\n",
    "    # Map raw sentiment (-1..+1) to 0..100 using rolling percentile on its own history\n",
    "    # If not enough history, linearly map [-1..+1] -> [0..100].\n",
    "    if len(scores_series) < 5:\n",
    "        return 50.0 + 50.0 * scores_series\n",
    "    rp = rolling_percentile(scores_series, window=window_days)\n",
    "    return rp\n",
    "\n",
    "def compute_trs_row(sym, q_score, s_raw, n_score, price_df):\n",
    "    # s_raw is -1..+1, convert to percentile 0..100 using history if available\n",
    "    s_prime = 50.0 + 50.0 * s_raw  # fallback\n",
    "    # If we had a time series of S, we'd do rolling percentile; here we do static map.\n",
    "    trs = W_Q*q_score + W_S*s_prime + W_N*n_score\n",
    "    trs = float(np.clip(trs, 0, 100))\n",
    "\n",
    "    latest = price_df.iloc[-1]\n",
    "    close = float(latest[\"Close\"])\n",
    "    sma50 = float(latest[\"SMA50\"]) if not pd.isna(latest[\"SMA50\"]) else np.nan\n",
    "    sma200 = float(latest[\"SMA200\"]) if not pd.isna(latest[\"SMA200\"]) else np.nan\n",
    "    atr14 = float(latest[\"ATR14\"]) if not pd.isna(latest[\"ATR14\"]) else np.nan\n",
    "\n",
    "    bias_up = (not pd.isna(sma50) and close > sma50) and (not pd.isna(sma200) and close > sma200)\n",
    "\n",
    "    # Entry suggestion & risk\n",
    "    direction = \"LONG\" if trs >= 70 and bias_up else (\"AVOID/SHORT\" if trs <= 35 else \"WATCH\")\n",
    "    stop = close - ATR_MULT_STOP * atr14 if direction == \"LONG\" else (close + ATR_MULT_STOP*atr14 if direction==\"AVOID/SHORT\" else np.nan)\n",
    "    tgt  = close + ATR_MULT_TARGET * atr14 if direction == \"LONG\" else (close - ATR_MULT_TARGET*atr14 if direction==\"AVOID/SHORT\" else np.nan)\n",
    "    shares = position_size(CAPITAL, RISK_PER_TRADE, abs(close - stop)) if not pd.isna(stop) else 0\n",
    "\n",
    "    return {\n",
    "        \"symbol\": sym,\n",
    "        \"TRS\": trs,\n",
    "        \"Q\": float(q_score),\n",
    "        \"S_prime\": float(s_prime),\n",
    "        \"S_raw\": float(s_raw),\n",
    "        \"N\": float(n_score),\n",
    "        \"Close\": close,\n",
    "        \"SMA50\": sma50,\n",
    "        \"SMA200\": sma200,\n",
    "        \"ATR14\": atr14,\n",
    "        \"BiasUp\": bool(bias_up),\n",
    "        \"Direction\": direction,\n",
    "        \"Entry\": close,\n",
    "        \"Stop\": float(stop) if not pd.isna(stop) else np.nan,\n",
    "        \"Target\": float(tgt) if not pd.isna(tgt) else np.nan,\n",
    "        \"PositionSize\": int(shares)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53fff9",
   "metadata": {},
   "source": [
    "## 8. Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c3fbf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 23:31:04,960 | INFO | Processing ATUL.NS\n",
      "2025-09-16 23:31:10,851 | INFO | Processing CENTRALBK.NS\n",
      "2025-09-16 23:31:22,855 | INFO | Processing COCHINSHIP.NS\n",
      "2025-09-16 23:31:25,414 | INFO | Processing FACT.NS\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2025-09-16 23:31:35,560 | INFO | Processing GSPL.NS\n",
      "2025-09-16 23:31:38,461 | INFO | Processing HINDPETRO.NS\n",
      "2025-09-16 23:31:41,450 | INFO | Processing IRFC.NS\n",
      "2025-09-16 23:31:44,828 | INFO | Processing LUPIN.NS\n",
      "2025-09-16 23:31:48,220 | INFO | Processing NBCC.NS\n",
      "2025-09-16 23:31:52,123 | INFO | Processing TARIL.NS\n",
      "2025-09-16 23:31:55,296 | INFO | Processing UCOBANK.NS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>TRS</th>\n",
       "      <th>Q</th>\n",
       "      <th>S_prime</th>\n",
       "      <th>S_raw</th>\n",
       "      <th>N</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA50</th>\n",
       "      <th>SMA200</th>\n",
       "      <th>ATR14</th>\n",
       "      <th>BiasUp</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Target</th>\n",
       "      <th>PositionSize</th>\n",
       "      <th>NewsDetail</th>\n",
       "      <th>SocialDetail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FACT.NS</td>\n",
       "      <td>56.996030</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.06172</td>\n",
       "      <td>0.421234</td>\n",
       "      <td>48.122142</td>\n",
       "      <td>1005.500000</td>\n",
       "      <td>961.866998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.217865</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>1005.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 98, 'avg_headline_sent': 0....</td>\n",
       "      <td>{'posts': 2, 'avg': 0.4212344028055668}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBCC.NS</td>\n",
       "      <td>51.535402</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.67493</td>\n",
       "      <td>0.513499</td>\n",
       "      <td>12.745881</td>\n",
       "      <td>109.589996</td>\n",
       "      <td>107.783800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.790715</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>109.589996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 1, 'avg_headline_sent': -0....</td>\n",
       "      <td>{'posts': 1, 'avg': 0.5134986042976379}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATUL.NS</td>\n",
       "      <td>50.560543</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.802715</td>\n",
       "      <td>6467.000000</td>\n",
       "      <td>6657.310000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.107143</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>6467.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 8, 'avg_headline_sent': 0.0...</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CENTRALBK.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>36.939999</td>\n",
       "      <td>36.564000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>36.939999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 0, 'avg_headline_sent': 0.0...</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCHINSHIP.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1821.599976</td>\n",
       "      <td>1761.169995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.742885</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>1821.599976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 0, 'avg_headline_sent': 0.0...</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GSPL.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>319.600006</td>\n",
       "      <td>311.624998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.907144</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>319.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 0, 'avg_headline_sent': 0.0...</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HINDPETRO.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>408.461000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.467856</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 0, 'avg_headline_sent': 0.0...</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TARIL.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>523.349976</td>\n",
       "      <td>506.225001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.089288</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>523.349976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 0, 'avg_headline_sent': 0.0...</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UCOBANK.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>29.870001</td>\n",
       "      <td>29.642600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630715</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>29.870001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 0, 'avg_headline_sent': 0.0...</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LUPIN.NS</td>\n",
       "      <td>48.840582</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.202909</td>\n",
       "      <td>2051.800049</td>\n",
       "      <td>1940.939995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.078587</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>2051.800049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 4, 'avg_headline_sent': -0....</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IRFC.NS</td>\n",
       "      <td>42.586895</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.934475</td>\n",
       "      <td>128.960007</td>\n",
       "      <td>128.164600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.587142</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>128.960007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'headline_count': 1, 'avg_headline_sent': -0....</td>\n",
       "      <td>{'posts': 0, 'avg': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol        TRS     Q   S_prime     S_raw          N  \\\n",
       "0         FACT.NS  56.996030  50.0  71.06172  0.421234  48.122142   \n",
       "1         NBCC.NS  51.535402  50.0  75.67493  0.513499  12.745881   \n",
       "2         ATUL.NS  50.560543  50.0  50.00000  0.000000  52.802715   \n",
       "3    CENTRALBK.NS  50.000000  50.0  50.00000  0.000000  50.000000   \n",
       "4   COCHINSHIP.NS  50.000000  50.0  50.00000  0.000000  50.000000   \n",
       "5         GSPL.NS  50.000000  50.0  50.00000  0.000000  50.000000   \n",
       "6    HINDPETRO.NS  50.000000  50.0  50.00000  0.000000  50.000000   \n",
       "7        TARIL.NS  50.000000  50.0  50.00000  0.000000  50.000000   \n",
       "8      UCOBANK.NS  50.000000  50.0  50.00000  0.000000  50.000000   \n",
       "9        LUPIN.NS  48.840582  50.0  50.00000  0.000000  44.202909   \n",
       "10        IRFC.NS  42.586895  50.0  50.00000  0.000000  12.934475   \n",
       "\n",
       "          Close        SMA50  SMA200       ATR14  BiasUp Direction  \\\n",
       "0   1005.500000   961.866998     NaN   32.217865   False     WATCH   \n",
       "1    109.589996   107.783800     NaN    2.790715   False     WATCH   \n",
       "2   6467.000000  6657.310000     NaN  115.107143   False     WATCH   \n",
       "3     36.939999    36.564000     NaN    0.685714   False     WATCH   \n",
       "4   1821.599976  1761.169995     NaN   64.742885   False     WATCH   \n",
       "5    319.600006   311.624998     NaN    8.907144   False     WATCH   \n",
       "6    402.000000   408.461000     NaN    7.467856   False     WATCH   \n",
       "7    523.349976   506.225001     NaN   14.089288   False     WATCH   \n",
       "8     29.870001    29.642600     NaN    0.630715   False     WATCH   \n",
       "9   2051.800049  1940.939995     NaN   39.078587   False     WATCH   \n",
       "10   128.960007   128.164600     NaN    2.587142   False     WATCH   \n",
       "\n",
       "          Entry  Stop  Target  PositionSize  \\\n",
       "0   1005.500000   NaN     NaN             0   \n",
       "1    109.589996   NaN     NaN             0   \n",
       "2   6467.000000   NaN     NaN             0   \n",
       "3     36.939999   NaN     NaN             0   \n",
       "4   1821.599976   NaN     NaN             0   \n",
       "5    319.600006   NaN     NaN             0   \n",
       "6    402.000000   NaN     NaN             0   \n",
       "7    523.349976   NaN     NaN             0   \n",
       "8     29.870001   NaN     NaN             0   \n",
       "9   2051.800049   NaN     NaN             0   \n",
       "10   128.960007   NaN     NaN             0   \n",
       "\n",
       "                                           NewsDetail  \\\n",
       "0   {'headline_count': 98, 'avg_headline_sent': 0....   \n",
       "1   {'headline_count': 1, 'avg_headline_sent': -0....   \n",
       "2   {'headline_count': 8, 'avg_headline_sent': 0.0...   \n",
       "3   {'headline_count': 0, 'avg_headline_sent': 0.0...   \n",
       "4   {'headline_count': 0, 'avg_headline_sent': 0.0...   \n",
       "5   {'headline_count': 0, 'avg_headline_sent': 0.0...   \n",
       "6   {'headline_count': 0, 'avg_headline_sent': 0.0...   \n",
       "7   {'headline_count': 0, 'avg_headline_sent': 0.0...   \n",
       "8   {'headline_count': 0, 'avg_headline_sent': 0.0...   \n",
       "9   {'headline_count': 4, 'avg_headline_sent': -0....   \n",
       "10  {'headline_count': 1, 'avg_headline_sent': -0....   \n",
       "\n",
       "                               SocialDetail  \n",
       "0   {'posts': 2, 'avg': 0.4212344028055668}  \n",
       "1   {'posts': 1, 'avg': 0.5134986042976379}  \n",
       "2                  {'posts': 0, 'avg': 0.0}  \n",
       "3                  {'posts': 0, 'avg': 0.0}  \n",
       "4                  {'posts': 0, 'avg': 0.0}  \n",
       "5                  {'posts': 0, 'avg': 0.0}  \n",
       "6                  {'posts': 0, 'avg': 0.0}  \n",
       "7                  {'posts': 0, 'avg': 0.0}  \n",
       "8                  {'posts': 0, 'avg': 0.0}  \n",
       "9                  {'posts': 0, 'avg': 0.0}  \n",
       "10                 {'posts': 0, 'avg': 0.0}  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def run_trs_pipeline(symbols):\n",
    "    # Fundamentals\n",
    "    dfQ = fundamentals_score(symbols)\n",
    "    qmap = {r.symbol: r.Q for r in dfQ.itertuples(index=False)}\n",
    "\n",
    "    rows = []\n",
    "    for sym in symbols:\n",
    "        logger.info(f\"Processing {sym}\")\n",
    "        # Price\n",
    "        pr = fetch_price(sym)\n",
    "        if pr is None or pr.empty:\n",
    "            logger.warning(f\"No price data for {sym}; skipping.\")\n",
    "            continue\n",
    "        pr = enrich_ta(pr)\n",
    "\n",
    "        # Sentiment (news + social)\n",
    "        n_score, n_detail = news_score_for_ticker(sym, hours=SENTIMENT_LOOKBACK_HOURS)\n",
    "        s_social, s_detail = social_sentiment_for_ticker(sym, hours=SENTIMENT_LOOKBACK_HOURS)\n",
    "\n",
    "        # Fuse S: combine news headline sentiment and social (simple average)\n",
    "        # Note: news_score_for_ticker returns N, but also has avg headline sentiment in [-1,+1]\n",
    "        # We can recompute a news-only sentiment by re-running classify on titles; here we mix social only.\n",
    "        # For robustness, you can fetch the news texts from news_score_for_ticker again.\n",
    "        s_raw = s_social  # keep it simple; news contributes via N\n",
    "\n",
    "        # Q score\n",
    "        q = qmap.get(sym, 50.0)\n",
    "\n",
    "        # TRS row\n",
    "        row = compute_trs_row(sym, q, s_raw, n_score, pr)\n",
    "        # Add details\n",
    "        row[\"NewsDetail\"] = n_detail\n",
    "        row[\"SocialDetail\"] = s_detail\n",
    "        rows.append(row)\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"TRS\", ascending=False).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "signals = run_trs_pipeline(TICKERS)\n",
    "signals.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf89234",
   "metadata": {},
   "source": [
    "## 9. Save signals & show Topâ€‘N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ca7a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to trs_signals.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>TRS</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Target</th>\n",
       "      <th>PositionSize</th>\n",
       "      <th>Q</th>\n",
       "      <th>S_prime</th>\n",
       "      <th>N</th>\n",
       "      <th>SMA50</th>\n",
       "      <th>SMA200</th>\n",
       "      <th>ATR14</th>\n",
       "      <th>BiasUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FACT.NS</td>\n",
       "      <td>56.996030</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>1005.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.06172</td>\n",
       "      <td>48.122142</td>\n",
       "      <td>961.866998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.217865</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBCC.NS</td>\n",
       "      <td>51.535402</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>109.589996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.67493</td>\n",
       "      <td>12.745881</td>\n",
       "      <td>107.783800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.790715</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATUL.NS</td>\n",
       "      <td>50.560543</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>6467.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>52.802715</td>\n",
       "      <td>6657.310000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.107143</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CENTRALBK.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>36.939999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>36.564000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCHINSHIP.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>1821.599976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1761.169995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.742885</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GSPL.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>319.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>311.624998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.907144</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HINDPETRO.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>408.461000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.467856</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TARIL.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>523.349976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>506.225001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.089288</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UCOBANK.NS</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>29.870001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>29.642600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630715</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LUPIN.NS</td>\n",
       "      <td>48.840582</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>2051.800049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>44.202909</td>\n",
       "      <td>1940.939995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.078587</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          symbol        TRS Direction        Entry  Stop  Target  \\\n",
       "0        FACT.NS  56.996030     WATCH  1005.500000   NaN     NaN   \n",
       "1        NBCC.NS  51.535402     WATCH   109.589996   NaN     NaN   \n",
       "2        ATUL.NS  50.560543     WATCH  6467.000000   NaN     NaN   \n",
       "3   CENTRALBK.NS  50.000000     WATCH    36.939999   NaN     NaN   \n",
       "4  COCHINSHIP.NS  50.000000     WATCH  1821.599976   NaN     NaN   \n",
       "5        GSPL.NS  50.000000     WATCH   319.600006   NaN     NaN   \n",
       "6   HINDPETRO.NS  50.000000     WATCH   402.000000   NaN     NaN   \n",
       "7       TARIL.NS  50.000000     WATCH   523.349976   NaN     NaN   \n",
       "8     UCOBANK.NS  50.000000     WATCH    29.870001   NaN     NaN   \n",
       "9       LUPIN.NS  48.840582     WATCH  2051.800049   NaN     NaN   \n",
       "\n",
       "   PositionSize     Q   S_prime          N        SMA50  SMA200       ATR14  \\\n",
       "0             0  50.0  71.06172  48.122142   961.866998     NaN   32.217865   \n",
       "1             0  50.0  75.67493  12.745881   107.783800     NaN    2.790715   \n",
       "2             0  50.0  50.00000  52.802715  6657.310000     NaN  115.107143   \n",
       "3             0  50.0  50.00000  50.000000    36.564000     NaN    0.685714   \n",
       "4             0  50.0  50.00000  50.000000  1761.169995     NaN   64.742885   \n",
       "5             0  50.0  50.00000  50.000000   311.624998     NaN    8.907144   \n",
       "6             0  50.0  50.00000  50.000000   408.461000     NaN    7.467856   \n",
       "7             0  50.0  50.00000  50.000000   506.225001     NaN   14.089288   \n",
       "8             0  50.0  50.00000  50.000000    29.642600     NaN    0.630715   \n",
       "9             0  50.0  50.00000  44.202909  1940.939995     NaN   39.078587   \n",
       "\n",
       "   BiasUp  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  \n",
       "5   False  \n",
       "6   False  \n",
       "7   False  \n",
       "8   False  \n",
       "9   False  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "signals.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved to {OUTPUT_CSV}\")\n",
    "\n",
    "topn = signals.head(TOP_N).copy()\n",
    "display_cols = [\"symbol\",\"TRS\",\"Direction\",\"Entry\",\"Stop\",\"Target\",\"PositionSize\",\"Q\",\"S_prime\",\"N\",\"SMA50\",\"SMA200\",\"ATR14\",\"BiasUp\"]\n",
    "topn[display_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5ea62",
   "metadata": {},
   "source": [
    "## 10. (Optional) Quick ATR backtest on latest signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cecd3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A very simple forward-simulation template:\n",
    "# - Enter on next day open (not executed here)\n",
    "# - Exit at stop/target if hit intraday, or after max_hold days\n",
    "# This is just a template; for realistic testing, you need walk-forward TRS recomputation.\n",
    "\n",
    "def quick_backtest_template(top_df, hold_days=10):\n",
    "    results = []\n",
    "    for r in top_df.itertuples(index=False):\n",
    "        sym = r.symbol\n",
    "        df = fetch_price(sym, period=\"6mo\", interval=\"1d\")\n",
    "        if df is None or len(df) < 50:\n",
    "            continue\n",
    "        # Entry assumed at last available Close for illustration\n",
    "        entry_idx = df.index[-1]\n",
    "        entry_price = float(df.loc[entry_idx, \"Close\"])\n",
    "        atr14 = float(atr(df.set_index(\"Date\"), 14).iloc[-1])\n",
    "        if math.isnan(atr14) or atr14 <= 0:\n",
    "            continue\n",
    "        stop = entry_price - ATR_MULT_STOP*atr14 if r.Direction==\"LONG\" else entry_price + ATR_MULT_STOP*atr14\n",
    "        tgt  = entry_price + ATR_MULT_TARGET*atr14 if r.Direction==\"LONG\" else entry_price - ATR_MULT_TARGET*atr14\n",
    "\n",
    "        # Simulate next 'hold_days' bars (imperfect because we need future data)\n",
    "        # Here, we simply compute hypothetical exit if we had that data. Template only.\n",
    "        results.append({\n",
    "            \"symbol\": sym, \"entry\": entry_price, \"stop\": stop, \"target\": tgt,\n",
    "            \"hypo_R\": (tgt - entry_price) / (entry_price - stop) if r.Direction==\"LONG\" else (entry_price - tgt) / (stop - entry_price)\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example run (commented to avoid confusion; this is illustrative only)\n",
    "# bt = quick_backtest_template(signals.head(TOP_N))\n",
    "# bt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528851a7",
   "metadata": {},
   "source": [
    "\n",
    "## Tips & Next Steps\n",
    "- **Improve fundamentals:** If you trade Indian equities, Alpha Vantage coverage can be sparse. Consider paid sources (FMP, TickerTape/Trendlyne APIs) or broker research dumps to populate Q metrics more reliably.\n",
    "- **Better news features:** Keep a per-ticker headline cache and compute a **rolling S' percentile** over 90 days to stabilize sentiment.\n",
    "- **Macro calendar:** Wire a real macro API (TradingEconomics, etc.) or maintain a small CSV of key **RBI/MoSPI/Fed/ECB** dates to drive the blackout multiplier.\n",
    "- **Execution & slippage:** Integrate your brokerâ€™s API (Groww/Kite/etc.) and include slippage/fees in the sizing + backtest.\n",
    "- **Model ensembling:** Blend FinBERT with Loughranâ€“McDonald lexicon deltas and Tweetâ€‘RoBERTa; calibrate weights on validation PnL, not just AUC.\n",
    "- **Walk-forward backtest:** Recompute TRS daily from **only data available at that time** and evaluate out-of-sample performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
