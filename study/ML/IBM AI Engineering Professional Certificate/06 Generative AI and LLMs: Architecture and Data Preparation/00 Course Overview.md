# Course Overview

Welcome to this short course on generative AI and data preparation for large language models (LLMs). This is the first of the series of courses in the Generative AI Engineering Essentials with LLMs Professional Certificate.

This course is your first step toward understanding how you can use generative AI architectures and LLMs, such as generative pre-trained transformers (GPT), for natural language processing (NLP). It is an ideal course to learn how text is preprocessed and loaded for effective training and analysis by LLMs.

Let's get into the details.

## Prerequisites

For this course, a basic knowledge of Python and PyTorch and an awareness of machine learning and neural networks would be an advantage, though not strictly required.

## Course Objectives

In this course, you will learn about the significance of generative AI in various domains. You will differentiate between generative AI models and learn how to apply LLMs for NLP tasks.

You will get hands-on opportunities through labs to explore generative AI libraries, implement tokenization, and create an NLP data loader.

### After completing this course, you will be able to:

- Explain the significance of generative AI in various domains
- Differentiate between various generative AI architectures and models
- Describe the use of LLMs for NLP tasks
- Describe the key features and significance of the libraries and tools used in generative AI for language processing
- Use Hugging Face libraries in a Jupyter environment to explore generative AI techniques and build a simple chatbot using the Transformers library
- Explain the tokenization process, tokenization methods, and the use of tokenizers
- Implement tokenization
- Explain how data loaders are used for training generative AI models
- Create an NLP data loader

## Who should take this course?

This course is suitable for those interested in AI engineering, including training, developing, fine-tuning, and deploying LLMs. It is specifically designed for those who want to learn about generative AI and LLMs and text data preprocessing using tokenizers and data loaders.

## Recommended background

As this is an intermediate-level course, it assumes that you have a basic knowledge of Python and PyTorch and a familiarity with machine learning and neural network concepts.

## Course content

This course is approximately four hours and is divided into two modules. You can complete one module a week or at a pace that suits you.

### Week 1 - Module 1: Generative AI Architecture

This module will teach you the basics of generative AI and using LLMs for NLP tasks. You will be able to describe the types of generative AI and its real-world applications. You will learn to differentiate between various generative AI architectures and models, such as transformers, recurrent neural networks (RNNs), diffusion models, generative adversarial networks (GANs) and variational autoencoders (VAEs). You will learn the differences in the training approaches used for each model. You will be able to explain the use of various generative AI architectures for NLP tasks and the key features and significance of the libraries and tools used in NLP.

The knowledge acquired in this module will help you use the generative AI libraries in Hugging Face. You will be able to explore generative AI libraries and build a simple chatbot using the Transformers library from Hugging Face.

### Week 2 - Module 2: Data Preparation for LLMs

In Module 2, you will learn to prepare data for training LLMs. You will learn about tokenization methods and the use of tokenizers for word-based, character-based, and subword-based tokenization. You will be able to explain how you can use data loaders for training generative AI models and list the PyTorch libraries for preparing and handling data within data loaders.

You will implement tokenization using various libraries such as nltk, spaCy, BertTokenizer, and XLNetTokenizer. You will also create a data loader and use the collate function to process batches of text.

The module includes a cheat sheet with quick reference content, such as code snippets. A glossary will help you review the technical terms used in the course. The module concludes with a final graded quiz.

> **Please note:** This course does not cover data acquisition techniques such as web crawling, initial data cleaning procedures or the use of regular expressions. When you practice the lab exercises, you may want to ensure that you have well-prepared data by removing unwanted characters, symbols, etc.

## Learning resources

The course offers a variety of learning assets: videos, readings, hands-on labs, a cheat sheet, a glossary, and quizzes.

The videos and readings present the instruction, supported by labs that provide hands-on learning experiences.

The cheat sheet provides quick reference material, such as code snippets.

The glossary provides a reference list for all the technical terms used in the course, along with their definitions.

Practice quizzes at the end of each lesson test your understanding of what you learned, and the graded quizzes will assess your conceptual understanding of the course.

We wish you good luck completing the course and getting the most out of it!
