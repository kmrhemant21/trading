{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e147c0",
   "metadata": {},
   "source": [
    "Below is a self-contained Python script that:\n",
    "\n",
    "1. Downloads historical OHLCV data (using `yfinance`)\n",
    "2. Engineers basic technical indicators as features\n",
    "3. Trains a machine-learning model (Random Forest) to predict next-day returns\n",
    "4. Generates entry/exit signals based on the model’s predictions\n",
    "5. Backtests the strategy with `vectorbt` and prints out key performance metrics\n",
    "\n",
    "### How it works\n",
    "\n",
    "1. **Data download**\n",
    "   We pull daily OHLCV for AAPL from 2015–2022 via `yfinance`.\n",
    "2. **Feature engineering**\n",
    "\n",
    "   * **EMA20 & EMA50** capture short- and medium-term trends\n",
    "   * **RSI14** (Relative Strength Index) flags over-bought/oversold conditions\n",
    "   * **Momentum (5-day)** measures short-term price acceleration\n",
    "   * **Volume change** for liquidity shifts\n",
    "3. **Target**\n",
    "   Next-day return (`ret1`) becomes our regression target.\n",
    "4. **Model**\n",
    "   A `RandomForestRegressor` learns to predict `ret1` from the features.\n",
    "5. **Signals**\n",
    "   We generate a **long** signal whenever the model’s predicted return > 0, flat otherwise.\n",
    "6. **Backtest**\n",
    "   Using `vectorbt`, we simulate trades at close prices, accounting for **0.1% fees**, and compute all major metrics and an equity‐curve plot.\n",
    "\n",
    "---\n",
    "\n",
    "#### Next Steps\n",
    "\n",
    "* **Hyperparameter tuning** (e.g. grid‐search RF depth, n\\_estimators)\n",
    "* Add **stop-loss/take-profit** logic\n",
    "* Use **walk-forward validation** rather than a single train/test split\n",
    "* Try other models: XGBoost, LightGBM, LSTM\n",
    "* Incorporate additional features: macro data, sentiment, advanced technicals\n",
    "\n",
    "Feel free to adapt this template to your favorite universe of stocks, intervals (e.g. 5 min, 1 h), or models—and let me know if you hit any snags!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356dc76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_60693/2320778380.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(SYMBOL, start=START, end=END, progress=False)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     76\u001b[39m y_pred_train = model.predict(X_train)\n\u001b[32m     77\u001b[39m y_pred_test  = model.predict(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43my_pred_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest  RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_squared_error(y_test,\u001b[38;5;250m  \u001b[39my_pred_test,\u001b[38;5;250m  \u001b[39msquared=\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# 10. GENERATE SIGNALS\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# We’ll go long when predicted return > 0, flat otherwise.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:3212\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3209\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3210\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3211\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:3201\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3199\u001b[39m         arguments[kwargs_param.name] = kwargs\n\u001b[32m   3200\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3201\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3202\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3203\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Machine Learning–Driven Backtest Example\n",
    "========================================\n",
    "\n",
    "1. Fetch data with yfinance\n",
    "2. Feature engineering: EMAs, RSI, momentum\n",
    "3. Train RandomForestRegressor on past data\n",
    "4. Predict next-day returns\n",
    "5. Generate long-only signals\n",
    "6. Backtest with vectorbt\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import vectorbt as vbt\n",
    "\n",
    "# 1. PARAMETERS\n",
    "SYMBOL    = 'AAPL'\n",
    "START     = '2015-01-01'\n",
    "END       = '2022-12-31'\n",
    "TEST_SIZE = 0.2\n",
    "RND_STATE = 42\n",
    "\n",
    "# 2. FETCH HISTORICAL DATA\n",
    "data = yf.download(SYMBOL, start=START, end=END, progress=False)\n",
    "# Keep only the columns we need\n",
    "df = data[['Open','High','Low','Close','Volume']].copy()\n",
    "\n",
    "# 3. FEATURE ENGINEERING\n",
    "# 3.1 Moving averages\n",
    "df['ema20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "df['ema50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
    "# 3.2 RSI (14-day)\n",
    "delta       = df['Close'].diff()\n",
    "gain        = delta.clip(lower=0)\n",
    "loss        = -delta.clip(upper=0)\n",
    "avg_gain    = gain.rolling(14).mean()\n",
    "avg_loss    = loss.rolling(14).mean()\n",
    "rs          = avg_gain / avg_loss\n",
    "df['rsi14'] = 100 - (100 / (1 + rs))\n",
    "# 3.3 Momentum: close / close.shift(5) - 1\n",
    "df['mom5']  = df['Close'].pct_change(5)\n",
    "# 3.4 Volume change\n",
    "df['vol_chg'] = df['Volume'].pct_change()\n",
    "\n",
    "# 4. TARGET: next-day return\n",
    "df['ret1'] = df['Close'].pct_change().shift(-1)\n",
    "\n",
    "# 5. DROP NA\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 6. SPLIT INTO FEATURES X AND TARGET y\n",
    "features = ['ema20','ema50','rsi14','mom5','vol_chg']\n",
    "X = df[features]\n",
    "y = df['ret1']\n",
    "\n",
    "# 7. TRAIN/TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, shuffle=False)\n",
    "\n",
    "# 8. MODEL TRAINING\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=RND_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 9. PREDICTIONS & EVALUATION\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test  = model.predict(X_test)\n",
    "print(f\"Train RMSE: {mean_squared_error(y_train, y_pred_train, squared=False):.5f}\")\n",
    "print(f\"Test  RMSE: {mean_squared_error(y_test,  y_pred_test,  squared=False):.5f}\")\n",
    "\n",
    "# 10. GENERATE SIGNALS\n",
    "# We’ll go long when predicted return > 0, flat otherwise.\n",
    "df_test = df.iloc[X_train.shape[0]:].copy()\n",
    "df_test['pred_ret'] = y_pred_test\n",
    "entries = df_test['pred_ret'] > 0\n",
    "exits   = entries.shift(1)  # exit when the signal flips off\n",
    "\n",
    "# 11. BACKTEST WITH VECTORBT\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    close=df_test['Close'],\n",
    "    entries=entries,\n",
    "    exits=~entries,\n",
    "    init_cash=100_000,\n",
    "    fees=0.001,\n",
    "    freq='1D'\n",
    ")\n",
    "\n",
    "# 12. OUTPUT PERFORMANCE\n",
    "print(\"\\n=== Performance Summary ===\")\n",
    "print(f\"Total Return      : {pf.total_return()*100:.2f}%\")\n",
    "print(f\"Annualized Return : {pf.annualized_return()*100:.2f}%\")\n",
    "print(f\"Sharpe Ratio      : {pf.sharpe_ratio():.2f}\")\n",
    "print(f\"Max Drawdown      : {pf.max_drawdown()*100:.2f}%\")\n",
    "\n",
    "# 13. PLOT EQUITY CURVE\n",
    "pf.plot().show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
