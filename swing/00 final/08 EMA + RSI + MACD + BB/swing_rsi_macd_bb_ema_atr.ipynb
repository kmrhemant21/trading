{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a91017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Swing Strategy: EMA/RSI/MACD/Bollinger/ATR ===\n",
      "Symbols:     500 from CONFIG[TICKERS]\n",
      "Period:      2010-01-01 .. 2025-10-05\n",
      "Fees:        ON | Start Capital: ₹200,000.0\n",
      "VolumeGate:  USE_VOLUME_SPIKE=False VOL_MULT=1.5\n",
      "Multi-Pos:   True | Allocation: split\n",
      "Grid:        OFF (backend=auto, workers=4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:13:00 | INFO | [INFO] No trades generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Metrics ===\n",
      "{\n",
      "  \"sharpe\": 3.545084585000063,\n",
      "  \"sortino\": 0.0,\n",
      "  \"max_drawdown_pct\": 0.0,\n",
      "  \"cagr_pct\": 3.6345479311231,\n",
      "  \"trades\": 0,\n",
      "  \"win_rate_pct\": 0.0,\n",
      "  \"avg_pnl_inr\": 0.0,\n",
      "  \"profit_factor\": 0.0,\n",
      "  \"final_equity_inr\": 350877.1929824561\n",
      "}\n",
      "\n",
      "Files saved:\n",
      "  - trades.csv\n",
      "  - equity.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Swing Trading Strategy (EMA/RSI/MACD/Bollinger/ATR)\n",
    "with brokerage fees, volume-spike toggle, robust/logged grid search,\n",
    "and proper capital allocation when ALLOW_MULTIPLE_POSITIONS=True.\n",
    "\n",
    "- Entry (all on signal day; filled next day's open):\n",
    "  • Up-trend: EMA_fast > EMA_slow\n",
    "  • RSI oversold cross up: RSI_y < OS and RSI_t >= OS\n",
    "  • MACD bullish crossover: MACD line crosses above its signal\n",
    "  • Bollinger reversion: Close_{t-1} < Lower_{t-1} AND Close_t > Lower_t\n",
    "  • Volume spike (optional): Vol_t >= VOL_MULT * SMA(VOL_SMA)\n",
    "\n",
    "- Exit (any):\n",
    "  • RSI > overbought\n",
    "  • MACD bearish cross\n",
    "  • Upper-band reversal: touched upper yesterday; today close < upper\n",
    "  • Intraday SL/TP using High/Low (if both hit, assume SL first conservatively)\n",
    "\n",
    "Outputs:\n",
    "  - trades.csv, equity.csv\n",
    "  - grid_results.csv (+ grid_results_partial.csv during runs)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, sys, math, json, time, itertools, warnings, logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.dummy import Pool as ThreadPool  # threads backend\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "CONFIG = {\n",
    "    # Universe (use Yahoo symbols; add .NS for NSE)\n",
    "    \"TICKERS\": ['360ONE.NS', '3MINDIA.NS', 'AADHARHFC.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ABB.NS', 'ABBOTINDIA.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'ABLBL.NS', 'ABREL.NS', 'ABSLAMC.NS', 'ACC.NS', 'ACE.NS', 'ACMESOLAR.NS', 'ADANIENSOL.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'AEGISLOG.NS', 'AEGISVOPAK.NS', 'AFCONS.NS', 'AFFLE.NS', 'AGARWALEYE.NS', 'AIAENG.NS', 'AIIL.NS', 'AJANTPHARM.NS', 'AKUMS.NS', 'AKZOINDIA.NS', 'ALKEM.NS', 'ALKYLAMINE.NS', 'ALOKINDS.NS', 'AMBER.NS', 'AMBUJACEM.NS', 'ANANDRATHI.NS', 'ANANTRAJ.NS', 'ANGELONE.NS', 'APARINDS.NS', 'APLAPOLLO.NS', 'APLLTD.NS', 'APOLLOHOSP.NS', 'APOLLOTYRE.NS', 'APTUS.NS', 'ARE&M.NS', 'ASAHIINDIA.NS', 'ASHOKLEY.NS', 'ASIANPAINT.NS', 'ASTERDM.NS', 'ASTRAL.NS', 'ASTRAZEN.NS', 'ATGL.NS', 'ATHERENERG.NS', 'ATUL.NS', 'AUBANK.NS', 'AUROPHARMA.NS', 'AWL.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJAJFINSV.NS', 'BAJAJHFL.NS', 'BAJAJHLDNG.NS', 'BAJFINANCE.NS', 'BALKRISIND.NS', 'BALRAMCHIN.NS', 'BANDHANBNK.NS', 'BANKBARODA.NS', 'BANKINDIA.NS', 'BASF.NS', 'BATAINDIA.NS', 'BAYERCROP.NS', 'BBTC.NS', 'BDL.NS', 'BEL.NS', 'BEML.NS', 'BERGEPAINT.NS', 'BHARATFORG.NS', 'BHARTIARTL.NS', 'BHARTIHEXA.NS', 'BHEL.NS', 'BIKAJI.NS', 'BIOCON.NS', 'BLS.NS', 'BLUEDART.NS', 'BLUEJET.NS', 'BLUESTARCO.NS', 'BOSCHLTD.NS', 'BPCL.NS', 'BRIGADE.NS', 'BRITANNIA.NS', 'BSE.NS', 'BSOFT.NS', 'CAMPUS.NS', 'CAMS.NS', 'CANBK.NS', 'CANFINHOME.NS', 'CAPLIPOINT.NS', 'CARBORUNIV.NS', 'CASTROLIND.NS', 'CCL.NS', 'CDSL.NS', 'CEATLTD.NS', 'CENTRALBK.NS', 'CENTURYPLY.NS', 'CERA.NS', 'CESC.NS', 'CGCL.NS', 'CGPOWER.NS', 'CHALET.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CHOICEIN.NS', 'CHOLAFIN.NS', 'CHOLAHLDNG.NS', 'CIPLA.NS', 'CLEAN.NS', 'COALINDIA.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COHANCE.NS', 'COLPAL.NS', 'CONCOR.NS', 'CONCORDBIO.NS', 'COROMANDEL.NS', 'CRAFTSMAN.NS', 'CREDITACC.NS', 'CRISIL.NS', 'CROMPTON.NS', 'CUB.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DALBHARAT.NS', 'DATAPATTNS.NS', 'DBREALTY.NS', 'DCMSHRIRAM.NS', 'DEEPAKFERT.NS', 'DEEPAKNTR.NS', 'DELHIVERY.NS', 'DEVYANI.NS', 'DIVISLAB.NS', 'DIXON.NS', 'DLF.NS', 'DMART.NS', 'DOMS.NS', 'DRREDDY.NS', 'ECLERX.NS', 'EICHERMOT.NS', 'EIDPARRY.NS', 'EIHOTEL.NS', 'ELECON.NS', 'ELGIEQUIP.NS', 'EMAMILTD.NS', 'EMCURE.NS', 'ENDURANCE.NS', 'ENGINERSIN.NS', 'ENRIN.NS', 'ERIS.NS', 'ESCORTS.NS', 'ETERNAL.NS', 'EXIDEIND.NS', 'FACT.NS', 'FEDERALBNK.NS', 'FINCABLES.NS', 'FINPIPE.NS', 'FIRSTCRY.NS', 'FIVESTAR.NS', 'FLUOROCHEM.NS', 'FORCEMOT.NS', 'FORTIS.NS', 'FSL.NS', 'GAIL.NS', 'GESHIP.NS', 'GICRE.NS', 'GILLETTE.NS', 'GLAND.NS', 'GLAXO.NS', 'GLENMARK.NS', 'GMDCLTD.NS', 'GMRAIRPORT.NS', 'GODFRYPHLP.NS', 'GODIGIT.NS', 'GODREJAGRO.NS', 'GODREJCP.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GPIL.NS', 'GRANULES.NS', 'GRAPHITE.NS', 'GRASIM.NS', 'GRAVITA.NS', 'GRSE.NS', 'GSPL.NS', 'GUJGASLTD.NS', 'GVT&D.NS', 'HAL.NS', 'HAPPSTMNDS.NS', 'HAVELLS.NS', 'HBLENGINE.NS', 'HCLTECH.NS', 'HDFCAMC.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEG.NS', 'HEROMOTOCO.NS', 'HEXT.NS', 'HFCL.NS', 'HINDALCO.NS', 'HINDCOPPER.NS', 'HINDPETRO.NS', 'HINDUNILVR.NS', 'HINDZINC.NS', 'HOMEFIRST.NS', 'HONASA.NS', 'HONAUT.NS', 'HSCL.NS', 'HUDCO.NS', 'HYUNDAI.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'IDBI.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFCI.NS', 'IGIL.NS', 'IGL.NS', 'IIFL.NS', 'IKS.NS', 'INDGN.NS', 'INDHOTEL.NS', 'INDIACEM.NS', 'INDIAMART.NS', 'INDIANB.NS', 'INDIGO.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INFY.NS', 'INOXINDIA.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'IOB.NS', 'IOC.NS', 'IPCALAB.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'IREDA.NS', 'IRFC.NS', 'ITC.NS', 'ITCHOTELS.NS', 'ITI.NS', 'J&KBANK.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JINDALSAW.NS', 'JINDALSTEL.NS', 'JIOFIN.NS', 'JKCEMENT.NS', 'JKTYRE.NS', 'JMFINANCIL.NS', 'JPPOWER.NS', 'JSL.NS', 'JSWENERGY.NS', 'JSWINFRA.NS', 'JSWSTEEL.NS', 'JUBLFOOD.NS', 'JUBLINGREA.NS', 'JUBLPHARMA.NS', 'JWL.NS', 'JYOTHYLAB.NS', 'JYOTICNC.NS', 'KAJARIACER.NS', 'KALYANKJIL.NS', 'KARURVYSYA.NS', 'KAYNES.NS', 'KEC.NS', 'KEI.NS', 'KFINTECH.NS', 'KIMS.NS', 'KIRLOSBROS.NS', 'KIRLOSENG.NS', 'KOTAKBANK.NS', 'KPIL.NS', 'KPITTECH.NS', 'KPRMILL.NS', 'KSB.NS', 'LALPATHLAB.NS', 'LATENTVIEW.NS', 'LAURUSLABS.NS', 'LEMONTREE.NS', 'LICHSGFIN.NS', 'LICI.NS', 'LINDEINDIA.NS', 'LLOYDSME.NS', 'LODHA.NS', 'LT.NS', 'LTF.NS', 'LTFOODS.NS', 'LTIM.NS', 'LTTS.NS', 'LUPIN.NS', 'M&M.NS', 'M&MFIN.NS', 'MAHABANK.NS', 'MAHSCOOTER.NS', 'MAHSEAMLES.NS', 'MANAPPURAM.NS', 'MANKIND.NS', 'MANYAVAR.NS', 'MAPMYINDIA.NS', 'MARICO.NS', 'MARUTI.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MCX.NS', 'MEDANTA.NS', 'METROPOLIS.NS', 'MFSL.NS', 'MGL.NS', 'MINDACORP.NS', 'MMTC.NS', 'MOTHERSON.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MRF.NS', 'MRPL.NS', 'MSUMI.NS', 'MUTHOOTFIN.NS', 'NAM-INDIA.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAUKRI.NS', 'NAVA.NS', 'NAVINFLUOR.NS', 'NBCC.NS', 'NCC.NS', 'NESTLEIND.NS', 'NETWEB.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NH.NS', 'NHPC.NS', 'NIACL.NS', 'NIVABUPA.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NSLNISP.NS', 'NTPC.NS', 'NTPCGREEN.NS', 'NUVAMA.NS', 'NUVOCO.NS', 'NYKAA.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLAELEC.NS', 'OLECTRA.NS', 'ONESOURCE.NS', 'ONGC.NS', 'PAGEIND.NS', 'PATANJALI.NS', 'PAYTM.NS', 'PCBL.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PFC.NS', 'PFIZER.NS', 'PGEL.NS', 'PGHH.NS', 'PHOENIXLTD.NS', 'PIDILITIND.NS', 'PIIND.NS', 'PNB.NS', 'PNBHOUSING.NS', 'POLICYBZR.NS', 'POLYCAB.NS', 'POLYMED.NS', 'POONAWALLA.NS', 'POWERGRID.NS', 'POWERINDIA.NS', 'PPLPHARMA.NS', 'PRAJIND.NS', 'PREMIERENE.NS', 'PRESTIGE.NS', 'PTCIL.NS', 'PVRINOX.NS', 'RADICO.NS', 'RAILTEL.NS', 'RAINBOW.NS', 'RAMCOCEM.NS', 'RBLBANK.NS', 'RCF.NS', 'RECLTD.NS', 'REDINGTON.NS', 'RELIANCE.NS', 'RELINFRA.NS', 'RHIM.NS', 'RITES.NS', 'RKFORGE.NS', 'RPOWER.NS', 'RRKABEL.NS', 'RVNL.NS', 'SAGILITY.NS', 'SAIL.NS', 'SAILIFE.NS', 'SAMMAANCAP.NS', 'SAPPHIRE.NS', 'SARDAEN.NS', 'SAREGAMA.NS', 'SBFC.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SBIN.NS', 'SCHAEFFLER.NS', 'SCHNEIDER.NS', 'SCI.NS', 'SHREECEM.NS', 'SHRIRAMFIN.NS', 'SHYAMMETL.NS', 'SIEMENS.NS', 'SIGNATURE.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SOBHA.NS', 'SOLARINDS.NS', 'SONACOMS.NS', 'SONATSOFTW.NS', 'SRF.NS', 'STARHEALTH.NS', 'SUMICHEM.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUNPHARMA.NS', 'SUNTV.NS', 'SUPREMEIND.NS', 'SUZLON.NS', 'SWANCORP.NS', 'SWIGGY.NS', 'SYNGENE.NS', 'SYRMA.NS', 'TARIL.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATACONSUM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TATATECH.NS', 'TBOTEK.NS', 'TCS.NS', 'TECHM.NS', 'TECHNOE.NS', 'TEJASNET.NS', 'THELEELA.NS', 'THERMAX.NS', 'TIINDIA.NS', 'TIMKEN.NS', 'TITAGARH.NS', 'TITAN.NS', 'TORNTPHARM.NS', 'TORNTPOWER.NS', 'TRENT.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'TRIVENI.NS', 'TTML.NS', 'TVSMOTOR.NS', 'UBL.NS', 'UCOBANK.NS', 'ULTRACEMCO.NS', 'UNIONBANK.NS', 'UNITDSPR.NS', 'UNOMINDA.NS', 'UPL.NS', 'USHAMART.NS', 'UTIAMC.NS', 'VBL.NS', 'VEDL.NS', 'VENTIVE.NS', 'VGUARD.NS', 'VIJAYA.NS', 'VMM.NS', 'VOLTAS.NS', 'VTL.NS', 'WAAREEENER.NS', 'WELCORP.NS', 'WELSPUNLIV.NS', 'WHIRLPOOL.NS', 'WIPRO.NS', 'WOCKPHARMA.NS', 'YESBANK.NS', 'ZEEL.NS', 'ZENSARTECH.NS', 'ZENTEC.NS', 'ZFCVINDIA.NS', 'ZYDUSLIFE.NS'],\n",
    "\n",
    "\n",
    "    \"START_DATE\": \"2010-01-01\",\n",
    "    \"END_DATE\": None,                 # None -> today (IST-normalized dates)\n",
    "\n",
    "    # Cache\n",
    "    \"CACHE_DIR\": \"./cache_yf\",\n",
    "    \"FORCE_REFRESH\": False,\n",
    "\n",
    "    # Strategy params (defaults for base run; grid can override)\n",
    "    \"EMA_FAST\": 20,\n",
    "    \"EMA_SLOW\": 50,\n",
    "    \"RSI_LEN\": 14,\n",
    "    \"RSI_OVERSOLD\": 30.0,\n",
    "    \"RSI_OVERBOUGHT\": 70.0,\n",
    "    \"MACD_FAST\": 12,\n",
    "    \"MACD_SLOW\": 26,\n",
    "    \"MACD_SIG\": 9,\n",
    "    \"BB_LEN\": 20,\n",
    "    \"BB_STD\": 2.0,\n",
    "    \"VOL_SMA\": 20,\n",
    "    \"VOL_MULT\": 1.5,\n",
    "    \"USE_VOLUME_SPIKE\": False,        # <<< toggle the volume gate in ENTRY\n",
    "\n",
    "    # ATR/Stops/Targets\n",
    "    \"ATR_LEN\": 14,\n",
    "    \"SL_ATR_MULT\": 1.5,\n",
    "    \"TARGET_R\": 2.0,\n",
    "\n",
    "    # Sizing\n",
    "    \"RISK_PER_TRADE_PCT\": 0.01,      # 1% of equity risked; set 0 to use FIXED_SHARES\n",
    "    \"FIXED_SHARES\": 0,\n",
    "\n",
    "    # Fees/slippage\n",
    "    \"APPLY_FEES\": True,\n",
    "    \"SLIPPAGE_BPS\": 0,               # per fill (basis points)\n",
    "\n",
    "    # Book\n",
    "    \"START_CAPITAL_INR\": 200_000.0,\n",
    "    \"ALLOW_MULTIPLE_POSITIONS\": True,\n",
    "\n",
    "    # Allocation when multiple positions allowed:\n",
    "    # \"split\" = split start capital equally across tickers\n",
    "    # \"full\"  = simulate each ticker with full capital (optimistic; rebase later)\n",
    "    \"CAPITAL_ALLOCATION\": \"split\",\n",
    "\n",
    "    # --- Grid Search ---\n",
    "    \"RUN_GRID\": False,\n",
    "    \"GRID_PROCESSES\": 4,\n",
    "    \"GRID_BACKEND\": \"auto\",          # auto -> threads in notebook, processes in .py\n",
    "    \"GRID_LOG_EVERY\": 1,             # log every N results\n",
    "    \"GRID_PARTIAL_SAVE_EVERY\": 25,   # write partial CSV every N results (0 to disable)\n",
    "    \"GRID_SCORE_PRIMARY\": \"sharpe\",  # (sharpe|sortino|cagr_pct|profit_factor)\n",
    "    \"GRID_SCORE_SECONDARY\": \"profit_factor\",\n",
    "    \"GRID_SCORE_TERTIARY\": \"cagr_pct\",\n",
    "    \"GRID_MAX_COMBOS\": 5000,         # 0/None to disable random capping\n",
    "    \"GRID_RANDOM_SEED\": 42,\n",
    "\n",
    "    # Parameter grid (includes MACD & BB; modest ranges to avoid explosion)\n",
    "    \"GRID\": {\n",
    "        \"USE_VOLUME_SPIKE\": [False],\n",
    "        \"VOL_MULT\": [1.2, 1.5, 2.0],\n",
    "\n",
    "        \"RSI_OVERSOLD\": [25.0, 30.0, 35.0],\n",
    "        \"RSI_OVERBOUGHT\": [65.0, 70.0, 75.0],\n",
    "\n",
    "        \"EMA_FAST\": [10, 20],\n",
    "        \"EMA_SLOW\": [50, 100],\n",
    "\n",
    "        # MACD & BB sweeps (small/sane)\n",
    "        \"MACD_FAST\": [10, 12],     # keep < MACD_SLOW\n",
    "        \"MACD_SLOW\": [26],         # classic slow\n",
    "        \"MACD_SIG\":  [9, 12],\n",
    "\n",
    "        \"BB_LEN\": [20],\n",
    "        \"BB_STD\": [1.5, 2.0],\n",
    "\n",
    "        \"SL_ATR_MULT\": [1.0, 1.5, 2.0],\n",
    "        \"TARGET_R\":   [1.5, 2.0, 2.5],\n",
    "    },\n",
    "}\n",
    "\n",
    "if CONFIG[\"END_DATE\"] is None:\n",
    "    CONFIG[\"END_DATE\"] = datetime.now().date().isoformat()\n",
    "\n",
    "# =========================\n",
    "# Logging helpers\n",
    "# =========================\n",
    "def setup_logging(level: str = \"INFO\"):\n",
    "    lvl = getattr(logging, level.upper(), logging.INFO)\n",
    "    logging.basicConfig(\n",
    "        level=lvl,\n",
    "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "        datefmt=\"%H:%M:%S\",\n",
    "    )\n",
    "\n",
    "def in_notebook() -> bool:\n",
    "    return \"ipykernel\" in sys.modules or \"IPython\" in sys.modules\n",
    "\n",
    "# =========================\n",
    "# Fees (your function)\n",
    "# =========================\n",
    "def calc_fees(turnover_buy: float, turnover_sell: float) -> float:\n",
    "    if not CONFIG[\"APPLY_FEES\"]: return 0.0\n",
    "    BROKER_PCT = 0.001; BROKER_MIN = 5.0; BROKER_CAP = 20.0\n",
    "    STT_PCT = 0.001; STAMP_BUY_PCT = 0.00015\n",
    "    EXCH_PCT = 0.0000297; SEBI_PCT = 0.000001; IPFT_PCT = 0.000001\n",
    "    GST_PCT = 0.18; DP_SELL = 20.0 if turnover_sell >= 100 else 0.0\n",
    "    def _broker(turn): return max(BROKER_MIN, min(turn*BROKER_PCT, BROKER_CAP)) if turn>0 else 0\n",
    "    brb, brs = _broker(turnover_buy), _broker(turnover_sell)\n",
    "    stt = STT_PCT*(turnover_buy+turnover_sell)\n",
    "    stamp = STAMP_BUY_PCT*turnover_buy\n",
    "    exch = EXCH_PCT*(turnover_buy+turnover_sell)\n",
    "    sebi = SEBI_PCT*(turnover_buy+turnover_sell)\n",
    "    ipft = IPFT_PCT*(turnover_buy+turnover_sell)\n",
    "    dp = DP_SELL\n",
    "    gst = GST_PCT*(brb+brs+dp+exch+sebi+ipft)\n",
    "    return float((brb+brs)+stt+stamp+exch+sebi+ipft+dp+gst)\n",
    "\n",
    "# =========================\n",
    "# Data utils\n",
    "# =========================\n",
    "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def to_ist_date_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not isinstance(df.index, pd.DatetimeIndex): return df\n",
    "    df = df.copy()\n",
    "    if df.index.tz is None:\n",
    "        df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Asia/Kolkata\")\n",
    "    else:\n",
    "        df.index = df.index.tz_convert(\"Asia/Kolkata\")\n",
    "    df.index = pd.to_datetime(df.index.date)\n",
    "    return df\n",
    "\n",
    "def load_yf(ticker: str, start: str, end: str, cache_dir: str, force_refresh: bool) -> pd.DataFrame:\n",
    "    \"\"\"Download/cached Yahoo data; always keep OHLCV; synthesize Adj Close when missing.\"\"\"\n",
    "    ensure_dir(cache_dir)\n",
    "    safe = ticker.replace(\"^\", \"_\")\n",
    "    path = os.path.join(cache_dir, f\"{safe}.csv\")\n",
    "\n",
    "    def _clean(df0: pd.DataFrame) -> pd.DataFrame:\n",
    "        if df0.empty: return df0\n",
    "        need = [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"]\n",
    "        have = [c for c in need if c in df0.columns]\n",
    "        df = df0[have].copy()\n",
    "        if \"Adj Close\" not in df and \"Close\" in df:\n",
    "            df[\"Adj Close\"] = df[\"Close\"]\n",
    "        df = to_ist_date_index(df)\n",
    "        df = df[~df.index.duplicated(keep=\"first\")].sort_index()\n",
    "        return df\n",
    "\n",
    "    if (not force_refresh) and os.path.exists(path):\n",
    "        df = pd.read_csv(path, parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "        df = _clean(df)\n",
    "        if not df.empty:\n",
    "            return df\n",
    "\n",
    "    df = yf.download(ticker, start=start, end=end, interval=\"1d\", auto_adjust=False, progress=False, multi_level_index=False)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data for {ticker}\")\n",
    "    df = _clean(df)\n",
    "    df.to_csv(path, index_label=\"Date\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Indicators\n",
    "# =========================\n",
    "def ema(s: pd.Series, span: int) -> pd.Series:\n",
    "    return s.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def rsi_wilder(close: pd.Series, length: int = 14) -> pd.Series:\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0.0)\n",
    "    down = -delta.clip(upper=0.0)\n",
    "    roll_up = up.ewm(alpha=1/length, adjust=False).mean()\n",
    "    roll_down = down.ewm(alpha=1/length, adjust=False).mean()\n",
    "    rs = roll_up / (roll_down.replace(0, np.nan))\n",
    "    return (100 - (100 / (1 + rs))).fillna(50.0)\n",
    "\n",
    "def macd(close: pd.Series, fast=12, slow=26, sig=9) -> Tuple[pd.Series,pd.Series,pd.Series]:\n",
    "    ema_f = ema(close, fast)\n",
    "    ema_s = ema(close, slow)\n",
    "    line = ema_f - ema_s\n",
    "    signal = ema(line, sig)\n",
    "    hist = line - signal\n",
    "    return line, signal, hist\n",
    "\n",
    "def bollinger(close: pd.Series, length=20, std=2.0) -> Tuple[pd.Series,pd.Series,pd.Series]:\n",
    "    ma = close.rolling(length).mean()\n",
    "    sd = close.rolling(length).std(ddof=0)\n",
    "    upper = ma + std * sd\n",
    "    lower = ma - std * sd\n",
    "    return ma, upper, lower\n",
    "\n",
    "def atr_wilder(high: pd.Series, low: pd.Series, close: pd.Series, length=14) -> pd.Series:\n",
    "    prev_close = close.shift(1)\n",
    "    tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
    "    return tr.ewm(alpha=1/length, adjust=False).mean()\n",
    "\n",
    "# =========================\n",
    "# Signals\n",
    "# =========================\n",
    "def build_signals(df: pd.DataFrame, params: Dict) -> pd.DataFrame:\n",
    "    o,h,l,c,v = df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"]\n",
    "\n",
    "    ema_fast = ema(c, params[\"EMA_FAST\"])\n",
    "    ema_slow = ema(c, params[\"EMA_SLOW\"])\n",
    "    uptrend = ema_fast > ema_slow\n",
    "\n",
    "    rsi = rsi_wilder(c, params[\"RSI_LEN\"])\n",
    "    rsi_oversold_cross = (rsi.shift(1) < params[\"RSI_OVERSOLD\"]) & (rsi >= params[\"RSI_OVERSOLD\"])\n",
    "\n",
    "    macd_line, macd_sig, _ = macd(c, params[\"MACD_FAST\"], params[\"MACD_SLOW\"], params[\"MACD_SIG\"])\n",
    "    macd_bull_cross = ((macd_line.shift(1) - macd_sig.shift(1)) <= 0) & ((macd_line - macd_sig) > 0)\n",
    "\n",
    "    bb_ma, bb_up, bb_lo = bollinger(c, params[\"BB_LEN\"], params[\"BB_STD\"])\n",
    "    bb_revert = (c.shift(1) < bb_lo.shift(1)) & (c > bb_lo)\n",
    "\n",
    "    vol_sma = v.rolling(params[\"VOL_SMA\"]).mean()\n",
    "    vol_spike = v >= (params[\"VOL_MULT\"] * vol_sma)\n",
    "\n",
    "    atr = atr_wilder(h, l, c, params[\"ATR_LEN\"])\n",
    "\n",
    "    # ENTRY (volume optional via toggle)\n",
    "    if params.get(\"USE_VOLUME_SPIKE\", True):\n",
    "        entry = uptrend & rsi_oversold_cross & macd_bull_cross & bb_revert & vol_spike\n",
    "    else:\n",
    "        entry = uptrend & rsi_oversold_cross & macd_bull_cross & bb_revert\n",
    "\n",
    "    # Exits (close-based)\n",
    "    rsi_overbought = rsi > params[\"RSI_OVERBOUGHT\"]\n",
    "    macd_bear = ((macd_line.shift(1) - macd_sig.shift(1)) >= 0) & ((macd_line - macd_sig) < 0)\n",
    "    bb_upper_rev = (c.shift(1) >= bb_up.shift(1)) & (c < bb_up)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Open\": o, \"High\": h, \"Low\": l, \"Close\": c, \"Volume\": v,\n",
    "        \"atr\": atr,\n",
    "        \"entry\": entry.astype(int),\n",
    "        \"exit_rsi_ob\": rsi_overbought.astype(int),\n",
    "        \"exit_macd_bear\": macd_bear.astype(int),\n",
    "        \"exit_bb_upper_rev\": bb_upper_rev.astype(int),\n",
    "        # diagnostics\n",
    "        \"entry_no_vol\": (uptrend & rsi_oversold_cross & macd_bull_cross & bb_revert).astype(int),\n",
    "        \"vol_spike\": vol_spike.astype(int),\n",
    "    }, index=df.index)\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# Backtest\n",
    "# =========================\n",
    "@dataclass\n",
    "class Position:\n",
    "    ticker: str\n",
    "    entry_date: pd.Timestamp\n",
    "    entry_price: float\n",
    "    shares: int\n",
    "    sl: float\n",
    "    tp: float\n",
    "\n",
    "def _apply_slippage(price: float, bps: int) -> float:\n",
    "    return price * (1 + bps/10000.0) if bps > 0 else price\n",
    "\n",
    "def simulate_ticker(ticker: str, sig: pd.DataFrame, params: Dict, start_capital: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    sl_bps = CONFIG[\"SLIPPAGE_BPS\"]\n",
    "    risk_pct = CONFIG[\"RISK_PER_TRADE_PCT\"]\n",
    "    fixed_sh = CONFIG[\"FIXED_SHARES\"]\n",
    "\n",
    "    cash = start_capital\n",
    "    pos: Optional[Position] = None\n",
    "    dates = sig.index\n",
    "    eq = pd.Series(index=dates, dtype=float)\n",
    "    trades = []\n",
    "\n",
    "    for i, d in enumerate(dates):\n",
    "        row = sig.loc[d]\n",
    "        h,l,c = row[\"High\"], row[\"Low\"], row[\"Close\"]\n",
    "\n",
    "        # Exits first - intraday SL/TP precedence\n",
    "        if pos is not None:\n",
    "            sl_hit = l <= pos.sl\n",
    "            tp_hit = h >= pos.tp\n",
    "            exit_reason = None\n",
    "            exit_price = None\n",
    "\n",
    "            if sl_hit and tp_hit:\n",
    "                exit_reason = \"exit_stop_intraday_both\"  # conservative\n",
    "                exit_price = pos.sl\n",
    "            elif sl_hit:\n",
    "                exit_reason = \"exit_stop\"\n",
    "                exit_price = pos.sl\n",
    "            elif tp_hit:\n",
    "                exit_reason = \"exit_target\"\n",
    "                exit_price = pos.tp\n",
    "            elif row[\"exit_rsi_ob\"] or row[\"exit_macd_bear\"] or row[\"exit_bb_upper_rev\"]:\n",
    "                exit_reason = \"exit_signal\"\n",
    "                exit_price = c\n",
    "\n",
    "            if exit_reason is not None:\n",
    "                px = _apply_slippage(exit_price, sl_bps)\n",
    "                proceeds = px * pos.shares\n",
    "                fees = calc_fees(pos.entry_price * pos.shares, proceeds)\n",
    "                pnl = proceeds - fees - (pos.entry_price * pos.shares)\n",
    "                cash += proceeds - fees\n",
    "                trades.append({\n",
    "                    \"ticker\": pos.ticker, \"side\": \"SELL\", \"date\": d,\n",
    "                    \"price\": px, \"shares\": pos.shares, \"reason\": exit_reason, \"pnl\": pnl\n",
    "                })\n",
    "                pos = None\n",
    "\n",
    "        # Entry for next day's open\n",
    "        if row[\"entry\"] == 1 and pos is None and (i + 1 < len(dates)):\n",
    "            next_d = dates[i+1]\n",
    "            next_open = sig.loc[next_d, \"Open\"]\n",
    "            atr = sig.loc[d, \"atr\"]\n",
    "            risk_per_share = max(1e-9, params[\"SL_ATR_MULT\"] * atr)\n",
    "\n",
    "            if fixed_sh > 0:\n",
    "                size = int(fixed_sh)\n",
    "            elif risk_pct > 0:\n",
    "                risk_cash = cash * risk_pct\n",
    "                size = int(max(0, math.floor(risk_cash / risk_per_share)))\n",
    "            else:\n",
    "                size = int(max(0, cash // max(1.0, next_open)))\n",
    "\n",
    "            if size > 0 and next_open > 0:\n",
    "                buy_px = _apply_slippage(next_open, sl_bps)\n",
    "                cost = buy_px * size\n",
    "                sl = buy_px - params[\"SL_ATR_MULT\"] * atr\n",
    "                tp = buy_px + params[\"TARGET_R\"] * (params[\"SL_ATR_MULT\"] * atr)\n",
    "                fees = calc_fees(cost, 0.0)\n",
    "                total_cost = cost + fees\n",
    "                if total_cost <= cash:\n",
    "                    cash -= total_cost\n",
    "                    pos = Position(ticker=ticker, entry_date=next_d, entry_price=buy_px, shares=size, sl=sl, tp=tp)\n",
    "                    trades.append({\n",
    "                        \"ticker\": ticker, \"side\": \"BUY\", \"date\": next_d,\n",
    "                        \"price\": buy_px, \"shares\": size, \"reason\": \"entry_rule\", \"pnl\": 0.0\n",
    "                    })\n",
    "\n",
    "        # Mark to market\n",
    "        mtm = cash\n",
    "        if pos is not None:\n",
    "            mtm += c * pos.shares\n",
    "        eq.loc[d] = mtm\n",
    "\n",
    "    # Force-close at the end\n",
    "    if pos is not None:\n",
    "        d = dates[-1]\n",
    "        c = sig.loc[d, \"Close\"]\n",
    "        px = _apply_slippage(c, sl_bps)\n",
    "        proceeds = px * pos.shares\n",
    "        fees = calc_fees(pos.entry_price * pos.shares, proceeds)\n",
    "        pnl = proceeds - fees - (pos.entry_price * pos.shares)\n",
    "        cash += proceeds - fees\n",
    "        trades.append({\n",
    "            \"ticker\": pos.ticker, \"side\": \"SELL\", \"date\": d,\n",
    "            \"price\": px, \"shares\": pos.shares, \"reason\": \"eod_force_close\", \"pnl\": pnl\n",
    "        })\n",
    "        eq.iloc[-1] = cash\n",
    "\n",
    "    trades_df = pd.DataFrame(trades, columns=[\"ticker\",\"side\",\"date\",\"price\",\"shares\",\"reason\",\"pnl\"])\n",
    "    return trades_df, eq.to_frame(name=ticker)\n",
    "\n",
    "# =========================\n",
    "# Metrics\n",
    "# =========================\n",
    "def _metrics_from_equity(eq: pd.Series) -> Dict:\n",
    "    if eq.empty:\n",
    "        return dict(sharpe=0.0, sortino=0.0, max_drawdown_pct=0.0, cagr_pct=0.0)\n",
    "    rets = eq.pct_change().fillna(0.0)\n",
    "    mean = rets.mean(); std = rets.std(ddof=0)\n",
    "    neg = rets[rets<0].std(ddof=0)\n",
    "    sharpe = 0.0 if std == 0 else (mean/std) * np.sqrt(252)\n",
    "    sortino = 0.0 if (neg == 0 or np.isnan(neg)) else (mean/neg) * np.sqrt(252)\n",
    "    dd = (eq / eq.cummax() - 1.0).min()\n",
    "    days = (eq.index[-1] - eq.index[0]).days\n",
    "    cagr = 0.0 if days <= 0 else (eq.iloc[-1]/eq.iloc[0])**(365.25/days) - 1.0\n",
    "    return dict(sharpe=float(sharpe), sortino=float(sortino),\n",
    "                max_drawdown_pct=100*float(dd), cagr_pct=100*float(cagr))\n",
    "\n",
    "def evaluate(trades_all: pd.DataFrame, equity_all: pd.DataFrame) -> Dict:\n",
    "    eq = equity_all[\"equity\"] if (\"equity\" in equity_all.columns) else pd.Series(dtype=float)\n",
    "    metrics = _metrics_from_equity(eq)\n",
    "\n",
    "    closed = trades_all[trades_all[\"side\"]==\"SELL\"]\n",
    "    n = int(len(closed))\n",
    "    win_rate = 100.0 * (closed[\"pnl\"] > 0).sum() / n if n > 0 else 0.0\n",
    "    avg_pnl = float(closed[\"pnl\"].mean()) if n > 0 else 0.0\n",
    "    gp = closed[\"pnl\"].clip(lower=0).sum()\n",
    "    gl = -closed[\"pnl\"].clip(upper=0).sum()\n",
    "    profit_factor = float(gp/gl) if gl > 0 else (float(\"inf\") if gp > 0 else 0.0)\n",
    "\n",
    "    metrics.update(dict(\n",
    "        trades=n,\n",
    "        win_rate_pct=float(win_rate),\n",
    "        avg_pnl_inr=float(avg_pnl),\n",
    "        profit_factor=float(profit_factor),\n",
    "        final_equity_inr=float(eq.iloc[-1]) if not eq.empty else CONFIG[\"START_CAPITAL_INR\"]\n",
    "    ))\n",
    "    return metrics\n",
    "\n",
    "# =========================\n",
    "# Run once over all tickers (with capital allocation fix)\n",
    "# =========================\n",
    "def run_once(params: Dict) -> Tuple[pd.DataFrame, pd.DataFrame, Dict]:\n",
    "    tickers = list(CONFIG[\"TICKERS\"])\n",
    "    start, end = CONFIG[\"START_DATE\"], CONFIG[\"END_DATE\"]\n",
    "    cache, force = CONFIG[\"CACHE_DIR\"], CONFIG[\"FORCE_REFRESH\"]\n",
    "\n",
    "    # Load data & build signals\n",
    "    data_map = {}\n",
    "    for tkr in tickers:\n",
    "        try:\n",
    "            data_map[tkr] = load_yf(tkr, start, end, cache, force)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"[DATA] {tkr}: {e}\")\n",
    "\n",
    "    if not data_map:\n",
    "        raise RuntimeError(\"No data loaded for any ticker.\")\n",
    "\n",
    "    sig_map = {tkr: build_signals(df, params) for tkr, df in data_map.items()}\n",
    "\n",
    "    # ---- Capital allocation fix ----\n",
    "    n_tickers = len(sig_map)\n",
    "    if CONFIG[\"ALLOW_MULTIPLE_POSITIONS\"]:\n",
    "        if CONFIG.get(\"CAPITAL_ALLOCATION\", \"split\") == \"full\":\n",
    "            per_start = CONFIG[\"START_CAPITAL_INR\"]     # optimistic; we'll rebase later\n",
    "        else:\n",
    "            per_start = CONFIG[\"START_CAPITAL_INR\"] / max(1, n_tickers)  # split equally\n",
    "    else:\n",
    "        per_start = CONFIG[\"START_CAPITAL_INR\"]\n",
    "\n",
    "    # Simulate each ticker independently; sum MTM and rebase to start capital\n",
    "    trades_list, eq_list = [], []\n",
    "    for tkr, sig in sig_map.items():\n",
    "        tdf, eq = simulate_ticker(tkr, sig, params, start_capital=per_start)\n",
    "        trades_list.append(tdf); eq_list.append(eq)\n",
    "\n",
    "    trades_all = pd.concat(trades_list, ignore_index=True) if trades_list else pd.DataFrame(\n",
    "        columns=[\"ticker\",\"side\",\"date\",\"price\",\"shares\",\"reason\",\"pnl\"]\n",
    "    )\n",
    "\n",
    "    if eq_list:\n",
    "        eq_all = pd.concat(eq_list, axis=1).fillna(method=\"ffill\").fillna(0.0)\n",
    "        # Rebase summed equity to START_CAPITAL_INR to avoid double counting book capital\n",
    "        first_val = float(eq_all.sum(axis=1).iloc[0])\n",
    "        if first_val == 0:\n",
    "            equity = pd.Series(CONFIG[\"START_CAPITAL_INR\"], index=eq_all.index, name=\"equity\")\n",
    "        else:\n",
    "            scale = CONFIG[\"START_CAPITAL_INR\"]/first_val\n",
    "            equity = (eq_all.sum(axis=1) * scale).rename(\"equity\")\n",
    "        equity_df = equity.to_frame()\n",
    "    else:\n",
    "        equity_df = pd.DataFrame(columns=[\"equity\"])\n",
    "\n",
    "    metrics = evaluate(trades_all, equity_df)\n",
    "    return trades_all, equity_df, metrics\n",
    "\n",
    "# =========================\n",
    "# Grid helpers\n",
    "# =========================\n",
    "def _grid_run_combo(args):\n",
    "    \"\"\"Top-level worker usable by threads/processes (picklable).\"\"\"\n",
    "    vals, base, keys, run_once_fn = args\n",
    "    params = base.copy()\n",
    "    for k, v in zip(keys, vals):\n",
    "        params[k] = v\n",
    "    try:\n",
    "        _, _, m = run_once_fn(params)\n",
    "        return {\"params\": json.dumps(params), **m}\n",
    "    except Exception as e:\n",
    "        return {\"params\": json.dumps(params), \"error\": str(e)}\n",
    "\n",
    "def _score_row(row: dict) -> tuple:\n",
    "    def getf(k):\n",
    "        try:\n",
    "            return float(row.get(k, float(\"nan\")))\n",
    "        except Exception:\n",
    "            return float(\"nan\")\n",
    "    pri = getf(CONFIG.get(\"GRID_SCORE_PRIMARY\", \"sharpe\"))\n",
    "    sec = getf(CONFIG.get(\"GRID_SCORE_SECONDARY\", \"profit_factor\"))\n",
    "    ter = getf(CONFIG.get(\"GRID_SCORE_TERTIARY\", \"cagr_pct\"))\n",
    "    pri = pri if np.isfinite(pri) else -1e9\n",
    "    sec = sec if np.isfinite(sec) else -1e9\n",
    "    ter = ter if np.isfinite(ter) else -1e9\n",
    "    return (pri, sec, ter)\n",
    "\n",
    "def _short_params(p_json: str) -> str:\n",
    "    try:\n",
    "        p = json.loads(p_json)\n",
    "        keys = [\"USE_VOLUME_SPIKE\",\"VOL_MULT\",\"EMA_FAST\",\"EMA_SLOW\",\n",
    "                \"MACD_FAST\",\"MACD_SLOW\",\"MACD_SIG\",\n",
    "                \"BB_LEN\",\"BB_STD\",\n",
    "                \"RSI_OVERSOLD\",\"RSI_OVERBOUGHT\",\n",
    "                \"SL_ATR_MULT\",\"TARGET_R\"]\n",
    "        return \"{\" + \", \".join(f\"{k}={p[k]}\" for k in keys if k in p) + \"}\"\n",
    "    except Exception:\n",
    "        return p_json\n",
    "\n",
    "# =========================\n",
    "# Grid search (logged, constrained, optional capping)\n",
    "# =========================\n",
    "def grid_search() -> pd.DataFrame:\n",
    "    base = dict(\n",
    "        EMA_FAST=CONFIG[\"EMA_FAST\"], EMA_SLOW=CONFIG[\"EMA_SLOW\"],\n",
    "        RSI_LEN=CONFIG[\"RSI_LEN\"], RSI_OVERSOLD=CONFIG[\"RSI_OVERSOLD\"], RSI_OVERBOUGHT=CONFIG[\"RSI_OVERBOUGHT\"],\n",
    "        MACD_FAST=CONFIG[\"MACD_FAST\"], MACD_SLOW=CONFIG[\"MACD_SLOW\"], MACD_SIG=CONFIG[\"MACD_SIG\"],\n",
    "        BB_LEN=CONFIG[\"BB_LEN\"], BB_STD=CONFIG[\"BB_STD\"],\n",
    "        VOL_SMA=CONFIG[\"VOL_SMA\"], VOL_MULT=CONFIG[\"VOL_MULT\"], USE_VOLUME_SPIKE=CONFIG[\"USE_VOLUME_SPIKE\"],\n",
    "        ATR_LEN=CONFIG[\"ATR_LEN\"], SL_ATR_MULT=CONFIG[\"SL_ATR_MULT\"], TARGET_R=CONFIG[\"TARGET_R\"]\n",
    "    )\n",
    "\n",
    "    grid = CONFIG[\"GRID\"]\n",
    "    keys = list(grid.keys())\n",
    "    raw = list(itertools.product(*[grid[k] for k in keys]))\n",
    "\n",
    "    # ---- constraint filter (avoid silly combos) ----\n",
    "    filtered = []\n",
    "    for vals in raw:\n",
    "        d = {k: v for k, v in zip(keys, vals)}\n",
    "        # EMA fast < slow\n",
    "        ema_fast = d.get(\"EMA_FAST\", base[\"EMA_FAST\"])\n",
    "        ema_slow = d.get(\"EMA_SLOW\", base[\"EMA_SLOW\"])\n",
    "        if ema_fast >= ema_slow:\n",
    "            continue\n",
    "        # MACD fast < slow (if provided)\n",
    "        macd_fast = d.get(\"MACD_FAST\", base[\"MACD_FAST\"])\n",
    "        macd_slow = d.get(\"MACD_SLOW\", base[\"MACD_SLOW\"])\n",
    "        if macd_fast >= macd_slow:\n",
    "            continue\n",
    "        # BB std must be positive\n",
    "        bb_std = d.get(\"BB_STD\", base[\"BB_STD\"])\n",
    "        if float(bb_std) <= 0:\n",
    "            continue\n",
    "        filtered.append(vals)\n",
    "\n",
    "    # ---- optional random subsample cap ----\n",
    "    maxc = int(CONFIG.get(\"GRID_MAX_COMBOS\") or 0)\n",
    "    if maxc and len(filtered) > maxc:\n",
    "        rng = np.random.default_rng(CONFIG.get(\"GRID_RANDOM_SEED\", 42))\n",
    "        idx = rng.choice(len(filtered), size=maxc, replace=False)\n",
    "        filtered = [filtered[i] for i in idx]\n",
    "\n",
    "    args_list = [(vals, base, keys, run_once) for vals in filtered]\n",
    "    total = len(args_list)\n",
    "    logging.info(f\"[GRID] prepared {total} combos (from {len(raw)} raw) after constraints/cap\")\n",
    "\n",
    "    # Backend select\n",
    "    backend = CONFIG.get(\"GRID_BACKEND\", \"auto\")\n",
    "    if backend == \"auto\":\n",
    "        backend = \"thread\" if in_notebook() else \"process\"\n",
    "    nworkers = max(1, min(CONFIG[\"GRID_PROCESSES\"], os.cpu_count() or 1))\n",
    "    logging.info(f\"[GRID] backend={backend} | workers={nworkers}\")\n",
    "\n",
    "    rows = []\n",
    "    best = None\n",
    "    best_score = (-1e9, -1e9, -1e9)\n",
    "    t0 = time.time()\n",
    "\n",
    "    def handle_row(i: int, row: dict):\n",
    "        nonlocal best, best_score, rows\n",
    "        rows.append(row)\n",
    "        if \"error\" in row:\n",
    "            logging.warning(f\"[{i}/{total}] error: {row['error']} | params={_short_params(row['params'])}\")\n",
    "        else:\n",
    "            score = _score_row(row)\n",
    "            is_best = score > best_score\n",
    "            if is_best:\n",
    "                best, best_score = row, score\n",
    "            # progress log\n",
    "            log_every = max(1, int(CONFIG.get(\"GRID_LOG_EVERY\", 1)))\n",
    "            if (i % log_every == 0) or is_best:\n",
    "                logging.info(\n",
    "                    f\"[{i}/{total}] sh={row.get('sharpe')} pf={row.get('profit_factor')} \"\n",
    "                    f\"cagr={row.get('cagr_pct')}% maxDD={row.get('max_drawdown_pct')}% \"\n",
    "                    f\"| best_by_{CONFIG.get('GRID_SCORE_PRIMARY','sharpe')} \"\n",
    "                    f\"sh={best.get('sharpe') if best else None}, \"\n",
    "                    f\"pf={best.get('profit_factor') if best else None}, \"\n",
    "                    f\"cagr={best.get('cagr_pct') if best else None}% \"\n",
    "                    f\"| params={_short_params(row['params'])}\"\n",
    "                )\n",
    "        # partial save\n",
    "        save_every = int(CONFIG.get(\"GRID_PARTIAL_SAVE_EVERY\", 0) or 0)\n",
    "        if save_every and (i % save_every == 0):\n",
    "            pd.DataFrame(rows).to_csv(\"grid_results_partial.csv\", index=False)\n",
    "\n",
    "    # Execute\n",
    "    if nworkers == 1 or backend == \"thread\":\n",
    "        iterator = map(_grid_run_combo, args_list)\n",
    "        if nworkers > 1 and backend == \"thread\":\n",
    "            with ThreadPool(processes=nworkers) as pool:\n",
    "                iterator = pool.imap_unordered(_grid_run_combo, args_list)\n",
    "                for i, row in enumerate(iterator, start=1):\n",
    "                    handle_row(i, row)\n",
    "        else:\n",
    "            for i, row in enumerate(iterator, start=1):\n",
    "                handle_row(i, row)\n",
    "    else:\n",
    "        ctx = mp.get_context(\"spawn\")\n",
    "        with ctx.Pool(processes=nworkers) as pool:\n",
    "            for i, row in enumerate(pool.imap_unordered(_grid_run_combo, args_list), start=1):\n",
    "                handle_row(i, row)\n",
    "\n",
    "    # Finalize\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(\"grid_results.csv\", index=False)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    logging.info(f\"[GRID] Done {total} combos in {dt:.1f}s\")\n",
    "    if df.empty:\n",
    "        logging.warning(\"[GRID] No results. (Check data/rules.)\")\n",
    "        return df\n",
    "\n",
    "    # Top 10 summary\n",
    "    df[\"_score_tuple\"] = df.apply(_score_row, axis=1)\n",
    "    df_sorted = df.sort_values(\"_score_tuple\", ascending=False).drop(columns=[\"_score_tuple\"])\n",
    "    top = df_sorted.head(10)\n",
    "    cols = [\"params\",\"trades\",\"win_rate_pct\",\"profit_factor\",\"sharpe\",\"sortino\",\n",
    "            \"max_drawdown_pct\",\"cagr_pct\",\"final_equity_inr\"]\n",
    "    logging.info(\"[GRID] Top results:\")\n",
    "    try:\n",
    "        print(top[cols].to_string(index=False))\n",
    "    except Exception:\n",
    "        print(top.to_string(index=False))\n",
    "    return df_sorted\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    setup_logging(\"INFO\")\n",
    "    print(\"=== Swing Strategy: EMA/RSI/MACD/Bollinger/ATR ===\")\n",
    "    print(f\"Symbols:     {len(CONFIG['TICKERS'])} from CONFIG[TICKERS]\")\n",
    "    print(f\"Period:      {CONFIG['START_DATE']} .. {CONFIG['END_DATE']}\")\n",
    "    print(f\"Fees:        {'ON' if CONFIG['APPLY_FEES'] else 'OFF'} | Start Capital: ₹{CONFIG['START_CAPITAL_INR']:,}\")\n",
    "    print(f\"VolumeGate:  USE_VOLUME_SPIKE={CONFIG['USE_VOLUME_SPIKE']} VOL_MULT={CONFIG['VOL_MULT']}\")\n",
    "    print(f\"Multi-Pos:   {CONFIG['ALLOW_MULTIPLE_POSITIONS']} | Allocation: {CONFIG['CAPITAL_ALLOCATION']}\")\n",
    "    print(f\"Grid:        {'ON' if CONFIG['RUN_GRID'] else 'OFF'} \"\n",
    "          f\"(backend={CONFIG['GRID_BACKEND']}, workers={CONFIG['GRID_PROCESSES']})\")\n",
    "\n",
    "    if CONFIG[\"RUN_GRID\"]:\n",
    "        df = grid_search()\n",
    "        if not df.empty:\n",
    "            best = df.iloc[0]\n",
    "            print(\"\\n[GRID] BEST:\")\n",
    "            print(f\"  score_by={CONFIG['GRID_SCORE_PRIMARY']}, \"\n",
    "                  f\"sh={best.get('sharpe')}, pf={best.get('profit_factor')}, \"\n",
    "                  f\"cagr={best.get('cagr_pct')}%, maxDD={best.get('max_drawdown_pct')}%\")\n",
    "            print(f\"  params={_short_params(best['params'])}\")\n",
    "        return\n",
    "\n",
    "    # Base run with CONFIG params\n",
    "    params = dict(\n",
    "        EMA_FAST=CONFIG[\"EMA_FAST\"], EMA_SLOW=CONFIG[\"EMA_SLOW\"],\n",
    "        RSI_LEN=CONFIG[\"RSI_LEN\"], RSI_OVERSOLD=CONFIG[\"RSI_OVERSOLD\"], RSI_OVERBOUGHT=CONFIG[\"RSI_OVERBOUGHT\"],\n",
    "        MACD_FAST=CONFIG[\"MACD_FAST\"], MACD_SLOW=CONFIG[\"MACD_SLOW\"], MACD_SIG=CONFIG[\"MACD_SIG\"],\n",
    "        BB_LEN=CONFIG[\"BB_LEN\"], BB_STD=CONFIG[\"BB_STD\"],\n",
    "        VOL_SMA=CONFIG[\"VOL_SMA\"], VOL_MULT=CONFIG[\"VOL_MULT\"], USE_VOLUME_SPIKE=CONFIG[\"USE_VOLUME_SPIKE\"],\n",
    "        ATR_LEN=CONFIG[\"ATR_LEN\"], SL_ATR_MULT=CONFIG[\"SL_ATR_MULT\"], TARGET_R=CONFIG[\"TARGET_R\"]\n",
    "    )\n",
    "\n",
    "    trades, equity, metrics = run_once(params)\n",
    "\n",
    "    # Save outputs (robust)\n",
    "    if trades is None or trades.empty:\n",
    "        logging.info(\"[INFO] No trades generated.\")\n",
    "        pd.DataFrame(columns=[\"ticker\",\"side\",\"date\",\"price\",\"shares\",\"reason\",\"pnl\"]).to_csv(\"trades.csv\", index=False)\n",
    "    else:\n",
    "        if \"date\" not in trades.columns and isinstance(trades.index, pd.DatetimeIndex):\n",
    "            trades = trades.reset_index().rename(columns={\"index\": \"date\"})\n",
    "        sort_keys = [c for c in [\"date\",\"ticker\",\"side\"] if c in trades.columns]\n",
    "        trades = trades.sort_values(sort_keys) if sort_keys else trades\n",
    "        trades.to_csv(\"trades.csv\", index=False)\n",
    "\n",
    "    if equity is None or equity.empty:\n",
    "        pd.DataFrame(columns=[\"equity\"]).to_csv(\"equity.csv\", index=True)\n",
    "    else:\n",
    "        equity.to_csv(\"equity.csv\", index=True)\n",
    "\n",
    "    print(\"\\n=== Metrics ===\")\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "    print(\"\\nFiles saved:\\n  - trades.csv\\n  - equity.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Keep this guard for multiprocessing safety on macOS/Windows\n",
    "    try:\n",
    "        mp.set_start_method(\"spawn\", force=True)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
