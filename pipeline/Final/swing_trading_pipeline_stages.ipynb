{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b570e6b7",
   "metadata": {},
   "source": [
    "\n",
    "# üîÑ Swing Trading Bot ‚Äî End‚Äëto‚ÄëEnd Pipeline (NSE/BSE, India)\n",
    "\n",
    "**Version:** 2025-09-28  \n",
    "**Timezone:** Asia/Kolkata (IST)  \n",
    "\n",
    "This notebook implements a **stage‚Äëbased, modular pipeline** for **swing trading** on the Indian stock market (NSE/BSE).  \n",
    "Each stage is self‚Äëcontained and documented.\n",
    "\n",
    "> ‚ö†Ô∏è **Disclaimer:** Educational use only. Validate and trade responsibly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907c5cb",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 0 ‚Äî Environment & Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8bddf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional installs (uncomment to run locally)\n",
    "# %pip install -U yfinance pandas numpy matplotlib scikit-learn python-dateutil pytz\n",
    "# %pip install -U lightgbm  # optional for ML filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034cbadc",
   "metadata": {},
   "source": [
    "\n",
    "## Global Imports & Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cb1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CONFIG ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, math, time, json, warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    print(\"yfinance not available. Install with `%pip install yfinance` if you plan to download data.\")\n",
    "\n",
    "# ML (optional)\n",
    "try:\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "pd.set_option(\"display.width\", 140)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "IST = pytz.timezone(\"Asia/Kolkata\")\n",
    "\n",
    "CONFIG: Dict[str, Any] = {\n",
    "    \"DATA\": {\n",
    "        \"tickers\": [\"HDFCBANK.NS\", \"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"ICICIBANK.NS\"],\n",
    "        \"start_date\": \"2018-01-01\",\n",
    "        \"end_date\": None,  # None = today\n",
    "        \"interval\": \"1d\",\n",
    "        \"cache_dir\": \"cache/data\",\n",
    "        \"force_refresh\": False\n",
    "    },\n",
    "    \"FEATURES\": {\n",
    "        \"use_indicators\": True,\n",
    "        \"indicators\": [\"SMA20\", \"SMA50\", \"EMA20\", \"RSI14\", \"MACD_12_26_9\", \"BBANDS_20_2\", \"ATR14\", \"ADX14\"],\n",
    "        \"include_patterns\": True,\n",
    "        \"include_stats\": True\n",
    "    },\n",
    "    \"SCREEN\": {\n",
    "        \"min_avg_volume\": 200000.0,\n",
    "        \"price_min\": 50.0,\n",
    "        \"price_max\": 5000.0,\n",
    "        \"trend_rule\": \"SMA20_gt_SMA50\",\n",
    "        \"atr_pct_range\": (0.5, 4.5)\n",
    "    },\n",
    "    \"SIGNAL\": {\n",
    "        \"rules\": [\n",
    "            \"SMA20_gt_SMA50\",\n",
    "            \"RSI_gt_55\",\n",
    "            \"MACD_hist_gt_0\",\n",
    "            \"Close_gt_BB_mid\"\n",
    "        ],\n",
    "        \"ml_filter_enabled\": False,\n",
    "        \"ml_prob_threshold\": 0.60,\n",
    "        \"label_horizon_days\": 10,\n",
    "        \"label_thr_pct\": 4.0\n",
    "    },\n",
    "    \"RISK\": {\n",
    "        \"initial_capital\": 500000.0,\n",
    "        \"risk_per_trade_pct\": 1.0,\n",
    "        \"atr_stop_mult\": 1.5,\n",
    "        \"atr_trail_mult\": 1.5,\n",
    "        \"max_open_positions\": 8,\n",
    "        \"max_hold_days\": 12\n",
    "    },\n",
    "    \"COSTS\": {\n",
    "        \"brokerage_per_order\": 20.0,\n",
    "        \"slippage_bps\": 5.0,\n",
    "        \"stt_equity_deliv_bps\": 100.0,\n",
    "        \"exchange_txn_bps\": 3.25,\n",
    "        \"clearing_bps\": 0.0,\n",
    "        \"stamp_duty_bps_buy\": 15.0,\n",
    "        \"gst_pct_on_brokerage\": 18.0\n",
    "    },\n",
    "    \"OUTPUTS\": {\n",
    "        \"base_dir\": \"outputs\",\n",
    "        \"save_equity_plot\": True,\n",
    "        \"save_csv\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "if CONFIG[\"DATA\"][\"end_date\"] is None:\n",
    "    CONFIG[\"DATA\"][\"end_date\"] = datetime.now(IST).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_outdir() -> Path:\n",
    "    d = datetime.now(IST).strftime(\"%Y-%m-%d\")\n",
    "    p = Path(CONFIG[\"OUTPUTS\"][\"base_dir\"]) / d\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "get_outdir()\n",
    "print(\"‚úÖ CONFIG ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5164a25",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 1 ‚Äî Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e0b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 1 ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_dir(path: str | Path) -> Path:\n",
    "    p = Path(path)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def normalize_ohlcv(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    rename_map = {\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\"Adj Close\":\"adj_close\",\"Volume\":\"volume\"}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        if \"Date\" in df.columns:\n",
    "            df.set_index(pd.to_datetime(df[\"Date\"]), inplace=True)\n",
    "            df.drop(columns=[\"Date\"], inplace=True, errors=\"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Missing DatetimeIndex or Date column\")\n",
    "    df.index = df.index.tz_localize(\"UTC\").tz_convert(IST) if df.index.tz is None else df.index.tz_convert(IST)\n",
    "    df = df.sort_index()\n",
    "    return df[[\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"]].dropna(how=\"any\")\n",
    "\n",
    "def load_ticker_df(ticker: str, start: str, end: str, interval: str, cache_dir: str, force_refresh: bool=False) -> pd.DataFrame:\n",
    "    cache_dir = ensure_dir(cache_dir)\n",
    "    fp = Path(cache_dir) / f\"{ticker}_{interval}.parquet\"\n",
    "    if fp.exists() and not force_refresh:\n",
    "        try:\n",
    "            return pd.read_parquet(fp)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if \"yf\" not in globals():\n",
    "        raise ImportError(\"Install yfinance or provide cached data.\")\n",
    "    print(f\"Downloading {ticker} ...\")\n",
    "    raw = yf.download(ticker, start=start, end=end, interval=interval, auto_adjust=False, progress=False)\n",
    "    if raw is None or raw.empty:\n",
    "        raise ValueError(f\"No data for {ticker}\")\n",
    "    df = normalize_ohlcv(raw)\n",
    "    df.to_parquet(fp)\n",
    "    return df\n",
    "\n",
    "def load_universe(config: Dict[str, Any]) -> Dict[str, pd.DataFrame]:\n",
    "    dcfg = config[\"DATA\"]\n",
    "    out = {}\n",
    "    for t in dcfg[\"tickers\"]:\n",
    "        try:\n",
    "            out[t] = load_ticker_df(t, dcfg[\"start_date\"], dcfg[\"end_date\"], dcfg[\"interval\"], dcfg[\"cache_dir\"], dcfg[\"force_refresh\"])\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è\", t, e)\n",
    "    return out\n",
    "\n",
    "print(\"‚úÖ Stage 1 ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb38d1b",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 2 ‚Äî Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc3d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 2 ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def SMA(s: pd.Series, n: int) -> pd.Series:\n",
    "    return s.rolling(n, min_periods=n).mean()\n",
    "\n",
    "def EMA(s: pd.Series, n: int) -> pd.Series:\n",
    "    return s.ewm(span=n, adjust=False).mean()\n",
    "\n",
    "def RSI(close: pd.Series, n: int = 14) -> pd.Series:\n",
    "    d = close.diff()\n",
    "    up = np.where(d > 0, d, 0.0)\n",
    "    dn = np.where(d < 0, -d, 0.0)\n",
    "    roll_up = pd.Series(up, index=close.index).ewm(alpha=1/n, adjust=False).mean()\n",
    "    roll_dn = pd.Series(dn, index=close.index).ewm(alpha=1/n, adjust=False).mean()\n",
    "    rs = roll_up / (roll_dn + 1e-12)\n",
    "    return 100.0 - (100.0 / (1.0 + rs))\n",
    "\n",
    "def MACD(close: pd.Series, fast: int=12, slow: int=26, signal: int=9):\n",
    "    ef, es = EMA(close, fast), EMA(close, slow)\n",
    "    macd = ef - es\n",
    "    sig = EMA(macd, signal)\n",
    "    hist = macd - sig\n",
    "    return macd, sig, hist\n",
    "\n",
    "def true_range(df: pd.DataFrame) -> pd.Series:\n",
    "    pc = df[\"close\"].shift(1)\n",
    "    return pd.concat([df[\"high\"]-df[\"low\"], (df[\"high\"]-pc).abs(), (df[\"low\"]-pc).abs()], axis=1).max(axis=1)\n",
    "\n",
    "def ATR(df: pd.DataFrame, n: int=14) -> pd.Series:\n",
    "    return true_range(df).ewm(alpha=1/n, adjust=False).mean()\n",
    "\n",
    "def Bollinger(close: pd.Series, n: int=20, nstd: float=2.0):\n",
    "    mid = close.rolling(n, min_periods=n).mean()\n",
    "    std = close.rolling(n, min_periods=n).std(ddof=0)\n",
    "    return mid + nstd*std, mid, mid - nstd*std\n",
    "\n",
    "def ADX(df: pd.DataFrame, n: int=14) -> pd.Series:\n",
    "    up = df[\"high\"].diff()\n",
    "    dn = -df[\"low\"].diff()\n",
    "    plus_dm = np.where((up > dn) & (up > 0), up, 0.0)\n",
    "    minus_dm = np.where((dn > up) & (dn > 0), dn, 0.0)\n",
    "    tr = true_range(df)\n",
    "    atr = tr.ewm(alpha=1/n, adjust=False).mean()\n",
    "    plus_di = 100 * (pd.Series(plus_dm, index=df.index).ewm(alpha=1/n, adjust=False).mean() / (atr + 1e-12))\n",
    "    minus_di = 100 * (pd.Series(minus_dm, index=df.index).ewm(alpha=1/n, adjust=False).mean() / (atr + 1e-12))\n",
    "    dx = 100 * ((plus_di - minus_di).abs() / ((plus_di + minus_di) + 1e-12))\n",
    "    return dx.ewm(alpha=1/n, adjust=False).mean()\n",
    "\n",
    "def bullish_engulfing(df: pd.DataFrame) -> pd.Series:\n",
    "    o, c = df[\"open\"], df[\"close\"]\n",
    "    o1, c1 = o.shift(1), c.shift(1)\n",
    "    return ((c > o) & (c1 < o1) & (c >= o1) & (o <= c1)).astype(int)\n",
    "\n",
    "def bearish_engulfing(df: pd.DataFrame) -> pd.Series:\n",
    "    o, c = df[\"open\"], df[\"close\"]\n",
    "    o1, c1 = o.shift(1), c.shift(1)\n",
    "    return ((c < o) & (c1 > o1) & (c <= o1) & (o >= c1)).astype(int)\n",
    "\n",
    "def doji(df: pd.DataFrame, tol: float=0.1) -> pd.Series:\n",
    "    body = (df[\"close\"] - df[\"open\"]).abs()\n",
    "    rng = (df[\"high\"] - df[\"low\"]).replace(0, np.nan)\n",
    "    return (body / rng < tol).fillna(0).astype(int)\n",
    "\n",
    "def hammer(df: pd.DataFrame) -> pd.Series:\n",
    "    o, h, l, c = df[\"open\"], df[\"high\"], df[\"low\"], df[\"close\"]\n",
    "    body = (c - o).abs()\n",
    "    lower_shadow = o.combine(c, min) - l\n",
    "    upper_shadow = h - o.combine(c, max)\n",
    "    return ((lower_shadow >= 2 * body) & (upper_shadow <= body)).astype(int)\n",
    "\n",
    "def hanging_man(df: pd.DataFrame) -> pd.Series:\n",
    "    return hammer(df)\n",
    "\n",
    "def add_features(df: pd.DataFrame, cfg: Dict[str, Any]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if cfg[\"FEATURES\"][\"use_indicators\"]:\n",
    "        if \"SMA20\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            df[\"SMA20\"] = SMA(df[\"close\"], 20)\n",
    "        if \"SMA50\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            df[\"SMA50\"] = SMA(df[\"close\"], 50)\n",
    "        if \"EMA20\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            df[\"EMA20\"] = EMA(df[\"close\"], 20)\n",
    "        if \"RSI14\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            df[\"RSI14\"] = RSI(df[\"close\"], 14)\n",
    "        if \"MACD_12_26_9\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            macd, macds, mach = MACD(df[\"close\"], 12, 26, 9)\n",
    "            df[\"MACD\"] = macd\n",
    "            df[\"MACD_signal\"] = macds\n",
    "            df[\"MACD_hist\"] = mach\n",
    "        if \"BBANDS_20_2\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            bb_u, bb_m, bb_l = Bollinger(df[\"close\"], 20, 2.0)\n",
    "            df[\"BB_upper\"] = bb_u\n",
    "            df[\"BB_mid\"] = bb_m\n",
    "            df[\"BB_lower\"] = bb_l\n",
    "        if \"ATR14\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            df[\"ATR14\"] = ATR(df, 14)\n",
    "        if \"ADX14\" in cfg[\"FEATURES\"][\"indicators\"]:\n",
    "            df[\"ADX14\"] = ADX(df, 14)\n",
    "\n",
    "    if cfg[\"FEATURES\"][\"include_patterns\"]:\n",
    "        df[\"bullish_engulfing\"] = bullish_engulfing(df)\n",
    "        df[\"bearish_engulfing\"] = bearish_engulfing(df)\n",
    "        df[\"doji\"] = doji(df)\n",
    "        df[\"hammer\"] = hammer(df)\n",
    "        df[\"hanging_man\"] = hanging_man(df)\n",
    "\n",
    "    if cfg[\"FEATURES\"][\"include_stats\"]:\n",
    "        df[\"ret_1d\"] = df[\"close\"].pct_change()\n",
    "        df[\"ret_5d\"] = df[\"close\"].pct_change(5)\n",
    "        df[\"vol_20\"] = df[\"ret_1d\"].rolling(20).std() * np.sqrt(252)\n",
    "        df[\"ATR_pct\"] = (df[\"ATR14\"] / df[\"close\"]) * 100.0\n",
    "\n",
    "    return df.dropna().copy()\n",
    "\n",
    "print(\"‚úÖ Stage 2 ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abcb4ac",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 3 ‚Äî Screening / Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8590c260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 3 ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def passes_screen(df: pd.DataFrame, cfg: Dict[str, Any]) -> bool:\n",
    "    if df is None or len(df) < 100:\n",
    "        return False\n",
    "    tail = df.tail(60)\n",
    "    last = df.iloc[-1]\n",
    "\n",
    "    if tail[\"volume\"].mean() < cfg[\"SCREEN\"][\"min_avg_volume\"]:\n",
    "        return False\n",
    "    if not (cfg[\"SCREEN\"][\"price_min\"] <= last[\"close\"] <= cfg[\"SCREEN\"][\"price_max\"]):\n",
    "        return False\n",
    "    if cfg[\"SCREEN\"][\"trend_rule\"] == \"SMA20_gt_SMA50\" and not (last.get(\"SMA20\", np.nan) > last.get(\"SMA50\", np.nan)):\n",
    "        return False\n",
    "    lo, hi = cfg[\"SCREEN\"][\"atr_pct_range\"]\n",
    "    if \"ATR_pct\" in last.index and not (lo <= last[\"ATR_pct\"] <= hi):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ Stage 3 ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c947ce",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 4 ‚Äî Signal Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd1c942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 4 ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rule_conditions_satisfied(row: pd.Series, rules: List[str]) -> bool:\n",
    "    conds = []\n",
    "    for r in rules:\n",
    "        if r == \"SMA20_gt_SMA50\":\n",
    "            conds.append(row.get(\"SMA20\", np.nan) > row.get(\"SMA50\", np.nan))\n",
    "        elif r == \"RSI_gt_55\":\n",
    "            conds.append(row.get(\"RSI14\", 0) > 55)\n",
    "        elif r == \"MACD_hist_gt_0\":\n",
    "            conds.append(row.get(\"MACD_hist\", -1e9) > 0)\n",
    "        elif r == \"Close_gt_BB_mid\":\n",
    "            conds.append(row.get(\"close\", np.nan) > row.get(\"BB_mid\", -1e9))\n",
    "        elif r == \"Bullish_Engulfing\":\n",
    "            conds.append(row.get(\"bullish_engulfing\", 0) == 1)\n",
    "        else:\n",
    "            conds.append(True)\n",
    "    return all(bool(x) for x in conds)\n",
    "\n",
    "def generate_entry_signals(df: pd.DataFrame, cfg: Dict[str, Any]) -> pd.Series:\n",
    "    rules = cfg[\"SIGNAL\"][\"rules\"]\n",
    "    return df.apply(lambda row: 1 if rule_conditions_satisfied(row, rules) else 0, axis=1).astype(int)\n",
    "\n",
    "def make_ml_dataset(df: pd.DataFrame, horizon_days: int, thr_pct: float):\n",
    "    # Label = 1 if max forward return within horizon_days >= thr_pct\n",
    "    fut_max = df[\"close\"].rolling(horizon_days).max().shift(-horizon_days+1)\n",
    "    fwd_ret_pct = (fut_max / df[\"close\"] - 1.0) * 100.0\n",
    "    y = (fwd_ret_pct >= thr_pct).astype(int)\n",
    "\n",
    "    X = df[[\n",
    "        \"SMA20\",\"SMA50\",\"EMA20\",\"RSI14\",\"MACD\",\"MACD_signal\",\"MACD_hist\",\n",
    "        \"BB_upper\",\"BB_mid\",\"BB_lower\",\"ATR14\",\"ADX14\",\"ATR_pct\",\n",
    "        \"bullish_engulfing\",\"bearish_engulfing\",\"doji\",\"hammer\",\"hanging_man\"\n",
    "    ]].copy()\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    y = y.loc[X.index]\n",
    "    return X, y\n",
    "\n",
    "def train_ml_filter(df: pd.DataFrame, cfg: Dict[str, Any]):\n",
    "    # Logistic Regression baseline with TimeSeriesSplit CV\n",
    "    try:\n",
    "        X, y = make_ml_dataset(df, cfg[\"SIGNAL\"][\"label_horizon_days\"], cfg[\"SIGNAL\"][\"label_thr_pct\"])\n",
    "    except Exception as e:\n",
    "        print(\"ML dataset error:\", e)\n",
    "        return None\n",
    "    if len(X) < 200:\n",
    "        print(\"Not enough data for ML filter; skipping.\")\n",
    "        return None\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    best_model, best_auc = None, -1\n",
    "    for tr, va in tscv.split(X):\n",
    "        Xtr, Xv = X.iloc[tr], X.iloc[va]\n",
    "        ytr, yv = y.iloc[tr], y.iloc[va]\n",
    "        model = LogisticRegression(max_iter=200)\n",
    "        model.fit(Xtr, ytr)\n",
    "        prob = model.predict_proba(Xv)[:,1]\n",
    "        auc = roc_auc_score(yv, prob)\n",
    "        if auc > best_auc:\n",
    "            best_auc, best_model = auc, model\n",
    "    print(f\"ML filter AUC (TS CV best): {best_auc:.3f}\")\n",
    "    return best_model\n",
    "\n",
    "def apply_ml_filter(model, row: pd.Series) -> float:\n",
    "    if model is None:\n",
    "        return 1.0\n",
    "    cols = [\"SMA20\",\"SMA50\",\"EMA20\",\"RSI14\",\"MACD\",\"MACD_signal\",\"MACD_hist\",\n",
    "            \"BB_upper\",\"BB_mid\",\"BB_lower\",\"ATR14\",\"ADX14\",\"ATR_pct\",\n",
    "            \"bullish_engulfing\",\"bearish_engulfing\",\"doji\",\"hammer\",\"hanging_man\"]\n",
    "    x = row[cols].values.reshape(1,-1)\n",
    "    return float(model.predict_proba(x)[0,1])\n",
    "\n",
    "print(\"‚úÖ Stage 4 ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8cec3c",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 5 ‚Äî Risk Management & Position Sizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac91c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 5 ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_costs(price: float, qty: int, cfg: Dict[str, Any], side: str) -> float:\n",
    "    # Simplified fee model using placeholders. Adjust to your broker/exchange.\n",
    "    costs = cfg[\"COSTS\"]\n",
    "    notional = price * qty\n",
    "    brokerage = costs[\"brokerage_per_order\"]\n",
    "    slippage = (costs[\"slippage_bps\"] / 10000.0) * notional\n",
    "    stt = (costs[\"stt_equity_deliv_bps\"] / 10000.0) * (notional if side.lower()==\"sell\" else 0.0)\n",
    "    exch = (costs[\"exchange_txn_bps\"] / 10000.0) * notional\n",
    "    clr  = (costs[\"clearing_bps\"] / 10000.0) * notional\n",
    "    stamp = (costs[\"stamp_duty_bps_buy\"] / 10000.0) * (notional if side.lower()==\"buy\" else 0.0)\n",
    "    gst = (costs[\"gst_pct_on_brokerage\"] / 100.0) * brokerage\n",
    "    return brokerage + slippage + stt + exch + clr + stamp + gst\n",
    "\n",
    "def position_size(entry_price: float, atr: float, cfg: Dict[str, Any], capital: float) -> int:\n",
    "    risk_per_trade = cfg[\"RISK\"][\"risk_per_trade_pct\"] / 100.0 * capital\n",
    "    stop_distance = cfg[\"RISK\"][\"atr_stop_mult\"] * atr\n",
    "    if stop_distance <= 0:\n",
    "        return 0\n",
    "    qty = int(risk_per_trade // stop_distance)\n",
    "    return max(qty, 0)\n",
    "\n",
    "print(\"‚úÖ Stage 5 ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee7a14",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 6 & 7 ‚Äî Execution (Simulated), Monitoring & Exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32dcca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 6 & 7 ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def backtest_symbol(df: pd.DataFrame, cfg: Dict[str, Any], ml_model=None, capital: float=0.0):\n",
    "    df = df.copy()\n",
    "    df[\"entry_signal\"] = generate_entry_signals(df, cfg)\n",
    "\n",
    "    atr_mult_sl = cfg[\"RISK\"][\"atr_stop_mult\"]\n",
    "    atr_mult_tsl = cfg[\"RISK\"][\"atr_trail_mult\"]\n",
    "    max_hold = cfg[\"RISK\"][\"max_hold_days\"]\n",
    "    ml_on = cfg[\"SIGNAL\"][\"ml_filter_enabled\"]\n",
    "    ml_thr = cfg[\"SIGNAL\"][\"ml_prob_threshold\"]\n",
    "\n",
    "    open_pos = None\n",
    "    trades = []\n",
    "    equity = []\n",
    "    cash = capital\n",
    "    pnl_running = 0.0\n",
    "\n",
    "    for ts, row in df.iterrows():\n",
    "        price = float(row[\"close\"])\n",
    "        atr = float(row.get(\"ATR14\", np.nan))\n",
    "        sma20, sma50 = row.get(\"SMA20\", np.nan), row.get(\"SMA50\", np.nan)\n",
    "\n",
    "        if open_pos is not None:\n",
    "            open_pos[\"day_count\"] += 1\n",
    "            open_pos[\"highest_close\"] = max(open_pos[\"highest_close\"], price)\n",
    "            tsl = open_pos[\"highest_close\"] - atr_mult_tsl * atr\n",
    "            open_pos[\"stop\"] = max(open_pos[\"stop\"], tsl)\n",
    "\n",
    "        def do_exit(reason: str):\n",
    "            nonlocal open_pos, cash, pnl_running\n",
    "            if open_pos is None:\n",
    "                return\n",
    "            exit_price = price\n",
    "            qty = open_pos[\"qty\"]\n",
    "            gross = (exit_price - open_pos[\"entry_price\"]) * qty\n",
    "            sell_cost = compute_costs(exit_price, qty, cfg, side=\"sell\")\n",
    "            buy_cost  = open_pos[\"buy_cost\"]\n",
    "            net = gross - sell_cost - buy_cost\n",
    "            pnl_running += net\n",
    "            cash += (exit_price * qty - sell_cost)\n",
    "            trades.append({\n",
    "                \"exit_time\": ts, \"exit_price\": exit_price, \"reason\": reason,\n",
    "                \"entry_time\": open_pos[\"entry_time\"], \"entry_price\": open_pos[\"entry_price\"],\n",
    "                \"qty\": qty, \"net_pnl\": net, \"gross_pnl\": gross, \"buy_cost\": buy_cost, \"sell_cost\": sell_cost,\n",
    "                \"hold_days\": open_pos[\"day_count\"]\n",
    "            })\n",
    "            open_pos = None\n",
    "\n",
    "        if open_pos is not None:\n",
    "            if price <= open_pos[\"stop\"]:\n",
    "                do_exit(\"HARD/TSL_STOP\")\n",
    "            elif not (sma20 > sma50):\n",
    "                do_exit(\"INDICATOR_EXIT\")\n",
    "            elif open_pos[\"day_count\"] >= max_hold:\n",
    "                do_exit(\"TIME_EXIT\")\n",
    "\n",
    "        if open_pos is None:\n",
    "            if not passes_screen(df.loc[:ts], cfg):\n",
    "                equity.append(pnl_running + cash)\n",
    "                continue\n",
    "            if row[\"entry_signal\"] == 1:\n",
    "                prob = 1.0\n",
    "                if ml_on and (ml_model is not None):\n",
    "                    try:\n",
    "                        prob = apply_ml_filter(ml_model, row)\n",
    "                    except Exception:\n",
    "                        prob = 1.0\n",
    "                if prob >= ml_thr:\n",
    "                    qty = position_size(price, atr, cfg, cash if cash>0 else cfg[\"RISK\"][\"initial_capital\"])\n",
    "                    if qty > 0:\n",
    "                        buy_cost = compute_costs(price, qty, cfg, side=\"buy\")\n",
    "                        cash -= (price * qty + buy_cost)\n",
    "                        open_pos = {\n",
    "                            \"entry_time\": ts,\n",
    "                            \"entry_price\": price,\n",
    "                            \"qty\": qty,\n",
    "                            \"stop\": price - atr_mult_sl * atr,\n",
    "                            \"highest_close\": price,\n",
    "                            \"day_count\": 0,\n",
    "                            \"buy_cost\": buy_cost\n",
    "                        }\n",
    "        equity.append(pnl_running + cash)\n",
    "\n",
    "    equity_ser = pd.Series(equity, index=df.index)\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    return trades_df, equity_ser\n",
    "\n",
    "print(\"‚úÖ Stage 6 & 7 ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc32050",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 8 ‚Äî Performance & Feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320773f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 8 ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_max_drawdown(equity: pd.Series):\n",
    "    roll_max = equity.cummax()\n",
    "    drawdown = equity / roll_max - 1.0\n",
    "    max_dd = drawdown.min()\n",
    "    end_idx = drawdown.idxmin()\n",
    "    start_idx = equity.loc[:end_idx].idxmax()\n",
    "    return float(max_dd), start_idx, end_idx\n",
    "\n",
    "def perf_metrics(trades: pd.DataFrame, equity: pd.Series, initial_capital: float):\n",
    "    if equity.empty:\n",
    "        return {\"note\": \"No equity series.\"}\n",
    "    total_return = (equity.iloc[-1] / initial_capital) - 1.0\n",
    "    daily_returns = equity.pct_change().dropna()\n",
    "    sharpe = (daily_returns.mean() / (daily_returns.std() + 1e-12)) * math.sqrt(252)\n",
    "    downside = daily_returns[daily_returns < 0]\n",
    "    sortino = (daily_returns.mean() / (downside.std() + 1e-12)) * math.sqrt(252)\n",
    "    max_dd, dd_start, dd_end = compute_max_drawdown(equity)\n",
    "    n = len(trades)\n",
    "    wins = (trades[\"net_pnl\"] > 0).sum() if n > 0 else 0\n",
    "    win_rate = (wins / n * 100.0) if n > 0 else 0.0\n",
    "    avg_pnl = trades[\"net_pnl\"].mean() if n > 0 else 0.0\n",
    "    gross_profit = trades.loc[trades[\"net_pnl\"] > 0, \"net_pnl\"].sum() if n > 0 else 0.0\n",
    "    gross_loss = trades.loc[trades[\"net_pnl\"] < 0, \"net_pnl\"].sum() if n > 0 else 0.0\n",
    "    profit_factor = (gross_profit / abs(gross_loss)) if gross_loss < 0 else np.nan\n",
    "    days = max(1, (equity.index[-1] - equity.index[0]).days)\n",
    "    years = days / 365.25\n",
    "    cagr = (equity.iloc[-1] / initial_capital) ** (1/years) - 1.0 if years > 0 else np.nan\n",
    "    return {\n",
    "        \"Total Return %\": round(total_return*100, 2),\n",
    "        \"CAGR %\": round(cagr*100, 2) if not np.isnan(cagr) else np.nan,\n",
    "        \"Sharpe\": round(float(sharpe), 2),\n",
    "        \"Sortino\": round(float(sortino), 2),\n",
    "        \"Max Drawdown %\": round(max_dd*100, 2),\n",
    "        \"MaxDD Start\": str(dd_start),\n",
    "        \"MaxDD End\": str(dd_end),\n",
    "        \"Trades\": int(n),\n",
    "        \"Win Rate %\": round(win_rate, 2),\n",
    "        \"Avg PnL (INR)\": round(avg_pnl, 2),\n",
    "        \"Profit Factor\": round(float(profit_factor), 2) if profit_factor==profit_factor else np.nan\n",
    "    }\n",
    "\n",
    "def plot_equity(equity: pd.Series, title: str=\"Equity Curve\"):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(equity.index, equity.values)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Equity (INR)\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Stage 8 ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75aafbd",
   "metadata": {},
   "source": [
    "\n",
    "## Orchestration ‚Äî Run the Full Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0bc3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Orchestration ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_pipeline(cfg: Dict[str, Any]):\n",
    "    outdir = get_outdir()\n",
    "    data_map = load_universe(cfg)\n",
    "\n",
    "    feat_map = {}\n",
    "    for t, df in data_map.items():\n",
    "        try:\n",
    "            feat_map[t] = add_features(df, cfg)\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è Feature error\", t, e)\n",
    "\n",
    "    ml_model = None\n",
    "    if cfg[\"SIGNAL\"][\"ml_filter_enabled\"]:\n",
    "        try:\n",
    "            big = pd.concat([d.assign(ticker=k) for k, d in feat_map.items()]).sort_index()\n",
    "            ml_model = train_ml_filter(big, cfg)\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è ML training skipped:\", e)\n",
    "\n",
    "    initial_capital = cfg[\"RISK\"][\"initial_capital\"]\n",
    "    cash_per_symbol = initial_capital / max(1, len(feat_map))\n",
    "    all_trades, eq_map = [], {}\n",
    "\n",
    "    for t, df in feat_map.items():\n",
    "        if not passes_screen(df, cfg):\n",
    "            print(\"Skip\", t, \"failed screen.\")\n",
    "            continue\n",
    "        try:\n",
    "            tr, eq = backtest_symbol(df, cfg, ml_model=ml_model, capital=cash_per_symbol)\n",
    "            if not tr.empty:\n",
    "                tr[\"ticker\"] = t\n",
    "                all_trades.append(tr)\n",
    "            eq_map[t] = eq\n",
    "        except Exception as e:\n",
    "            print(\"‚ö†Ô∏è Backtest error\", t, e)\n",
    "\n",
    "    if len(all_trades) == 0:\n",
    "        print(\"No trades generated.\")\n",
    "        return {\"trades\": pd.DataFrame(), \"metrics\": {}}\n",
    "\n",
    "    trades_df = pd.concat(all_trades).sort_values(\"exit_time\")\n",
    "    eq_df = pd.concat(eq_map, axis=1).fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    port_equity = eq_df.sum(axis=1)\n",
    "\n",
    "    metrics = perf_metrics(trades_df, port_equity, initial_capital)\n",
    "    print(\"Summary Metrics:\", json.dumps(metrics, indent=2))\n",
    "\n",
    "    if cfg[\"OUTPUTS\"][\"save_csv\"]:\n",
    "        trades_df.to_csv(outdir / \"trades.csv\", index=False)\n",
    "        print(\"Saved trades to\", outdir / \"trades.csv\")\n",
    "\n",
    "    if cfg[\"OUTPUTS\"][\"save_equity_plot\"]:\n",
    "        plot_equity(port_equity, title=\"Portfolio Equity Curve\")\n",
    "\n",
    "    return {\"trades\": trades_df, \"equity\": port_equity, \"metrics\": metrics, \"outdir\": outdir}\n",
    "\n",
    "print(\"‚úÖ Orchestration ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876c6ac",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) Telegram Alerts ‚Äî Stub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d368cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Telegram stub ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def send_telegram(message: str, bot_token: str, chat_id: str):\n",
    "    # Minimal Telegram sender stub for live mode integration.\n",
    "    try:\n",
    "        import requests\n",
    "        url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "        payload = {\"chat_id\": chat_id, \"text\": message}\n",
    "        # r = requests.post(url, data=payload, timeout=10)\n",
    "        print(\"[stub] Would send Telegram message:\", message[:120], \"...\")\n",
    "    except Exception as e:\n",
    "        print(\"Telegram send failed:\", e)\n",
    "\n",
    "print(\"‚úÖ Telegram stub ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52ea31",
   "metadata": {},
   "source": [
    "\n",
    "## Quick Start ‚Äî Run the Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b9bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# results = run_pipeline(CONFIG)\n",
    "# results[\"trades\"].head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
