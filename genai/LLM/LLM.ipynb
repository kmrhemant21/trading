{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fca0d48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (4.53.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: datasets in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: peft in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: accelerate in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (1.8.1)\n",
      "Requirement already satisfied: filelock in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: psutil in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.53.1\n",
      "    Uninstalling transformers-4.53.1:\n",
      "      Successfully uninstalled transformers-4.53.1\n",
      "Successfully installed transformers-4.53.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets peft accelerate --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8729866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (1.8.1)\n",
      "Requirement already satisfied: datasets in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: transformers in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (4.53.2)\n",
      "Requirement already satisfied: peft in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from accelerate>=0.26.0) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (1.1.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hemank/Documents/github/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9c2d02848d448484e6ea41dd339f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d336addca3d444f18414e4a9aa80916c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/tx231v5158797chnp22wm9000000gp/T/ipykernel_63649/1704780711.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m     85\u001b[39m training_args = TrainingArguments(\n\u001b[32m     86\u001b[39m     output_dir=OUTPUT_DIR,\n\u001b[32m     87\u001b[39m     per_device_train_batch_size=BATCH_SIZE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     use_mps_device=torch.backends.mps.is_available(),\n\u001b[32m    100\u001b[39m )\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# ▶️ 8. TRAINER & TRAIN\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m trainer.train()\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# ▶️ 9. SAVE\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/transformers/trainer.py:465\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28mself\u001b[39m.is_in_train = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;28mself\u001b[39m.model = model\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28mself\u001b[39m._memory_tracker = TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m.args.skip_memory_metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/transformers/trainer.py:5208\u001b[39m, in \u001b[36mTrainer.create_accelerator_and_postprocess\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   5205\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mRequires accelerate>1.3.0 to use Tensor Parallelism.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5207\u001b[39m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5208\u001b[39m \u001b[38;5;28mself\u001b[39m.accelerator = \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5209\u001b[39m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[32m   5210\u001b[39m \u001b[38;5;28mself\u001b[39m.gather_function = \u001b[38;5;28mself\u001b[39m.accelerator.gather_for_metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:547\u001b[39m, in \u001b[36mAccelerator.__init__\u001b[39m\u001b[34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, torch_tp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend, dynamo_plugin, deepspeed_plugins)\u001b[39m\n\u001b[32m    536\u001b[39m \u001b[38;5;28mself\u001b[39m.native_amp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m    538\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mxpu\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    539\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    545\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msdaa\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    546\u001b[39m ) \u001b[38;5;129;01mor\u001b[39;00m is_torch_xla_available(check_is_tpu=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfp16 mixed precision requires a GPU (not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.device.type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    548\u001b[39m kwargs = \u001b[38;5;28mself\u001b[39m.scaler_handler.to_kwargs() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scaler_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# FSDP2 doesn't use ShardedGradScaler, don't want to modify `get_grad_scaler`, rather create a simple utility\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "source": [
    "# ▶️ 1. INSTALL & IMPORTS\n",
    "!pip install 'accelerate>=0.26.0' datasets transformers peft\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# ▶️ 2. CONFIG\n",
    "DATA_PATH     = \"stock_bot_data.jsonl\"    # your JSONL\n",
    "OUTPUT_DIR    = \"ft-stock-bot\"\n",
    "BASE_MODEL    = \"gpt2-medium\"\n",
    "MAX_LENGTH    = 256\n",
    "BATCH_SIZE    = 4\n",
    "NUM_EPOCHS    = 3\n",
    "LEARNING_RATE = 3e-5\n",
    "EVAL_STEPS    = 200\n",
    "LOGGING_STEPS = 50\n",
    "SAVE_TOTAL    = 2\n",
    "\n",
    "# ▶️ 3. DEVICE DETECTION\n",
    "device = (\n",
    "    torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"mps\")\n",
    "    if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ▶️ 4. LOAD & SPLIT YOUR DATA\n",
    "dataset = load_dataset(\"json\", data_files=DATA_PATH)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# ▶️ 5. TOKENIZER & MODEL SETUP\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# ─ PEFT/LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# move model to device\n",
    "model.to(device)\n",
    "\n",
    "# ▶️ 6. TOKENIZATION FUNCTION\n",
    "def tokenize_fn(batch):\n",
    "    texts = [\n",
    "        p.strip()\n",
    "        + tokenizer.eos_token\n",
    "        + c.strip()\n",
    "        + tokenizer.eos_token\n",
    "        for p, c in zip(batch[\"prompt\"], batch[\"completion\"])\n",
    "    ]\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    enc[\"labels\"] = enc[\"input_ids\"].copy()\n",
    "    return enc\n",
    "\n",
    "tokenized = dataset.map(\n",
    "    tokenize_fn, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "# ▶️ 7. TRAINING ARGUMENTS (no fp16 on MPS/CPU)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    do_eval=True,\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    save_total_limit=SAVE_TOTAL,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, \"logs\"),\n",
    "    fp16=torch.cuda.is_available(),    # only true if CUDA is available\n",
    "    no_cuda=not (torch.cuda.is_available() or torch.backends.mps.is_available()),\n",
    "    use_mps_device=torch.backends.mps.is_available(),\n",
    ")\n",
    "\n",
    "# ▶️ 8. TRAINER & TRAIN\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# ▶️ 9. SAVE\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"\\n✅ Fine-tuning complete! Saved in '{OUTPUT_DIR}/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ft-stock-bot\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ft-stock-bot\")\n",
    "prompt = \"Analyze the 14-week RSI for AAPL and advise on action.\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "print(tokenizer.decode(model.generate(input_ids, max_new_tokens=50)[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
