{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98991fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "====================================================================================\n",
    "ðŸ“˜ README: NSE F&O SENTIMENT ANALYZER (No-Argument Version)\n",
    "====================================================================================\n",
    "\n",
    "This script computes **derivatives-based sentiment** for NSE equities \n",
    "using Futures and Options data from NSEâ€™s public API.\n",
    "\n",
    "âš™ï¸ HOW TO USE\n",
    "-------------\n",
    "1. Edit the `SYMBOLS` list near the top of this file.\n",
    "   Example:\n",
    "       SYMBOLS = [\"RELIANCE\", \"HDFCBANK\", \"INFY\", \"ABB\"]\n",
    "2. Install dependencies:\n",
    "       pip install requests pandas numpy pytz python-dateutil\n",
    "3. Run:\n",
    "       python fno_sentiment.py\n",
    "4. Check results:\n",
    "       outputs/YYYY-MM-DD/fno_sentiment_summary.csv\n",
    "       outputs/YYYY-MM-DD/fno_sentiment_details.csv\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "ðŸ“Š HOW SENTIMENT IS CALCULATED\n",
    "------------------------------------------------------------------------------------\n",
    "\n",
    "ðŸ”¹ OPTIONS COMPONENTS\n",
    "----------------------\n",
    "1. **Putâ€“Call Ratio (PCR)**  \n",
    "   PCR = total Put OI / total Call OI  \n",
    "   Normalized: `pcr_score = tanh((PCR âˆ’ 1.0) / 0.4)`  \n",
    "   - PCR > 1.3 â†’ bullish tilt  \n",
    "   - PCR < 0.7 â†’ bearish tilt  \n",
    "\n",
    "2. **Î”OI Bias (doi_net)**  \n",
    "   doi_net = (Î£ Î”OI_puts) âˆ’ (Î£ Î”OI_calls)  \n",
    "   Normalized: `oi_bias_score = tanh(doi_net / max(|doi_net|, 1))`  \n",
    "   Positive = bullish (more put build-up)\n",
    "\n",
    "3. **ATM IV & IV Skew**  \n",
    "   - Take Â±2 strikes around the ATM by index  \n",
    "   - Compute avg CE_IV, avg PE_IV â†’ `iv_skew = PE_IV âˆ’ CE_IV`  \n",
    "   - Convert to score: `iv_trend_score = tanh(iv_skew / max(|iv_skew|, 5))`  \n",
    "   Positive skew â‡’ market paying more for puts â‡’ mild bullish sentiment.\n",
    "\n",
    "ðŸ”¹ FUTURES COMPONENTS\n",
    "----------------------\n",
    "1. **Basis** = Near Future LTP âˆ’ Spot  \n",
    "   **Basis% annualized** = (basis/spot) Ã— (365 / days_to_expiry) Ã— 100  \n",
    "   - Positive basis â†’ bullish carry  \n",
    "   - Negative basis â†’ bearish discount  \n",
    "\n",
    "2. **Roll Spread** = Next Future âˆ’ Near Future  \n",
    "   Positive widening â†’ bullish rollover  \n",
    "\n",
    "3. **Regime (Price vs Î”OI):**  \n",
    "   | Î”Price | Î”OI | Interpretation | Score |\n",
    "   |---------|------|----------------|--------|\n",
    "   | â†‘ | â†‘ | Long Buildup | +1.0 |\n",
    "   | â†“ | â†‘ | Short Buildup | âˆ’1.0 |\n",
    "   | â†“ | â†“ | Long Unwinding | âˆ’0.4 |\n",
    "   | â†‘ | â†“ | Short Covering | +0.4 |\n",
    "\n",
    "ðŸ”¹ COMPOSITE SENTIMENT SCORE\n",
    "-----------------------------\n",
    "Weighted combination:\n",
    "    Score = 0.40Â·Futures + 0.30Â·PCR + 0.20Â·OI_bias + 0.10Â·IV_trend\n",
    "Label:\n",
    "    Bullish  if Score > +0.20  \n",
    "    Bearish  if Score < âˆ’0.20  \n",
    "    Neutral  otherwise\n",
    "\n",
    "If futures data are missing (e.g., outside market hours),\n",
    "only the options parts contribute.\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "ðŸ“‚ OUTPUT FILES\n",
    "------------------------------------------------------------------------------------\n",
    "1. **fno_sentiment_summary.csv**  \n",
    "   Per-symbol summary including:\n",
    "   - `pcr`, `doi_net`, `iv_skew`, `basis`, `roll_spread`\n",
    "   - `fut_regime`, `sentiment_score`, `sentiment_label`\n",
    "   - Diagnostics: `has_options`, `has_futures`, `missing_fields`\n",
    "\n",
    "2. **fno_sentiment_details.csv**  \n",
    "   Strike-level view with OI, IV, and LTP for both calls and puts.\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "ðŸ“ˆ INTERPRETATION QUICK GUIDE\n",
    "------------------------------------------------------------------------------------\n",
    "| Futures + Options Mix | Likely Sentiment |\n",
    "|------------------------|------------------|\n",
    "| Long Buildup + High PCR | Strong Bullish |\n",
    "| Short Buildup + Low PCR | Strong Bearish |\n",
    "| Short Covering + Rising PCR | Bullish Reversal |\n",
    "| Long Unwinding + Falling PCR | Bearish Reversal |\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "ðŸ§© TROUBLESHOOTING\n",
    "------------------------------------------------------------------------------------\n",
    "- `has_futures=False` â†’ symbol not in F&O or endpoint gave no FUTSTK data.\n",
    "- `missing_fields` â†’ shows which keys were absent (`oi`, `prev_close`, etc.)\n",
    "- Run during market hours for richer data.\n",
    "- NSE may rate-limit; keep SYMBOLS list small (10â€“20 max) and respect pacing.\n",
    "\n",
    "====================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os, time, math, datetime as dt\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dateutil import parser as dateparser\n",
    "from pytz import timezone\n",
    "\n",
    "# =========================\n",
    "# CONFIG (EDIT HERE)\n",
    "# =========================\n",
    "SYMBOLS = [\"RELIANCE\", \"HDFCBANK\", \"INFY\", \"ABB\"]  # <â€” put your list here\n",
    "IST = timezone(\"Asia/Kolkata\")\n",
    "\n",
    "REQUEST_TIMEOUT   = 12\n",
    "MAX_RETRIES       = 5\n",
    "RETRY_SLEEP_SEC   = 1.2\n",
    "PACING_SLEEP_SEC  = 0.8\n",
    "ATM_NEIGHBORS     = 2\n",
    "SENTIMENT_THRESH  = 0.20\n",
    "\n",
    "# Weights for composite sentiment\n",
    "W_FUTURES = 0.40\n",
    "W_PCR     = 0.30\n",
    "W_OI_BIAS = 0.20\n",
    "W_IV_TREND= 0.10\n",
    "\n",
    "OUTDIR = os.path.join(\"outputs\", dt.date.today().strftime(\"%Y-%m-%d\"))\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# HTTP SESSION (NSE)\n",
    "# ---------------------------------------------------------------------------------\n",
    "def make_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Referer\": \"https://www.nseindia.com/\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "    })\n",
    "    # Warm cookies to avoid 401/403\n",
    "    for _ in range(2):\n",
    "        try:\n",
    "            s.get(\"https://www.nseindia.com\", timeout=REQUEST_TIMEOUT)\n",
    "            break\n",
    "        except requests.RequestException:\n",
    "            time.sleep(0.6)\n",
    "    return s\n",
    "\n",
    "def _get_json(s: requests.Session, url: str, params: Optional[dict] = None) -> dict:\n",
    "    for i in range(MAX_RETRIES):\n",
    "        try:\n",
    "            r = s.get(url, params=params, timeout=REQUEST_TIMEOUT)\n",
    "            if r.status_code == 200:\n",
    "                return r.json()\n",
    "            if r.status_code in (401, 403):\n",
    "                s.get(\"https://www.nseindia.com\", timeout=REQUEST_TIMEOUT)\n",
    "            time.sleep(RETRY_SLEEP_SEC * (i + 1))\n",
    "        except requests.RequestException:\n",
    "            time.sleep(RETRY_SLEEP_SEC * (i + 1))\n",
    "    raise RuntimeError(f\"Failed after {MAX_RETRIES} tries: {url}\")\n",
    "\n",
    "def fetch_option_chain_equity(s: requests.Session, symbol: str) -> dict:\n",
    "    url = \"https://www.nseindia.com/api/option-chain-equities\"\n",
    "    return _get_json(s, url, params={\"symbol\": symbol.upper()})\n",
    "\n",
    "def fetch_futures_quote(s: requests.Session, symbol: str) -> dict:\n",
    "    url = \"https://www.nseindia.com/api/quote-derivative\"\n",
    "    return _get_json(s, url, params={\"symbol\": symbol.upper()})\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# UTILITIES\n",
    "# ---------------------------------------------------------------------------------\n",
    "def days_to(date_str: str, now_ist: dt.datetime) -> float:\n",
    "    try:\n",
    "        d = dateparser.parse(date_str)\n",
    "        d_ist = IST.localize(dt.datetime(d.year, d.month, d.day, 15, 30))\n",
    "        return max((d_ist - now_ist).total_seconds() / 86400.0, 0.0001)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def safe_tanh(x, scale=1.0):\n",
    "    try:\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "            return np.nan\n",
    "        return math.tanh(float(x) / float(scale if scale else 1.0))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# OPTIONS METRICS\n",
    "# ---------------------------------------------------------------------------------\n",
    "def compute_options_metrics(oc_json: dict) -> dict:\n",
    "    rec = oc_json.get(\"records\", {})\n",
    "    underlying = rec.get(\"underlyingValue\", np.nan)\n",
    "    data = oc_json.get(\"filtered\", {}).get(\"data\") or oc_json.get(\"records\", {}).get(\"data\") or []\n",
    "\n",
    "    ce_oi = pe_oi = ce_oi_chg = pe_oi_chg = 0.0\n",
    "    rows = []\n",
    "\n",
    "    for row in data:\n",
    "        strike = row.get(\"strikePrice\")\n",
    "        ce = row.get(\"CE\"); pe = row.get(\"PE\")\n",
    "\n",
    "        if ce:\n",
    "            ce_oi     += float(ce.get(\"openInterest\", 0) or 0)\n",
    "            ce_oi_chg += float(ce.get(\"changeinOpenInterest\", 0) or 0)\n",
    "        if pe:\n",
    "            pe_oi     += float(pe.get(\"openInterest\", 0) or 0)\n",
    "            pe_oi_chg += float(pe.get(\"changeinOpenInterest\", 0) or 0)\n",
    "\n",
    "        rows.append({\n",
    "            \"strike\": float(strike) if strike is not None else np.nan,\n",
    "            \"ce_oi\": float(ce.get(\"openInterest\", 0)) if ce else 0.0,\n",
    "            \"pe_oi\": float(pe.get(\"openInterest\", 0)) if pe else 0.0,\n",
    "            \"ce_chg_oi\": float(ce.get(\"changeinOpenInterest\", 0)) if ce else 0.0,\n",
    "            \"pe_chg_oi\": float(pe.get(\"changeinOpenInterest\", 0)) if pe else 0.0,\n",
    "            \"ce_iv\": float(ce.get(\"impliedVolatility\", np.nan)) if ce else np.nan,\n",
    "            \"pe_iv\": float(pe.get(\"impliedVolatility\", np.nan)) if pe else np.nan,\n",
    "            \"ce_ltp\": float(ce.get(\"lastPrice\", np.nan)) if ce else np.nan,\n",
    "            \"pe_ltp\": float(pe.get(\"lastPrice\", np.nan)) if pe else np.nan,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\n",
    "        \"strike\",\"ce_oi\",\"pe_oi\",\"ce_chg_oi\",\"pe_chg_oi\",\"ce_iv\",\"pe_iv\",\"ce_ltp\",\"pe_ltp\"\n",
    "    ])\n",
    "\n",
    "    # PCR (guard zero)\n",
    "    pcr = (pe_oi / ce_oi) if ce_oi not in (0, None) else np.nan\n",
    "    pcr_score = safe_tanh((pcr - 1.0), scale=0.4) if not pd.isna(pcr) else np.nan\n",
    "\n",
    "    # Î”OI bias (todayâ€™s tilt)\n",
    "    doi_net = (pe_oi_chg - ce_oi_chg)\n",
    "    oi_bias_score = safe_tanh(doi_net, scale=max(abs(doi_net), 1.0))\n",
    "\n",
    "    # ATM IV from Â±N strikes by index\n",
    "    atm_ce_iv = atm_pe_iv = iv_skew = np.nan\n",
    "    if not df.empty and not pd.isna(underlying):\n",
    "        strikes = sorted(df[\"strike\"].dropna().unique().tolist())\n",
    "        if strikes:\n",
    "            # find nearest strike index\n",
    "            nearest_idx = int(np.argmin([abs(k - underlying) for k in strikes]))\n",
    "            lo = max(nearest_idx - ATM_NEIGHBORS, 0)\n",
    "            hi = min(nearest_idx + ATM_NEIGHBORS, len(strikes)-1)\n",
    "            band_strikes = set(strikes[lo:hi+1])\n",
    "            band = df[df[\"strike\"].isin(band_strikes)]\n",
    "            atm_ce_iv = band[\"ce_iv\"].replace(0, np.nan).mean()\n",
    "            atm_pe_iv = band[\"pe_iv\"].replace(0, np.nan).mean()\n",
    "            if not pd.isna(atm_ce_iv) and not pd.isna(atm_pe_iv):\n",
    "                iv_skew = atm_pe_iv - atm_ce_iv\n",
    "\n",
    "    return dict(\n",
    "        has_options=True,\n",
    "        underlying=underlying,\n",
    "        pcr=pcr, pcr_score=pcr_score,\n",
    "        doi_net=doi_net, oi_bias_score=oi_bias_score,\n",
    "        atm_ce_iv=atm_ce_iv, atm_pe_iv=atm_pe_iv, iv_skew=iv_skew,\n",
    "        oc_table=df\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# FUTURES METRICS\n",
    "# ---------------------------------------------------------------------------------\n",
    "def parse_futures_from_derivative_quote(dq_json: dict) -> pd.DataFrame:\n",
    "    futures = []\n",
    "    def scan(node):\n",
    "        if isinstance(node, dict):\n",
    "            if node.get(\"instrumentType\") in (\"FUTSTK\", \"FUTIDX\"):\n",
    "                futures.append(node)\n",
    "            for v in node.values():\n",
    "                scan(v)\n",
    "        elif isinstance(node, list):\n",
    "            for x in node:\n",
    "                scan(x)\n",
    "    scan(dq_json)\n",
    "\n",
    "    rows = []\n",
    "    for f in futures:\n",
    "        rows.append({\n",
    "            \"expiry\": f.get(\"expiryDate\") or f.get(\"expirydate\") or f.get(\"expDate\"),\n",
    "            \"ltp\": float(f.get(\"lastPrice\") or f.get(\"ltp\") or f.get(\"closePrice\") or np.nan),\n",
    "            \"oi\": float(f.get(\"openInterest\") or f.get(\"oi\") or np.nan),\n",
    "            \"chg_oi\": float(f.get(\"changeinOpenInterest\") or f.get(\"changeInOpenInterest\") or 0.0),\n",
    "            \"prev_close\": float(f.get(\"previousClose\") or f.get(\"prevClose\") or np.nan),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    df = df.dropna(subset=[\"expiry\"]).copy()\n",
    "    try:\n",
    "        df[\"expiry_dt\"] = df[\"expiry\"].apply(lambda x: dateparser.parse(str(x)))\n",
    "    except Exception:\n",
    "        df[\"expiry_dt\"] = pd.NaT\n",
    "    return df.sort_values(\"expiry_dt\").reset_index(drop=True)\n",
    "\n",
    "def compute_futures_metrics(fut_df: pd.DataFrame, underlying: float, now_ist: dt.datetime) -> dict:\n",
    "    if fut_df is None or fut_df.empty:\n",
    "        return dict(\n",
    "            has_futures=False, missing_fields=\"no_fut_rows\",\n",
    "            near_price=np.nan, next_price=np.nan, near_oi=np.nan, near_chg_oi=np.nan,\n",
    "            basis=np.nan, basis_pct_ann=np.nan, roll_spread=np.nan,\n",
    "            regime=None, fut_regime_score=np.nan, dte=np.nan, price_change=np.nan\n",
    "        )\n",
    "\n",
    "    near = fut_df.iloc[0]\n",
    "    nxt = fut_df.iloc[1] if len(fut_df) > 1 else None\n",
    "\n",
    "    # Validate fields\n",
    "    missing = []\n",
    "    near_price = float(near.get(\"ltp\", np.nan))\n",
    "    if pd.isna(near_price): missing.append(\"ltp\")\n",
    "    next_price = float(nxt.get(\"ltp\", np.nan)) if nxt is not None else np.nan\n",
    "    near_oi = float(near.get(\"oi\", np.nan))\n",
    "    if pd.isna(near_oi): missing.append(\"oi\")\n",
    "    near_chg_oi = float(near.get(\"chg_oi\", np.nan))\n",
    "    if pd.isna(near_chg_oi): missing.append(\"chg_oi\")\n",
    "    prev_close = float(near.get(\"prev_close\", np.nan))\n",
    "    if pd.isna(prev_close): missing.append(\"prev_close\")\n",
    "    near_exp = near.get(\"expiry\")\n",
    "\n",
    "    dte = days_to(near_exp, now_ist) if near_exp else np.nan\n",
    "    if pd.isna(dte): missing.append(\"expiry\")\n",
    "\n",
    "    # Derived\n",
    "    basis = near_price - float(underlying) if (not pd.isna(near_price) and not pd.isna(underlying)) else np.nan\n",
    "    basis_pct_ann = ((basis / float(underlying)) * (365.0 / dte) * 100.0) if (not pd.isna(basis) and dte and dte > 0) else np.nan\n",
    "    roll_spread = (next_price - near_price) if (not pd.isna(next_price) and not pd.isna(near_price)) else np.nan\n",
    "    price_change = (near_price - prev_close) if (not pd.isna(near_price) and not pd.isna(prev_close)) else np.nan\n",
    "\n",
    "    regime = None\n",
    "    if not pd.isna(price_change) and not pd.isna(near_chg_oi):\n",
    "        if price_change > 0 and near_chg_oi > 0:\n",
    "            regime = \"Long Buildup\"\n",
    "        elif price_change < 0 and near_chg_oi > 0:\n",
    "            regime = \"Short Buildup\"\n",
    "        elif price_change < 0 and near_chg_oi < 0:\n",
    "            regime = \"Long Unwinding\"\n",
    "        elif price_change > 0 and near_chg_oi < 0:\n",
    "            regime = \"Short Covering\"\n",
    "\n",
    "    fut_regime_score = {\n",
    "        \"Long Buildup\": 1.0,\n",
    "        \"Short Buildup\": -1.0,\n",
    "        \"Short Covering\": 0.4,\n",
    "        \"Long Unwinding\": -0.4\n",
    "    }.get(regime, np.nan)\n",
    "\n",
    "    return dict(\n",
    "        has_futures=True if len(missing)==0 or len(missing)<5 else False,\n",
    "        missing_fields=\",\".join(sorted(set(missing))) if missing else \"\",\n",
    "        near_price=near_price, next_price=next_price,\n",
    "        near_oi=near_oi, near_chg_oi=near_chg_oi,\n",
    "        basis=basis, basis_pct_ann=basis_pct_ann,\n",
    "        roll_spread=roll_spread, regime=regime,\n",
    "        fut_regime_score=fut_regime_score, dte=dte, price_change=price_change\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# SENTIMENT COMBINATION\n",
    "# ---------------------------------------------------------------------------------\n",
    "def combine_sentiment(fut_score, pcr_score, oi_bias_score, iv_skew) -> Tuple[float, str]:\n",
    "    # IV trend proxy from skew: PE IV > CE IV â†’ mild bullish\n",
    "    if pd.isna(iv_skew):\n",
    "        iv_trend_score = 0.0\n",
    "    else:\n",
    "        iv_trend_score = safe_tanh(iv_skew, scale=max(abs(iv_skew), 5.0))\n",
    "\n",
    "    parts = []\n",
    "    for val, w in [(fut_score, W_FUTURES), (pcr_score, W_PCR), (oi_bias_score, W_OI_BIAS), (iv_trend_score, W_IV_TREND)]:\n",
    "        parts.append(0.0 if pd.isna(val) else w * float(val))\n",
    "\n",
    "    score = float(np.nansum(parts))\n",
    "    label = \"Bullish\" if score > SENTIMENT_THRESH else \"Bearish\" if score < -SENTIMENT_THRESH else \"Neutral\"\n",
    "    return score, label\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# PROCESS ONE SYMBOL\n",
    "# ---------------------------------------------------------------------------------\n",
    "def process_symbol(s: requests.Session, symbol: str, now_ist: dt.datetime) -> dict:\n",
    "    try:\n",
    "        oc_json = fetch_option_chain_equity(s, symbol)\n",
    "        oc_metrics = compute_options_metrics(oc_json)\n",
    "\n",
    "        dq_json = fetch_futures_quote(s, symbol)\n",
    "        fut_df = parse_futures_from_derivative_quote(dq_json)\n",
    "        fut_metrics = compute_futures_metrics(fut_df, oc_metrics[\"underlying\"], now_ist)\n",
    "\n",
    "        score, label = combine_sentiment(\n",
    "            fut_metrics.get(\"fut_regime_score\", np.nan),\n",
    "            oc_metrics.get(\"pcr_score\", np.nan),\n",
    "            oc_metrics.get(\"oi_bias_score\", np.nan),\n",
    "            oc_metrics.get(\"iv_skew\", np.nan),\n",
    "        )\n",
    "\n",
    "        out = dict(\n",
    "            symbol=symbol.upper(),\n",
    "            time_ist=now_ist.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            spot=oc_metrics.get(\"underlying\", np.nan),\n",
    "\n",
    "            has_options=oc_metrics.get(\"has_options\", False),\n",
    "            has_futures=fut_metrics.get(\"has_futures\", False),\n",
    "            missing_fields=fut_metrics.get(\"missing_fields\", \"\"),\n",
    "\n",
    "            # Options\n",
    "            pcr=oc_metrics.get(\"pcr\", np.nan),\n",
    "            pcr_score=oc_metrics.get(\"pcr_score\", np.nan),\n",
    "            doi_net=oc_metrics.get(\"doi_net\", np.nan),\n",
    "            oi_bias_score=oc_metrics.get(\"oi_bias_score\", np.nan),\n",
    "            atm_ce_iv=oc_metrics.get(\"atm_ce_iv\", np.nan),\n",
    "            atm_pe_iv=oc_metrics.get(\"atm_pe_iv\", np.nan),\n",
    "            iv_skew=oc_metrics.get(\"iv_skew\", np.nan),\n",
    "\n",
    "            # Futures\n",
    "            fut_near_price=fut_metrics.get(\"near_price\", np.nan),\n",
    "            fut_next_price=fut_metrics.get(\"next_price\", np.nan),\n",
    "            fut_near_oi=fut_metrics.get(\"near_oi\", np.nan),\n",
    "            fut_near_chg_oi=fut_metrics.get(\"near_chg_oi\", np.nan),\n",
    "            basis=fut_metrics.get(\"basis\", np.nan),\n",
    "            basis_pct_ann=fut_metrics.get(\"basis_pct_ann\", np.nan),\n",
    "            roll_spread=fut_metrics.get(\"roll_spread\", np.nan),\n",
    "            fut_regime=fut_metrics.get(\"regime\", None),\n",
    "            fut_regime_score=fut_metrics.get(\"fut_regime_score\", np.nan),\n",
    "            dte=fut_metrics.get(\"dte\", np.nan),\n",
    "            fut_price_change=fut_metrics.get(\"price_change\", np.nan),\n",
    "\n",
    "            # Final\n",
    "            sentiment_score=score,\n",
    "            sentiment_label=label,\n",
    "        )\n",
    "\n",
    "        out[\"_oc_table\"] = oc_metrics.get(\"oc_table\")\n",
    "        out[\"_fut_table\"] = fut_df\n",
    "        return out\n",
    "\n",
    "    except Exception as e:\n",
    "        return dict(\n",
    "            symbol=symbol.upper(),\n",
    "            time_ist=now_ist.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            error=str(e),\n",
    "            has_options=False, has_futures=False, missing_fields=\"exception\",\n",
    "            sentiment_score=np.nan, sentiment_label=\"NA\"\n",
    "        )\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# MAIN\n",
    "# ---------------------------------------------------------------------------------\n",
    "def main():\n",
    "    s = make_session()\n",
    "    now_ist = dt.datetime.now(IST)\n",
    "    results: List[dict] = []\n",
    "\n",
    "    for sym in [x.strip().upper() for x in SYMBOLS if x.strip()]:\n",
    "        print(f\"[{now_ist.strftime('%H:%M:%S')}] Processing {sym} ...\")\n",
    "        res = process_symbol(s, sym, now_ist)\n",
    "        results.append(res)\n",
    "        time.sleep(PACING_SLEEP_SEC)\n",
    "\n",
    "    # Summary CSV (add diagnostics columns up front)\n",
    "    summary_cols = [\n",
    "        \"symbol\",\"time_ist\",\"spot\",\n",
    "        \"has_options\",\"has_futures\",\"missing_fields\",\n",
    "        \"pcr\",\"pcr_score\",\"doi_net\",\"oi_bias_score\",\"atm_ce_iv\",\"atm_pe_iv\",\"iv_skew\",\n",
    "        \"fut_near_price\",\"fut_next_price\",\"fut_near_oi\",\"fut_near_chg_oi\",\n",
    "        \"basis\",\"basis_pct_ann\",\"roll_spread\",\"fut_regime\",\"fut_regime_score\",\"dte\",\"fut_price_change\",\n",
    "        \"sentiment_score\",\"sentiment_label\",\"error\"\n",
    "    ]\n",
    "    summary_df = pd.DataFrame([{k: r.get(k, np.nan) for k in summary_cols} for r in results])\n",
    "    summary_path = os.path.join(OUTDIR, \"fno_sentiment_summary.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(\"Wrote:\", summary_path)\n",
    "\n",
    "    # Details CSV (strike-level, if available)\n",
    "    detail_rows = []\n",
    "    for r in results:\n",
    "        base = {k: r.get(k, np.nan) for k in summary_cols}\n",
    "        oc_tbl = r.get(\"_oc_table\")\n",
    "        if isinstance(oc_tbl, pd.DataFrame) and not oc_tbl.empty:\n",
    "            tmp = oc_tbl.copy()\n",
    "            tmp[\"symbol\"] = r[\"symbol\"]; tmp[\"time_ist\"] = r[\"time_ist\"]\n",
    "            for _, row in tmp.iterrows():\n",
    "                detail_rows.append({\n",
    "                    **base,\n",
    "                    \"strike\": row.get(\"strike\", np.nan),\n",
    "                    \"ce_oi\": row.get(\"ce_oi\", np.nan),\n",
    "                    \"pe_oi\": row.get(\"pe_oi\", np.nan),\n",
    "                    \"ce_chg_oi\": row.get(\"ce_chg_oi\", np.nan),\n",
    "                    \"pe_chg_oi\": row.get(\"pe_chg_oi\", np.nan),\n",
    "                    \"ce_iv\": row.get(\"ce_iv\", np.nan),\n",
    "                    \"pe_iv\": row.get(\"pe_iv\", np.nan),\n",
    "                    \"ce_ltp\": row.get(\"ce_ltp\", np.nan),\n",
    "                    \"pe_ltp\": row.get(\"pe_ltp\", np.nan),\n",
    "                })\n",
    "        else:\n",
    "            detail_rows.append(base)\n",
    "\n",
    "    details_df = pd.DataFrame(detail_rows)\n",
    "    details_path = os.path.join(OUTDIR, \"fno_sentiment_details.csv\")\n",
    "    details_df.to_csv(details_path, index=False)\n",
    "    print(\"Wrote:\", details_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
