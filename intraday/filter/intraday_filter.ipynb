{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6cfbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/500] Processing 360ONE ...\n",
      "[2/500] Processing 3MINDIA ...\n",
      "[3/500] Processing AADHARHFC ...\n",
      "[4/500] Processing AARTIIND ...\n",
      "[5/500] Processing AAVAS ...\n",
      "[6/500] Processing ABB ...\n",
      "[7/500] Processing ABBOTINDIA ...\n",
      "[8/500] Processing ABCAPITAL ...\n",
      "[9/500] Processing ABFRL ...\n",
      "[10/500] Processing ABLBL ...\n",
      "[11/500] Processing ABREL ...\n",
      "[12/500] Processing ABSLAMC ...\n",
      "[13/500] Processing ACC ...\n",
      "[14/500] Processing ACE ...\n",
      "[15/500] Processing ACMESOLAR ...\n",
      "[16/500] Processing ADANIENSOL ...\n",
      "[17/500] Processing ADANIENT ...\n",
      "[18/500] Processing ADANIGREEN ...\n",
      "[19/500] Processing ADANIPORTS ...\n",
      "[20/500] Processing ADANIPOWER ...\n",
      "[21/500] Processing AEGISLOG ...\n",
      "[22/500] Processing AEGISVOPAK ...\n",
      "[23/500] Processing AFCONS ...\n",
      "[24/500] Processing AFFLE ...\n",
      "[25/500] Processing AGARWALEYE ...\n",
      "[26/500] Processing AIAENG ...\n",
      "[27/500] Processing AIIL ...\n",
      "[28/500] Processing AJANTPHARM ...\n",
      "[29/500] Processing AKUMS ...\n",
      "[30/500] Processing AKZOINDIA ...\n",
      "[31/500] Processing ALKEM ...\n",
      "[32/500] Processing ALKYLAMINE ...\n",
      "[33/500] Processing ALOKINDS ...\n",
      "[34/500] Processing AMBER ...\n",
      "[35/500] Processing AMBUJACEM ...\n",
      "[36/500] Processing ANANDRATHI ...\n",
      "[37/500] Processing ANANTRAJ ...\n",
      "[38/500] Processing ANGELONE ...\n",
      "[39/500] Processing APARINDS ...\n",
      "[40/500] Processing APLAPOLLO ...\n",
      "[41/500] Processing APLLTD ...\n",
      "[42/500] Processing APOLLOHOSP ...\n",
      "[43/500] Processing APOLLOTYRE ...\n",
      "[44/500] Processing APTUS ...\n",
      "[45/500] Processing ARE&M ...\n",
      "[46/500] Processing ASAHIINDIA ...\n",
      "[47/500] Processing ASHOKLEY ...\n",
      "[48/500] Processing ASIANPAINT ...\n",
      "[49/500] Processing ASTERDM ...\n",
      "[50/500] Processing ASTRAL ...\n",
      "[51/500] Processing ASTRAZEN ...\n",
      "[52/500] Processing ATGL ...\n",
      "[53/500] Processing ATHERENERG ...\n",
      "[54/500] Processing ATUL ...\n",
      "[55/500] Processing AUBANK ...\n",
      "[56/500] Processing AUROPHARMA ...\n",
      "[57/500] Processing AWL ...\n",
      "[58/500] Processing AXISBANK ...\n",
      "[59/500] Processing BAJAJ-AUTO ...\n",
      "[60/500] Processing BAJAJFINSV ...\n",
      "[61/500] Processing BAJAJHFL ...\n",
      "[62/500] Processing BAJAJHLDNG ...\n",
      "[63/500] Processing BAJFINANCE ...\n",
      "[64/500] Processing BALKRISIND ...\n",
      "[65/500] Processing BALRAMCHIN ...\n",
      "[66/500] Processing BANDHANBNK ...\n",
      "[67/500] Processing BANKBARODA ...\n",
      "[68/500] Processing BANKINDIA ...\n",
      "[69/500] Processing BASF ...\n",
      "[70/500] Processing BATAINDIA ...\n",
      "[71/500] Processing BAYERCROP ...\n",
      "[72/500] Processing BBTC ...\n",
      "[73/500] Processing BDL ...\n",
      "[74/500] Processing BEL ...\n",
      "[75/500] Processing BEML ...\n",
      "[76/500] Processing BERGEPAINT ...\n",
      "[77/500] Processing BHARATFORG ...\n",
      "[78/500] Processing BHARTIARTL ...\n",
      "[79/500] Processing BHARTIHEXA ...\n",
      "[80/500] Processing BHEL ...\n",
      "[81/500] Processing BIKAJI ...\n",
      "[82/500] Processing BIOCON ...\n",
      "[83/500] Processing BLS ...\n",
      "[84/500] Processing BLUEDART ...\n",
      "[85/500] Processing BLUEJET ...\n",
      "[86/500] Processing BLUESTARCO ...\n",
      "[87/500] Processing BOSCHLTD ...\n",
      "[88/500] Processing BPCL ...\n",
      "[89/500] Processing BRIGADE ...\n",
      "[90/500] Processing BRITANNIA ...\n",
      "[91/500] Processing BSE ...\n",
      "[92/500] Processing BSOFT ...\n",
      "[93/500] Processing CAMPUS ...\n",
      "[94/500] Processing CAMS ...\n",
      "[95/500] Processing CANBK ...\n",
      "[96/500] Processing CANFINHOME ...\n",
      "[97/500] Processing CAPLIPOINT ...\n",
      "[98/500] Processing CARBORUNIV ...\n",
      "[99/500] Processing CASTROLIND ...\n",
      "[100/500] Processing CCL ...\n",
      "[101/500] Processing CDSL ...\n",
      "[102/500] Processing CEATLTD ...\n",
      "[103/500] Processing CENTRALBK ...\n",
      "[104/500] Processing CENTURYPLY ...\n",
      "[105/500] Processing CERA ...\n",
      "[106/500] Processing CESC ...\n",
      "[107/500] Processing CGCL ...\n",
      "[108/500] Processing CGPOWER ...\n",
      "[109/500] Processing CHALET ...\n",
      "[110/500] Processing CHAMBLFERT ...\n",
      "[111/500] Processing CHENNPETRO ...\n",
      "[112/500] Processing CHOICEIN ...\n",
      "[113/500] Processing CHOLAFIN ...\n",
      "[114/500] Processing CHOLAHLDNG ...\n",
      "[115/500] Processing CIPLA ...\n",
      "[116/500] Processing CLEAN ...\n",
      "[117/500] Processing COALINDIA ...\n",
      "[118/500] Processing COCHINSHIP ...\n",
      "[119/500] Processing COFORGE ...\n",
      "[120/500] Processing COHANCE ...\n",
      "[121/500] Processing COLPAL ...\n",
      "[122/500] Processing CONCOR ...\n",
      "[123/500] Processing CONCORDBIO ...\n",
      "[124/500] Processing COROMANDEL ...\n",
      "[125/500] Processing CRAFTSMAN ...\n",
      "[126/500] Processing CREDITACC ...\n",
      "[127/500] Processing CRISIL ...\n",
      "[128/500] Processing CROMPTON ...\n",
      "[129/500] Processing CUB ...\n",
      "[130/500] Processing CUMMINSIND ...\n",
      "[131/500] Processing CYIENT ...\n",
      "[132/500] Processing DABUR ...\n",
      "[133/500] Processing DALBHARAT ...\n",
      "[134/500] Processing DATAPATTNS ...\n",
      "[135/500] Processing DBREALTY ...\n",
      "[136/500] Processing DCMSHRIRAM ...\n",
      "[137/500] Processing DEEPAKFERT ...\n",
      "[138/500] Processing DEEPAKNTR ...\n",
      "[139/500] Processing DELHIVERY ...\n",
      "[140/500] Processing DEVYANI ...\n",
      "[141/500] Processing DIVISLAB ...\n",
      "[142/500] Processing DIXON ...\n",
      "[143/500] Processing DLF ...\n",
      "[144/500] Processing DMART ...\n",
      "[145/500] Processing DOMS ...\n",
      "[146/500] Processing DRREDDY ...\n",
      "[147/500] Processing ECLERX ...\n",
      "[148/500] Processing EICHERMOT ...\n",
      "[149/500] Processing EIDPARRY ...\n",
      "[150/500] Processing EIHOTEL ...\n",
      "[151/500] Processing ELECON ...\n",
      "[152/500] Processing ELGIEQUIP ...\n",
      "[153/500] Processing EMAMILTD ...\n",
      "[154/500] Processing EMCURE ...\n",
      "[155/500] Processing ENDURANCE ...\n",
      "[156/500] Processing ENGINERSIN ...\n",
      "[157/500] Processing ENRIN ...\n",
      "[158/500] Processing ERIS ...\n",
      "[159/500] Processing ESCORTS ...\n",
      "[160/500] Processing ETERNAL ...\n",
      "[161/500] Processing EXIDEIND ...\n",
      "[162/500] Processing FACT ...\n",
      "[163/500] Processing FEDERALBNK ...\n",
      "[164/500] Processing FINCABLES ...\n",
      "[165/500] Processing FINPIPE ...\n",
      "[166/500] Processing FIRSTCRY ...\n",
      "[167/500] Processing FIVESTAR ...\n",
      "[168/500] Processing FLUOROCHEM ...\n",
      "[169/500] Processing FORCEMOT ...\n",
      "[170/500] Processing FORTIS ...\n",
      "[171/500] Processing FSL ...\n",
      "[172/500] Processing GAIL ...\n",
      "[173/500] Processing GESHIP ...\n",
      "[174/500] Processing GICRE ...\n",
      "[175/500] Processing GILLETTE ...\n",
      "[176/500] Processing GLAND ...\n",
      "[177/500] Processing GLAXO ...\n",
      "[178/500] Processing GLENMARK ...\n",
      "[179/500] Processing GMDCLTD ...\n",
      "[180/500] Processing GMRAIRPORT ...\n",
      "[181/500] Processing GODFRYPHLP ...\n",
      "[182/500] Processing GODIGIT ...\n",
      "[183/500] Processing GODREJAGRO ...\n",
      "[184/500] Processing GODREJCP ...\n",
      "[185/500] Processing GODREJIND ...\n",
      "[186/500] Processing GODREJPROP ...\n",
      "[187/500] Processing GPIL ...\n",
      "[188/500] Processing GRANULES ...\n",
      "[189/500] Processing GRAPHITE ...\n",
      "[190/500] Processing GRASIM ...\n",
      "[191/500] Processing GRAVITA ...\n",
      "[192/500] Processing GRSE ...\n",
      "[193/500] Processing GSPL ...\n",
      "[194/500] Processing GUJGASLTD ...\n",
      "[195/500] Processing GVT&D ...\n",
      "[196/500] Processing HAL ...\n",
      "[197/500] Processing HAPPSTMNDS ...\n",
      "[198/500] Processing HAVELLS ...\n",
      "[199/500] Processing HBLENGINE ...\n",
      "[200/500] Processing HCLTECH ...\n",
      "[201/500] Processing HDFCAMC ...\n",
      "[202/500] Processing HDFCBANK ...\n",
      "[203/500] Processing HDFCLIFE ...\n",
      "[204/500] Processing HEG ...\n",
      "[205/500] Processing HEROMOTOCO ...\n",
      "[206/500] Processing HEXT ...\n",
      "[207/500] Processing HFCL ...\n",
      "[208/500] Processing HINDALCO ...\n",
      "[209/500] Processing HINDCOPPER ...\n",
      "[210/500] Processing HINDPETRO ...\n",
      "[211/500] Processing HINDUNILVR ...\n",
      "[212/500] Processing HINDZINC ...\n",
      "[213/500] Processing HOMEFIRST ...\n",
      "[214/500] Processing HONASA ...\n",
      "[215/500] Processing HONAUT ...\n",
      "[216/500] Processing HSCL ...\n",
      "[217/500] Processing HUDCO ...\n",
      "[218/500] Processing HYUNDAI ...\n",
      "[219/500] Processing ICICIBANK ...\n",
      "[220/500] Processing ICICIGI ...\n",
      "[221/500] Processing ICICIPRULI ...\n",
      "[222/500] Processing IDBI ...\n",
      "[223/500] Processing IDEA ...\n",
      "[224/500] Processing IDFCFIRSTB ...\n",
      "[225/500] Processing IEX ...\n",
      "[226/500] Processing IFCI ...\n",
      "[227/500] Processing IGIL ...\n",
      "[228/500] Processing IGL ...\n",
      "[229/500] Processing IIFL ...\n",
      "[230/500] Processing IKS ...\n",
      "[231/500] Processing INDGN ...\n",
      "[232/500] Processing INDHOTEL ...\n",
      "[233/500] Processing INDIACEM ...\n",
      "[234/500] Processing INDIAMART ...\n",
      "[235/500] Processing INDIANB ...\n",
      "[236/500] Processing INDIGO ...\n",
      "[237/500] Processing INDUSINDBK ...\n",
      "[238/500] Processing INDUSTOWER ...\n",
      "[239/500] Processing INFY ...\n",
      "[240/500] Processing INOXINDIA ...\n",
      "[241/500] Processing INOXWIND ...\n",
      "[242/500] Processing INTELLECT ...\n",
      "[243/500] Processing IOB ...\n",
      "[244/500] Processing IOC ...\n",
      "[245/500] Processing IPCALAB ...\n",
      "[246/500] Processing IRB ...\n",
      "[247/500] Processing IRCON ...\n",
      "[248/500] Processing IRCTC ...\n",
      "[249/500] Processing IREDA ...\n",
      "[250/500] Processing IRFC ...\n",
      "[251/500] Processing ITC ...\n",
      "[252/500] Processing ITCHOTELS ...\n",
      "[253/500] Processing ITI ...\n",
      "[254/500] Processing J&KBANK ...\n",
      "[255/500] Processing JBCHEPHARM ...\n",
      "[256/500] Processing JBMA ...\n",
      "[257/500] Processing JINDALSAW ...\n",
      "[258/500] Processing JINDALSTEL ...\n",
      "[259/500] Processing JIOFIN ...\n",
      "[260/500] Processing JKCEMENT ...\n",
      "[261/500] Processing JKTYRE ...\n",
      "[262/500] Processing JMFINANCIL ...\n",
      "[263/500] Processing JPPOWER ...\n",
      "[264/500] Processing JSL ...\n",
      "[265/500] Processing JSWENERGY ...\n",
      "[266/500] Processing JSWINFRA ...\n",
      "[267/500] Processing JSWSTEEL ...\n",
      "[268/500] Processing JUBLFOOD ...\n",
      "[269/500] Processing JUBLINGREA ...\n",
      "[270/500] Processing JUBLPHARMA ...\n",
      "[271/500] Processing JWL ...\n",
      "[272/500] Processing JYOTHYLAB ...\n",
      "[273/500] Processing JYOTICNC ...\n",
      "[274/500] Processing KAJARIACER ...\n",
      "[275/500] Processing KALYANKJIL ...\n",
      "[276/500] Processing KARURVYSYA ...\n",
      "[277/500] Processing KAYNES ...\n",
      "[278/500] Processing KEC ...\n",
      "[279/500] Processing KEI ...\n",
      "[280/500] Processing KFINTECH ...\n",
      "[281/500] Processing KIMS ...\n",
      "[282/500] Processing KIRLOSBROS ...\n",
      "[283/500] Processing KIRLOSENG ...\n",
      "[284/500] Processing KOTAKBANK ...\n",
      "[285/500] Processing KPIL ...\n",
      "[286/500] Processing KPITTECH ...\n",
      "[287/500] Processing KPRMILL ...\n",
      "[288/500] Processing KSB ...\n",
      "[289/500] Processing LALPATHLAB ...\n",
      "[290/500] Processing LATENTVIEW ...\n",
      "[291/500] Processing LAURUSLABS ...\n",
      "[292/500] Processing LEMONTREE ...\n",
      "[293/500] Processing LICHSGFIN ...\n",
      "[294/500] Processing LICI ...\n",
      "[295/500] Processing LINDEINDIA ...\n",
      "[296/500] Processing LLOYDSME ...\n",
      "[297/500] Processing LODHA ...\n",
      "[298/500] Processing LT ...\n",
      "[299/500] Processing LTF ...\n",
      "[300/500] Processing LTFOODS ...\n",
      "[301/500] Processing LTIM ...\n",
      "[302/500] Processing LTTS ...\n",
      "[303/500] Processing LUPIN ...\n",
      "[304/500] Processing M&M ...\n",
      "[305/500] Processing M&MFIN ...\n",
      "[306/500] Processing MAHABANK ...\n",
      "[307/500] Processing MAHSCOOTER ...\n",
      "[308/500] Processing MAHSEAMLES ...\n",
      "[309/500] Processing MANAPPURAM ...\n",
      "[310/500] Processing MANKIND ...\n",
      "[311/500] Processing MANYAVAR ...\n",
      "[312/500] Processing MAPMYINDIA ...\n",
      "[313/500] Processing MARICO ...\n",
      "[314/500] Processing MARUTI ...\n",
      "[315/500] Processing MAXHEALTH ...\n",
      "[316/500] Processing MAZDOCK ...\n",
      "[317/500] Processing MCX ...\n",
      "[318/500] Processing MEDANTA ...\n",
      "[319/500] Processing METROPOLIS ...\n",
      "[320/500] Processing MFSL ...\n",
      "[321/500] Processing MGL ...\n",
      "[322/500] Processing MINDACORP ...\n",
      "[323/500] Processing MMTC ...\n",
      "[324/500] Processing MOTHERSON ...\n",
      "[325/500] Processing MOTILALOFS ...\n",
      "[326/500] Processing MPHASIS ...\n",
      "[327/500] Processing MRF ...\n",
      "[328/500] Processing MRPL ...\n",
      "[329/500] Processing MSUMI ...\n",
      "[330/500] Processing MUTHOOTFIN ...\n",
      "[331/500] Processing NAM-INDIA ...\n",
      "[332/500] Processing NATCOPHARM ...\n",
      "[333/500] Processing NATIONALUM ...\n",
      "[334/500] Processing NAUKRI ...\n",
      "[335/500] Processing NAVA ...\n",
      "[336/500] Processing NAVINFLUOR ...\n",
      "[337/500] Processing NBCC ...\n",
      "[338/500] Processing NCC ...\n",
      "[339/500] Processing NESTLEIND ...\n",
      "[340/500] Processing NETWEB ...\n",
      "[341/500] Processing NEULANDLAB ...\n",
      "[342/500] Processing NEWGEN ...\n",
      "[343/500] Processing NH ...\n",
      "[344/500] Processing NHPC ...\n",
      "[345/500] Processing NIACL ...\n",
      "[346/500] Processing NIVABUPA ...\n",
      "[347/500] Processing NLCINDIA ...\n",
      "[348/500] Processing NMDC ...\n",
      "[349/500] Processing NSLNISP ...\n",
      "[350/500] Processing NTPC ...\n",
      "[351/500] Processing NTPCGREEN ...\n",
      "[352/500] Processing NUVAMA ...\n",
      "[353/500] Processing NUVOCO ...\n",
      "[354/500] Processing NYKAA ...\n",
      "[355/500] Processing OBEROIRLTY ...\n",
      "[356/500] Processing OFSS ...\n",
      "[357/500] Processing OIL ...\n",
      "[358/500] Processing OLAELEC ...\n",
      "[359/500] Processing OLECTRA ...\n",
      "[360/500] Processing ONESOURCE ...\n",
      "[361/500] Processing ONGC ...\n",
      "[362/500] Processing PAGEIND ...\n",
      "[363/500] Processing PATANJALI ...\n",
      "[364/500] Processing PAYTM ...\n",
      "[365/500] Processing PCBL ...\n",
      "[366/500] Processing PERSISTENT ...\n",
      "[367/500] Processing PETRONET ...\n",
      "[368/500] Processing PFC ...\n",
      "[369/500] Processing PFIZER ...\n",
      "[370/500] Processing PGEL ...\n",
      "[371/500] Processing PGHH ...\n",
      "[372/500] Processing PHOENIXLTD ...\n",
      "[373/500] Processing PIDILITIND ...\n",
      "[374/500] Processing PIIND ...\n",
      "[375/500] Processing PNB ...\n",
      "[376/500] Processing PNBHOUSING ...\n",
      "[377/500] Processing POLICYBZR ...\n",
      "[378/500] Processing POLYCAB ...\n",
      "[379/500] Processing POLYMED ...\n",
      "[380/500] Processing POONAWALLA ...\n",
      "[381/500] Processing POWERGRID ...\n",
      "[382/500] Processing POWERINDIA ...\n",
      "[383/500] Processing PPLPHARMA ...\n",
      "[384/500] Processing PRAJIND ...\n",
      "[385/500] Processing PREMIERENE ...\n",
      "[386/500] Processing PRESTIGE ...\n",
      "[387/500] Processing PTCIL ...\n",
      "[388/500] Processing PVRINOX ...\n",
      "[389/500] Processing RADICO ...\n",
      "[390/500] Processing RAILTEL ...\n",
      "[391/500] Processing RAINBOW ...\n",
      "[392/500] Processing RAMCOCEM ...\n",
      "[393/500] Processing RBLBANK ...\n",
      "[394/500] Processing RCF ...\n",
      "[395/500] Processing RECLTD ...\n",
      "[396/500] Processing REDINGTON ...\n",
      "[397/500] Processing RELIANCE ...\n",
      "[398/500] Processing RELINFRA ...\n",
      "[399/500] Processing RHIM ...\n",
      "[400/500] Processing RITES ...\n",
      "[401/500] Processing RKFORGE ...\n",
      "[402/500] Processing RPOWER ...\n",
      "[403/500] Processing RRKABEL ...\n",
      "[404/500] Processing RVNL ...\n",
      "[405/500] Processing SAGILITY ...\n",
      "[406/500] Processing SAIL ...\n",
      "[407/500] Processing SAILIFE ...\n",
      "[408/500] Processing SAMMAANCAP ...\n",
      "[409/500] Processing SAPPHIRE ...\n",
      "[410/500] Processing SARDAEN ...\n",
      "[411/500] Processing SAREGAMA ...\n",
      "[412/500] Processing SBFC ...\n",
      "[413/500] Processing SBICARD ...\n",
      "[414/500] Processing SBILIFE ...\n",
      "[415/500] Processing SBIN ...\n",
      "[416/500] Processing SCHAEFFLER ...\n",
      "[417/500] Processing SCHNEIDER ...\n",
      "[418/500] Processing SCI ...\n",
      "[419/500] Processing SHREECEM ...\n",
      "[420/500] Processing SHRIRAMFIN ...\n",
      "[421/500] Processing SHYAMMETL ...\n",
      "[422/500] Processing SIEMENS ...\n",
      "[423/500] Processing SIGNATURE ...\n",
      "[424/500] Processing SJVN ...\n",
      "[425/500] Processing SKFINDIA ...\n",
      "[426/500] Processing SOBHA ...\n",
      "[427/500] Processing SOLARINDS ...\n",
      "[428/500] Processing SONACOMS ...\n",
      "[429/500] Processing SONATSOFTW ...\n",
      "[430/500] Processing SRF ...\n",
      "[431/500] Processing STARHEALTH ...\n",
      "[432/500] Processing SUMICHEM ...\n",
      "[433/500] Processing SUNDARMFIN ...\n",
      "[434/500] Processing SUNDRMFAST ...\n",
      "[435/500] Processing SUNPHARMA ...\n",
      "[436/500] Processing SUNTV ...\n",
      "[437/500] Processing SUPREMEIND ...\n",
      "[438/500] Processing SUZLON ...\n",
      "[439/500] Processing SWANCORP ...\n",
      "[440/500] Processing SWIGGY ...\n",
      "[441/500] Processing SYNGENE ...\n",
      "[442/500] Processing SYRMA ...\n",
      "[443/500] Processing TARIL ...\n",
      "[444/500] Processing TATACHEM ...\n",
      "[445/500] Processing TATACOMM ...\n",
      "[446/500] Processing TATACONSUM ...\n",
      "[447/500] Processing TATAELXSI ...\n",
      "[448/500] Processing TATAINVEST ...\n",
      "[449/500] Processing TATAMOTORS ...\n",
      "[450/500] Processing TATAPOWER ...\n",
      "[451/500] Processing TATASTEEL ...\n",
      "[452/500] Processing TATATECH ...\n",
      "[453/500] Processing TBOTEK ...\n",
      "[454/500] Processing TCS ...\n",
      "[455/500] Processing TECHM ...\n",
      "[456/500] Processing TECHNOE ...\n",
      "[457/500] Processing TEJASNET ...\n",
      "[458/500] Processing THELEELA ...\n",
      "[459/500] Processing THERMAX ...\n",
      "[460/500] Processing TIINDIA ...\n",
      "[461/500] Processing TIMKEN ...\n",
      "[462/500] Processing TITAGARH ...\n",
      "[463/500] Processing TITAN ...\n",
      "[464/500] Processing TORNTPHARM ...\n",
      "[465/500] Processing TORNTPOWER ...\n",
      "[466/500] Processing TRENT ...\n",
      "[467/500] Processing TRIDENT ...\n",
      "[468/500] Processing TRITURBINE ...\n",
      "[469/500] Processing TRIVENI ...\n",
      "[470/500] Processing TTML ...\n",
      "[471/500] Processing TVSMOTOR ...\n",
      "[472/500] Processing UBL ...\n",
      "[473/500] Processing UCOBANK ...\n",
      "[474/500] Processing ULTRACEMCO ...\n",
      "[475/500] Processing UNIONBANK ...\n",
      "[476/500] Processing UNITDSPR ...\n",
      "[477/500] Processing UNOMINDA ...\n",
      "[478/500] Processing UPL ...\n",
      "[479/500] Processing USHAMART ...\n",
      "[480/500] Processing UTIAMC ...\n",
      "[481/500] Processing VBL ...\n",
      "[482/500] Processing VEDL ...\n",
      "[483/500] Processing VENTIVE ...\n",
      "[484/500] Processing VGUARD ...\n",
      "[485/500] Processing VIJAYA ...\n",
      "[486/500] Processing VMM ...\n",
      "[487/500] Processing VOLTAS ...\n",
      "[488/500] Processing VTL ...\n",
      "[489/500] Processing WAAREEENER ...\n",
      "[490/500] Processing WELCORP ...\n",
      "[491/500] Processing WELSPUNLIV ...\n",
      "[492/500] Processing WHIRLPOOL ...\n",
      "[493/500] Processing WIPRO ...\n",
      "[494/500] Processing WOCKPHARMA ...\n",
      "[495/500] Processing YESBANK ...\n",
      "[496/500] Processing ZEEL ...\n",
      "[497/500] Processing ZENSARTECH ...\n",
      "[498/500] Processing ZENTEC ...\n",
      "[499/500] Processing ZFCVINDIA ...\n",
      "[500/500] Processing ZYDUSLIFE ...\n",
      "\n",
      "=== Top Candidates (by final_score) ===\n",
      "    symbol      bias                                    skip_reason  final_score    volar  volar_norm fo_sentiment  fo_score   pcr  delivery_pct_avg  delivery_score  candle  candle_score  last_close  avg_vol_20  price_ok  avg_vol_ok\n",
      "FEDERALBNK Long Bias                                                    0.905500 0.232461       0.944      Bullish   0.80200 1.008            60.502        1.000000 Bullish           1.0  236.610001 13404885.75      True        True\n",
      "SHRIRAMFIN Long Bias                                                    0.880163 0.193973       0.884      Bullish   0.80675 1.027            54.036        1.000000 Bullish           1.0  748.900024  6079038.45      True        True\n",
      "       LTF Long Bias                                                    0.874287 0.299547       0.984      Bullish   0.80425 1.017            53.078        1.000000 Neutral           0.0  270.489990  6843432.50      True        True\n",
      "  HINDALCO Long Bias                                                    0.872512 0.264600       0.968      Bullish   0.81975 1.079            54.946        1.000000 Neutral           0.0  847.849976  5510764.65      True        True\n",
      "BANKBARODA Long Bias                                                    0.819637 0.203280       0.900      Bullish   0.78125 0.925            49.120        0.941333 Neutral           0.0  278.399994  9266154.60      True        True\n",
      "       IOC Long Bias                                                    0.780058 0.200883       0.896      Bullish   0.82125 1.085            43.942        0.596133 Neutral           0.0  165.899994 15209455.10      True        True\n",
      "SAMMAANCAP Long Bias                                                    0.771735 0.228249       0.936      Bullish   0.75450 0.818            43.646        0.576400 Neutral           0.0  188.589996 28476334.15      True        True\n",
      "     CANBK Long Bias                                                    0.763572 0.274433       0.972      Bullish   0.82575 1.103            38.716        0.247733 Neutral           0.0  136.990005 32465556.85      True        True\n",
      "      BPCL Long Bias                                                    0.730357 0.146277       0.764      Bullish   0.78725 0.949            46.102        0.740133 Neutral           0.0  356.799988  7659444.60      True        True\n",
      "   SBILIFE Long Bias                                                    0.709887 0.110066       0.628      Bullish   0.79225 0.969            62.104        1.000000 Neutral           0.0 1955.699951  1082600.20      True        True\n",
      "  UNOMINDA Long Bias                                                    0.706567 0.127710       0.700      Bullish   0.79625 0.985            46.288        0.752533 Neutral           0.0 1235.199951   904183.75      True        True\n",
      " ABCAPITAL Long Bias                                                    0.614285 0.155587       0.788      Bullish   0.75750 0.830            39.456        0.297067 Bearish          -1.0  324.200012  5791331.80      True        True\n",
      "IDFCFIRSTB      Skip price<100 or NaN (last_close=81.7699966430664)     0.553800 0.183494       0.864      Neutral  -0.10000 0.578            53.348        1.000000 Bullish           1.0   81.769997 34622712.65     False        True\n",
      "      BHEL Long Bias                                                    0.524565 0.085930       0.512      Bullish   0.86350 1.254            34.194       -0.053733 Neutral           0.0  265.489990 10261665.60      True        True\n",
      "   PVRINOX Watchlist                                                    0.519000 0.167781       0.820           NA   0.00000   NaN            53.078        1.000000 Neutral           0.0 1206.599976   423436.00      True        True\n",
      "  GRANULES Watchlist                                                    0.515800 0.218112       0.924           NA   0.00000   NaN            51.324        1.000000 Bearish          -1.0  565.599976  1032074.00      True        True\n",
      "PNBHOUSING Watchlist                                                    0.512468 0.179276       0.852      Neutral  -0.05775 0.769            49.928        0.995200 Neutral           0.0  928.700012  1260318.25      True        True\n",
      "    GESHIP Watchlist                                                    0.502020 0.171616       0.832           NA   0.00000   NaN            47.762        0.850800 Neutral           0.0 1099.599976   468741.90      True        True\n",
      "CANFINHOME Watchlist                                                    0.501000 0.151022       0.780           NA   0.00000   NaN            63.848        1.000000 Neutral           0.0  867.900024   347219.90      True        True\n",
      "NATIONALUM Watchlist                                                    0.496638 0.226865       0.932      Neutral  -0.08475 0.661            45.690        0.712667 Neutral           0.0  234.139999 11845956.95      True        True\n",
      "\n",
      "✅ Saved ranked picks to: filtered_intraday_picks.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Intraday Stock Filter — VOLAR + F&O Sentiment + Delivery% (+ optional Candles)\n",
    "=============================================================================\n",
    "\n",
    "What it does\n",
    "------------\n",
    "1) Reads universe from symbols.txt (one symbol per line).\n",
    "2) Loads latest F&O sentiment from: option_chain_outputs/summary.csv (produced by your OC script).\n",
    "3) Pulls daily prices (Yahoo Finance) to compute VOLAR over lookback window.\n",
    "4) Fetches NSE deliverable stats to compute recent Delivery% averages.\n",
    "5) (Optional) Detects simple bullish/bearish candle patterns without TA-Lib.\n",
    "6) Scores each stock and produces a ranked list of long/short candidates.\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "- Prints a terminal summary (top-N).\n",
    "- Saves 'filtered_intraday_picks.csv' with detailed columns.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- News sentiment intentionally excluded (by your request).\n",
    "- Candlestick filter is optional (toggle in CONFIG).\n",
    "- F&O sentiment is read-only from your generated 'summary.csv'; this script does not hit OC endpoints.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, sys, time, math, warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "from datetime import date, timedelta, datetime, timezone  # ✅ timezone-aware datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# -----------------------------------\n",
    "# CONFIG\n",
    "# -----------------------------------\n",
    "class CONFIG:\n",
    "    # Universe & paths\n",
    "    SYMBOLS_FILE = \"symbols.txt\"\n",
    "    FNO_SUMMARY_CSV = os.path.join(\"option_chain_outputs\", \"summary.csv\")\n",
    "    OUTPUT_CSV = \"filtered_intraday_picks.csv\"\n",
    "\n",
    "    # Data sources / lookbacks\n",
    "    VOLAR_LOOKBACK_DAYS = 60         # trading days for VOLAR calc (daily)\n",
    "    DELIVERY_LOOKBACK_DAYS = 30      # days to pull from NSE deliverables\n",
    "    DELIVERY_RECENT_AVG_DAYS = 5     # average Delivery% over last N days\n",
    "\n",
    "    # Scoring Weights (sum doesn't need to be exactly 1; we normalize)\n",
    "    WEIGHT_VOLAR = 0.45\n",
    "    WEIGHT_FNO   = 0.35\n",
    "    WEIGHT_DELV  = 0.15\n",
    "    WEIGHT_CDL   = 0.05             # set to 0.0 to ignore candle_score altogether\n",
    "\n",
    "    # Candlestick toggle\n",
    "    ENABLE_CANDLE_FILTER = True      # if True, adds candle_score (+1 bull, -1 bear, 0 neutral)\n",
    "\n",
    "    # Ranking/selection controls\n",
    "    MIN_PRICE = 100                  # basic quality filter (close >= MIN_PRICE)\n",
    "    MIN_VOLUMN_AVG = 2e5             # 20d avg volume minimum (2 lakh)\n",
    "    TOP_N_PRINT = 20                 # print top-N to terminal\n",
    "\n",
    "    # NSE deliverables fetch config (reuses your approach)\n",
    "    NSE_RETRIES = 3\n",
    "    NSE_TIMEOUT = 30\n",
    "    REQUEST_SLEEP_SEC = 0.8          # be gentle\n",
    "\n",
    "# -----------------------------------\n",
    "# Yahoo helper (no external creds)\n",
    "# -----------------------------------\n",
    "def fetch_yahoo_history(symbol: str, lookback_days: int = 90) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch last ~lookback_days of daily OHLCV using yfinance.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception:\n",
    "        warnings.warn(\"yfinance not available; install with: pip install yfinance\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # ✅ timezone-aware UTC datetime (fixes DeprecationWarning)\n",
    "    end = datetime.now(timezone.utc).date()\n",
    "    start = end - timedelta(days=int(lookback_days * 2))  # buffer for weekends/holidays\n",
    "    try:\n",
    "        df = yf.download(symbol + \".NS\", start=start.isoformat(), end=end.isoformat(),\n",
    "                         interval=\"1d\", progress=False, auto_adjust=False, threads=False, multi_level_index=False)\n",
    "        if df is None or df.empty:\n",
    "            # Try without \".NS\" (indices or already NSE format)\n",
    "            df = yf.download(symbol, start=start.isoformat(), end=end.isoformat(),\n",
    "                             interval=\"1d\", progress=False, auto_adjust=False, threads=False, multi_level_index=False)\n",
    "        if df is None or df.empty:\n",
    "            return pd.DataFrame()\n",
    "        df = df.rename(columns={\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\n",
    "                                \"Adj Close\":\"adjclose\",\"Volume\":\"volume\"})\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Yahoo fetch failed for {symbol}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# -----------------------------------\n",
    "# VOLAR\n",
    "# -----------------------------------\n",
    "def compute_volar(df: pd.DataFrame, lookback_days: int) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    VOLAR = mean(returns) / std(returns) over lookback_days.\n",
    "    Uses log returns of 'close'.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty or \"close\" not in df.columns:\n",
    "        return None\n",
    "    d = df.dropna(subset=[\"close\"]).copy()\n",
    "    if d.empty:\n",
    "        return None\n",
    "    d[\"ret\"] = np.log(d[\"close\"]).diff()\n",
    "    tail = d[\"ret\"].dropna().tail(lookback_days)\n",
    "    if len(tail) < max(10, lookback_days // 3):\n",
    "        return None\n",
    "    mu = tail.mean()\n",
    "    sd = tail.std(ddof=0)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return None\n",
    "    return float(mu / sd)\n",
    "\n",
    "# -----------------------------------\n",
    "# Candlestick (very light, no TA-Lib)\n",
    "# -----------------------------------\n",
    "def recent_candle_score(df: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Returns +1 if recent daily pattern is bullish, -1 if bearish, 0 otherwise.\n",
    "    Patterns: Bullish Engulfing, Hammer; Bearish Engulfing, Shooting Star.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return 0\n",
    "    d = df.dropna(subset=[\"open\",\"high\",\"low\",\"close\"]).copy()\n",
    "    if len(d) < 3:\n",
    "        return 0\n",
    "    d = d.tail(3).reset_index(drop=True)\n",
    "\n",
    "    # simple helpers\n",
    "    def body(o,c): return abs(c-o)\n",
    "    def upper(o,h,c): return h - max(o,c)\n",
    "    def lower(o,l,c): return min(o,c) - l\n",
    "\n",
    "    # Last two candles for engulfing check\n",
    "    o1,c1 = d.loc[1,\"open\"], d.loc[1,\"close\"]\n",
    "    o2,c2 = d.loc[2,\"open\"], d.loc[2,\"close\"]\n",
    "    h2,l2 = d.loc[2,\"high\"], d.loc[2,\"low\"]\n",
    "\n",
    "    # Bullish engulfing\n",
    "    if (c1 < o1) and (c2 > o2) and (o2 <= c1) and (c2 >= o1):\n",
    "        return +1\n",
    "    # Bearish engulfing\n",
    "    if (c1 > o1) and (c2 < o2) and (o2 >= c1) and (c2 <= o1):\n",
    "        return -1\n",
    "\n",
    "    # Hammer (bullish reversal proxy)\n",
    "    if lower(o2,l2,c2) >= 2*body(o2,c2) and upper(o2,h2,c2) <= body(o2,c2):\n",
    "        return +1\n",
    "    # Shooting star (bearish)\n",
    "    if upper(o2,h2,c2) >= 2*body(o2,c2) and lower(o2,l2,c2) <= body(o2,c2):\n",
    "        return -1\n",
    "\n",
    "    return 0\n",
    "\n",
    "# -----------------------------------\n",
    "# F&O sentiment (from your summary.csv)\n",
    "# -----------------------------------\n",
    "def load_fno_sentiment(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads option_chain_outputs/summary.csv and maps to a numeric score.\n",
    "    Expecting columns: symbol, sentiment, pcr, ...\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        warnings.warn(f\"F&O summary not found at {path}\")\n",
    "        return pd.DataFrame()\n",
    "    df = pd.read_csv(path)\n",
    "    # Normalize symbol to uppercase (strip .NS if present)\n",
    "    df[\"symbol\"] = df[\"symbol\"].astype(str).str.upper().str.replace(\".NS\",\"\", regex=False)\n",
    "\n",
    "    # Sentiment to numeric score (+1 bullish, 0 neutral, -1 bearish)\n",
    "    sent_map = {\"BULLISH\": 1.0, \"NEUTRAL\": 0.0, \"BEARISH\": -1.0}\n",
    "    df[\"fo_sentiment_score\"] = df.get(\"sentiment\",\"Neutral\").astype(str).str.upper().map(sent_map).fillna(0.0)\n",
    "\n",
    "    # Optional: mild continuous tilt from PCR band (cap between -1,+1)\n",
    "    if \"pcr\" in df.columns:\n",
    "        df[\"pcr_score_raw\"] = df[\"pcr\"].clip(0.5, 1.5)\n",
    "        # Map PCR: <0.8 → -0.5 .. >1.2 → +0.5 linearly\n",
    "        df[\"pcr_score\"] = ((df[\"pcr_score_raw\"] - 1.0) / 0.4).clip(-1,1) * 0.5\n",
    "    else:\n",
    "        df[\"pcr_score\"] = 0.0\n",
    "\n",
    "    # Combine discrete sentiment + PCR tilt\n",
    "    df[\"fo_score\"] = (0.8*df[\"fo_sentiment_score\"] + 0.2*df[\"pcr_score\"]).clip(-1,1)\n",
    "    return df[[\"symbol\",\"fo_score\",\"sentiment\",\"pcr\"]].copy()\n",
    "\n",
    "# -----------------------------------\n",
    "# Delivery% (NSE deliverables)\n",
    "# -----------------------------------\n",
    "def get_nse_history(symbol, from_date, to_date,\n",
    "                    retries=CONFIG.NSE_RETRIES, timeout=CONFIG.NSE_TIMEOUT) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches historical stock data incl. Deliverable_Perc from NSE India.\n",
    "    \"\"\"\n",
    "    api_url = (\n",
    "        \"https://www.nseindia.com/api/historicalOR/generateSecurityWiseHistoricalData?\"\n",
    "        f\"symbol={symbol}&series=EQ&type=priceVolumeDeliverable&\"\n",
    "        f\"from={from_date}&to={to_date}\"\n",
    "    )\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36',\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'X-Requested-With': 'XMLHttpRequest'\n",
    "    }\n",
    "    session = requests.Session()\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            report_page_url = f\"https://www.nseindia.com/get-quotes/equity?symbol={symbol}\"\n",
    "            session.get(report_page_url, headers=headers, timeout=timeout)\n",
    "            response = session.get(api_url, headers=headers, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['data'])\n",
    "            if df.empty:\n",
    "                return pd.DataFrame()\n",
    "            df.rename(columns={\n",
    "                'mTIMESTAMP': 'Date',\n",
    "                'CH_SYMBOL': 'Symbol',\n",
    "                'CH_SERIES': 'Series',\n",
    "                'CH_OPENING_PRICE': 'Open',\n",
    "                'CH_TRADE_HIGH_PRICE': 'High',\n",
    "                'CH_TRADE_LOW_PRICE': 'Low',\n",
    "                'CH_CLOSING_PRICE': 'Close',\n",
    "                'CH_TOT_TRADED_QTY': 'Volume',\n",
    "                'CH_TOTAL_TRADES': 'Trades',\n",
    "                'COP_DELIV_PERC': 'Deliverable_Perc'\n",
    "            }, inplace=True)\n",
    "            df = df[['Symbol','Series','Date','Open','High','Low','Close','Volume','Trades','Deliverable_Perc']]\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format='%d-%b-%Y', errors='coerce')\n",
    "            df = df.dropna(subset=['Date']).set_index('Date').sort_index()\n",
    "            return df\n",
    "        except requests.exceptions.RequestException:\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(1.6)\n",
    "            else:\n",
    "                return pd.DataFrame()\n",
    "\n",
    "def recent_delivery_pct(symbol: str, days_to_pull: int, recent_avg_days: int) -> Optional[float]:\n",
    "    to_date = date.today()\n",
    "    from_date = to_date - timedelta(days=days_to_pull)\n",
    "    to_date_str = to_date.strftime('%d-%m-%Y')\n",
    "    from_date_str = from_date.strftime('%d-%m-%Y')\n",
    "    df = get_nse_history(symbol, from_date_str, to_date_str)\n",
    "    if df is None or df.empty or \"Deliverable_Perc\" not in df.columns:\n",
    "        return None\n",
    "    tail = df[\"Deliverable_Perc\"].astype(float).tail(recent_avg_days)\n",
    "    if tail.empty:\n",
    "        return None\n",
    "    return float(tail.mean())\n",
    "\n",
    "def delivery_score_from_pct(p: Optional[float]) -> float:\n",
    "    \"\"\"\n",
    "    Map Delivery% to a score in [-1,+1], centered ~30-35%.\n",
    "    \"\"\"\n",
    "    if p is None or math.isnan(p):\n",
    "        return 0.0\n",
    "    # Piecewise: <20% -> -1 to 0, 20-50% -> linear to +1\n",
    "    if p <= 20:  return -1.0\n",
    "    if p >= 50:  return +1.0\n",
    "    # Linear between 20 and 50\n",
    "    return ((p - 20) / 30.0) * 2 - 1  # maps 20->-1, 50->+1\n",
    "\n",
    "# -----------------------------------\n",
    "# Scoring\n",
    "# -----------------------------------\n",
    "def normalize_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rank-based scaling to [-1,+1] (robust vs outliers).\n",
    "    \"\"\"\n",
    "    if s.isnull().all():\n",
    "        return pd.Series([0]*len(s), index=s.index, dtype=float)\n",
    "    r = s.rank(method=\"average\", pct=True)\n",
    "    return (r - 0.5) * 2.0\n",
    "\n",
    "def final_score(volar, fo, delv, cdl) -> float:\n",
    "    w = np.array([CONFIG.WEIGHT_VOLAR, CONFIG.WEIGHT_FNO, CONFIG.WEIGHT_DELV, CONFIG.WEIGHT_CDL], dtype=float)\n",
    "    V = np.array([volar, fo, delv, cdl], dtype=float)\n",
    "    # Normalize weights\n",
    "    if w.sum() == 0:\n",
    "        return float(np.nan)\n",
    "    w = w / w.sum()\n",
    "    return float(np.nansum(w * V))\n",
    "\n",
    "# -----------------------------------\n",
    "# Main pipeline\n",
    "# -----------------------------------\n",
    "def load_universe(path: str) -> List[str]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"❌ Universe file not found: {path}\")\n",
    "        sys.exit(1)\n",
    "    with open(path) as f:\n",
    "        syms = [s.strip().upper() for s in f if s.strip()]\n",
    "    return syms\n",
    "\n",
    "def main():\n",
    "    syms = load_universe(CONFIG.SYMBOLS_FILE)\n",
    "\n",
    "    # Load F&O summary\n",
    "    fno_df = load_fno_sentiment(CONFIG.FNO_SUMMARY_CSV)\n",
    "\n",
    "    rows = []\n",
    "    for i, sym in enumerate(syms, 1):\n",
    "        print(f\"[{i}/{len(syms)}] Processing {sym} ...\")\n",
    "        row = {\"symbol\": sym}\n",
    "\n",
    "        # --- Prices for VOLAR + basic sanity filters\n",
    "        px = fetch_yahoo_history(sym, lookback_days=max(CONFIG.VOLAR_LOOKBACK_DAYS, 120))\n",
    "        if px is None or px.empty:\n",
    "            row[\"volar\"] = np.nan\n",
    "            row[\"last_close\"] = np.nan\n",
    "            row[\"avg_vol_20\"] = np.nan\n",
    "            row[\"price_ok\"] = False\n",
    "            row[\"avg_vol_ok\"] = False\n",
    "        else:\n",
    "            last_close = float(px[\"close\"].dropna().iloc[-1]) if \"close\" in px.columns and not px[\"close\"].dropna().empty else np.nan\n",
    "            avg_vol_20 = float(px[\"volume\"].dropna().tail(20).mean()) if \"volume\" in px.columns else np.nan\n",
    "            row[\"last_close\"] = last_close\n",
    "            row[\"avg_vol_20\"] = avg_vol_20\n",
    "            row[\"price_ok\"] = (not math.isnan(last_close)) and (last_close >= CONFIG.MIN_PRICE)\n",
    "            row[\"avg_vol_ok\"] = (not math.isnan(avg_vol_20)) and (avg_vol_20 >= CONFIG.MIN_VOLUMN_AVG)\n",
    "            row[\"volar\"] = compute_volar(px, CONFIG.VOLAR_LOOKBACK_DAYS)\n",
    "\n",
    "        # --- Candlestick score (optional)\n",
    "        cdl_score = 0.0\n",
    "        cdl_tag = \"Neutral\"\n",
    "        if CONFIG.ENABLE_CANDLE_FILTER and px is not None and not px.empty:\n",
    "            score = recent_candle_score(px)\n",
    "            cdl_score = float(score)  # {-1,0,+1}\n",
    "            cdl_tag = \"Bullish\" if score > 0 else \"Bearish\" if score < 0 else \"Neutral\"\n",
    "        row[\"candle\"] = cdl_tag\n",
    "        row[\"candle_score\"] = cdl_score\n",
    "\n",
    "        # --- F&O score (from summary)\n",
    "        if not fno_df.empty:\n",
    "            m = fno_df[fno_df[\"symbol\"] == sym]\n",
    "            if not m.empty:\n",
    "                row[\"fo_score\"] = float(m[\"fo_score\"].iloc[0])\n",
    "                row[\"fo_sentiment\"] = str(m[\"sentiment\"].iloc[0])\n",
    "                row[\"pcr\"] = float(m[\"pcr\"].iloc[0]) if not pd.isna(m[\"pcr\"].iloc[0]) else np.nan\n",
    "            else:\n",
    "                row[\"fo_score\"] = 0.0\n",
    "                row[\"fo_sentiment\"] = \"NA\"\n",
    "                row[\"pcr\"] = np.nan\n",
    "        else:\n",
    "            row[\"fo_score\"] = 0.0\n",
    "            row[\"fo_sentiment\"] = \"NA\"\n",
    "            row[\"pcr\"] = np.nan\n",
    "\n",
    "        # --- Delivery%\n",
    "        d_pct = recent_delivery_pct(sym, CONFIG.DELIVERY_LOOKBACK_DAYS, CONFIG.DELIVERY_RECENT_AVG_DAYS)\n",
    "        row[\"delivery_pct_avg\"] = d_pct if d_pct is not None else np.nan\n",
    "        row[\"delivery_score\"] = delivery_score_from_pct(d_pct)\n",
    "\n",
    "        rows.append(row)\n",
    "        time.sleep(CONFIG.REQUEST_SLEEP_SEC)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Normalize VOLAR into [-1,+1] based on ranks (to combine fairly)\n",
    "    df[\"volar_norm\"] = normalize_series(df[\"volar\"])\n",
    "\n",
    "    # Combine to final score\n",
    "    df[\"final_score\"] = df.apply(\n",
    "        lambda r: final_score(\n",
    "            r.get(\"volar_norm\", 0.0),\n",
    "            r.get(\"fo_score\", 0.0),\n",
    "            r.get(\"delivery_score\", 0.0),\n",
    "            r.get(\"candle_score\", 0.0)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # --- Bias + reason (so you know why something was skipped)\n",
    "    def bias_from_scores_with_reason(row):\n",
    "        reasons = []\n",
    "        if not row.get(\"price_ok\", False):\n",
    "            reasons.append(f\"price<{CONFIG.MIN_PRICE} or NaN (last_close={row.get('last_close')})\")\n",
    "        if not row.get(\"avg_vol_ok\", False):\n",
    "            reasons.append(f\"avgVol20<{CONFIG.MIN_VOLUMN_AVG} or NaN (avg_vol_20={row.get('avg_vol_20')})\")\n",
    "        if reasons:\n",
    "            return \"Skip\", \"; \".join(reasons)\n",
    "\n",
    "        tilt = (row.get(\"fo_score\", 0.0)) + 0.25*row.get(\"candle_score\", 0.0)\n",
    "        if row.get(\"final_score\", 0.0) >= 0.2 and tilt > 0:\n",
    "            return \"Long Bias\", \"\"\n",
    "        if row.get(\"final_score\", 0.0) <= -0.2 and tilt < 0:\n",
    "            return \"Short Bias\", \"\"\n",
    "        return \"Watchlist\", \"\"\n",
    "\n",
    "    df[\"bias\"], df[\"skip_reason\"] = zip(*df.apply(bias_from_scores_with_reason, axis=1))\n",
    "\n",
    "    # Sort & save\n",
    "    df_sorted = df.sort_values(by=\"final_score\", ascending=False)\n",
    "\n",
    "    keep_cols = [\n",
    "        \"symbol\",\"bias\",\"skip_reason\",\"final_score\",\n",
    "        \"volar\",\"volar_norm\",\n",
    "        \"fo_sentiment\",\"fo_score\",\"pcr\",\n",
    "        \"delivery_pct_avg\",\"delivery_score\",\n",
    "        \"candle\",\"candle_score\",\n",
    "        \"last_close\",\"avg_vol_20\",\"price_ok\",\"avg_vol_ok\"\n",
    "    ]\n",
    "    for c in keep_cols:\n",
    "        if c not in df_sorted.columns:\n",
    "            df_sorted[c] = np.nan\n",
    "\n",
    "    df_sorted[keep_cols].to_csv(CONFIG.OUTPUT_CSV, index=False)\n",
    "\n",
    "    # Terminal print\n",
    "    print(\"\\n=== Top Candidates (by final_score) ===\")\n",
    "    to_show = df_sorted[keep_cols].head(CONFIG.TOP_N_PRINT)\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 180):\n",
    "        print(to_show.to_string(index=False))\n",
    "\n",
    "    print(f\"\\n✅ Saved ranked picks to: {CONFIG.OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
