{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f87a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 22:41:02 | INFO | Using benchmark: ^CRSLDX\n",
      "2025-10-15 22:43:54 | INFO | Calendar: prev=2025-10-13 last=2025-10-14 next=None\n",
      "2025-10-15 22:44:37 | INFO | WROTE    \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Daily SuperTrend Scheduler (No-CLI version)\n",
    "- All configuration lives in the CONFIG block below.\n",
    "- Run this script once per day after market close (IST).\n",
    "- It persists state to keep tracking positions, pending orders, and ledger.\n",
    "\n",
    "Usage:\n",
    "    python daily_supertrend_scheduler_nocli.py\n",
    "\"\"\"\n",
    "import os, json, math, logging, warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception:\n",
    "    yf = None\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "log = logging.getLogger(\"st_sched\")\n",
    "\n",
    "# ============================ CONFIG ============================\n",
    "# Set everything here (no command-line flags)\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Dates\n",
    "    start_date: str = \"2015-01-01\"\n",
    "    end_date: str   = \"today\"                       # 'today' resolves to Asia/Kolkata today\n",
    "\n",
    "    # Paths\n",
    "    universe_path: str = \"nifty500.txt\"\n",
    "    cache_dir: str     = \"cache\"\n",
    "    out_dir: str       = \"daily_outputs\"\n",
    "    state_dir: str     = \"state\"\n",
    "\n",
    "    # Best-combo knobs you shared\n",
    "    min_confirmations: int = 2\n",
    "    use_macd_confirm: bool = False\n",
    "    use_ema_confirm: bool = True      # EMA(5/20)\n",
    "    use_ema921_confirm: bool = False  # EMA(9/21)\n",
    "    use_adx_confirm: bool = False\n",
    "\n",
    "    use_rsi_filter: bool = True\n",
    "    use_bb_reinforce: bool = False\n",
    "    use_obv_confirm: bool = False\n",
    "\n",
    "    # Indicators / filters\n",
    "    rsi_len: int = 14\n",
    "    rsi_ob_level: float = 70.0\n",
    "    rsi_require_rising: bool = True\n",
    "    st_atr_len: int = 10\n",
    "    st_multiplier: float = 3.0\n",
    "    macd_fast: int = 12\n",
    "    macd_slow: int = 26\n",
    "    macd_signal: int = 9\n",
    "    macd_cross_lookback: int = 3\n",
    "    ema_fast: int = 5\n",
    "    ema_slow: int = 20\n",
    "    ema_fast_2: int = 9\n",
    "    ema_slow_2: int = 21\n",
    "    bb_len: int = 20\n",
    "    bb_std: float = 2.0\n",
    "    bb_require_rising: bool = True\n",
    "    adx_len: int = 14\n",
    "    adx_min: float = 20.0\n",
    "    volar_lookback: int = 252\n",
    "    filter_52w_window: int = 252\n",
    "    within_pct_of_52w_high: float = 0.70\n",
    "\n",
    "    # Portfolio & execution\n",
    "    apply_fees: bool = True\n",
    "    initial_capital: float = 200_000.0\n",
    "    max_concurrent_positions: int = 4\n",
    "    deploy_cash_frac: float = 0.25\n",
    "    top_k_daily: int = 3\n",
    "    entry_on_next_open: bool = True\n",
    "    exit_on_next_open: bool = True\n",
    "\n",
    "    # Benchmark preference\n",
    "    benchmark_try: Tuple[str,...] = (\"^CRSLDX\",\"^CNX500\",\"^NIFTY500\",\"^NSEI\",\"^BSESN\",\"^BSE500\")\n",
    "\n",
    "CFG = Config()\n",
    "# ============================ END CONFIG ============================\n",
    "\n",
    "TZ = \"Asia/Kolkata\"\n",
    "def today_str(): return pd.Timestamp.today(tz=TZ).strftime(\"%Y-%m-%d\")\n",
    "def resolve_end_date(end: str) -> str: return today_str() if str(end).lower()==\"today\" else end\n",
    "def ensure_dirs(*paths): [os.makedirs(p, exist_ok=True) for p in paths]\n",
    "\n",
    "def load_universe(path: str) -> List[str]:\n",
    "    if not os.path.exists(path): raise FileNotFoundError(f\"universe file not found: {path}\")\n",
    "    out, seen = [], set()\n",
    "    for ln in open(path, \"r\", encoding=\"utf-8\"):\n",
    "        s = ln.strip().upper()\n",
    "        if not s: continue\n",
    "        if not s.endswith(\".NS\"): s += \".NS\"\n",
    "        if s not in seen: out.append(s); seen.add(s)\n",
    "    return out\n",
    "\n",
    "def fetch_prices(tickers: List[str], start: str, end: str, cache_dir: str) -> Dict[str, pd.DataFrame]:\n",
    "    ensure_dirs(cache_dir)\n",
    "    data = {}\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            df = yf.download(t, start=start, end=end, auto_adjust=True, progress=False, multi_level_index=False)\n",
    "            if df is None or df.empty: continue\n",
    "            df = df.rename(columns=str.title)[['Open','High','Low','Close','Volume']].dropna()\n",
    "            df.index.name = \"date\"\n",
    "            data[t] = df\n",
    "        except Exception as e:\n",
    "            log.warning(\"download fail %s: %s\", t, e)\n",
    "    return data\n",
    "\n",
    "def ema(s, span): return s.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "def rsi(s, length=14):\n",
    "    d=s.diff(); g=(d.where(d>0,0.0)).rolling(length).mean(); l=(-d.where(d<0,0.0)).rolling(length).mean()\n",
    "    rs=g/l.replace(0.0,np.nan); out=100-(100/(1+rs)); return out.fillna(50.0)\n",
    "def _tr(h,l,pc): \n",
    "    return pd.concat([(h-l).abs(), (h-pc).abs(), (l-pc).abs()], axis=1).max(axis=1)\n",
    "def atr(h,l,c,length=14): return _tr(h,l,c.shift(1)).rolling(length).mean()\n",
    "def supertrend(df, atr_len=10, mult=3.0):\n",
    "    hl2=(df[\"High\"]+df[\"Low\"])/2.0; _a=atr(df[\"High\"],df[\"Low\"],df[\"Close\"],atr_len)\n",
    "    up=hl2+mult*_a; dn=hl2-mult*_a\n",
    "    st=pd.Series(index=df.index,dtype=float); dr=pd.Series(index=df.index,dtype=int)\n",
    "    st.iloc[0]=up.iloc[0]; dr.iloc[0]=1\n",
    "    for i in range(1,len(df)):\n",
    "        dr.iloc[i]=1 if df[\"Close\"].iloc[i]>st.iloc[i-1] else (-1 if df[\"Close\"].iloc[i]<st.iloc[i-1] else dr.iloc[i-1])\n",
    "        st.iloc[i]=min(up.iloc[i],st.iloc[i-1]) if dr.iloc[i]==1 else max(dn.iloc[i],st.iloc[i-1])\n",
    "        if dr.iloc[i]==1 and df[\"Close\"].iloc[i]<st.iloc[i]: dr.iloc[i]=-1; st.iloc[i]=dn.iloc[i]\n",
    "        elif dr.iloc[i]==-1 and df[\"Close\"].iloc[i]>st.iloc[i]: dr.iloc[i]=1; st.iloc[i]=up.iloc[i]\n",
    "    return pd.DataFrame({\"st_value\":st,\"st_dir\":dr})\n",
    "def macd(s,fast=12,slow=26,signal=9):\n",
    "    ef=s.ewm(span=fast,adjust=False,min_periods=fast).mean(); es=s.ewm(span=slow,adjust=False,min_periods=slow).mean()\n",
    "    line=ef-es; sig=line.ewm(span=signal,adjust=False,min_periods=signal).mean(); hist=line-sig; return line,sig,hist\n",
    "def boll(s, length=20, std=2.0):\n",
    "    mid=s.rolling(length).mean(); dev=s.rolling(length).std(ddof=0); return mid, mid+std*dev, mid-std*dev\n",
    "def obv(c,v): return (np.sign(c.diff().fillna(0.0))*v).cumsum().fillna(0.0)\n",
    "def adx_di(h,l,c,length=14):\n",
    "    ph,pl,pc=h.shift(1),l.shift(1),c.shift(1); up, dn = h-ph, pl-l\n",
    "    plus_dm=up.where((up>dn)&(up>0),0.0); minus_dm=dn.where((dn>up)&(dn>0),0.0)\n",
    "    tr=_tr(h,l,pc); alpha=1.0/length\n",
    "    atr_=tr.ewm(alpha=alpha, adjust=False, min_periods=length).mean()\n",
    "    plus_di=100*(plus_dm.ewm(alpha=alpha, adjust=False, min_periods=length).mean()/atr_)\n",
    "    minus_di=100*(minus_dm.ewm(alpha=alpha, adjust=False, min_periods=length).mean()/atr_)\n",
    "    dx=100*(plus_di-minus_di).abs()/(plus_di+minus_di).replace(0,np.nan)\n",
    "    adx=dx.ewm(alpha=alpha, adjust=False, min_periods=length).mean()\n",
    "    return adx, plus_di, minus_di\n",
    "\n",
    "def compute_indicators(df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    d=df.copy()\n",
    "    st=supertrend(d, cfg.st_atr_len, cfg.st_multiplier); d=pd.concat([d,st],axis=1)\n",
    "    d[\"rsi\"]=rsi(d[\"Close\"], cfg.rsi_len); d[\"rsi_prev\"]=d[\"rsi\"].shift(1)\n",
    "    d[\"ema_f\"]=ema(d[\"Close\"], cfg.ema_fast); d[\"ema_s\"]=ema(d[\"Close\"], cfg.ema_slow)\n",
    "    d[\"ema_f2\"]=ema(d[\"Close\"], cfg.ema_fast_2); d[\"ema_s2\"]=ema(d[\"Close\"], cfg.ema_slow_2)\n",
    "    d[\"macd_line\"],d[\"macd_signal\"],d[\"macd_hist\"]=macd(d[\"Close\"], cfg.macd_fast, cfg.macd_slow, cfg.macd_signal)\n",
    "    d[\"bb_mid\"],d[\"bb_up\"],d[\"bb_dn\"]=boll(d[\"Close\"], cfg.bb_len, cfg.bb_std)\n",
    "    d[\"obv\"]=obv(d[\"Close\"], d[\"Volume\"]); d[\"obv_prev\"]=d[\"obv\"].shift(1)\n",
    "    d[\"adx\"],d[\"di_plus\"],d[\"di_minus\"]=adx_di(d[\"High\"], d[\"Low\"], d[\"Close\"], cfg.adx_len)\n",
    "    d[\"avg_vol_20\"]=d[\"Volume\"].rolling(20).mean()\n",
    "    d[\"high_52w\"]=d[\"Close\"].rolling(cfg.filter_52w_window).max()\n",
    "    return d.dropna()\n",
    "\n",
    "def pick_benchmark(benchmarks: Tuple[str,...], start: str, end: str, cache_dir: str):\n",
    "    for t in benchmarks:\n",
    "        df_map=fetch_prices([t], start, end, cache_dir); df=df_map.get(t)\n",
    "        if df is not None and not df.empty:\n",
    "            log.info(\"Using benchmark: %s\", t); return t, df\n",
    "    idx=pd.date_range(start=start, end=end, freq=\"B\")\n",
    "    return \"SYNTH\", pd.DataFrame({\"Close\":np.ones(len(idx))}, index=idx)\n",
    "\n",
    "def compute_volar_scores(end_dt: pd.Timestamp, tickers: List[str], data_map: Dict[str,pd.DataFrame], bench_df: pd.DataFrame, lookback: int) -> Dict[str,float]:\n",
    "    scores={}; b=bench_df[\"Close\"].loc[:end_dt].pct_change().dropna().iloc[-lookback:]\n",
    "    for t in tickers:\n",
    "        df=data_map.get(t); scores[t]=0.0\n",
    "        if df is None or df.empty: continue\n",
    "        if end_dt not in df.index: df=df[df.index<=end_dt]; \n",
    "        if df is None or len(df)==0: continue\n",
    "        r=df[\"Close\"].loc[:end_dt].pct_change().dropna().iloc[-lookback:]\n",
    "        common=pd.concat([r,b],axis=1,keys=[\"s\",\"b\"]).dropna()\n",
    "        if common.shape[0] < max(20, int(0.4*lookback)): continue\n",
    "        excess=common[\"s\"]-common[\"b\"]; vol=common[\"s\"].std(ddof=0)\n",
    "        scores[t]=0.0 if vol<=1e-8 else float((excess.mean()/vol)*math.sqrt(252.0))\n",
    "    return scores\n",
    "\n",
    "def markowitz_long_only(mu: np.ndarray, Sigma: np.ndarray) -> np.ndarray:\n",
    "    n=len(mu); eps=1e-6; Sigma=Sigma+eps*np.eye(n)\n",
    "    def solve_lambda(lmbd, active=None):\n",
    "        if active is None:\n",
    "            A=np.block([[2*lmbd*Sigma, np.ones((n,1))],[np.ones((1,n)), np.zeros((1,1))]]); b=np.concatenate([mu,[1.0]])\n",
    "            try: sol=np.linalg.solve(A,b); w=sol[:n]\n",
    "            except np.linalg.LinAlgError: w=np.full(n,1.0/n)\n",
    "            return w\n",
    "        idx=np.where(active)[0]\n",
    "        if len(idx)==0: return np.full(n,1.0/n)\n",
    "        S=Sigma[np.ix_(idx,idx)]; o=np.ones(len(idx)); m=mu[idx]\n",
    "        A=np.block([[2*lmbd*S, o[:,None]],[o[None,:], np.zeros((1,1))]]); b=np.concatenate([m,[1.0]])\n",
    "        try: sol=np.linalg.solve(A,b); wsub=sol[:len(idx)]\n",
    "        except np.linalg.LinAlgError: wsub=np.full(len(idx),1.0/len(idx))\n",
    "        w=np.zeros(n); w[idx]=wsub; return w\n",
    "    best_w=np.full(n,1.0/n); best_sr=-1e9\n",
    "    for lmbd in np.logspace(-3,3,31):\n",
    "        active=np.ones(n,dtype=bool); w=None\n",
    "        for _ in range(n):\n",
    "            w=solve_lambda(lmbd,active); neg=w<0\n",
    "            if not neg.any(): break\n",
    "            worst=np.argmin(w); active[worst]=False\n",
    "        if w is None: continue\n",
    "        w=np.clip(w,0,None); \n",
    "        if w.sum()<=0: continue\n",
    "        w=w/w.sum(); mu_p=float(mu@w); vol_p=float(np.sqrt(w@Sigma@w))\n",
    "        if vol_p<=1e-8: continue\n",
    "        sr=mu_p/vol_p\n",
    "        if sr>best_sr: best_sr, best_w = sr, w.copy()\n",
    "    return best_w\n",
    "\n",
    "def calc_fees(turnover_buy: float, turnover_sell: float, apply=True) -> float:\n",
    "    if not apply: return 0.0\n",
    "    BROKER_PCT=0.001; BROKER_MIN=5.0; BROKER_CAP=20.0\n",
    "    STT_PCT=0.001; STAMP_BUY_PCT=0.00015; EXCH_PCT=0.0000297; SEBI_PCT=0.000001; IPFT_PCT=0.000001; GST_PCT=0.18\n",
    "    DP_SELL=20.0 if turnover_sell>=100 else 0.0\n",
    "    def _br(turn): \n",
    "        if turn<=0: return 0.0\n",
    "        return max(BROKER_MIN, min(turn*BROKER_PCT, BROKER_CAP))\n",
    "    brb=_br(turnover_buy); brs=_br(turnover_sell)\n",
    "    stt=STT_PCT*(turnover_buy+turnover_sell); stamp=STAMP_BUY_PCT*turnover_buy\n",
    "    exch=EXCH_PCT*(turnover_buy+turnover_sell); sebi=SEBI_PCT*(turnover_buy+turnover_sell); ipft=IPFT_PCT*(turnover_buy+turnover_sell)\n",
    "    gst=GST_PCT*(brb+brs+DP_SELL+exch+sebi+ipft)\n",
    "    return float((brb+brs)+stt+stamp+exch+sebi+ipft+DP_SELL+gst)\n",
    "\n",
    "def next_trading_date(current_dt: pd.Timestamp, reference_df: pd.DataFrame) -> Optional[pd.Timestamp]:\n",
    "    idx=list(reference_df.index)\n",
    "    for i,d in enumerate(idx):\n",
    "        if d==current_dt and i+1 < len(idx): return idx[i+1]\n",
    "        if d>current_dt: return d\n",
    "    return None\n",
    "\n",
    "def build_signals_for_date(dt0: pd.Timestamp, data_map: Dict[str,pd.DataFrame], cfg: Config) -> pd.DataFrame:\n",
    "    out=[]\n",
    "    for t, df in data_map.items():\n",
    "        if df is None or df.empty or dt0 not in df.index: continue\n",
    "        d=compute_indicators(df, cfg); \n",
    "        if d.empty or dt0 not in d.index: continue\n",
    "        row=d.loc[dt0]\n",
    "        # ST flip up today?\n",
    "        st_flip_up = (d[\"st_dir\"].shift(1).loc[dt0]==-1) and (row[\"st_dir\"]==1)\n",
    "        if not st_flip_up: continue\n",
    "        bits=[]; oks=[]\n",
    "        if cfg.use_rsi_filter:\n",
    "            rsi_ok=(row[\"rsi\"]<cfg.rsi_ob_level) and (row[\"rsi\"]>=d[\"rsi_prev\"].loc[dt0] if cfg.rsi_require_rising else True)\n",
    "            oks.append(rsi_ok); \n",
    "            if rsi_ok: bits.append(f\"RSI<{cfg.rsi_ob_level:g}\"+(\" & rising\" if cfg.rsi_require_rising else \"\"))\n",
    "        if cfg.use_ema_confirm:\n",
    "            ema_ok=row[\"ema_f\"]>row[\"ema_s\"]; oks.append(ema_ok); \n",
    "            if ema_ok: bits.append(\"EMA5>EMA20\")\n",
    "        if cfg.use_ema921_confirm:\n",
    "            e921=row[\"ema_f2\"]>row[\"ema_s2\"]; oks.append(e921); \n",
    "            if e921: bits.append(\"EMA9>EMA21\")\n",
    "        if cfg.use_bb_reinforce:\n",
    "            mid_rise=d[\"bb_mid\"].loc[dt0] >= d[\"bb_mid\"].shift(1).loc[dt0] if cfg.bb_require_rising else True\n",
    "            bb_ok=(row[\"Close\"]>=row[\"bb_up\"]) and mid_rise; oks.append(bb_ok); \n",
    "            if bb_ok: bits.append(\"Close≥UpperBB & mid rising\")\n",
    "        if cfg.use_obv_confirm:\n",
    "            obv_ok=row[\"obv\"]>=d[\"obv_prev\"].loc[dt0]; oks.append(obv_ok); \n",
    "            if obv_ok: bits.append(\"OBV rising\")\n",
    "        if cfg.use_adx_confirm:\n",
    "            adx_ok=(row[\"adx\"]>=cfg.adx_min) and (row[\"di_plus\"]>=row[\"di_minus\"]); oks.append(adx_ok); \n",
    "            if adx_ok: bits.append(f\"ADX≥{cfg.adx_min:g} & +DI≥−DI\")\n",
    "        confirmed = (sum(1 for v in oks if v) >= int(cfg.min_confirmations)) if (cfg.min_confirmations and cfg.min_confirmations>0) else (all(oks) if oks else True)\n",
    "        if not confirmed: continue\n",
    "        # 52w proximity\n",
    "        hist=df[\"Close\"].loc[:dt0]; window=hist.iloc[-cfg.filter_52w_window:] if len(hist)>=cfg.filter_52w_window else hist\n",
    "        high_52w=float(window.max())\n",
    "        if not (high_52w>0 and row[\"Close\"] >= cfg.within_pct_of_52w_high * high_52w): continue\n",
    "        out.append({\"ticker\":t,\"signal_date\":dt0,\"close\":float(row[\"Close\"]),\"reason\":\"ST flip ↑; \"+\"; \".join(bits)+f\"; min_conf={cfg.min_confirmations}\"})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "def run_once(cfg: Config):\n",
    "    ensure_dirs(cfg.cache_dir, cfg.out_dir, cfg.state_dir)\n",
    "    state_path=os.path.join(cfg.state_dir,\"portfolio_state.json\")\n",
    "    state={\"cash\":cfg.initial_capital,\"positions\":{},\"pending_orders\":[],\"ledger\":[]} if not os.path.exists(state_path) else json.load(open(state_path,\"r\"))\n",
    "    start=cfg.start_date; end=resolve_end_date(cfg.end_date)\n",
    "    symbols=load_universe(cfg.universe_path)\n",
    "    bench_tkr, bench_df = pick_benchmark(cfg.benchmark_try, start, end, cfg.cache_dir)\n",
    "    if bench_df is None or bench_df.empty:\n",
    "        log.error(\"No benchmark data; abort.\"); return\n",
    "    data_map=fetch_prices(symbols, start, end, cfg.cache_dir)\n",
    "    last_dt=bench_df.index[-1]; prev_dt=bench_df.index[-2] if len(bench_df.index)>=2 else bench_df.index[-1]\n",
    "    next_dt=next_trading_date(last_dt, bench_df)\n",
    "    log.info(\"Calendar: prev=%s last=%s next=%s\", str(prev_dt.date()), str(last_dt.date()), str(next_dt.date() if next_dt else None))\n",
    "    # Execute pending orders for last_dt\n",
    "    for od in state[\"pending_orders\"]:\n",
    "        if od.get(\"exec_date\") is None: od[\"exec_date\"] = str(last_dt.date())\n",
    "    new_pending=[]\n",
    "    for od in state[\"pending_orders\"]:\n",
    "        if pd.to_datetime(od[\"exec_date\"]).date() != last_dt.date():\n",
    "            new_pending.append(od); continue\n",
    "        t=od[\"ticker\"]; df=data_map.get(t)\n",
    "        if df is None or df.empty or last_dt not in df.index: new_pending.append(od); continue\n",
    "        px=float(df.loc[last_dt,\"Open\"]); side=od[\"side\"]\n",
    "        if side==\"BUY\":\n",
    "            shares=int(od[\"shares\"]); turn=shares*px; fee=calc_fees(turn,0.0,cfg.apply_fees)\n",
    "            if turn+fee>state[\"cash\"]+1e-6: new_pending.append(od); continue\n",
    "            state[\"cash\"]-= (turn+fee)\n",
    "            state[\"positions\"][t]={\"entry_date\":str(last_dt.date()),\"entry_px\":px,\"shares\":shares,\"buy_fee\":fee,\"entry_reason\":od.get(\"entry_reason\",\"\"),\"entry_signal_reason\":od.get(\"entry_signal_reason\",\"\")}\n",
    "            state[\"ledger\"].append({\"date\":str(last_dt.date()),\"ticker\":t,\"side\":\"BUY\",\"price\":px,\"shares\":shares,\"turnover\":turn,\"fees_inr\":fee,\"reason\":od.get(\"entry_reason\",\"\"),\"entry_reason\":od.get(\"entry_reason\",\"\"),\"entry_signal_reason\":od.get(\"entry_signal_reason\",\"\"),\"exit_reason\":\"\",\"days_held\":0,\"pnl_inr\":0.0})\n",
    "            log.info(\"FILLED BUY  %-10s dt=%s px=%.2f sh=%d fee=%.2f cash→%.2f\", t, last_dt.date(), px, shares, fee, state[\"cash\"])\n",
    "        elif side==\"SELL\":\n",
    "            pos=state[\"positions\"].get(t)\n",
    "            if pos is None: continue\n",
    "            shares=int(pos[\"shares\"]); turn=shares*px; fee=calc_fees(0.0,turn,cfg.apply_fees)\n",
    "            pnl=(px-pos[\"entry_px\"])*shares; realized=pnl-fee-pos.get(\"buy_fee\",0.0)\n",
    "            state[\"cash\"]+=(turn-fee); days=(last_dt.date()-pd.to_datetime(pos[\"entry_date\"]).date()).days\n",
    "            state[\"ledger\"].append({\"date\":str(last_dt.date()),\"ticker\":t,\"side\":\"SELL\",\"price\":px,\"shares\":shares,\"turnover\":turn,\"fees_inr\":fee,\"reason\":od.get(\"exit_reason\",\"\"),\"entry_reason\":pos.get(\"entry_reason\",\"\"),\"entry_signal_reason\":pos.get(\"entry_signal_reason\",\"\"),\"exit_reason\":od.get(\"exit_reason\",\"\"),\"days_held\":int(days),\"pnl_inr\":float(realized)})\n",
    "            del state[\"positions\"][t]\n",
    "            log.info(\"FILLED SELL %-10s dt=%s px=%.2f sh=%d pnl=%.2f fee=%.2f cash→%.2f\", t, last_dt.date(), px, shares, realized, fee, state[\"cash\"])\n",
    "    state[\"pending_orders\"]=new_pending\n",
    "    # Detect exits on last_dt -> plan sell next_dt\n",
    "    def detect_exits_for_date(dt0):\n",
    "        planned=[]\n",
    "        for t,pos in list(state[\"positions\"].items()):\n",
    "            df=data_map.get(t); \n",
    "            if df is None or df.empty or dt0 not in df.index: continue\n",
    "            d=compute_indicators(df, cfg); \n",
    "            if d.empty or dt0 not in d.index: continue\n",
    "            row=d.loc[dt0]\n",
    "            st_down = (d[\"st_dir\"].shift(1).loc[dt0]==1) and (row[\"st_dir\"]==-1)\n",
    "            macd_bear=(row[\"macd_line\"]<row[\"macd_signal\"]) if cfg.use_macd_confirm else False\n",
    "            ema_bear=(row[\"ema_f\"]<row[\"ema_s\"]) if cfg.use_ema_confirm else False\n",
    "            ema921_bear=(row[\"ema_f2\"]<row[\"ema_s2\"]) if cfg.use_ema921_confirm else False\n",
    "            di_bear=(row[\"di_minus\"]>row[\"di_plus\"]) if cfg.use_adx_confirm else False\n",
    "            rsi_ob=(row[\"rsi\"]>=cfg.rsi_ob_level) if cfg.use_rsi_filter else False\n",
    "            reason=None\n",
    "            if st_down: reason=\"st_bear_flip\"\n",
    "            elif macd_bear: reason=\"macd_bear\"\n",
    "            elif ema_bear: reason=\"ema5_20_bear\"\n",
    "            elif ema921_bear: reason=\"ema9_21_bear\"\n",
    "            elif di_bear: reason=\"di_bear\"\n",
    "            elif rsi_ob: reason=\"rsi_overbought\"\n",
    "            if reason and next_dt is not None:\n",
    "                planned.append({\"ticker\":t,\"side\":\"SELL\",\"exec_date\":str(next_dt.date()),\"exit_reason\":reason})\n",
    "        return planned\n",
    "    sells = detect_exits_for_date(last_dt)\n",
    "    state[\"pending_orders\"].extend(sells)\n",
    "    if sells: log.info(\"Planned SELL next: %s\", \", \".join(f\"{o['ticker']}({o['exit_reason']})\" for o in sells))\n",
    "    # Build entries on last_dt -> plan buys next_dt\n",
    "    sig_df = build_signals_for_date(last_dt, data_map, cfg)\n",
    "    if not sig_df.empty:\n",
    "        sig_df = sig_df[~sig_df[\"ticker\"].isin(state[\"positions\"].keys())]\n",
    "    # rank by VOLAᵣ\n",
    "    if not sig_df.empty:\n",
    "        volar=compute_volar_scores(last_dt, sig_df[\"ticker\"].tolist(), data_map, bench_df, cfg.volar_lookback)\n",
    "        sig_df[\"volar\"]=sig_df[\"ticker\"].map(volar); sig_df=sig_df.sort_values(\"volar\", ascending=False).reset_index(drop=True)\n",
    "    # select\n",
    "    slots=cfg.max_concurrent_positions - len(state[\"positions\"])\n",
    "    selected=pd.DataFrame(columns=sig_df.columns)\n",
    "    if slots>0 and not sig_df.empty:\n",
    "        selected=sig_df.head(min(cfg.top_k_daily, slots)).copy()\n",
    "    # weights\n",
    "    weights=np.array([])\n",
    "    if not selected.empty:\n",
    "        names=selected[\"ticker\"].tolist(); rets=[]\n",
    "        for t in names:\n",
    "            df=data_map.get(t); ser=df[\"Close\"].loc[:last_dt].pct_change().dropna().iloc[-cfg.volar_lookback:]; rets.append(ser)\n",
    "        R=pd.concat(rets, axis=1); R.columns=names; R=R.dropna()\n",
    "        if R.empty or R.shape[0] < max(20, int(0.4*cfg.volar_lookback)) or R.shape[1]==0:\n",
    "            weights=np.full(len(names), 1.0/len(names))\n",
    "        else:\n",
    "            mu=R.mean().values; Sigma=R.cov().values; weights=markowitz_long_only(mu,Sigma)\n",
    "        weights=weights/weights.sum()\n",
    "    planned_buys=[]\n",
    "    if not selected.empty and weights.size>0 and next_dt is not None:\n",
    "        deploy_cash=max(0.0,float(state[\"cash\"])) * float(cfg.deploy_cash_frac)\n",
    "        alloc=weights*deploy_cash\n",
    "        for w_amt, (_, rr) in zip(alloc, selected.iterrows()):\n",
    "            t=rr[\"ticker\"]; df_t=data_map.get(t)\n",
    "            last_px=float(df_t.loc[last_dt,\"Close\"]) if last_dt in df_t.index else float(df_t[\"Close\"].iloc[-1])\n",
    "            shares=int(math.floor(w_amt/last_px)); \n",
    "            if shares<=0: continue\n",
    "            planned_buys.append({\"ticker\":t,\"side\":\"BUY\",\"exec_date\":str(next_dt.date()),\"shares\":int(shares),\n",
    "                                 \"entry_reason\":\"SuperTrend entry\",\"entry_signal_reason\":rr[\"reason\"]})\n",
    "        state[\"pending_orders\"].extend(planned_buys)\n",
    "    # write outputs\n",
    "    tag=str(last_dt.date()); ensure_dirs(cfg.out_dir)\n",
    "    sig_path=os.path.join(cfg.out_dir, f\"signals_{tag}.csv\"); sel_path=os.path.join(cfg.out_dir, f\"selected_{tag}.csv\")\n",
    "    if not sig_df.empty: sig_df.to_csv(sig_path, index=False)\n",
    "    if not selected.empty:\n",
    "        sel = selected.copy()\n",
    "        if weights.size: sel[\"weight\"]=weights; sel[\"planned_alloc_inr\"]=weights*max(0.0,float(state[\"cash\"]))*cfg.deploy_cash_frac\n",
    "        sel.to_csv(sel_path, index=False)\n",
    "    pos_path=os.path.join(cfg.out_dir, f\"positions_{tag}.csv\")\n",
    "    if state[\"positions\"]:\n",
    "        pd.DataFrame.from_dict(state[\"positions\"], orient=\"index\").reset_index(names=\"ticker\").to_csv(pos_path, index=False)\n",
    "    pend_path=os.path.join(cfg.out_dir, f\"pending_{tag}.json\"); json.dump(state[\"pending_orders\"], open(pend_path,\"w\"), indent=2)\n",
    "    ledger_path=os.path.join(cfg.out_dir, \"ledger_all.csv\")\n",
    "    if state[\"ledger\"]:\n",
    "        pd.DataFrame(state[\"ledger\"]).to_csv(ledger_path, index=False)\n",
    "    json.dump(state, open(state_path,\"w\"), indent=2)\n",
    "    log.info(\"WROTE %s %s %s %s\", sig_path if not sig_df.empty else \"\", sel_path if not selected.empty else \"\", pos_path if state[\"positions\"] else \"\", ledger_path if state[\"ledger\"] else \"\")\n",
    "\n",
    "def main():\n",
    "    run_once(CFG)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".talib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
