# Summary and Highlights: Build RAG Apps with LlamaIndex

Congratulations! You have completed this lesson. At this point in the course, you know:  

- **LlamaIndex** is a flexible framework for building LLM-powered applications that focuses on context augmentation through structured document ingestion, chunking, indexing, and retrieval.  

- **LlamaIndex** offers built-in document loaders and customizable query engines, unlike **LangChain**, which emphasizes chaining steps in workflows. 

- To design a conversational RAG app with **LlamaIndex**, ingest LinkedIn profile data, chunk it into nodes, embed and store vectors, and use a response synthesizer or query engine to generate personalized responses from user prompts. 

- You can apply the RAG pipeline—loading, chunking, indexing, and querying—using **LlamaIndex’s** document, node, index, and query engine classes. 