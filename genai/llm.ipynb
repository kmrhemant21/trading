{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8729866d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtextblob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import snapshot_download\n",
    "import datetime\n",
    "\n",
    "# === CONFIG ===\n",
    "SYMBOL      = \"NVDA\"\n",
    "INTERVAL    = \"5m\"\n",
    "PERIOD      = \"1d\"\n",
    "CONF_THRESH = 0.75\n",
    "REPO_ID     = \"TheBloke/Llama-7B-4bit-GGUF\"  # quantized Llama-7B example\n",
    "\n",
    "# === 1. Dynamically download & load the model ===\n",
    "# This will cache the repo to ~/.cache/huggingface/hub by default\n",
    "cache_dir = snapshot_download(repo_id=REPO_ID)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cache_dir, use_fast=False)\n",
    "model     = AutoModelForCausalLM.from_pretrained(\n",
    "    cache_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "def query_local_llm(prompt: str, max_tokens: int = 128) -> str:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.0,\n",
    "        top_p=0.9,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    # Decode only the newly generated tokens\n",
    "    return tokenizer.decode(\n",
    "        output[0][inputs.input_ids.shape[-1]:],\n",
    "        skip_special_tokens=True\n",
    "    ).strip()\n",
    "\n",
    "# === 2. Fetch headline sentiment ===\n",
    "def fetch_sentiment(symbol: str, n_headlines: int = 5):\n",
    "    url  = f\"https://finance.yahoo.com/quote/{symbol}\"\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    # Selector may change; this grabs the first few headline links\n",
    "    head_elems = soup.select(\".Mb\\\\(5px\\\\) .Fw\\\\(600\\\\) a\")[:n_headlines]\n",
    "    headlines  = [h.get_text() for h in head_elems]\n",
    "    polarities = [TextBlob(h).sentiment.polarity for h in headlines] or [0]\n",
    "    return sum(polarities) / len(polarities), headlines\n",
    "\n",
    "# === 3. Main trading logic ===\n",
    "def main():\n",
    "    # --- Market data & EMAs ---\n",
    "    data   = yf.Ticker(SYMBOL).history(period=PERIOD, interval=INTERVAL)\n",
    "    latest = data.iloc[-1]\n",
    "    ema20  = data[\"Close\"].ewm(span=20).mean().iloc[-1]\n",
    "    ema50  = data[\"Close\"].ewm(span=50).mean().iloc[-1]\n",
    "\n",
    "    # --- Sentiment ---\n",
    "    avg_sent, headlines = fetch_sentiment(SYMBOL)\n",
    "\n",
    "    # --- Build prompt ---\n",
    "    snapshot = {\n",
    "        \"time\":      str(datetime.datetime.now()),\n",
    "        \"price\":     {\n",
    "            \"open\":  round(latest.Open,  2),\n",
    "            \"high\":  round(latest.High,  2),\n",
    "            \"low\":   round(latest.Low,   2),\n",
    "            \"close\": round(latest.Close, 2)\n",
    "        },\n",
    "        \"EMA20\":     round(ema20, 2),\n",
    "        \"EMA50\":     round(ema50, 2),\n",
    "        \"sentiment\": round(avg_sent, 2),\n",
    "        \"headlines\": headlines\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a disciplined intraday trading assistant. Here’s the current snapshot for {SYMBOL}:\n",
    "\n",
    "{snapshot}\n",
    "\n",
    "Based on EMA20 vs EMA50 and the average sentiment of recent headlines:\n",
    "— Should we ENTER a trade now? (Answer LONG, SHORT, or NO ENTRY)\n",
    "— Provide a confidence score between 0.0 and 1.0.\n",
    "\n",
    "Respond in strict JSON: {{ \"signal\":\"\", \"confidence\":0.00 }}\n",
    "\"\"\"\n",
    "\n",
    "    # --- Query the local LLM ---\n",
    "    llm_output = query_local_llm(prompt)\n",
    "    # Expect something like: {\"signal\":\"LONG\",\"confidence\":0.82}\n",
    "    result = eval(llm_output)\n",
    "\n",
    "    signal, conf = result[\"signal\"], result[\"confidence\"]\n",
    "    price = latest.Close\n",
    "\n",
    "    # --- Execution rule ---\n",
    "    if signal == \"LONG\" and conf > CONF_THRESH and ema20 > ema50:\n",
    "        print(f\"➡️ ENTER LONG {SYMBOL} @ {price} (conf={conf:.2f})\")\n",
    "    elif signal == \"SHORT\" and conf > CONF_THRESH and ema20 < ema50:\n",
    "        print(f\"➡️ ENTER SHORT {SYMBOL} @ {price} (conf={conf:.2f})\")\n",
    "    else:\n",
    "        print(\"➡️ NO ENTRY\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
